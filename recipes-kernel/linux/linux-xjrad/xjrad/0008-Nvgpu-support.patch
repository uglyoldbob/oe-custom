From 4325ffb641a7d3706d9b71165082ac2d77e1c23e Mon Sep 17 00:00:00 2001
From: Thomas Epperson <thomas.epperson@snapon.com>
Date: Mon, 16 Sep 2024 16:26:03 -0500
Subject: [PATCH] Nvgpu support
Upstream-Status: Pending

---
 arch/arm64/include/asm/assembler.h            |   29 +
 arch/arm64/include/asm/cacheflush.h           |   13 +
 arch/arm64/include/asm/dma-iommu.h            |   39 +
 arch/arm64/mm/cache.S                         |  279 +++
 arch/arm64/mm/dma-mapping.c                   |  381 ++-
 arch/arm64/mm/flush.c                         |    5 +
 drivers/iommu/arm/arm-smmu/arm-smmu.c         |    2 +
 drivers/iommu/dma-iommu.c                     |   52 +-
 drivers/platform/tegra/Makefile               |    7 +
 drivers/platform/tegra/dmce_perfmon.h         |  157 ++
 drivers/platform/tegra/mc/Makefile            |   43 +
 drivers/platform/tegra/mc/emc_bwmgr-t18x.c    |  280 +++
 drivers/platform/tegra/mc/emc_bwmgr-t19x.c    |  882 +++++++
 drivers/platform/tegra/mc/emc_bwmgr-t21x.c    |  190 ++
 drivers/platform/tegra/mc/emc_bwmgr.c         | 1203 ++++++++++
 drivers/platform/tegra/mc/fixed_point.c       |  600 +++++
 drivers/platform/tegra/mc/fixed_point.h       |  118 +
 drivers/platform/tegra/mc/isomgr-pre_t19x.c   |  466 ++++
 drivers/platform/tegra/mc/isomgr-t19x.c       |  249 ++
 drivers/platform/tegra/mc/isomgr.c            | 1125 +++++++++
 drivers/platform/tegra/mc/la_priv.h           |  645 +++++
 drivers/platform/tegra/mc/latency_allowance.c |  813 +++++++
 drivers/platform/tegra/mc/mc-regs-t19x.h      | 1113 +++++++++
 drivers/platform/tegra/mc/mc-t19x.c           |   22 +
 drivers/platform/tegra/mc/mc.c                |  514 ++++
 drivers/platform/tegra/mc/mc_addr_translate.c |  308 +++
 drivers/platform/tegra/mc/mcerr-t18x.c        |  455 ++++
 drivers/platform/tegra/mc/mcerr-t19x.c        |  643 +++++
 drivers/platform/tegra/mc/mcerr-t21.c         |  494 ++++
 drivers/platform/tegra/mc/mcerr.c             |  282 +++
 drivers/platform/tegra/mc/mcerr_ecc_t18x.c    |  757 ++++++
 drivers/platform/tegra/mc/nvrm_drf.h          |  201 ++
 .../platform/tegra/mc/pmqos_bwmgr_client.c    |   72 +
 drivers/platform/tegra/mc/tegra-mc-sid.c      |  272 +++
 drivers/platform/tegra/mc/tegra186-mc-sid.c   |  539 +++++
 drivers/platform/tegra/mc/tegra18_emc.c       |   38 +
 drivers/platform/tegra/mc/tegra18x_la.c       |  708 ++++++
 drivers/platform/tegra/mc/tegra194-mc-sid.c   |  804 +++++++
 drivers/platform/tegra/mc/tegra19x_la_ptsa.c  |  976 ++++++++
 drivers/platform/tegra/mc/tegra19x_la_ptsa.h  |  594 +++++
 .../platform/tegra/mc/tegra19x_la_ptsa_core.c | 2072 +++++++++++++++++
 drivers/platform/tegra/mc/tegra21x_la.c       |  934 ++++++++
 .../platform/tegra/mc/tegra_emc_dt_parse.h    |   27 +
 drivers/platform/tegra/mc/tegra_fd.c          |   25 +
 drivers/platform/tegra/tegra-mce.c            |  855 +++++++
 drivers/platform/tegra/tegra18x-mce.h         |  155 ++
 drivers/platform/tegra/tegra19x-mce.c         |  438 ++++
 drivers/platform/tegra/tegra19x-mce.h         |  135 ++
 drivers/soc/tegra/common.c                    |   20 +
 drivers/soc/tegra/fuse/tegra-apbmisc.c        |    4 +-
 drivers/video/tegra/nvmap/nvmap_init.c        |    2 +
 drivers/video/tegra/nvmap/nvmap_ioctl.c       |    8 +-
 drivers/video/tegra/nvmap/nvmap_mm.c          |   13 +-
 fs/file.c                                     |   15 +-
 include/asm-generic/dma-coherent.h            |    8 +-
 include/asm-generic/dma-mapping.h             |    2 +
 include/linux/cma.h                           |    2 +
 include/linux/dma-mapping.h                   |   16 +
 include/linux/fdtable.h                       |    2 +
 include/linux/platform/tegra/bwmgr_mc.h       |   37 +
 include/linux/platform/tegra/iso_client.h     |   33 +
 .../linux/platform/tegra/latency_allowance.h  |  341 +++
 include/linux/platform/tegra/mc-regs-t18x.h   | 1113 +++++++++
 include/linux/platform/tegra/mc-regs-t21x.h   |  473 ++++
 include/linux/platform/tegra/mc.h             |  256 ++
 include/linux/platform/tegra/mcerr.h          |  176 ++
 include/linux/platform/tegra/tegra-mc-sid.h   |   72 +
 include/linux/platform/tegra/tegra_emc.h      |   96 +
 include/linux/platform/tegra/tegra_emc_err.h  |   23 +
 include/linux/platform/tegra/tegra_mc.h       |   84 +
 include/linux/syscalls.h                      |    1 +
 include/linux/t194_nvg.h                      |  438 ++++
 include/soc/tegra/common.h                    |    2 +
 include/soc/tegra/fuse.h                      |   25 +
 kernel/dma/coherent.c                         |  647 +++++
 kernel/dma/contiguous.c                       |   11 +
 mm/cma.c                                      |  236 ++
 77 files changed, 25141 insertions(+), 26 deletions(-)
 create mode 100644 drivers/platform/tegra/dmce_perfmon.h
 create mode 100644 drivers/platform/tegra/mc/Makefile
 create mode 100644 drivers/platform/tegra/mc/emc_bwmgr-t18x.c
 create mode 100644 drivers/platform/tegra/mc/emc_bwmgr-t19x.c
 create mode 100644 drivers/platform/tegra/mc/emc_bwmgr-t21x.c
 create mode 100644 drivers/platform/tegra/mc/emc_bwmgr.c
 create mode 100644 drivers/platform/tegra/mc/fixed_point.c
 create mode 100644 drivers/platform/tegra/mc/fixed_point.h
 create mode 100644 drivers/platform/tegra/mc/isomgr-pre_t19x.c
 create mode 100644 drivers/platform/tegra/mc/isomgr-t19x.c
 create mode 100644 drivers/platform/tegra/mc/isomgr.c
 create mode 100644 drivers/platform/tegra/mc/la_priv.h
 create mode 100644 drivers/platform/tegra/mc/latency_allowance.c
 create mode 100644 drivers/platform/tegra/mc/mc-regs-t19x.h
 create mode 100644 drivers/platform/tegra/mc/mc-t19x.c
 create mode 100644 drivers/platform/tegra/mc/mc.c
 create mode 100644 drivers/platform/tegra/mc/mc_addr_translate.c
 create mode 100644 drivers/platform/tegra/mc/mcerr-t18x.c
 create mode 100644 drivers/platform/tegra/mc/mcerr-t19x.c
 create mode 100644 drivers/platform/tegra/mc/mcerr-t21.c
 create mode 100644 drivers/platform/tegra/mc/mcerr.c
 create mode 100644 drivers/platform/tegra/mc/mcerr_ecc_t18x.c
 create mode 100644 drivers/platform/tegra/mc/nvrm_drf.h
 create mode 100644 drivers/platform/tegra/mc/pmqos_bwmgr_client.c
 create mode 100644 drivers/platform/tegra/mc/tegra-mc-sid.c
 create mode 100644 drivers/platform/tegra/mc/tegra186-mc-sid.c
 create mode 100644 drivers/platform/tegra/mc/tegra18_emc.c
 create mode 100644 drivers/platform/tegra/mc/tegra18x_la.c
 create mode 100644 drivers/platform/tegra/mc/tegra194-mc-sid.c
 create mode 100644 drivers/platform/tegra/mc/tegra19x_la_ptsa.c
 create mode 100644 drivers/platform/tegra/mc/tegra19x_la_ptsa.h
 create mode 100644 drivers/platform/tegra/mc/tegra19x_la_ptsa_core.c
 create mode 100644 drivers/platform/tegra/mc/tegra21x_la.c
 create mode 100644 drivers/platform/tegra/mc/tegra_emc_dt_parse.h
 create mode 100644 drivers/platform/tegra/mc/tegra_fd.c
 create mode 100644 drivers/platform/tegra/tegra-mce.c
 create mode 100644 drivers/platform/tegra/tegra18x-mce.h
 create mode 100644 drivers/platform/tegra/tegra19x-mce.c
 create mode 100644 drivers/platform/tegra/tegra19x-mce.h
 create mode 100644 include/linux/platform/tegra/bwmgr_mc.h
 create mode 100644 include/linux/platform/tegra/iso_client.h
 create mode 100644 include/linux/platform/tegra/latency_allowance.h
 create mode 100644 include/linux/platform/tegra/mc-regs-t18x.h
 create mode 100644 include/linux/platform/tegra/mc-regs-t21x.h
 create mode 100644 include/linux/platform/tegra/mc.h
 create mode 100644 include/linux/platform/tegra/mcerr.h
 create mode 100644 include/linux/platform/tegra/tegra-mc-sid.h
 create mode 100644 include/linux/platform/tegra/tegra_emc.h
 create mode 100644 include/linux/platform/tegra/tegra_emc_err.h
 create mode 100644 include/linux/platform/tegra/tegra_mc.h
 create mode 100644 include/linux/t194_nvg.h

diff --git a/arch/arm64/include/asm/assembler.h b/arch/arm64/include/asm/assembler.h
index 376a980f2bad..15a72ddfaf39 100644
--- a/arch/arm64/include/asm/assembler.h
+++ b/arch/arm64/include/asm/assembler.h
@@ -493,6 +493,35 @@ alternative_endif
 	load_ttbr1 \page_table, \tmp, \tmp2
 	.endm
 
+/*
+ * Macro to perform a data cache maintenance for the interval
+ * [kaddr, kaddr + size) without dsb
+ *
+ * 	op:		operation passed to dc instruction
+ * 	kaddr:		starting virtual address of the region
+ * 	size:		size of the region
+ * 	Corrupts:	kaddr, size, tmp1, tmp2
+ */
+	.macro dcache_by_line_op_no_dsb op, kaddr, size, tmp1, tmp2
+	dcache_line_size \tmp1, \tmp2
+	add	\size, \kaddr, \size
+	sub	\tmp2, \tmp1, #1
+	bic	\kaddr, \kaddr, \tmp2
+9998:
+	.if	(\op == cvau || \op == cvac)
+alternative_if_not ARM64_WORKAROUND_CLEAN_CACHE
+	dc	\op, \kaddr
+alternative_else
+	dc	civac, \kaddr
+alternative_endif
+	.else
+	dc	\op, \kaddr
+	.endif
+	add	\kaddr, \kaddr, \tmp1
+	cmp	\kaddr, \size
+	b.lo	9998b
+	.endm
+
 /*
  * reset_pmuserenr_el0 - reset PMUSERENR_EL0 if PMUv3 present
  */
diff --git a/arch/arm64/include/asm/cacheflush.h b/arch/arm64/include/asm/cacheflush.h
index d115451ed263..b65c0fcc0cdd 100644
--- a/arch/arm64/include/asm/cacheflush.h
+++ b/arch/arm64/include/asm/cacheflush.h
@@ -69,6 +69,10 @@
  *
  *		Clean D-cache region to the Point of Unification.
  */
+
+extern void __clean_dcache_all(void *arg);
+extern void __flush_dcache_all(void *arg);
+extern void __clean_dcache_area_poc(void *addr, size_t len);
 extern void caches_clean_inval_pou(unsigned long start, unsigned long end);
 extern void icache_inval_pou(unsigned long start, unsigned long end);
 extern void dcache_clean_inval_poc(unsigned long start, unsigned long end);
@@ -79,6 +83,15 @@ extern void dcache_clean_pou(unsigned long start, unsigned long end);
 extern long caches_clean_inval_user_pou(unsigned long start, unsigned long end);
 extern void sync_icache_aliases(unsigned long start, unsigned long end);
 
+/*
+ * Cache maintenance functions used by the DMA API. No to be used directly.
+ */
+extern void __dma_map_area(const void *, size_t, int);
+extern void __dma_map_area_no_dsb(const void *, size_t, int);
+extern void __dma_flush_area(const void *, size_t);
+extern void __dma_unmap_area(const void *, size_t, int);
+extern void __dma_unmap_area_no_dsb(const void *, size_t, int);
+
 static inline void flush_icache_range(unsigned long start, unsigned long end)
 {
 	caches_clean_inval_pou(start, end);
diff --git a/arch/arm64/include/asm/dma-iommu.h b/arch/arm64/include/asm/dma-iommu.h
index 7ec955d234b1..8d4fe9e2664f 100644
--- a/arch/arm64/include/asm/dma-iommu.h
+++ b/arch/arm64/include/asm/dma-iommu.h
@@ -45,6 +45,45 @@ struct dma_iommu_mapping {
 	struct list_head	list;
 };
 
+/*
+ * These implement the bulk of the relevant DMA mapping callbacks, but require
+ * the arch code to take care of attributes and cache maintenance
+ */
+struct page **iommu_dma_alloc(struct device *dev, size_t size, gfp_t gfp,
+		unsigned long attrs, int prot, dma_addr_t *handle,
+		void (*flush_sg)(struct device *, struct sg_table *));
+void iommu_dma_free(struct device *dev, struct page **pages, size_t size,
+		dma_addr_t *handle, unsigned long attrs);
+
+int iommu_dma_mmap(struct page **pages, size_t size, struct vm_area_struct *vma);
+
+dma_addr_t iommu_dma_alloc_iova(struct device *dev, size_t size,
+		dma_addr_t dma_limit);
+void iommu_dma_free_iova(struct device *dev, dma_addr_t iova, size_t size);
+
+dma_addr_t iommu_dma_map_page(struct device *dev, struct page *page,
+		unsigned long offset, size_t size, int prot);
+dma_addr_t iommu_dma_map_at(struct device *dev, dma_addr_t dma_handle,
+			    phys_addr_t phys, size_t size, int prot);
+int iommu_dma_map_sg(struct device *dev, struct scatterlist *sg,
+		int nents, int prot);
+
+/*
+ * Arch code with no special attribute handling may use these
+ * directly as DMA mapping callbacks for simplicity
+ */
+void iommu_dma_unmap_page(struct device *dev, dma_addr_t handle, size_t size,
+		enum dma_data_direction dir, unsigned long attrs);
+void iommu_dma_unmap_sg(struct device *dev, struct scatterlist *sg, int nents,
+		enum dma_data_direction dir, unsigned long attrs);
+int iommu_dma_supported(struct device *dev, u64 mask);
+int iommu_dma_mapping_error(struct device *dev, dma_addr_t dma_addr);
+
+struct msi_msg;
+
+/* The DMA API isn't _quite_ the whole story, though... */
+void iommu_dma_map_msi_msg(int irq, struct msi_msg *msg);
+
 struct dma_iommu_mapping *
 arm_iommu_create_mapping(struct bus_type *bus, dma_addr_t base, size_t size);
 
diff --git a/arch/arm64/mm/cache.S b/arch/arm64/mm/cache.S
index 503567c864fd..01c818c64431 100644
--- a/arch/arm64/mm/cache.S
+++ b/arch/arm64/mm/cache.S
@@ -14,6 +14,59 @@
 #include <asm/alternative.h>
 #include <asm/asm-uaccess.h>
 
+/*
+ *	v8_op_dcache_all op
+ *
+ * op=cisw, Flush the whole D-cache.
+ * op=csw, Clean the whole D-cache.
+ *
+ *	Corrupted registers: x0-x7, x9-x11
+ */
+.macro v8_op_dcache_all op			// op=csw clean, op=cisw flush
+	cbz	x3, 5f			// if loc is 0, then no need to clean
+	mov	x10, #0				// start clean at cache level 0
+1:
+	add	x2, x10, x10, lsr #1		// work out 3x current cache level
+	lsr	x1, x0, x2			// extract cache type bits from clidr
+	and	x1, x1, #7			// mask of the bits for current cache only
+	cmp	x1, #2				// see what cache we have at this level
+	b.lt	4f				// skip if no cache, or just i-cache
+	save_and_disable_irq x9			// make CSSELR and CCSIDR access atomic
+	msr	csselr_el1, x10			// select current cache level in csselr
+	isb					// isb to sych the new cssr&csidr
+	mrs	x1, ccsidr_el1			// read the new ccsidr
+	restore_irq x9
+	and	x2, x1, #7			// extract the length of the cache lines
+	add	x2, x2, #4			// add 4 (line length offset)
+	mov	x4, #0x3ff
+	and	x4, x4, x1, lsr #3		// find maximum number on the way size
+	clz	w5, w4				// find bit position of way size increment
+	mov	x7, #0x7fff
+	and	x7, x7, x1, lsr #13		// extract max number of the index size
+2:
+	mov	x9, x4				// create working copy of max way size
+3:
+	lsl	x6, x9, x5
+	orr	x11, x10, x6			// factor way and cache number into x11
+	lsl	x6, x7, x2
+	orr	x11, x11, x6			// factor index number into x11
+	dc	\op, x11			// op=csw/cisw, clean/flush by set/way
+	subs	x9, x9, #1			// decrement the way
+	b.ge	3b
+	subs	x7, x7, #1			// decrement the index
+	b.ge	2b
+4:
+	add	x10, x10, #2			// increment cache number
+	cmp	x3, x10
+	b.gt	1b
+5:
+	mov	x10, #0				// swith back to cache level 0
+	msr	csselr_el1, x10			// select current cache level in csselr
+	dsb	sy
+	isb
+	ret
+.endm
+
 /*
  *	caches_clean_inval_pou_macro(start,end) [fixup]
  *
@@ -42,6 +95,38 @@ alternative_else_nop_endif
 .Lic_skip_\@:
 .endm
 
+/*
+ *	__clean_dcache_louis()
+ *
+ *	Clean D-cache to the level of unification inner shareable
+ *
+ *	Corrupted registers: x0-x7, x9-x11
+ */
+SYM_FUNC_START(__clean_dcache_louis)
+	dsb	sy				// ensure ordering with previous memory accesses
+	mrs	x0, clidr_el1			// read clidr
+	and	x3, x0, #0xe00000		// extract louis from clidr
+	lsr	x3, x3, #20			// left align louis bit field
+	v8_op_dcache_all csw
+SYM_FUNC_END(__clean_dcache_louis)
+
+/*
+ *	__clean_dcache_all()
+ *
+ *	Clean the whole D-cache.
+ *
+ *	Corrupted registers: x0-x7, x9-x11
+ */
+SYM_FUNC_START(__clean_dcache_all)
+	.weak	__clean_dcache_all
+	dmb	sy				// ensure ordering with previous memory accesses
+	mrs	x0, clidr_el1			// read clidr
+	and	x3, x0, #0x7000000		// extract loc from clidr
+	lsr	x3, x3, #23			// left align loc bit field
+
+	v8_op_dcache_all csw
+SYM_FUNC_END(__clean_dcache_all)
+
 /*
  *	caches_clean_inval_pou(start,end)
  *
@@ -195,3 +280,197 @@ SYM_FUNC_START(__pi_dcache_clean_pop)
 	ret
 SYM_FUNC_END(__pi_dcache_clean_pop)
 SYM_FUNC_ALIAS(dcache_clean_pop, __pi_dcache_clean_pop)
+
+/*
+ *	__clean_dcache_area_poc(kaddr, size)
+ *
+ * 	Ensure that any D-cache lines for the interval [kaddr, kaddr+size)
+ * 	are cleaned to the PoC.
+ *
+ *	- kaddr   - kernel address
+ *	- size    - size in question
+ */
+SYM_FUNC_START(__clean_dcache_area_poc)
+	/* FALLTHROUGH */
+
+/*
+ *	__dma_clean_area(start, size)
+ *	- start   - virtual start address of region
+ *	- size    - size in question
+ */
+SYM_FUNC_START(__dma_clean_area)
+	dcache_by_line_op cvac, sy, x0, x1, x2, x3
+	ret
+SYM_FUNC_END(__clean_dcache_area_poc)
+SYM_FUNC_END(__dma_clean_area)
+
+/*
+ *	__dma_inv_area(start, size)
+ *	- start   - virtual start address of region
+ *	- size    - size in question
+ */
+SYM_FUNC_START(__dma_inv_area)
+	add	x1, x1, x0
+	/* FALLTHROUGH */
+
+/*
+ *	__inval_cache_range(start, end)
+ *	- start   - start address of region
+ *	- end     - end address of region
+ */
+SYM_FUNC_START(__inval_cache_range)
+	dcache_line_size x2, x3
+	sub	x3, x2, #1
+	tst	x1, x3				// end cache line aligned?
+	bic	x1, x1, x3
+	b.eq	1f
+	dc	civac, x1			// clean & invalidate D / U line
+1:	tst	x0, x3				// start cache line aligned?
+	bic	x0, x0, x3
+	b.eq	2f
+	dc	civac, x0			// clean & invalidate D / U line
+	b	3f
+2:	dc	ivac, x0			// invalidate D / U line
+3:	add	x0, x0, x2
+	cmp	x0, x1
+	b.lo	2b
+	dsb	sy
+	ret
+SYM_FUNC_END(__inval_cache_range)
+SYM_FUNC_END(__dma_inv_area)
+
+/*
+ *      __dma_inv_area_no_dsb(start, size)
+ *      - start   - virtual start address of region
+ *      - size    - size in question
+ */
+SYM_FUNC_START(__dma_inv_area_no_dsb)
+        add     x1, x1, x0
+        /* FALLTHROUGH */
+
+/*
+ *      __inval_cache_range(start, end)
+ *      - start   - start address of region
+ *      - end     - end address of region
+ */
+SYM_FUNC_START(__inval_cache_range_no_dsb)
+        dcache_line_size x2, x3
+        sub     x3, x2, #1
+        tst     x1, x3                          // end cache line aligned?
+        bic     x1, x1, x3
+        b.eq    1f
+        dc      civac, x1                       // clean & invalidate D / U line
+1:      tst     x0, x3                          // start cache line aligned?
+        bic     x0, x0, x3
+        b.eq    2f
+        dc      civac, x0                       // clean & invalidate D / U line
+        b       3f
+2:      dc      ivac, x0                        // invalidate D / U line
+3:      add     x0, x0, x2
+        cmp     x0, x1
+        b.lo    2b
+        ret
+SYM_FUNC_END(__inval_cache_range_no_dsb)
+SYM_FUNC_END(__dma_inv_area_no_dsb)
+
+/*
+ *	__dma_map_area(start, size, dir)
+ *	- start	- kernel virtual start address
+ *	- size	- size of region
+ *	- dir	- DMA direction
+ */
+SYM_FUNC_START(__dma_map_area)
+	cmp	w2, #DMA_FROM_DEVICE
+	b.eq	__dma_inv_area
+	b	__dma_clean_area
+SYM_FUNC_END(__dma_map_area)
+
+/*
+ *	__dma_unmap_area(start, size, dir)
+ *	- start	- kernel virtual start address
+ *	- size	- size of region
+ *	- dir	- DMA direction
+ */
+SYM_FUNC_START(__dma_unmap_area)
+	cmp	w2, #DMA_TO_DEVICE
+	b.ne	__dma_inv_area
+	ret
+SYM_FUNC_END(__dma_unmap_area)
+
+/*
+ *      __clean_dcache_area_poc_no_dsb(kaddr, size)
+ *
+ *      Ensure that any D-cache lines for the interval [kaddr, kaddr+size)
+ *      are cleaned to the PoC.
+ *
+ *      - kaddr   - kernel address
+ *      - size    - size in question
+ */
+SYM_FUNC_START(__clean_dcache_area_poc_no_dsb)
+        /* FALLTHROUGH */
+
+/*
+ *      __dma_clean_area_no_dsb(start, size)
+ *      - start   - virtual start address of region
+ *      - size    - size in question
+ */
+SYM_FUNC_START(__dma_clean_area_no_dsb)
+        dcache_by_line_op_no_dsb cvac, x0, x1, x2, x3
+        ret
+SYM_FUNC_END(__clean_dcache_area_poc_no_dsb)
+SYM_FUNC_END(__dma_clean_area_no_dsb)
+
+/*
+ *	__flush_dcache_all()
+ *
+ *	Flush the whole D-cache.
+ *
+ *	Corrupted registers: x0-x7, x9-x11
+ */
+SYM_FUNC_START(__flush_dcache_all)
+	.weak	__flush_dcache_all
+	dmb	sy				// ensure ordering with previous memory accesses
+	mrs	x0, clidr_el1			// read clidr
+	and	x3, x0, #0x7000000		// extract loc from clidr
+	lsr	x3, x3, #23			// left align loc bit field
+
+	v8_op_dcache_all cisw
+SYM_FUNC_END(__flush_dcache_all)
+
+/*
+ *	__dma_flush_area(start, size)
+ *
+ *	clean & invalidate D / U line
+ *
+ *	- start   - virtual start address of region
+ *	- size    - size in question
+ */
+SYM_FUNC_START(__dma_flush_area)
+	dcache_by_line_op civac, sy, x0, x1, x2, x3
+	ret
+SYM_FUNC_END(__dma_flush_area)
+
+/*
+ *	__dma_map_area_no_dsb(start, size, dir)
+ *	- start	- kernel virtual start address
+ *	- size	- size of region
+ *	- dir	- DMA direction
+ */
+SYM_FUNC_START(__dma_map_area_no_dsb)
+	cmp	w2, #DMA_FROM_DEVICE
+	b.eq	__dma_inv_area_no_dsb
+	b	__dma_clean_area_no_dsb
+SYM_FUNC_END(__dma_map_area_no_dsb)
+
+/*
+ *	__dma_unmap_area_no_dsb(start, size, dir)
+ *	- start	- kernel virtual start address
+ *	- size	- size of region
+ *	- dir	- DMA direction
+ */
+SYM_FUNC_START(__dma_unmap_area_no_dsb)
+	cmp	w2, #DMA_TO_DEVICE
+	b.ne	__dma_inv_area_no_dsb
+	ret
+SYM_FUNC_END(__dma_unmap_area_no_dsb)
+
diff --git a/arch/arm64/mm/dma-mapping.c b/arch/arm64/mm/dma-mapping.c
index efd4a7a4f26b..11eb3b98b45e 100644
--- a/arch/arm64/mm/dma-mapping.c
+++ b/arch/arm64/mm/dma-mapping.c
@@ -6,13 +6,36 @@
 
 #include <linux/gfp.h>
 #include <linux/cache.h>
+#include <linux/dma-attrs.h>
 #include <linux/dma-map-ops.h>
+#include <linux/genalloc.h>
 #include <linux/iommu.h>
 #include <xen/xen.h>
 
 #include <asm/cacheflush.h>
+#include <asm/dma-iommu.h>
 #include <asm/xen/xen-ops.h>
 
+#define UL_ATR(a) (a)
+
+extern struct page **iommu_dma_alloc(struct device *dev, size_t size, gfp_t gfp,
+		unsigned long attrs, int prot, dma_addr_t *handle,
+		void (*flush_sg)(struct device *, struct sg_table *));
+
+static void flush_sg(struct device *dev, struct sg_table *sgt)
+{
+	struct scatterlist *s;
+	int i = 0;
+	int nents = sgt->orig_nents;
+
+	for_each_sg(sgt->sgl, s, nents, i) {
+		dcache_clean_inval_poc((unsigned long)sg_virt(s), (unsigned long)sg_virt(s) + s->length);
+	}
+}
+
+__weak void dma_qualify_ioprot(enum dma_data_direction dir,
+	unsigned long *ioprot) {}
+
 void arch_sync_dma_for_device(phys_addr_t paddr, size_t size,
 			      enum dma_data_direction dir)
 {
@@ -21,6 +44,58 @@ void arch_sync_dma_for_device(phys_addr_t paddr, size_t size,
 	dcache_clean_poc(start, start + size);
 }
 
+static struct gen_pool *atomic_pool;
+static struct page **atomic_pool_pages;
+
+static size_t atomic_pool_size = SZ_1M;
+
+static int __init early_coherent_pool(char *p)
+{
+	atomic_pool_size = memparse(p, &p);
+	return 0;
+}
+early_param("coherent_pool", early_coherent_pool);
+
+static void *__alloc_from_pool(size_t size, struct page **ret_page, gfp_t flags)
+{
+	unsigned long val;
+	void *ptr = NULL;
+
+	if (!atomic_pool) {
+		WARN(1, "coherent pool not initialised!\n");
+		return NULL;
+	}
+
+	val = gen_pool_alloc(atomic_pool, size);
+	if (val) {
+		phys_addr_t phys = gen_pool_virt_to_phys(atomic_pool, val);
+
+		*ret_page = phys_to_page(phys);
+		ptr = (void *)val;
+		memset(ptr, 0, size);
+	}
+
+	return ptr;
+}
+
+static bool __in_atomic_pool(void *start, size_t size)
+{
+	if (!atomic_pool)
+		return false;
+
+	return gen_pool_has_addr(atomic_pool, (unsigned long)start, size);
+}
+
+static int __free_from_pool(void *start, size_t size)
+{
+	if (!__in_atomic_pool(start, size))
+		return 0;
+
+	gen_pool_free(atomic_pool, (unsigned long)start, size);
+
+	return 1;
+}
+
 void arch_sync_dma_for_cpu(phys_addr_t paddr, size_t size,
 			   enum dma_data_direction dir)
 {
@@ -39,6 +114,309 @@ void arch_dma_prep_coherent(struct page *page, size_t size)
 	dcache_clean_poc(start, start + size);
 }
 
+static pgprot_t __get_dma_pgprot(unsigned long attrs, pgprot_t prot,
+				 bool coherent)
+{
+	if (!coherent || dma_get_attr(DMA_ATTR_WRITE_COMBINE, attrs))
+		return pgprot_writecombine(prot);
+	return prot;
+}
+
+static int dma_get_ioprot(unsigned long attrs,
+		enum dma_data_direction dir, bool coherent)
+{
+	unsigned long ioprot;
+
+#if ENABLE_IOMMU_DMA_OPS
+	ioprot = dma_direction_to_prot(dir, coherent);
+#else
+	ioprot = IOMMU_READ | IOMMU_WRITE;
+	if (dma_get_attr(DMA_ATTR_READ_ONLY, (unsigned long)attrs))
+		ioprot &= ~IOMMU_WRITE;
+	else if (dma_get_attr(DMA_ATTR_WRITE_ONLY, (unsigned long)attrs))
+		ioprot &= ~IOMMU_READ;
+
+	if (coherent)
+		ioprot |= IOMMU_CACHE;
+#endif
+	dma_qualify_ioprot(dir, &ioprot);
+
+	return ioprot;
+}
+
+static void *__iommu_alloc_attrs(struct device *dev, size_t size,
+				 dma_addr_t *handle, gfp_t gfp,
+				 unsigned long attrs)
+{
+	bool coherent = dev_is_dma_coherent(dev);
+	int ioprot = dma_get_ioprot(attrs, DMA_BIDIRECTIONAL, coherent);
+	size_t iosize = size;
+	void *addr;
+
+	/* Following is a work-around (a.k.a. hack) to prevent pages
+	 * with __GFP_COMP being passed to split_page() which cannot
+	 * handle them.  The real problem is that this flag probably
+	 * should be 0 on ARM as it is not supported on this
+	 * platform--see CONFIG_HUGETLB_PAGE.
+	 */
+	gfp &= ~(__GFP_COMP);
+
+	if (WARN(!dev, "cannot create IOMMU mapping for unknown device\n"))
+		return NULL;
+
+	size = PAGE_ALIGN(size);
+
+	if (gfpflags_allow_blocking(gfp)) {
+		struct page **pages;
+		pgprot_t prot = __get_dma_pgprot(attrs, PAGE_KERNEL, coherent);
+
+		pages = iommu_dma_alloc(dev, iosize, gfp, UL_ATR(attrs),
+					ioprot, handle, flush_sg);
+		if (!pages)
+			return NULL;
+
+//		trace_dmadebug_alloc_attrs(dev, *handle, size, pages[0]);
+
+		if (dma_get_attr(DMA_ATTR_NO_KERNEL_MAPPING, attrs))
+			return pages;
+
+		addr = dma_common_pages_remap(pages, size, prot,
+					      __builtin_return_address(0));
+		if (!addr)
+			iommu_dma_free(dev, pages, iosize, handle, attrs);
+	} else {
+		struct page *page;
+		/*
+		 * In atomic context we can't remap anything, so we'll only
+		 * get the virtually contiguous buffer we need by way of a
+		 * physically contiguous allocation.
+		 */
+		if (coherent) {
+			page = alloc_pages(gfp, get_order(size));
+			addr = page ? page_address(page) : NULL;
+		} else {
+			addr = __alloc_from_pool(size, &page, gfp);
+		}
+		if (!addr)
+			return NULL;
+
+		*handle = iommu_dma_map_page(dev, page, 0, iosize, ioprot);
+		if (iommu_dma_mapping_error(dev, *handle)) {
+			if (coherent)
+				__free_pages(page, get_order(size));
+			else
+				__free_from_pool(addr, size);
+			addr = NULL;
+		}/* else
+			trace_dmadebug_alloc_attrs(dev, *handle, size, page);*/
+	}
+	return addr;
+}
+
+static void __iommu_free_attrs(struct device *dev, size_t size, void *cpu_addr,
+			       dma_addr_t handle, unsigned long attrs)
+{
+	size_t iosize = size;
+
+	size = PAGE_ALIGN(size);
+
+//	trace_dmadebug_free_attrs(dev, handle, size, NULL);
+
+	/*
+	 * @cpu_addr will be one of 3 things depending on how it was allocated:
+	 * - A remapped array of pages from iommu_dma_alloc(), for all
+	 *   non-atomic allocations.
+	 * - A non-cacheable alias from the atomic pool, for atomic
+	 *   allocations by non-coherent devices.
+	 * - A normal lowmem address, for atomic allocations by
+	 *   coherent devices.
+	 * Hence how dodgy the below logic looks...
+	 */
+	if (__in_atomic_pool(cpu_addr, size)) {
+		iommu_dma_unmap_page(dev, handle, iosize, 0, 0);
+		__free_from_pool(cpu_addr, size);
+	} else if (dma_get_attr(DMA_ATTR_NO_KERNEL_MAPPING, attrs)) {
+		iommu_dma_free(dev, (struct page **)cpu_addr, iosize,
+			       &handle, attrs);
+	} else if (is_vmalloc_addr(cpu_addr)){
+		struct vm_struct *area = find_vm_area(cpu_addr);
+
+		if (WARN_ON(!area || !area->pages))
+			return;
+		iommu_dma_free(dev, area->pages, iosize, &handle, attrs);
+		dma_common_free_remap(cpu_addr, size);
+	} else {
+		iommu_dma_unmap_page(dev, handle, iosize, 0, 0);
+		__free_pages(virt_to_page(cpu_addr), get_order(size));
+	}
+}
+
+extern int iommu_dma_mmap2(struct page **pages, size_t size, struct vm_area_struct *vma);
+
+static int __iommu_mmap_attrs(struct device *dev, struct vm_area_struct *vma,
+			      void *cpu_addr, dma_addr_t dma_addr, size_t size,
+			      unsigned long attrs)
+{
+	struct vm_struct *area;
+	int ret;
+
+	vma->vm_page_prot = __get_dma_pgprot(attrs, vma->vm_page_prot,
+					     is_device_dma_coherent(dev));
+
+	if (dma_mmap_from_dev_coherent(dev, vma, cpu_addr, size, &ret))
+		return ret;
+
+	area = find_vm_area(cpu_addr);
+	if (WARN_ON(!area || !area->pages))
+		return -ENXIO;
+
+	return iommu_dma_mmap2(area->pages, size, vma);
+}
+
+static int __iommu_get_sgtable(struct device *dev, struct sg_table *sgt,
+			       void *cpu_addr, dma_addr_t dma_addr,
+			       size_t size, unsigned long attrs)
+{
+	unsigned int count = PAGE_ALIGN(size) >> PAGE_SHIFT;
+	struct vm_struct *area = find_vm_area(cpu_addr);
+
+	if (WARN_ON(!area || !area->pages))
+		return -ENXIO;
+
+	return sg_alloc_table_from_pages(sgt, area->pages, count, 0, size,
+					 GFP_KERNEL);
+}
+
+static void __iommu_sync_single_for_cpu(struct device *dev,
+					dma_addr_t dev_addr, size_t size,
+					enum dma_data_direction dir)
+{
+	phys_addr_t phys;
+
+	if (is_device_dma_coherent(dev))
+		return;
+
+	phys = iommu_iova_to_phys(iommu_get_domain_for_dev(dev), dev_addr);
+	__dma_unmap_area(phys_to_virt(phys), size, dir);
+}
+
+static void __iommu_sync_single_for_device(struct device *dev,
+					   dma_addr_t dev_addr, size_t size,
+					   enum dma_data_direction dir)
+{
+	phys_addr_t phys;
+
+	if (is_device_dma_coherent(dev))
+		return;
+
+	phys = iommu_iova_to_phys(iommu_get_domain_for_dev(dev), dev_addr);
+	__dma_map_area(phys_to_virt(phys), size, dir);
+}
+
+static dma_addr_t __iommu_map_page(struct device *dev, struct page *page,
+				   unsigned long offset, size_t size,
+				   enum dma_data_direction dir,
+				   unsigned long attrs)
+{
+	bool coherent = is_device_dma_coherent(dev);
+	int prot = dma_get_ioprot(attrs, dir, coherent);
+	dma_addr_t dev_addr = iommu_dma_map_page(dev, page, offset, size, prot);
+
+	if (!iommu_dma_mapping_error(dev, dev_addr) &&
+	    (UL_ATR(attrs) & DMA_ATTR_SKIP_CPU_SYNC) == 0)
+		__iommu_sync_single_for_device(dev, dev_addr, size, dir);
+
+	//trace_dmadebug_map_page(dev, dev_addr + offset, size, page);
+	return dev_addr;
+}
+/*
+static dma_addr_t arm_iommu_map_at(struct device *dev, dma_addr_t dma_addr,
+				       phys_addr_t phys, size_t size,
+				       enum dma_data_direction dir,
+				       unsigned long attrs);
+*/
+
+#if ENABLE_IOMMU_DMA_OPS
+static dma_addr_t __iommu_map_at(struct device *dev, dma_addr_t dma_addr,
+				 phys_addr_t phys, size_t size,
+				 enum dma_data_direction dir,
+				 unsigned long attrs)
+{
+	bool coherent = is_device_dma_coherent(dev);
+	int prot = dma_get_ioprot(attrs, dir, coherent);
+
+	return iommu_dma_map_at(dev, dma_addr, phys, size, prot);
+}
+#endif
+
+
+static void __iommu_unmap_page(struct device *dev, dma_addr_t dev_addr,
+			       size_t size, enum dma_data_direction dir,
+			       unsigned long attrs)
+{
+	if ((UL_ATR(attrs) & DMA_ATTR_SKIP_CPU_SYNC) == 0)
+		__iommu_sync_single_for_cpu(dev, dev_addr, size, dir);
+
+/*	trace_dmadebug_unmap_page(dev, dev_addr, size,
+		  phys_to_page(iommu_iova_to_phys(iommu_get_domain_for_dev(dev),
+				 dev_addr)));*/
+	iommu_dma_unmap_page(dev, dev_addr, size, dir, UL_ATR(attrs));
+}
+
+static void __iommu_sync_sg_for_cpu(struct device *dev,
+				    struct scatterlist *sgl, int nelems,
+				    enum dma_data_direction dir)
+{
+	struct scatterlist *sg;
+	int i;
+
+	if (is_device_dma_coherent(dev))
+		return;
+
+	for_each_sg(sgl, sg, nelems, i)
+		__dma_unmap_area_no_dsb(sg_virt(sg), sg->length, dir);
+	dsb(sy);
+}
+
+static void __iommu_sync_sg_for_device(struct device *dev,
+				       struct scatterlist *sgl, int nelems,
+				       enum dma_data_direction dir)
+{
+	struct scatterlist *sg;
+	int i;
+
+	if (is_device_dma_coherent(dev))
+		return;
+
+	for_each_sg(sgl, sg, nelems, i)
+		__dma_map_area_no_dsb(sg_virt(sg), sg->length, dir);
+	dsb(sy);
+}
+
+static int __iommu_map_sg_attrs(struct device *dev, struct scatterlist *sgl,
+				int nelems, enum dma_data_direction dir,
+				unsigned long attrs)
+{
+	bool coherent = is_device_dma_coherent(dev);
+
+	if ((UL_ATR(attrs) & DMA_ATTR_SKIP_CPU_SYNC) == 0)
+		__iommu_sync_sg_for_device(dev, sgl, nelems, dir);
+
+	return iommu_dma_map_sg(dev, sgl, nelems,
+			dma_get_ioprot(attrs, dir, coherent));
+}
+
+static void __iommu_unmap_sg_attrs(struct device *dev,
+				   struct scatterlist *sgl, int nelems,
+				   enum dma_data_direction dir,
+				   unsigned long attrs)
+{
+	if ((UL_ATR(attrs) & DMA_ATTR_SKIP_CPU_SYNC) == 0)
+		__iommu_sync_sg_for_cpu(dev, sgl, nelems, dir);
+
+	iommu_dma_unmap_sg(dev, sgl, nelems, dir, UL_ATR(attrs));
+}
+
 static struct dma_map_ops iommu_dma_ops = {
 	.alloc = __iommu_alloc_attrs,
 	.free = __iommu_free_attrs,
@@ -53,9 +431,8 @@ static struct dma_map_ops iommu_dma_ops = {
 	.sync_sg_for_cpu = __iommu_sync_sg_for_cpu,
 	.sync_sg_for_device = __iommu_sync_sg_for_device,
 	.dma_supported = iommu_dma_supported,
-	.mapping_error = iommu_dma_mapping_error,
 
-	.map_at = arm_iommu_map_at,
+//	.map_at = arm_iommu_map_at,
 };
 
 #ifdef CONFIG_IOMMU_DMA
diff --git a/arch/arm64/mm/flush.c b/arch/arm64/mm/flush.c
index 013eead9b695..11fb5083d7a4 100644
--- a/arch/arm64/mm/flush.c
+++ b/arch/arm64/mm/flush.c
@@ -49,6 +49,11 @@ void copy_to_user_page(struct vm_area_struct *vma, struct page *page,
 	flush_ptrace_access(vma, (unsigned long)dst, (unsigned long)dst + len);
 }
 
+void __clean_dcache_page(struct page *page)
+{
+	__clean_dcache_area_poc(page_address(page), PAGE_SIZE);
+}
+
 void __sync_icache_dcache(pte_t pte)
 {
 	struct folio *folio = page_folio(pte_page(pte));
diff --git a/drivers/iommu/arm/arm-smmu/arm-smmu.c b/drivers/iommu/arm/arm-smmu/arm-smmu.c
index d6d1a2a55cc0..5379b8e4cd42 100644
--- a/drivers/iommu/arm/arm-smmu/arm-smmu.c
+++ b/drivers/iommu/arm/arm-smmu/arm-smmu.c
@@ -1529,6 +1529,8 @@ static int arm_smmu_of_xlate(struct device *dev, struct of_phandle_args *args)
 	return iommu_fwspec_add_ids(dev, &fwid, 1);
 }
 
+extern void iommu_dma_get_resv_regions(struct device *dev, struct list_head *list);
+
 static void arm_smmu_get_resv_regions(struct device *dev,
 				      struct list_head *head)
 {
diff --git a/drivers/iommu/dma-iommu.c b/drivers/iommu/dma-iommu.c
index 2da969fc8990..07bdd614c621 100644
--- a/drivers/iommu/dma-iommu.c
+++ b/drivers/iommu/dma-iommu.c
@@ -1027,7 +1027,47 @@ static void iommu_dma_sync_sg_for_device(struct device *dev,
 			arch_sync_dma_for_device(sg_phys(sg), sg->length, dir);
 }
 
-static dma_addr_t iommu_dma_map_page(struct device *dev, struct page *page,
+/**
+ * iommu_dma_mmap2 - Map a buffer into provided user VMA
+ * @pages: Array representing buffer from iommu_dma_alloc()
+ * @size: Size of buffer in bytes
+ * @vma: VMA describing requested userspace mapping
+ *
+ * Maps the pages of the buffer in @pages into @vma. The caller is responsible
+ * for verifying the correct size and protection of @vma beforehand.
+ */
+
+int iommu_dma_mmap2(struct page **pages, size_t size, struct vm_area_struct *vma)
+{
+	unsigned long uaddr = vma->vm_start;
+	unsigned int i, count = PAGE_ALIGN(size) >> PAGE_SHIFT;
+	int ret = -ENXIO;
+
+	for (i = vma->vm_pgoff; i < count && uaddr < vma->vm_end; i++) {
+		ret = vm_insert_page(vma, uaddr, pages[i]);
+		if (ret)
+			break;
+		uaddr += PAGE_SIZE;
+	}
+	return ret;
+}
+
+int iommu_dma_supported(struct device *dev, u64 mask)
+{
+	/*
+	 * 'Special' IOMMUs which don't have the same addressing capability
+	 * as the CPU will have to wait until we have some way to query that
+	 * before they'll be able to use this framework.
+	 */
+	return 1;
+}
+
+int iommu_dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
+{
+	return dma_addr == DMA_ERROR_CODE;
+}
+
+dma_addr_t iommu_dma_map_page(struct device *dev, struct page *page,
 		unsigned long offset, size_t size, enum dma_data_direction dir,
 		unsigned long attrs)
 {
@@ -1084,7 +1124,7 @@ static dma_addr_t iommu_dma_map_page(struct device *dev, struct page *page,
 	return iova;
 }
 
-static void iommu_dma_unmap_page(struct device *dev, dma_addr_t dma_handle,
+void iommu_dma_unmap_page(struct device *dev, dma_addr_t dma_handle,
 		size_t size, enum dma_data_direction dir, unsigned long attrs)
 {
 	struct iommu_domain *domain = iommu_get_dma_domain(dev);
@@ -1238,7 +1278,7 @@ static int iommu_dma_map_sg_swiotlb(struct device *dev, struct scatterlist *sg,
  * impedance-matching, to be able to hand off a suitably-aligned list,
  * but still preserve the original offsets and sizes for the caller.
  */
-static int iommu_dma_map_sg(struct device *dev, struct scatterlist *sg,
+int iommu_dma_map_sg(struct device *dev, struct scatterlist *sg,
 		int nents, enum dma_data_direction dir, unsigned long attrs)
 {
 	struct iommu_domain *domain = iommu_get_dma_domain(dev);
@@ -1358,7 +1398,7 @@ static int iommu_dma_map_sg(struct device *dev, struct scatterlist *sg,
 	return ret;
 }
 
-static void iommu_dma_unmap_sg(struct device *dev, struct scatterlist *sg,
+void iommu_dma_unmap_sg(struct device *dev, struct scatterlist *sg,
 		int nents, enum dma_data_direction dir, unsigned long attrs)
 {
 	dma_addr_t end = 0, start;
@@ -1453,7 +1493,7 @@ static void __iommu_dma_free(struct device *dev, size_t size, void *cpu_addr)
 		dma_free_contiguous(dev, page, alloc_size);
 }
 
-static void iommu_dma_free(struct device *dev, size_t size, void *cpu_addr,
+void iommu_dma_free(struct device *dev, size_t size, void *cpu_addr,
 		dma_addr_t handle, unsigned long attrs)
 {
 	__iommu_dma_unmap(dev, handle, size);
@@ -1497,7 +1537,7 @@ static void *iommu_dma_alloc_pages(struct device *dev, size_t size,
 	return NULL;
 }
 
-static void *iommu_dma_alloc(struct device *dev, size_t size,
+void *iommu_dma_alloc(struct device *dev, size_t size,
 		dma_addr_t *handle, gfp_t gfp, unsigned long attrs)
 {
 	bool coherent = dev_is_dma_coherent(dev);
diff --git a/drivers/platform/tegra/Makefile b/drivers/platform/tegra/Makefile
index 8069a0ed2b17..b79d052b5b9d 100644
--- a/drivers/platform/tegra/Makefile
+++ b/drivers/platform/tegra/Makefile
@@ -1,3 +1,10 @@
 obj-y					+= tegra_vpr.o
 obj-y 					+= smc-calls.o
 obj-y					+= tegra-hv-mode.o
+obj-y					+= tegra-mce.o
+
+ifdef CONFIG_ARCH_TEGRA_19x_SOC
+obj-y					+= tegra19x-mce.o
+endif
+
+obj-$(CONFIG_TEGRA_MC) += mc/
diff --git a/drivers/platform/tegra/dmce_perfmon.h b/drivers/platform/tegra/dmce_perfmon.h
new file mode 100644
index 000000000000..56611aad7e27
--- /dev/null
+++ b/drivers/platform/tegra/dmce_perfmon.h
@@ -0,0 +1,157 @@
+/*
+ * Copyright (c) 2015-2016, NVIDIA CORPORATION.  All rights reserved.
+ *
+ * NVIDIA CORPORATION and its licensors retain all intellectual property
+ * and proprietary rights in and to this software, related documentation
+ * and any modifications thereto.  Any use, reproduction, disclosure or
+ * distribution of this software and related documentation without an express
+ * license agreement from NVIDIA CORPORATION is strictly prohibited.
+ */
+
+#ifndef DMCE_PERFMON_H
+#define DMCE_PERFMON_H
+
+/**
+ * Commands used in Command field of an ARI perfmon request.
+ */
+enum DMCE_PERFMON_COMMAND {
+	DMCE_PERFMON_COMMAND_READ	= 0,   /* Read uncore perfmon reg */
+	DMCE_PERFMON_COMMAND_WRITE	= 1,   /* Write uncore perfmon reg */
+	DMCE_PERFMON_COMMAND_MAX
+};
+
+/**
+ * Registers used in Register field of an ARI perfmon request.
+ */
+enum DMCE_PERFMON_REGISTER {
+	NV_PMEVCNTR	= 0,
+	NV_PMEVTYPER	= 1,
+	DMCE_PERFMON_FIRST_UNIT_REGISTER	= 2,
+	NV_PMCNTENSET	= 2,
+	NV_PMCNTENCLR	= 3,
+	NV_PMOVSSET	= 4,
+	NV_PMOVSCLR	= 5,
+	NV_PMCR		= 6,
+	NV_PMINTENSET	= 7,
+	NV_PMINTENCLR	= 8,
+	DMCE_PERFMON_FIRST_GROUP_REGISTER	= 9,
+	NV_PMCRNUNITS	= 9,
+	NV_PMCEID0	= 10,
+	NV_PMCEID1	= 11,
+	DMCE_PERFMON_FIRST_GLOBAL_REGISTER	= 12,
+	NV_AFR0		= 12,
+	NV_SECURE	= 13,
+	DMCE_PERFMON_REGISTER_MAX
+};
+
+/**
+ * Status codes returned in Status field of an ARI perfmon response.
+ */
+enum DMCE_PERFMON_STATUS {
+	DMCE_PERFMON_STATUS_SUCCESS		= 0,
+	DMCE_PERFMON_STATUS_INVALID_GROUP	= 1,
+	DMCE_PERFMON_STATUS_INVALID_UNIT	= 2,
+	DMCE_PERFMON_STATUS_INVALID_COUNTER	= 3,
+	DMCE_PERFMON_STATUS_INVALID_REGISTER	= 4,
+	DMCE_PERFMON_STATUS_INVALID_COMMAND	= 5,
+	DMCE_PERFMON_STATUS_READ_ONLY		= 6,
+	DMCE_PERFMON_STATUS_NOT_SECURE		= 7,
+	DMCE_PERFMON_STATUS_MAX
+};
+
+/**
+ * Format of the value in ARI_REQUEST_DATA_HI
+ * when making an uncore perfmon call.
+ */
+union dmce_perfmon_ari_request_hi_t {
+	uint32_t flat;
+	struct {
+		uint8_t command:8;	/* Operation: 0 - read, 1 - write */
+		uint8_t group:4;	/* Group selector */
+		uint8_t unit:4;		/* Unit selector */
+		uint8_t reg:8;		/* Register to read or write */
+		uint8_t counter:8;	/* CNTR num for EVCNTR and EVTYPER */
+	} bits;
+};
+
+/**
+ * Format of the value returned in ARI_RESPONSE_DATA_HI
+ * returned by an uncore perfmon call.
+ */
+union dmce_perfmon_ari_response_hi_t {
+	uint32_t flat;
+	struct {
+		uint8_t status:8;	/* Resulting command statue */
+		uint32_t unused:24;
+	} bits;
+};
+
+/**
+ * Layout of the uncore perfmon NV_PMEVTYPER register.
+ */
+union dmce_perfmon_pmevtyper_t {
+	uint32_t flat;
+	struct {
+		uint32_t evt_count:10;	/* Event number to count */
+		uint32_t reserved_15_10:6;
+		uint32_t int_core:4;	/* Core to handle interrupt */
+		uint32_t reserved_31_20:12;
+	} bits;
+};
+
+/**
+ * Layout of the NV_PMCR register.
+ */
+union dmce_perfmon_pmcr_t {
+	uint32_t flat;
+	struct {
+		uint32_t e:1;	/* Enable counters */
+		uint32_t p:1;	/* Reset counters (WO bit) */
+		uint32_t reserved_10_2:9;
+		uint32_t n:5;	/* Number of counters (RO bit)*/
+		uint32_t idcode:8;	/* Identification code (0) */
+		uint32_t imp:8;	/* Implementor code ('N') */
+	} bits;
+};
+
+/**
+ * Data for each uncore perfmon counter
+ */
+struct dmce_perfmon_cnt_info {
+	uint8_t counter;	/* Event id */
+	uint8_t group;		/* Group selector */
+	uint8_t unit;		/* Unit selector */
+	uint8_t index;		/* Virtual Index */
+	uint8_t idx;		/* Physical Index */
+	uint8_t valid;		/* Valid info */
+};
+
+typedef enum {
+	ACTLR_EL3,
+	CPSR,
+	NV_PMCCFILTR_EL0,
+	NV_PMCCNTR_EL0,
+	NV_PMCEID0_EL0,
+	NV_PMCEID1_EL0,
+	NV_PMCNTENCLR_EL0,
+	NV_PMCNTENSET_EL0,
+	NV_PMCR_EL0,
+	NV_PMCRN_EL0,
+	NV_PMINTENCLR_EL1,
+	NV_PMINTENSET_EL1,
+	NV_PMOVSCLR_EL0,
+	NV_PMOVSSET_EL0,
+	NV_PMSELR_EL0,
+	NV_PMSWINC_EL0,
+	NV_PMUSERENR_EL0,
+	NV_PMEVCNTR0_EL0,
+	NV_PMEVCNTR1_EL0,
+	NV_PMEVTYPER0_EL0,
+	NV_PMEVTYPER1_EL0,
+	NV_PMEVCNTRn_EL0,
+	NV_PMEVTYPERn_EL0,
+
+
+} carmel_pmc_reg_t;
+
+#endif
diff --git a/drivers/platform/tegra/mc/Makefile b/drivers/platform/tegra/mc/Makefile
new file mode 100644
index 000000000000..1d59a5b16665
--- /dev/null
+++ b/drivers/platform/tegra/mc/Makefile
@@ -0,0 +1,43 @@
+#
+# Memory controller code.
+#
+
+GCOV_PROFILE := y
+
+ccflags-y += -I$(srctree)/arch/arm/mach-tegra/include \
+             -I$(srctree)/arch/arm/mach-tegra \
+             -I$(srctree)/drivers/platform/tegra/include
+
+obj-y                                   += mc.o
+
+obj-y                                   += mcerr.o
+obj-y                                   += mcerr-t21.o
+
+obj-y                                   += latency_allowance.o
+obj-y                                   += tegra21x_la.o
+
+obj-$(CONFIG_ARCH_TEGRA_19x_SOC)        += tegra19x_la_ptsa_core.o tegra19x_la_ptsa.o
+obj-y                                   += fixed_point.o
+obj-$(CONFIG_TEGRA_ISOMGR)              += isomgr.o isomgr-pre_t19x.o isomgr-t19x.o
+obj-$(CONFIG_TEGRA_BWMGR)               += emc_bwmgr.o pmqos_bwmgr_client.o
+obj-$(CONFIG_TEGRA_BWMGR)               += emc_bwmgr-t21x.o emc_bwmgr-t18x.o emc_bwmgr-t19x.o
+
+obj-y                                   += tegra-mc-sid.o
+obj-$(CONFIG_ARCH_TEGRA_18x_SOC)        += mcerr_ecc_t18x.o
+obj-$(CONFIG_ARCH_TEGRA_18x_SOC)        += mc_addr_translate.o
+obj-$(CONFIG_ARCH_TEGRA_18x_SOC)        += mcerr-t18x.o
+obj-$(CONFIG_ARCH_TEGRA_18x_SOC)        += tegra18_emc.o
+obj-$(CONFIG_ARCH_TEGRA_18x_SOC)        += tegra18x_la.o
+obj-$(CONFIG_ARCH_TEGRA_18x_SOC)        += tegra186-mc-sid.o
+
+obj-y					+= tegra_fd.o
+
+ifdef CONFIG_ARCH_TEGRA_19x_SOC
+
+ccflags-y += -Werror
+
+obj-y += tegra194-mc-sid.o
+obj-y += mc-t19x.o
+obj-y += mcerr-t19x.o
+
+endif
diff --git a/drivers/platform/tegra/mc/emc_bwmgr-t18x.c b/drivers/platform/tegra/mc/emc_bwmgr-t18x.c
new file mode 100644
index 000000000000..b15c576a38be
--- /dev/null
+++ b/drivers/platform/tegra/mc/emc_bwmgr-t18x.c
@@ -0,0 +1,280 @@
+/**
+ * Copyright (c) 2015-2018, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ */
+
+#include <linux/platform/tegra/bwmgr_mc.h>
+#include <linux/platform/tegra/emc_bwmgr.h>
+#include <linux/io.h>
+#include <soc/tegra/bpmp_abi.h>
+#include <soc/tegra/tegra_bpmp.h>
+
+static u32 bwmgr_t186_iso_bw_table[] = { /* MHz */
+	  5,  10,  20,  30,  40,  60,  80, 100, 120, 140,
+	160, 180, 200, 250, 300, 350, 360, 370, 380, 400,
+	450, 500, 550, 600, 650, 700, 750
+};
+
+/* value of 1 indicates the range over max ISO Bw allowed for the DRAM type */
+static u32 bwmgr_t186_lpddr4_4ch_ecc_iso_eff[] = {
+	 15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
+	 15,  15,  15,  15,   1,   1,   1,   1,   1,   1,
+	  1,   1,   1,   1,   1,   1,   1
+};
+
+static u32 bwmgr_t186_lpddr4_2ch_ecc_iso_eff[] = {
+	 28,  28,  28,  28,  28,  28,  28,  28,  28,  28,
+	 28,  28,  28,  28,  28,  28,  28,  28,  28,  28,
+	 28,   1,   1,   1,   1,   1,   1
+};
+
+static u32 bwmgr_t186_lpddr4_4ch_iso_eff[] = {
+	 15,  19,  27,  35,  40,  42,  43,  44,  45,  46,
+	 48,  49,  50,  50,  50,  50,  50,  50,  50,  50,
+	 50,  50,  50,  50,  48,  46,  45
+};
+
+static u32 bwmgr_t186_lpddr4_2ch_iso_eff[] = {
+	 27,  28,  29,  30,  33,  39,  44,  47,  47,  47,
+	 47,  47,  47,  47,  47,  47,  47,  47,  47,  47,
+	 47,  47,  47,  47,  47,  47,  47
+};
+
+static u32 bwmgr_t186_lpddr3_iso_eff[] = {
+	31,  32,  33,  34,  36,  40,  44,  48,  48,  48,
+	48,  48,  48,  48,  47,  31,   1,   1,   1,   1,
+	 1,   1,   1,   1,   1,   1,   1
+};
+
+static u32 bwmgr_t186_ddr3_iso_eff[] = {
+	28,  29,  32,  34,  36,  41,  45,  47,  47,  47,
+	47,  47,  47,  47,  47,  47,  47,  47,  47,  47,
+	47,  47,   1,   1,   1,   1,   1
+};
+
+static struct mrq_emc_dvfs_latency_response bwmgr_emc_dvfs;
+
+#define MC_BASE 0x02c10000
+#define EMC_BASE 0x02c60000
+
+#define MC_EMEM_ADR_CFG_CHANNEL_ENABLE_0 0xdf8
+#define MC_ECC_CONTROL_0 0x1880
+#define EMC_FBIO_CFG5_0 0x104
+
+#define CH_MASK 0xf /* Change bit counting if this mask changes */
+#define CH4 0xf
+#define CH2 0x3
+
+#define ECC_MASK 0x1 /* 1 = enabled, 0 = disabled */
+
+#define DRAM_MASK 0x3
+#define DRAM_DDR3 0
+#define DRAM_LPDDR4 1
+#define DRAM_LPDDR3 2 /* On T186 this value is LPDDR3 */
+#define DRAM_DDR2 3
+
+static int get_iso_bw_table_idx(unsigned long iso_bw)
+{
+	int i = ARRAY_SIZE(bwmgr_t186_iso_bw_table) - 1;
+
+	/* Input is in Hz, iso_bw table's unit is MHz */
+	iso_bw /= 1000000;
+
+	while (i > 0 && bwmgr_t186_iso_bw_table[i] > iso_bw)
+		i--;
+
+	return i;
+}
+
+static unsigned long freq_to_bw(unsigned long freq)
+{
+	if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_4CH_ECC ||
+			bwmgr_dram_type == DRAM_TYPE_LPDDR4_4CH ||
+			bwmgr_dram_type == DRAM_TYPE_LPDDR3_2CH ||
+			bwmgr_dram_type == DRAM_TYPE_DDR3_2CH)
+		return freq * 32;
+
+	return freq * 16;
+}
+
+static unsigned long bw_to_freq(unsigned long bw)
+{
+	if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_4CH_ECC ||
+			bwmgr_dram_type == DRAM_TYPE_LPDDR4_4CH ||
+			bwmgr_dram_type == DRAM_TYPE_LPDDR3_2CH ||
+			bwmgr_dram_type == DRAM_TYPE_DDR3_2CH)
+		return (bw + 32 - 1) / 32;
+
+	return (bw + 16 - 1) / 16;
+}
+
+static u32 dvfs_latency(u32 ufreq)
+{
+	u32 lt = 4000; /* default value of 4000 nsec */
+	int i;
+
+	if (bwmgr_emc_dvfs.num_pairs <= 0)
+		return lt / 1000; /* convert nsec to usec, Bug 1697424 */
+
+	for (i = 0; i < bwmgr_emc_dvfs.num_pairs; i++) {
+		if (ufreq <= bwmgr_emc_dvfs.pairs[i].freq) {
+			lt = bwmgr_emc_dvfs.pairs[i].latency;
+			break;
+		}
+	}
+
+	if (i >= bwmgr_emc_dvfs.num_pairs)
+		lt =
+		bwmgr_emc_dvfs.pairs[bwmgr_emc_dvfs.num_pairs - 1].latency;
+
+	return lt / 1000; /* convert nsec to usec, Bug 1697424 */
+}
+
+static unsigned long t18x_bwmgr_apply_efficiency(
+		unsigned long total_bw, unsigned long iso_bw,
+		unsigned long max_rate, u64 usage_flags,
+		unsigned long *iso_bw_min, unsigned long iso_bw_nvdis,
+		unsigned long iso_bw_vi)
+{
+	u8 efficiency = bwmgr_dram_efficiency;
+
+	if (total_bw && efficiency && (efficiency < 100)) {
+		total_bw = total_bw / efficiency;
+		total_bw = (total_bw < max_rate / 100) ?
+			(total_bw * 100) : max_rate;
+	}
+
+	efficiency = bwmgr_dram_iso_eff_table[get_iso_bw_table_idx(iso_bw)];
+	WARN_ON_ONCE(efficiency == 1);
+	if (iso_bw && efficiency && (efficiency < 100)) {
+		iso_bw /= efficiency;
+		iso_bw = (iso_bw < max_rate / 100) ?
+		(iso_bw * 100) : max_rate;
+	}
+
+	if (iso_bw_min)
+		*iso_bw_min = iso_bw;
+
+	return max(total_bw, iso_bw);
+}
+
+static struct bwmgr_ops bwmgr_ops_t18x = {
+	.freq_to_bw = freq_to_bw,
+	.bw_to_freq = bw_to_freq,
+	.dvfs_latency = dvfs_latency,
+	.bwmgr_apply_efficiency = t18x_bwmgr_apply_efficiency,
+};
+
+struct bwmgr_ops *bwmgr_eff_init_t18x(void)
+{
+	int i, ch_num;
+	u32 dram, ch, ecc;
+	void __iomem *mc_base, *emc_base;
+
+	mc_base = ioremap(MC_BASE, 0x00010000);
+	emc_base = ioremap(EMC_BASE, 0x00010000);
+
+	dram = readl(emc_base + EMC_FBIO_CFG5_0) & DRAM_MASK;
+	ch = readl(mc_base + MC_EMEM_ADR_CFG_CHANNEL_ENABLE_0) & CH_MASK;
+	ecc = readl(mc_base + MC_ECC_CONTROL_0) & ECC_MASK;
+
+	iounmap(emc_base);
+	iounmap(mc_base);
+
+	ch_num = ((ch >> 3) & 1) + ((ch >> 2) & 1) + ((ch >> 1) & 1) + (ch & 1);
+
+	/* T186 platforms should only have LPDDR4 */
+	switch (dram) {
+	case DRAM_LPDDR4:
+		if (ecc) {
+			if (ch_num == 4) {
+				bwmgr_dram_type =
+					DRAM_TYPE_LPDDR4_4CH_ECC;
+				bwmgr_dram_iso_eff_table =
+				bwmgr_t186_lpddr4_4ch_ecc_iso_eff;
+			} else if (ch_num == 2) {
+				bwmgr_dram_type =
+					DRAM_TYPE_LPDDR4_2CH_ECC;
+				bwmgr_dram_iso_eff_table =
+				bwmgr_t186_lpddr4_2ch_ecc_iso_eff;
+			}
+		} else {
+			if (ch_num == 4) {
+				bwmgr_dram_type = DRAM_TYPE_LPDDR4_4CH;
+				bwmgr_dram_iso_eff_table =
+				bwmgr_t186_lpddr4_4ch_iso_eff;
+			} else if (ch_num == 2) {
+				bwmgr_dram_type = DRAM_TYPE_LPDDR4_2CH;
+				bwmgr_dram_iso_eff_table =
+				bwmgr_t186_lpddr4_2ch_iso_eff;
+			}
+		}
+
+		if ((ch_num == 0) || (ch_num == 1) || (ch_num == 3)) {
+			pr_err("bwmgr: Unknown memory channel configuration\n");
+			bwmgr_dram_type =
+				DRAM_TYPE_LPDDR4_2CH_ECC;
+			bwmgr_dram_iso_eff_table =
+				bwmgr_t186_lpddr4_2ch_ecc_iso_eff;
+		}
+
+		bwmgr_dram_efficiency = 70;
+		emc_to_dram_freq_factor = 2;
+		/* valid ddr configuration */
+		bwmgr_dram_config_supported = 1;
+		break;
+
+	case DRAM_LPDDR3:
+		bwmgr_dram_type = DRAM_TYPE_LPDDR3_2CH;
+		bwmgr_dram_efficiency = 80;
+		bwmgr_dram_iso_eff_table =
+			bwmgr_t186_lpddr3_iso_eff;
+		emc_to_dram_freq_factor = 1;
+		/* valid ddr configuration */
+		bwmgr_dram_config_supported = 1;
+		break;
+
+	case DRAM_DDR3:
+		bwmgr_dram_type = DRAM_TYPE_DDR3_2CH;
+		bwmgr_dram_efficiency = 80;
+		bwmgr_dram_iso_eff_table =
+			bwmgr_t186_ddr3_iso_eff;
+		emc_to_dram_freq_factor = 1;
+		/* valid ddr configuration */
+		bwmgr_dram_config_supported = 1;
+		break;
+
+	case DRAM_DDR2:
+		pr_err("bwmgr: ddr config not supported\n");
+		WARN_ON(true);
+		break;
+
+	default:
+		pr_err("bwmgr: ddr config not supported\n");
+		WARN_ON(true);
+	}
+	bwmgr_dram_num_channels = ch_num;
+
+	if (bwmgr_dram_config_supported) {
+		for (i = ARRAY_SIZE(bwmgr_t186_iso_bw_table) - 1; i >= 0; i--) {
+			if (bwmgr_dram_iso_eff_table[i] > 1) {
+				bwmgr_iso_bw_percentage =
+					bwmgr_dram_iso_eff_table[i];
+				break;
+			}
+		}
+	}
+
+	tegra_bpmp_send_receive(MRQ_EMC_DVFS_LATENCY, NULL, 0,
+			&bwmgr_emc_dvfs, sizeof(bwmgr_emc_dvfs));
+
+	return &bwmgr_ops_t18x;
+}
diff --git a/drivers/platform/tegra/mc/emc_bwmgr-t19x.c b/drivers/platform/tegra/mc/emc_bwmgr-t19x.c
new file mode 100644
index 000000000000..bcd550410f0c
--- /dev/null
+++ b/drivers/platform/tegra/mc/emc_bwmgr-t19x.c
@@ -0,0 +1,882 @@
+/**
+ * Copyright (c) 2018, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ */
+
+#include <linux/platform/tegra/bwmgr_mc.h>
+#include <linux/platform/tegra/emc_bwmgr.h>
+#include <linux/io.h>
+#include <soc/tegra/bpmp_abi.h>
+#include <soc/tegra/tegra_bpmp.h>
+#include <soc/tegra/chip-id.h>
+
+/* T194 dram freq table */
+static u32 bwmgr_t194_dram_freq_table[] = { /* MHz */
+	  68,   102,   204,   408,   600,
+	 792,   924,  1056,  1200,  1600,
+	1866,  2133
+};
+
+/* ALL VALUES BELOW CORRESPOND TO FREQ in bwmgr_t194_dram_freq_table */
+
+/* efficiency percentage 8ch ecc 4X 1-rank*/
+static u32 bwmgr_t194_8ch_ecc_4X_1rank_eff[] = { /* % */
+	  20,    20,    20,    20,    20,
+	  20,    30,    30,    30,    55,
+	  55,    60
+};
+
+/* efficiency percentage 4ch ecc 4X 1-rank*/
+static u32 bwmgr_t194_4ch_ecc_4X_1rank_eff[] = { /* % */
+	  20,    20,    20,    20,    20,
+	  20,    30,    30,    30,    55,
+	  55,    60
+};
+
+/* efficiency percentage 16ch ecc 4X 1-rank*/
+static u32 bwmgr_t194_16ch_ecc_4X_1rank_eff[] = { /* % */
+	  20,    20,    20,    20,    20,
+	  20,    30,    30,    30,    55,
+	  55,    60
+};
+
+/* efficiency percentage 8ch 4X 1-rank*/
+static u32 bwmgr_t194_8ch_4X_1rank_eff[] = { /* % */
+	  30,    30,    30,    30,    30,
+	  30,    40,    40,    40,    70,
+	  70,    70
+};
+
+/* efficiency percentage 4ch 4X 1-rank*/
+static u32 bwmgr_t194_4ch_4X_1rank_eff[] = { /* % */
+	  30,    30,    30,    30,    30,
+	  30,    40,    40,    40,    70,
+	  70,    70
+};
+
+/* efficiency percentage 16ch 4X 1-rank*/
+static u32 bwmgr_t194_16ch_4X_1rank_eff[] = { /* % */
+	  30,    30,    30,    30,    30,
+	  30,    40,    40,    40,    70,
+	  70,    70
+};
+
+/* efficiency percentage 8ch ecc 4X 2-rank*/
+static u32 bwmgr_t194_8ch_ecc_4X_2rank_eff[] = { /* % */
+	  20,    20,    20,    20,    20,
+	  20,    30,    30,    30,    55,
+	  55,    60
+};
+
+/* efficiency percentage 4ch ecc 4X 2-rank*/
+static u32 bwmgr_t194_4ch_ecc_4X_2rank_eff[] = { /* % */
+	  20,    20,    20,    20,    20,
+	  20,    30,    30,    30,    55,
+	  55,    60
+};
+
+/* efficiency percentage 16ch ecc 4X 2-rank*/
+static u32 bwmgr_t194_16ch_ecc_4X_2rank_eff[] = { /* % */
+	  20,    20,    20,    20,    20,
+	  20,    30,    30,    30,    55,
+	  55,    60
+};
+
+/* efficiency percentage 8ch 4X 2-rank*/
+static u32 bwmgr_t194_8ch_4X_2rank_eff[] = { /* % */
+	  25,    25,    25,    25,    25,
+	  25,    40,    40,    40,    65,
+	  65,    65
+};
+
+/* efficiency percentage 4ch 4X 2-rank*/
+static u32 bwmgr_t194_4ch_4X_2rank_eff[] = { /* % */
+	  25,    25,    25,    25,    25,
+	  25,    40,    40,    40,    65,
+	  65,    65
+};
+
+/* efficiency percentage 16ch 4X 2-rank*/
+static u32 bwmgr_t194_16ch_4X_2rank_eff[] = { /* % */
+	  30,    30,    30,    30,    30,
+	  30,    35,    35,    35,    65,
+	  65,    65
+};
+
+/* efficiency percentage 8ch ecc 1X 1-rank*/
+static u32 bwmgr_t194_8ch_ecc_1X_1rank_eff[] = { /* % */
+	  45,    45,    45,    45,    45,
+	  45,    50,    50,    50,    65,
+	  65,    70
+};
+
+/* efficiency percentage 4ch ecc 1X 1-rank*/
+static u32 bwmgr_t194_4ch_ecc_1X_1rank_eff[] = { /* % */
+	  45,    45,    45,    45,    45,
+	  45,    50,    50,    50,    65,
+	  65,    70
+};
+
+/* efficiency percentage 16ch ecc 1X 1-rank*/
+static u32 bwmgr_t194_16ch_ecc_1X_1rank_eff[] = { /* % */
+	  40,    40,    40,    40,    40,
+	  40,    50,    50,    50,    65,
+	  65,    70
+};
+
+/* efficiency percentage 8ch 1X 1-rank*/
+static u32 bwmgr_t194_8ch_1X_1rank_eff[] = { /* % */
+	  60,    60,    60,    60,    60,
+	  60,    60,    60,    60,    80,
+	  80,    80
+};
+
+/* efficiency percentage 4ch 1X 1-rank*/
+static u32 bwmgr_t194_4ch_1X_1rank_eff[] = { /* % */
+	  60,    60,    60,    60,    60,
+	  60,    60,    60,    60,    80,
+	  80,    80
+};
+
+/* efficiency percentage 16ch 1X 1-rank*/
+static u32 bwmgr_t194_16ch_1X_1rank_eff[] = { /* % */
+	  60,    60,    60,    60,    60,
+	  60,    60,    60,    60,    80,
+	  80,    80
+};
+
+/* efficiency percentage 8ch ecc 1X 2-rank*/
+static u32 bwmgr_t194_8ch_ecc_1X_2rank_eff[] = { /* % */
+	  40,    40,    40,    40,    40,
+	  40,    45,    45,    45,    60,
+	  55,    55
+};
+
+/* efficiency percentage 4ch ecc 1X 2-rank*/
+static u32 bwmgr_t194_4ch_ecc_1X_2rank_eff[] = { /* % */
+	  40,    40,    40,    40,    40,
+	  40,    45,    45,    45,    60,
+	  55,    55
+};
+
+/* efficiency percentage 16ch ecc 1X 2-rank*/
+static u32 bwmgr_t194_16ch_ecc_1X_2rank_eff[] = { /* % */
+	  40,    40,    40,    40,    40,
+	  40,    50,    50,    50,    60,
+	  55,    55
+};
+
+/* efficiency percentage 8ch 1X 2-rank*/
+static u32 bwmgr_t194_8ch_1X_2rank_eff[] = { /* % */
+	  55,    55,    55,    55,    55,
+	  55,    55,    55,    55,    70,
+	  70,    70
+};
+
+/* efficiency percentage 4ch 1X 2-rank*/
+static u32 bwmgr_t194_4ch_1X_2rank_eff[] = { /* % */
+	  55,    55,    55,    55,    55,
+	  55,    55,    55,    55,    70,
+	  70,    70
+};
+
+/* efficiency percentage 16ch 1X 2-rank*/
+static u32 bwmgr_t194_16ch_1X_2rank_eff[] = { /* % */
+	  55,    55,    55,    55,    55,
+	  55,    55,    55,    55,    70,
+	  70,    70
+};
+
+/* max nvdis bw req in MHz
+ * The value below reflects the maximum display bandwidth supported
+ * at the frequency corresponding to the same index in
+ * dram freq table.
+ */
+static u32 bwmgr_t194_lpddr4_8ch_iso_max_nvdis_bw_reqd[] = { /* MHz */
+	   0,     0,    22,    66,   107,
+	 148,   177,   205,   237,   437,
+	 656,   684
+};
+
+static u32 bwmgr_t194_lpddr4_4ch_iso_max_nvdis_bw_reqd[] = { /* MHz */
+	   0,     0,    22,    66,   107,
+	 148,   177,   205,   237,   437,
+	 656,   684
+};
+
+static u32 bwmgr_t194_lpddr4_16ch_iso_max_nvdis_bw_reqd[] = { /* MHz */
+	   0,     0,    11,    33,    53,
+	  74,    88,   102,   167,   347,
+	 361,   375
+};
+
+static u32 bwmgr_t194_lpddr4_8ch_ecc_iso_max_nvdis_bw_reqd[] = { /* MHz */
+	   0,     0,    26,    80,   131,
+	 169,   196,   222,   251,   397,
+	 494,   591
+};
+
+static u32 bwmgr_t194_lpddr4_4ch_ecc_iso_max_nvdis_bw_reqd[] = { /* MHz */
+	   0,     0,    26,    80,   131,
+	 169,   196,   222,   251,   397,
+	 494,   591
+};
+
+static u32 bwmgr_t194_lpddr4_16ch_ecc_iso_max_nvdis_bw_reqd[] = { /* MHz */
+	   0,     0,    14,    43,    70,
+	  98,   116,   135,   156,   250,
+	 312,   375
+};
+
+/* max vi bw req in MHz
+ * The value below reflects the maximum vi bandwidth supported
+ * at the frequency corresponding to the same index in
+ * dram freq table.
+ */
+static u32 bwmgr_t194_lpddr4_8ch_iso_max_vi_bw_reqd[] = { /* MHz */
+	   0,     0,    14,    42,    68,
+	  95,   113,   131,   151,   279,
+	 279,   279
+};
+
+static u32 bwmgr_t194_lpddr4_4ch_iso_max_vi_bw_reqd[] = { /* MHz */
+	   0,     0,    14,    42,    68,
+	  95,   113,   131,   151,   279,
+	 279,   279
+};
+
+static u32 bwmgr_t194_lpddr4_16ch_iso_max_vi_bw_reqd[] = { /* MHz */
+	   0,     0,     8,    24,    40,
+	  55,    66,    76,    88,   139,
+	 139,   139
+};
+
+static u32 bwmgr_t194_lpddr4_8ch_ecc_iso_max_vi_bw_reqd[] = { /* MHz */
+	   0,     0,    11,    34,    56,
+	  78,    93,   108,   124,   279,
+	 279,   279
+};
+
+static u32 bwmgr_t194_lpddr4_4ch_ecc_iso_max_vi_bw_reqd[] = { /* MHz */
+	   0,     0,    11,    34,    56,
+	  78,    93,   108,   124,   279,
+	 279,   279
+};
+
+static u32 bwmgr_t194_lpddr4_16ch_ecc_iso_max_vi_bw_reqd[] = { /* MHz */
+	   0,     0,     6,    19,    31,
+	  43,    52,    60,    69,   139,
+	 139,   139
+};
+
+/* slope for calculating eff
+ * The value below reflects the slope
+ * at the frequency corresponding to the same index in
+ * dram freq table.
+ */
+static int bwmgr_t194_lpddr4_8ch_iso_slope[] = {
+	  -1,    -1,    -1,    -1,    -1,
+	  -1,    -1,    -1,    -1,    -1,
+	  -1,    -1
+};
+
+static int bwmgr_t194_lpddr4_4ch_iso_slope[] = {
+	  -1,    -1,    -1,    -1,    -1,
+	  -1,    -1,    -1,    -1,    -1,
+	  -1,    -1
+};
+
+static int bwmgr_t194_lpddr4_16ch_iso_slope[] = {
+	  -1,    -1,    -1,    -1,    -1,
+	  -1,    -1,    -1,    -1,    -1,
+	  -1,    -1
+};
+
+static int bwmgr_t194_lpddr4_8ch_ecc_iso_slope[] = {
+	  -1,    -1,    -1,    -1,    -1,
+	  -1,    -1,    -1,    -1,    -1,
+	  -1,    -2
+};
+
+static int bwmgr_t194_lpddr4_4ch_ecc_iso_slope[] = {
+	  -1,    -1,    -1,    -1,    -1,
+	  -1,    -1,    -1,    -1,    -1,
+	  -1,    -2
+};
+
+static int bwmgr_t194_lpddr4_16ch_ecc_iso_slope[] = {
+	  -1,    -1,    -1,    -1,    -1,
+	  -1,    -1,    -1,    -1,    -1,
+	  -1,    -1
+};
+
+/* vi offset bw req in MHz
+ * The value below reflects the vi offset
+ * at the frequency corresponding to the same index in
+ * dram freq table.
+ */
+static u32 bwmgr_t194_lpddr4_8ch_iso_vi_bw_reqd_offset[] = { /* MHz */
+	   0,     0,     0,     0,     0,
+	   0,     0,     0,     0,     0,
+	   0,     0
+};
+
+static u32 bwmgr_t194_lpddr4_4ch_iso_vi_bw_reqd_offset[] = { /* MHz */
+	   0,     0,     0,     0,     0,
+	   0,     0,     0,     0,     0,
+	   0,     0
+};
+
+static u32 bwmgr_t194_lpddr4_16ch_iso_vi_bw_reqd_offset[] = { /* MHz */
+	   0,     0,     0,     0,     0,
+	   0,     0,     0,     0,     0,
+	   0,    37
+};
+
+static u32 bwmgr_t194_lpddr4_8ch_ecc_iso_vi_bw_reqd_offset[] = { /* MHz */
+	   0,     0,     0,     0,     0,
+	   0,     0,     0,     0,     0,
+	   0,     0
+};
+
+static u32 bwmgr_t194_lpddr4_4ch_ecc_iso_vi_bw_reqd_offset[] = { /* MHz */
+	   0,     0,     0,     0,     0,
+	   0,     0,     0,     0,     0,
+	   0,     0
+};
+
+static u32 bwmgr_t194_lpddr4_16ch_ecc_iso_vi_bw_reqd_offset[] = { /* MHz */
+	   0,     0,     0,     0,     0,
+	   0,     0,     0,     0,     0,
+	   0,    37
+};
+
+static struct mrq_emc_dvfs_latency_response bwmgr_emc_dvfs;
+static int dram_rank;
+static int dram_freq_count;
+
+#define MC_BASE 0x02c10000
+#define EMC_BASE 0x02c60000
+
+#define MC_EMEM_ADR_CFG_CHANNEL_ENABLE_0 0xdf8
+#define MC_EMEM_ADR_CFG_0 0x54
+#define MC_ECC_CONTROL_0 0x1880
+#define EMC_FBIO_CFG5_0 0x104
+
+#define CH_MASK 0xFFFF /* Change bit counting if this mask changes */
+#define CH4 0xf
+#define CH2 0x3
+
+#define ECC_MASK 0x1 /* 1 = enabled, 0 = disabled */
+#define RANK_MASK 0x1 /* 1 = 2-RANK, 0 = 1-RANK */
+
+#define DRAM_MASK 0x3
+#define DRAM_DDR3 0
+#define DRAM_LPDDR4 1
+#define DRAM_LPDDR3 2 /* On T186 this value is LPDDR3 */
+#define DRAM_DDR2 3
+
+#define DRAM_REFRESH_1X 0
+#define DRAM_REFRESH_4X 1
+
+static unsigned long get_best_iso_freq(long total_iso_bw, long iso_bw_nvdis,
+						long iso_bw_vi)
+{
+	long max_nvdis_bw_reqd_mhz = 0;
+	long max_vi_bw_reqd_mhz = 0;
+	long slope = -1;
+	long vi_bw_reqd_offset_mhz = 0;
+	int i;
+	unsigned long dram_freq_mhz = 0;
+
+	if (!bwmgr_dram_config_supported)
+		return dram_freq_mhz;
+
+	/*Input is in Hz, converting into MHz*/
+	total_iso_bw /= 1000000;
+	iso_bw_nvdis /= 1000000;
+	iso_bw_vi /= 1000000;
+
+	for (i = 0; i < dram_freq_count; i++) {
+		max_nvdis_bw_reqd_mhz = bwmgr_max_nvdis_bw_reqd[i];
+		max_vi_bw_reqd_mhz = bwmgr_max_vi_bw_reqd[i];
+		slope = bwmgr_slope[i];
+		vi_bw_reqd_offset_mhz = bwmgr_vi_bw_reqd_offset[i];
+
+		if (!(iso_bw_nvdis <= max_nvdis_bw_reqd_mhz))
+			continue;
+
+		if (!(iso_bw_vi <= max_vi_bw_reqd_mhz))
+			continue;
+
+		if (!(iso_bw_vi <= (slope * (iso_bw_nvdis -
+			max_nvdis_bw_reqd_mhz) + vi_bw_reqd_offset_mhz)))
+			continue;
+
+		if (!(total_iso_bw <= (slope *
+				(iso_bw_nvdis - max_nvdis_bw_reqd_mhz)
+				+ vi_bw_reqd_offset_mhz + iso_bw_nvdis)))
+			continue;
+
+		dram_freq_mhz = bwmgr_t194_dram_freq_table[i] * 1000000;
+		break;
+	}
+
+	return dram_freq_mhz;
+}
+
+static unsigned long freq_to_bw(unsigned long freq)
+{
+	if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_16CH_ECC ||
+			bwmgr_dram_type == DRAM_TYPE_LPDDR4_16CH)
+		return freq * 64;
+
+	if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_8CH_ECC ||
+			bwmgr_dram_type == DRAM_TYPE_LPDDR4_8CH)
+		return freq * 32;
+
+	/*4CH and 4CH_ECC*/
+	return freq * 16;
+}
+
+static unsigned long bw_to_freq(unsigned long bw)
+{
+	if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_16CH_ECC ||
+			bwmgr_dram_type == DRAM_TYPE_LPDDR4_16CH)
+		return (bw + 64 - 1) / 64;
+
+	if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_8CH_ECC ||
+			bwmgr_dram_type == DRAM_TYPE_LPDDR4_8CH)
+		return (bw + 32 - 1) / 32;
+
+	/*4CH and 4CH_ECC*/
+	return (bw + 16 - 1) / 16;
+}
+
+static u32 dvfs_latency(u32 ufreq)
+{
+	u32 lt = 80000; /* default value of 80000 nsec */
+	int i;
+
+	if (bwmgr_emc_dvfs.num_pairs <= 0)
+		return lt / 1000; /* convert nsec to usec, Bug 1697424 */
+
+	for (i = 0; i < bwmgr_emc_dvfs.num_pairs; i++) {
+		if (ufreq <= bwmgr_emc_dvfs.pairs[i].freq) {
+			lt = bwmgr_emc_dvfs.pairs[i].latency;
+			break;
+		}
+	}
+
+	if (i >= bwmgr_emc_dvfs.num_pairs)
+		lt =
+		bwmgr_emc_dvfs.pairs[bwmgr_emc_dvfs.num_pairs - 1].latency;
+
+	return lt / 1000; /* convert nsec to usec, Bug 1697424 */
+}
+
+static unsigned long t19x_bwmgr_apply_efficiency(
+		unsigned long total_bw, unsigned long iso_bw,
+		unsigned long max_rate, u64 usage_flags,
+		unsigned long *iso_bw_min, unsigned long iso_bw_nvdis,
+		unsigned long iso_bw_vi)
+{
+	int i;
+	unsigned long total_bw_mhz, freq_after_eff_mhz;
+	u8 efficiency;
+	bool bw_req_satisfied = 1;
+
+	if (total_bw) {
+		total_bw_mhz = total_bw / 1000000;
+
+		/* loop over all dram freq and its corresponding
+		 * efficiency and check if total bw request can
+		 * satisfied at that freq
+		 */
+		for (i = 0; i < dram_freq_count; i++) {
+			efficiency = bwmgr_dram_noniso_eff_table[i];
+			freq_after_eff_mhz = bwmgr_t194_dram_freq_table[i] *
+						efficiency;
+			freq_after_eff_mhz /= 100;
+			if (total_bw_mhz < freq_after_eff_mhz) {
+				total_bw = bwmgr_t194_dram_freq_table[i] *
+						1000000;
+				bw_req_satisfied = 0;
+				break;
+			}
+		}
+		/*defaults to max emc rate if reqd rate is not satisfied*/
+		if (bw_req_satisfied)
+			total_bw = max_rate;
+	}
+
+	// This functions loops over the available dram freq and returns the
+	//lowest freq which can satisfy the *iso* bw requirement
+	iso_bw = get_best_iso_freq(iso_bw, iso_bw_nvdis, iso_bw_vi);
+
+	if (iso_bw_min)
+		*iso_bw_min = iso_bw;
+
+	return max(total_bw, iso_bw);
+}
+
+static void t19x_update_efficiency(unsigned long dram_refresh_rate)
+{
+	if ((dram_refresh_rate != DRAM_REFRESH_4X) &&
+		(dram_refresh_rate != DRAM_REFRESH_1X)) {
+		pr_err("bwmgr:Unknown cooling state. Set 4X refresh co-eff\n");
+		dram_refresh_rate = DRAM_REFRESH_4X;
+	}
+
+	if (dram_refresh_rate == DRAM_REFRESH_4X) {
+		if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_16CH_ECC) {
+			if (dram_rank)
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_16ch_ecc_4X_2rank_eff;
+			else
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_16ch_ecc_4X_1rank_eff;
+		} else if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_8CH_ECC) {
+			if (dram_rank)
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_8ch_ecc_4X_2rank_eff;
+			else
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_8ch_ecc_4X_1rank_eff;
+		} else if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_4CH_ECC) {
+			if (dram_rank)
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_4ch_ecc_4X_2rank_eff;
+			else
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_4ch_ecc_4X_1rank_eff;
+		} else if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_16CH) {
+			if (dram_rank)
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_16ch_4X_2rank_eff;
+			else
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_16ch_4X_1rank_eff;
+		} else if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_8CH) {
+			if (dram_rank)
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_8ch_4X_2rank_eff;
+			else
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_8ch_4X_1rank_eff;
+		} else if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_4CH) {
+			if (dram_rank)
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_4ch_4X_2rank_eff;
+			else
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_4ch_4X_1rank_eff;
+		}
+	} else if (dram_refresh_rate == DRAM_REFRESH_1X) {
+		if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_16CH_ECC) {
+			if (dram_rank)
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_16ch_ecc_1X_2rank_eff;
+			else
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_16ch_ecc_1X_1rank_eff;
+		} else if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_8CH_ECC) {
+			if (dram_rank)
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_8ch_ecc_1X_2rank_eff;
+			else
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_8ch_ecc_1X_1rank_eff;
+		} else if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_4CH_ECC) {
+			if (dram_rank)
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_4ch_ecc_1X_2rank_eff;
+			else
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_4ch_ecc_1X_1rank_eff;
+		} else if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_16CH) {
+			if (dram_rank)
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_16ch_1X_2rank_eff;
+			else
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_16ch_1X_1rank_eff;
+		} else if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_8CH) {
+			if (dram_rank)
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_8ch_1X_2rank_eff;
+			else
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_8ch_1X_1rank_eff;
+		} else if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_4CH) {
+			if (dram_rank)
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_4ch_1X_2rank_eff;
+			else
+				bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_4ch_1X_1rank_eff;
+		}
+	}
+}
+
+static int get_dram_freq_table_idx(unsigned long emc_rate)
+{
+	int i = ARRAY_SIZE(bwmgr_t194_dram_freq_table) - 1;
+
+	/* emc_rate is in Hz, dram_freq table's unit is MHz */
+	emc_rate /= 1000000;
+
+	while (i > 0 && bwmgr_t194_dram_freq_table[i] > emc_rate)
+		i--;
+
+	return i;
+}
+
+static u32 t19x_get_max_iso_bw(enum tegra_iso_client client)
+{
+	u8 idx = 0;
+	unsigned long emc_max_rate = tegra_bwmgr_get_max_emc_rate();
+
+	idx = get_dram_freq_table_idx(emc_max_rate);
+
+	if ((client == TEGRA_ISO_CLIENT_DISP_0) ||
+		(client == TEGRA_ISO_CLIENT_DISP_1) ||
+		(client == TEGRA_ISO_CLIENT_DISP_2))
+		return bwmgr_freq_to_bw(bwmgr_max_nvdis_bw_reqd[idx] * 1000);
+	else if (client == TEGRA_ISO_CLIENT_TEGRA_CAMERA)
+		return bwmgr_freq_to_bw(bwmgr_max_vi_bw_reqd[idx] * 1000);
+	else
+		return bwmgr_freq_to_bw((((bwmgr_slope[idx] *
+		bwmgr_max_nvdis_bw_reqd[idx]) +
+		bwmgr_vi_bw_reqd_offset[idx]) - 1) * 1000);
+}
+
+static struct bwmgr_ops bwmgr_ops_t19x = {
+	.get_best_iso_freq = get_best_iso_freq,
+	.freq_to_bw = freq_to_bw,
+	.bw_to_freq = bw_to_freq,
+	.dvfs_latency = dvfs_latency,
+	.bwmgr_apply_efficiency = t19x_bwmgr_apply_efficiency,
+	.update_efficiency = t19x_update_efficiency,
+	.get_max_iso_bw = t19x_get_max_iso_bw,
+};
+
+struct bwmgr_ops *bwmgr_eff_init_t19x(void)
+{
+	int ch_num = 0;
+	u32 dram, ch, ecc;
+	void __iomem *mc_base, *emc_base;
+
+	mc_base = ioremap(MC_BASE, 0x00010000);
+	emc_base = ioremap(EMC_BASE, 0x00010000);
+
+	dram = readl(emc_base + EMC_FBIO_CFG5_0) & DRAM_MASK;
+	ch = readl(mc_base + MC_EMEM_ADR_CFG_CHANNEL_ENABLE_0) & CH_MASK;
+	ecc = readl(mc_base + MC_ECC_CONTROL_0) & ECC_MASK;
+	dram_rank = readl(mc_base + MC_EMEM_ADR_CFG_0) & RANK_MASK;
+
+	iounmap(emc_base);
+	iounmap(mc_base);
+
+	while (ch) {
+		if (ch & 1)
+			ch_num++;
+		ch >>= 1;
+	}
+
+	/* pre silicon use LPDDR4 16ch no ecc 1-rank config*/
+	if (tegra_platform_is_sim() || tegra_platform_is_fpga()) {
+		dram = DRAM_LPDDR4;
+		ch_num = 16;
+	}
+
+	bwmgr_dram_num_channels = ch_num;
+
+	/* T194 platforms should only have LPDDR4 */
+	switch (dram) {
+	case DRAM_LPDDR4:
+		if (ecc) {
+			if (ch_num == 16) {
+				bwmgr_dram_type =
+					DRAM_TYPE_LPDDR4_16CH_ECC;
+
+				if (dram_rank)
+					bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_16ch_ecc_4X_2rank_eff;
+				else
+					bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_16ch_ecc_4X_1rank_eff;
+
+				bwmgr_max_nvdis_bw_reqd =
+			bwmgr_t194_lpddr4_16ch_ecc_iso_max_nvdis_bw_reqd;
+
+				bwmgr_max_vi_bw_reqd =
+				bwmgr_t194_lpddr4_16ch_ecc_iso_max_vi_bw_reqd;
+
+				bwmgr_slope =
+					bwmgr_t194_lpddr4_16ch_ecc_iso_slope;
+
+				bwmgr_vi_bw_reqd_offset =
+			bwmgr_t194_lpddr4_16ch_ecc_iso_vi_bw_reqd_offset;
+
+			} else if (ch_num == 8) {
+				bwmgr_dram_type =
+					DRAM_TYPE_LPDDR4_8CH_ECC;
+				if (dram_rank)
+					bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_8ch_ecc_4X_2rank_eff;
+				else
+					bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_8ch_ecc_4X_1rank_eff;
+
+				bwmgr_max_nvdis_bw_reqd =
+				bwmgr_t194_lpddr4_8ch_ecc_iso_max_nvdis_bw_reqd;
+
+				bwmgr_max_vi_bw_reqd =
+				bwmgr_t194_lpddr4_8ch_ecc_iso_max_vi_bw_reqd;
+
+				bwmgr_slope =
+				bwmgr_t194_lpddr4_8ch_ecc_iso_slope;
+
+				bwmgr_vi_bw_reqd_offset =
+				bwmgr_t194_lpddr4_8ch_ecc_iso_vi_bw_reqd_offset;
+
+			} else if (ch_num == 4) {
+				bwmgr_dram_type =
+					DRAM_TYPE_LPDDR4_4CH_ECC;
+				if (dram_rank)
+					bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_4ch_ecc_4X_2rank_eff;
+				else
+					bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_4ch_ecc_4X_1rank_eff;
+
+				bwmgr_max_nvdis_bw_reqd =
+				bwmgr_t194_lpddr4_4ch_ecc_iso_max_nvdis_bw_reqd;
+
+				bwmgr_max_vi_bw_reqd =
+				bwmgr_t194_lpddr4_4ch_ecc_iso_max_vi_bw_reqd;
+
+				bwmgr_slope =
+				bwmgr_t194_lpddr4_4ch_ecc_iso_slope;
+
+				bwmgr_vi_bw_reqd_offset =
+				bwmgr_t194_lpddr4_4ch_ecc_iso_vi_bw_reqd_offset;
+
+			}
+		} else {
+			if (ch_num == 16) {
+				bwmgr_dram_type = DRAM_TYPE_LPDDR4_16CH;
+				if (dram_rank)
+					bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_16ch_4X_2rank_eff;
+				else
+					bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_16ch_4X_1rank_eff;
+
+				bwmgr_max_nvdis_bw_reqd =
+				bwmgr_t194_lpddr4_16ch_iso_max_nvdis_bw_reqd;
+
+				bwmgr_max_vi_bw_reqd =
+				bwmgr_t194_lpddr4_16ch_iso_max_vi_bw_reqd;
+
+				bwmgr_slope = bwmgr_t194_lpddr4_16ch_iso_slope;
+
+				bwmgr_vi_bw_reqd_offset =
+				bwmgr_t194_lpddr4_16ch_iso_vi_bw_reqd_offset;
+
+			} else if (ch_num == 8) {
+				bwmgr_dram_type = DRAM_TYPE_LPDDR4_8CH;
+				if (dram_rank)
+					bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_8ch_4X_2rank_eff;
+				else
+					bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_8ch_4X_1rank_eff;
+
+				bwmgr_max_nvdis_bw_reqd =
+				bwmgr_t194_lpddr4_8ch_iso_max_nvdis_bw_reqd;
+
+				bwmgr_max_vi_bw_reqd =
+				bwmgr_t194_lpddr4_8ch_iso_max_vi_bw_reqd;
+
+				bwmgr_slope = bwmgr_t194_lpddr4_8ch_iso_slope;
+
+				bwmgr_vi_bw_reqd_offset =
+				bwmgr_t194_lpddr4_8ch_iso_vi_bw_reqd_offset;
+
+			} else if (ch_num == 4) {
+				bwmgr_dram_type = DRAM_TYPE_LPDDR4_4CH;
+				if (dram_rank)
+					bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_4ch_4X_2rank_eff;
+				else
+					bwmgr_dram_noniso_eff_table =
+					bwmgr_t194_4ch_4X_1rank_eff;
+
+				bwmgr_max_nvdis_bw_reqd =
+				bwmgr_t194_lpddr4_4ch_iso_max_nvdis_bw_reqd;
+
+				bwmgr_max_vi_bw_reqd =
+				bwmgr_t194_lpddr4_4ch_iso_max_vi_bw_reqd;
+
+				bwmgr_slope = bwmgr_t194_lpddr4_4ch_iso_slope;
+
+				bwmgr_vi_bw_reqd_offset =
+				bwmgr_t194_lpddr4_4ch_iso_vi_bw_reqd_offset;
+
+			}
+		}
+
+		if (ch_num < 4) {
+			pr_err("bwmgr: Unknown memory channel configuration\n");
+			pr_err("bwmgr: ddr config not supported\n");
+			WARN_ON(true);
+		} else {
+			emc_to_dram_freq_factor = 2;
+			/* valid ddr configuration */
+			bwmgr_dram_config_supported = 1;
+		}
+
+		break;
+
+	case DRAM_LPDDR3:
+		pr_err("bwmgr: ddr config not supported\n");
+		WARN_ON(true);
+		break;
+
+	case DRAM_DDR3:
+		pr_err("bwmgr: ddr config not supported\n");
+		WARN_ON(true);
+		break;
+
+	case DRAM_DDR2:
+		pr_err("bwmgr: ddr config not supported\n");
+		WARN_ON(true);
+		break;
+
+	default:
+		pr_err("bwmgr: ddr config not supported\n");
+		WARN_ON(true);
+	}
+
+	dram_freq_count = ARRAY_SIZE(bwmgr_t194_dram_freq_table);
+
+	tegra_bpmp_send_receive(MRQ_EMC_DVFS_LATENCY, NULL, 0,
+			&bwmgr_emc_dvfs, sizeof(bwmgr_emc_dvfs));
+
+	/* isomgr uses this value to calculate max_iso_bw.
+	 * We need this until the isomgr framework changes are checked in.
+	 */
+	bwmgr_iso_bw_percentage = 28;
+
+	return &bwmgr_ops_t19x;
+}
diff --git a/drivers/platform/tegra/mc/emc_bwmgr-t21x.c b/drivers/platform/tegra/mc/emc_bwmgr-t21x.c
new file mode 100644
index 000000000000..afcf12502144
--- /dev/null
+++ b/drivers/platform/tegra/mc/emc_bwmgr-t21x.c
@@ -0,0 +1,190 @@
+/**
+ * Copyright (c) 2016-2019, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ */
+
+#include <linux/types.h>
+#include <linux/mutex.h>
+#include <linux/err.h>
+#include <linux/module.h>
+#include <linux/platform/tegra/emc_bwmgr.h>
+#include <linux/platform/tegra/isomgr.h>
+#include <linux/debugfs.h>
+#include <linux/io.h>
+
+#include "../../../../arch/arm/mach-tegra/iomap.h"
+
+static u32 bwmgr_t210_iso_bw_table[] = { /* MHz */
+	  5,  10,  20,  30,  40,  60,  80, 100, 120, 140,
+	160, 180, 200, 250, 300, 350, 360, 370, 380, 400,
+	450, 500, 550, 600, 650, 700
+};
+
+/* value of 1 indicates the range over max ISO Bw allowed for the DRAM type */
+static u32 bwmgr_t210_lpddr4_iso_eff[] = {
+	56,  56,  56,  56,  56,  56,  56,  56,  56,  56,
+	56,  56,  56,  56,  56,  56,  56,  56,  56,  56,
+	56,  56,  56,  56,  49,  45
+};
+
+static u32 bwmgr_t210_lpddr3_iso_eff[] = {
+	64,  64,  64,  64,  64,  64,  64,  64,  64,  64,
+	64,  64,  64,  63,  60,  54,  45,   1,   1,   1,
+	 1,   1,   1,   1,   1,   1
+};
+
+static u32 bwmgr_t210_ddr3_iso_eff[] = {
+	65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
+	65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
+	65,  65,  65,  65,  65,   1
+};
+
+#define EMC_FBIO_CFG5_0 0x104
+
+#define DRAM_MASK 0x3
+#define DRAM_DDR3 0
+#define DRAM_LPDDR4 1
+#define DRAM_LPDDR3 2 /* On T210 this value is LPDDR3 */
+
+static int get_iso_bw_table_idx(unsigned long iso_bw)
+{
+	int i = ARRAY_SIZE(bwmgr_t210_iso_bw_table) - 1;
+
+	/* Input is in Hz, iso_bw table's unit is MHz */
+	iso_bw /= 1000000;
+
+	while (i > 0 && bwmgr_t210_iso_bw_table[i] > iso_bw)
+		i--;
+
+	return i;
+}
+
+static unsigned long freq_to_bw(unsigned long freq)
+{
+	if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_4CH_ECC ||
+			bwmgr_dram_type == DRAM_TYPE_LPDDR4_4CH ||
+			bwmgr_dram_type == DRAM_TYPE_LPDDR3_2CH ||
+			bwmgr_dram_type == DRAM_TYPE_DDR3_2CH)
+		return freq * 32;
+
+	return freq * 16;
+}
+
+static unsigned long bw_to_freq(unsigned long bw)
+{
+	if (bwmgr_dram_type == DRAM_TYPE_LPDDR4_4CH_ECC ||
+			bwmgr_dram_type == DRAM_TYPE_LPDDR4_4CH ||
+			bwmgr_dram_type == DRAM_TYPE_LPDDR3_2CH ||
+			bwmgr_dram_type == DRAM_TYPE_DDR3_2CH)
+		return (bw + 32 - 1) / 32;
+
+	return (bw + 16 - 1) / 16;
+}
+
+static u32 dvfs_latency(u32 ufreq)
+{
+	return 4;
+}
+
+static unsigned long t21x_bwmgr_apply_efficiency(
+		unsigned long total_bw, unsigned long iso_bw,
+		unsigned long max_rate, u64 usage_flags,
+		unsigned long *iso_bw_min, unsigned long iso_bw_nvdis,
+		unsigned long iso_bw_vi)
+{
+	u8 efficiency = bwmgr_dram_efficiency;
+
+	if (total_bw && efficiency && (efficiency < 100)) {
+		total_bw = total_bw / efficiency;
+		total_bw = (total_bw < max_rate / 100) ?
+			(total_bw * 100) : max_rate;
+	}
+
+	efficiency = bwmgr_dram_iso_eff_table[get_iso_bw_table_idx(iso_bw)];
+	WARN_ON(efficiency == 1);
+	if (iso_bw && efficiency && (efficiency < 100)) {
+		iso_bw /= efficiency;
+		iso_bw = (iso_bw < max_rate / 100) ?
+		(iso_bw * 100) : max_rate;
+	}
+
+	if (iso_bw_min)
+		*iso_bw_min = iso_bw;
+
+	return max(total_bw, iso_bw);
+}
+
+static struct bwmgr_ops bwmgr_ops_t21x = {
+	.freq_to_bw = freq_to_bw,
+	.bw_to_freq = bw_to_freq,
+	.dvfs_latency = dvfs_latency,
+	.bwmgr_apply_efficiency = t21x_bwmgr_apply_efficiency,
+};
+
+struct bwmgr_ops *bwmgr_eff_init_t21x(void)
+{
+	int i;
+	u32 dram;
+	void __iomem *emc_base;
+
+	emc_base = ioremap(TEGRA_T210_EMC_BASE, TEGRA_T210_EMC_SIZE);
+
+	dram = readl(emc_base + EMC_FBIO_CFG5_0) & DRAM_MASK;
+
+	iounmap(emc_base);
+
+	switch (dram) {
+	case DRAM_LPDDR4:
+		bwmgr_dram_type = DRAM_TYPE_LPDDR4_2CH;
+		bwmgr_dram_iso_eff_table = bwmgr_t210_lpddr4_iso_eff;
+		bwmgr_dram_efficiency = 70;
+		emc_to_dram_freq_factor = 2;
+		/* valid ddr configuration */
+		bwmgr_dram_config_supported = 1;
+
+		break;
+
+	case DRAM_LPDDR3:
+		bwmgr_dram_type = DRAM_TYPE_LPDDR3_2CH;
+		bwmgr_dram_efficiency = 80;
+		bwmgr_dram_iso_eff_table = bwmgr_t210_lpddr3_iso_eff;
+		emc_to_dram_freq_factor = 1;
+		/* valid ddr configuration */
+		bwmgr_dram_config_supported = 1;
+		break;
+
+	case DRAM_DDR3:
+		bwmgr_dram_type = DRAM_TYPE_DDR3_2CH;
+		bwmgr_dram_efficiency = 80;
+		bwmgr_dram_iso_eff_table = bwmgr_t210_ddr3_iso_eff;
+		emc_to_dram_freq_factor = 1;
+		/* valid ddr configuration */
+		bwmgr_dram_config_supported = 1;
+		break;
+
+	default:
+		pr_err("bwmgr: ddr config not supported\n");
+		WARN_ON(true);
+	}
+	bwmgr_dram_num_channels = 2;
+
+	if (bwmgr_dram_config_supported) {
+		for (i = ARRAY_SIZE(bwmgr_t210_iso_bw_table) - 1; i >= 0; i--) {
+			if (bwmgr_dram_iso_eff_table[i] > 1) {
+				bwmgr_iso_bw_percentage =
+					bwmgr_dram_iso_eff_table[i];
+				break;
+			}
+		}
+	}
+
+	return &bwmgr_ops_t21x;
+}
diff --git a/drivers/platform/tegra/mc/emc_bwmgr.c b/drivers/platform/tegra/mc/emc_bwmgr.c
new file mode 100644
index 000000000000..c1941a55d157
--- /dev/null
+++ b/drivers/platform/tegra/mc/emc_bwmgr.c
@@ -0,0 +1,1203 @@
+/**
+ * Copyright (c) 2015-2019, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ */
+
+#include <linux/types.h>
+#include <linux/mutex.h>
+#include <linux/err.h>
+#include <linux/slab.h>
+#include <linux/module.h>
+#include <linux/platform/tegra/emc_bwmgr.h>
+#include <linux/platform/tegra/isomgr.h>
+#include <linux/debugfs.h>
+#include <linux/thermal.h>
+#include <linux/version.h>
+#include <soc/tegra/chip-id.h>
+
+#define CREATE_TRACE_POINTS
+#include <trace/events/bwmgr.h>
+
+u8 bwmgr_dram_efficiency;
+u8 bwmgr_dram_num_channels;
+/* flag to determine supported memory and channel configuration */
+u8 bwmgr_dram_config_supported;
+u32 *bwmgr_dram_iso_eff_table;
+u32 *bwmgr_dram_noniso_eff_table;
+u32 *bwmgr_max_nvdis_bw_reqd;
+u32 *bwmgr_max_vi_bw_reqd;
+int *bwmgr_slope;
+u32 *bwmgr_vi_bw_reqd_offset;
+int bwmgr_iso_bw_percentage;
+enum bwmgr_dram_types bwmgr_dram_type;
+int emc_to_dram_freq_factor;
+
+#define IS_HANDLE_VALID(x) ((x >= bwmgr.bwmgr_client) && \
+		(x < bwmgr.bwmgr_client + TEGRA_BWMGR_CLIENT_COUNT))
+
+struct tegra_bwmgr_client {
+	unsigned long bw;
+	unsigned long iso_bw;
+	unsigned long cap;
+	unsigned long iso_cap;
+	unsigned long floor;
+	int refcount;
+};
+
+/* TODO: Manage client state in a dynamic list */
+static struct {
+	struct tegra_bwmgr_client bwmgr_client[TEGRA_BWMGR_CLIENT_COUNT];
+	struct mutex lock;
+	unsigned long emc_min_rate;
+	unsigned long emc_max_rate;
+	struct clk *emc_clk;
+	struct task_struct *task;
+	bool status;
+	struct bwmgr_ops *ops;
+	bool override;
+} bwmgr;
+
+static struct dram_refresh_alrt {
+	unsigned long cur_state;
+	u32 max_cooling_state;
+	struct thermal_cooling_device *cdev;
+} *galert_data;
+
+static bool clk_update_disabled;
+
+static struct {
+	unsigned long bw;
+	unsigned long iso_bw;
+	unsigned long non_iso_cap;
+	unsigned long iso_cap;
+	unsigned long floor;
+	unsigned long total_bw_aftr_eff;
+	unsigned long iso_bw_aftr_eff;
+	unsigned long calc_freq;
+	unsigned long req_freq;
+} debug_info;
+
+static void bwmgr_debugfs_init(void);
+
+/* keep in sync with tegra_bwmgr_client_id */
+static const char * const tegra_bwmgr_client_names[] = {
+	"cpu_cluster_0",
+	"cpu_cluster_1",
+	"cpu_cluster_2",
+	"cpu_cluster_3",
+	"disp_0",
+	"disp_1",
+	"disp_2",
+	"disp1_la_emc",
+	"disp2_la_emc",
+	"usbd",
+	"xhci",
+	"sdmmc1",
+	"sdmmc2",
+	"sdmmc3",
+	"sdmmc4",
+	"mon",
+	"gpu",
+	"msenc",
+	"nvenc1",
+	"nvjpg",
+	"nvdec",
+	"nvdec1",
+	"tsec",
+	"tsecb",
+	"vi",
+	"ispa",
+	"ispb",
+	"camera",
+	"camera_non_iso",
+	"camrtc",
+	"isomgr",
+	"thermal",
+	"vic",
+	"adsp",
+	"adma",
+	"pcie",
+	"pcie_1",
+	"pcie_2",
+	"pcie_3",
+	"pcie_4",
+	"pcie_5",
+	"bbc_0",
+	"eqos",
+	"se0",
+	"se1",
+	"se2",
+	"se3",
+	"se4",
+	"pmqos",
+	"nvpmodel",
+	"debug",
+	"nvdla0",
+	"nvdla1",
+	"null",
+};
+
+#if defined(CONFIG_DEBUG_FS) && defined(CONFIG_TRACEPOINTS)
+static const char *bwmgr_req_to_name(enum tegra_bwmgr_request_type req)
+{
+	/* Keep in sync with enum tegra_bwmgr_request_type. */
+	switch (req) {
+	case TEGRA_BWMGR_SET_EMC_FLOOR:
+		return "TEGRA_BWMGR_SET_EMC_FLOOR";
+	case TEGRA_BWMGR_SET_EMC_CAP:
+		return "TEGRA_BWMGR_SET_EMC_CAP";
+	case TEGRA_BWMGR_SET_EMC_ISO_CAP:
+		return "TEGRA_BWMGR_SET_EMC_ISO_CAP";
+	case TEGRA_BWMGR_SET_EMC_SHARED_BW:
+		return "TEGRA_BWMGR_SET_EMC_SHARED_BW";
+	case TEGRA_BWMGR_SET_EMC_SHARED_BW_ISO:
+		return "TEGRA_BWMGR_SET_EMC_SHARED_BW_ISO";
+	default:
+		return "INVALID_REQUEST";
+	}
+}
+#endif /* defined(CONFIG_DEBUG_FS) && defined(CONFIG_TRACEPOINTS) */
+
+static inline bool bwmgr_lock(void)
+{
+	/* disallow rentrance, avoid deadlock */
+	if (unlikely(bwmgr.task == current)) {
+		pr_err("bwmgr: %s deadlock ?\n", __func__);
+		dump_stack();
+		return false;
+	}
+	mutex_lock(&bwmgr.lock);
+	bwmgr.task = current;
+	return true;
+}
+
+static inline bool bwmgr_unlock(void)
+{
+	/* detect mismatched calls */
+	if (unlikely(bwmgr.task != current)) {
+		pr_err("bwmgr: %s mismatch ?\n", __func__);
+		dump_stack();
+		return false;
+	}
+	bwmgr.task = NULL;
+	mutex_unlock(&bwmgr.lock);
+	return true;
+}
+
+/* call with bwmgr lock held except during init*/
+static void purge_client(struct tegra_bwmgr_client *handle)
+{
+	handle->bw = 0;
+	handle->iso_bw = 0;
+	handle->cap = bwmgr.emc_max_rate;
+	handle->iso_cap = bwmgr.emc_max_rate;
+	handle->floor = 0;
+	handle->refcount = 0;
+}
+
+static unsigned long tegra_bwmgr_apply_efficiency(
+		unsigned long total_bw, unsigned long iso_bw,
+		unsigned long max_rate, u64 usage_flags,
+		unsigned long *iso_bw_min, unsigned long iso_bw_nvdis,
+		unsigned long iso_bw_vi)
+{
+	return bwmgr.ops->bwmgr_apply_efficiency(total_bw, iso_bw,
+			max_rate, usage_flags, iso_bw_min,
+			iso_bw_nvdis, iso_bw_vi);
+}
+
+/* call with bwmgr lock held */
+static int bwmgr_update_clk(void)
+{
+	int i;
+	unsigned long bw = 0;
+	unsigned long iso_bw = 0; // iso_bw_guarantee
+	unsigned long iso_bw_nvdis = 0; //DISP0 + DISP1 + DISP2
+	unsigned long iso_bw_vi = 0; //CAMERA
+	unsigned long iso_bw_other_clients = 0; //Other ISO clients
+	unsigned long non_iso_cap = bwmgr.emc_max_rate;
+	unsigned long iso_cap = bwmgr.emc_max_rate;
+	unsigned long floor = 0;
+	unsigned long iso_bw_min;
+	u64 iso_client_flags = 0;
+	int ret = 0;
+
+	/* sizeof(iso_client_flags) */
+	BUILD_BUG_ON(TEGRA_BWMGR_CLIENT_COUNT > 64);
+	/* check that lock is held */
+	if (unlikely(bwmgr.task != current)) {
+		pr_err("bwmgr: %s called without lock\n", __func__);
+		return -EINVAL;
+	}
+
+	if (bwmgr.override)
+		return 0;
+
+	for (i = 0; i < TEGRA_BWMGR_CLIENT_COUNT; i++) {
+		bw += bwmgr.bwmgr_client[i].bw;
+		bw = min(bw, bwmgr.emc_max_rate);
+
+		if (bwmgr.bwmgr_client[i].iso_bw > 0) {
+			iso_client_flags |= BIT(i);
+
+			if ((i == TEGRA_BWMGR_CLIENT_DISP0) ||
+					(i == TEGRA_BWMGR_CLIENT_DISP1) ||
+					(i == TEGRA_BWMGR_CLIENT_DISP2)) {
+				iso_bw_nvdis += bwmgr.bwmgr_client[i].iso_bw;
+				iso_bw_nvdis = min(iso_bw_nvdis,
+							bwmgr.emc_max_rate);
+			} else if (i == TEGRA_BWMGR_CLIENT_CAMERA) {
+				iso_bw_vi += bwmgr.bwmgr_client[i].iso_bw;
+				iso_bw_vi = min(iso_bw_vi, bwmgr.emc_max_rate);
+			} else {
+				iso_bw_other_clients +=
+						bwmgr.bwmgr_client[i].iso_bw;
+				iso_bw_other_clients = min(iso_bw_other_clients,
+							bwmgr.emc_max_rate);
+			}
+
+			iso_bw = iso_bw_nvdis + iso_bw_vi +
+						iso_bw_other_clients;
+			iso_bw = min(iso_bw, bwmgr.emc_max_rate);
+		}
+
+		non_iso_cap = min(non_iso_cap, bwmgr.bwmgr_client[i].cap);
+		iso_cap = min(iso_cap, bwmgr.bwmgr_client[i].iso_cap);
+		floor = max(floor, bwmgr.bwmgr_client[i].floor);
+	}
+	debug_info.bw = bw;
+	debug_info.iso_bw = iso_bw;
+	debug_info.floor = floor;
+	debug_info.iso_cap = iso_cap;
+	debug_info.non_iso_cap = non_iso_cap;
+	bw += iso_bw;
+	bw = tegra_bwmgr_apply_efficiency(
+			bw, iso_bw, bwmgr.emc_max_rate,
+			iso_client_flags, &iso_bw_min,
+			iso_bw_nvdis, iso_bw_vi);
+	debug_info.total_bw_aftr_eff = bw;
+	debug_info.iso_bw_aftr_eff = iso_bw_min;
+	floor = min(floor, bwmgr.emc_max_rate);
+	bw = max(bw, floor);
+	bw = min(bw, min(iso_cap, max(non_iso_cap, iso_bw_min)));
+	debug_info.calc_freq = bw;
+	debug_info.req_freq = bw;
+
+	ret = clk_set_rate(bwmgr.emc_clk, bw);
+	if (ret)
+		pr_err
+		("bwmgr: clk_set_rate failed for freq %lu Hz with errno %d\n",
+				bw, ret);
+
+	return ret;
+}
+
+struct tegra_bwmgr_client *tegra_bwmgr_register(
+		enum tegra_bwmgr_client_id client)
+{
+	if (!bwmgr_dram_config_supported) {
+		pr_err("bwmgr: ddr config not supported\n");
+		WARN_ON(true);
+		return ERR_PTR(-EINVAL);
+	}
+
+	if ((client >= TEGRA_BWMGR_CLIENT_COUNT) || (client < 0)) {
+		pr_err("bwmgr: invalid client id %d tried to register",
+				client);
+		WARN_ON(true);
+		return ERR_PTR(-EINVAL);
+	}
+
+	if (!bwmgr_lock()) {
+		pr_err("bwmgr: %s failed for client %s\n",
+			__func__, tegra_bwmgr_client_names[client]);
+		return ERR_PTR(-EINVAL);
+	}
+
+	(bwmgr.bwmgr_client + client)->refcount++;
+
+	if (!bwmgr_unlock()) {
+		pr_err("bwmgr: %s failed for client %s\n",
+			__func__, tegra_bwmgr_client_names[client]);
+		return ERR_PTR(-EINVAL);
+	}
+	return (bwmgr.bwmgr_client + client);
+}
+EXPORT_SYMBOL_GPL(tegra_bwmgr_register);
+
+void tegra_bwmgr_unregister(struct tegra_bwmgr_client *handle)
+{
+	if (!IS_HANDLE_VALID(handle)) {
+		WARN_ON(true);
+		return;
+	}
+
+	if (!bwmgr_lock()) {
+		pr_err("bwmgr: %s failed for client %s\n",
+			__func__,
+			tegra_bwmgr_client_names[handle - bwmgr.bwmgr_client]);
+		return;
+	}
+	handle->refcount--;
+
+	if (handle->refcount <= 0) {
+		if (handle->refcount < 0) {
+			pr_err("bwmgr: Mismatched unregister call, client %ld\n",
+				handle - bwmgr.bwmgr_client);
+			WARN_ON(true);
+		}
+		purge_client(handle);
+	}
+
+	if (!bwmgr_unlock()) {
+		pr_err("bwmgr: %s failed for client %s\n",
+			__func__,
+			tegra_bwmgr_client_names[handle - bwmgr.bwmgr_client]);
+		return;
+	}
+}
+EXPORT_SYMBOL_GPL(tegra_bwmgr_unregister);
+
+u8 tegra_bwmgr_get_dram_num_channels(void)
+{
+	return bwmgr_dram_num_channels;
+}
+EXPORT_SYMBOL_GPL(tegra_bwmgr_get_dram_num_channels);
+
+unsigned long tegra_bwmgr_get_max_emc_rate(void)
+{
+	return bwmgr.emc_max_rate;
+}
+EXPORT_SYMBOL_GPL(tegra_bwmgr_get_max_emc_rate);
+
+/* Returns the ratio between dram and emc freq based on the type of dram */
+int bwmgr_get_emc_to_dram_freq_factor(void)
+{
+	return emc_to_dram_freq_factor;
+}
+EXPORT_SYMBOL_GPL(bwmgr_get_emc_to_dram_freq_factor);
+
+/* Returns the actual emc frequency calculated using the dram
+ * frequency and emc_to_dram conversion factor
+ */
+unsigned long tegra_bwmgr_get_core_emc_rate(void)
+{
+	return (unsigned long)(tegra_bwmgr_get_emc_rate() /
+		bwmgr_get_emc_to_dram_freq_factor());
+}
+EXPORT_SYMBOL_GPL(tegra_bwmgr_get_core_emc_rate);
+
+unsigned long tegra_bwmgr_round_rate(unsigned long bw)
+{
+	if (bwmgr.emc_clk)
+		return clk_round_rate(bwmgr.emc_clk, bw);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(tegra_bwmgr_round_rate);
+
+int tegra_bwmgr_set_emc(struct tegra_bwmgr_client *handle, unsigned long val,
+		enum tegra_bwmgr_request_type req)
+{
+	int ret = 0;
+	bool update_clk = false;
+
+	if (!bwmgr.emc_clk)
+		return 0;
+
+	if (!bwmgr.status)
+		return 0;
+
+	if (!bwmgr_dram_config_supported) {
+		pr_err("bwmgr: ddr config not supported\n");
+		WARN_ON(true);
+		return -EINVAL;
+	}
+
+	if (!IS_HANDLE_VALID(handle)) {
+		pr_err("bwmgr: client sent bad handle %p\n",
+				handle);
+		WARN_ON(true);
+		return -EINVAL;
+	}
+
+	if (req >= TEGRA_BWMGR_SET_EMC_REQ_COUNT) {
+		pr_err("bwmgr: client %ld sent bad request type %d\n",
+				handle - bwmgr.bwmgr_client, req);
+		WARN_ON(true);
+		return -EINVAL;
+	}
+
+	if (!bwmgr_lock()) {
+		pr_err("bwmgr: %s failed for client %s\n",
+			__func__,
+			tegra_bwmgr_client_names[handle - bwmgr.bwmgr_client]);
+		return -EINVAL;
+	}
+
+#ifdef CONFIG_TRACEPOINTS
+	trace_tegra_bwmgr_set_emc(
+			tegra_bwmgr_client_names[handle - bwmgr.bwmgr_client],
+			val, bwmgr_req_to_name(req));
+#endif /* CONFIG_TRACEPOINTS */
+
+	switch (req) {
+	case TEGRA_BWMGR_SET_EMC_FLOOR:
+		if (handle->floor != val) {
+			handle->floor = val;
+			update_clk = true;
+		}
+		break;
+
+	case TEGRA_BWMGR_SET_EMC_CAP:
+		if (val == 0)
+			val = bwmgr.emc_max_rate;
+
+		if (handle->cap != val) {
+			handle->cap = val;
+			update_clk = true;
+		}
+		break;
+
+	case TEGRA_BWMGR_SET_EMC_ISO_CAP:
+		if (val == 0)
+			val = bwmgr.emc_max_rate;
+
+		if (handle->iso_cap != val) {
+			handle->iso_cap = val;
+			update_clk = true;
+		}
+		break;
+
+	case TEGRA_BWMGR_SET_EMC_SHARED_BW:
+		if (handle->bw != val) {
+			handle->bw = val;
+			update_clk = true;
+		}
+		break;
+
+	case TEGRA_BWMGR_SET_EMC_SHARED_BW_ISO:
+		if (handle->iso_bw != val) {
+			handle->iso_bw = val;
+			update_clk = true;
+		}
+		break;
+
+	default:
+		WARN_ON(true);
+		if (!bwmgr_unlock()) {
+			pr_err("bwmgr: %s failed for client %s\n",
+			__func__,
+			tegra_bwmgr_client_names[handle - bwmgr.bwmgr_client]);
+			return -EINVAL;
+		}
+		return -EINVAL;
+	}
+
+	if (update_clk && !clk_update_disabled)
+		ret = bwmgr_update_clk();
+
+	if (!bwmgr_unlock()) {
+		pr_err("bwmgr: %s failed for client %s\n",
+			__func__,
+			tegra_bwmgr_client_names[handle - bwmgr.bwmgr_client]);
+		return -EINVAL;
+	}
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(tegra_bwmgr_set_emc);
+
+int tegra_bwmgr_get_client_info(struct tegra_bwmgr_client *handle,
+		unsigned long *out_val,
+		enum tegra_bwmgr_request_type req)
+{
+	if (!bwmgr.emc_clk)
+		return 0;
+
+	if (!bwmgr.status)
+		return 0;
+
+	if (!bwmgr_dram_config_supported) {
+		pr_err("bwmgr: ddr config not supported\n");
+		WARN_ON(true);
+		return -EINVAL;
+	}
+
+	if (!IS_HANDLE_VALID(handle)) {
+		pr_err("bwmgr: client sent bad handle %p\n",
+				handle);
+		WARN_ON(true);
+		return -EINVAL;
+	}
+
+	if (req >= TEGRA_BWMGR_SET_EMC_REQ_COUNT) {
+		pr_err("bwmgr: client %ld sent bad request type %d\n",
+				handle - bwmgr.bwmgr_client, req);
+		WARN_ON(true);
+		return -EINVAL;
+	}
+
+	if (!bwmgr_lock()) {
+		pr_err("bwmgr: %s failed for client %s\n",
+			__func__,
+			tegra_bwmgr_client_names[handle - bwmgr.bwmgr_client]);
+		return -EINVAL;
+	}
+
+	switch (req) {
+	case TEGRA_BWMGR_SET_EMC_FLOOR:
+		*out_val = handle->floor;
+		break;
+
+	case TEGRA_BWMGR_SET_EMC_CAP:
+		*out_val = handle->cap;
+		break;
+
+	case TEGRA_BWMGR_SET_EMC_ISO_CAP:
+		*out_val = handle->iso_cap;
+		break;
+
+	case TEGRA_BWMGR_SET_EMC_SHARED_BW:
+		*out_val = handle->bw;
+		break;
+
+	case TEGRA_BWMGR_SET_EMC_SHARED_BW_ISO:
+		*out_val = handle->iso_bw;
+		break;
+
+	default:
+		WARN_ON(true);
+		if (!bwmgr_unlock()) {
+			pr_err("bwmgr: %s failed for client %s\n",
+			__func__,
+			tegra_bwmgr_client_names[handle - bwmgr.bwmgr_client]);
+			return -EINVAL;
+		}
+		return -EINVAL;
+	}
+
+	if (!bwmgr_unlock()) {
+		pr_err("bwmgr: %s failed for client %s\n",
+			__func__,
+			tegra_bwmgr_client_names[handle - bwmgr.bwmgr_client]);
+		return -EINVAL;
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(tegra_bwmgr_get_client_info);
+
+int tegra_bwmgr_notifier_register(struct notifier_block *nb)
+{
+	if (!nb)
+		return -EINVAL;
+
+	if (bwmgr.emc_clk)
+		return clk_notifier_register(bwmgr.emc_clk, nb);
+	else
+		return -ENODEV;
+}
+EXPORT_SYMBOL_GPL(tegra_bwmgr_notifier_register);
+
+int tegra_bwmgr_notifier_unregister(struct notifier_block *nb)
+{
+	if (!nb)
+		return -EINVAL;
+
+	if (bwmgr.emc_clk)
+		return clk_notifier_unregister(bwmgr.emc_clk, nb);
+	else
+		return -ENODEV;
+}
+EXPORT_SYMBOL_GPL(tegra_bwmgr_notifier_unregister);
+
+unsigned long tegra_bwmgr_get_emc_rate(void)
+{
+	if (bwmgr.emc_clk)
+		return clk_get_rate(bwmgr.emc_clk);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(tegra_bwmgr_get_emc_rate);
+
+/* bwmgr_get_lowest_iso_emc_freq
+ * bwmgr_apply_efficiency function will use this api to calculate
+ * the lowest emc frequency that satisfies the requests of ISO clients.
+ *
+ * A return value of 0 indicates that the requested
+ * iso bandwidth cannot be supported.
+ */
+unsigned long bwmgr_get_lowest_iso_emc_freq(long iso_bw,
+				long iso_bw_nvdis, long iso_bw_vi)
+{
+	return bwmgr.ops->get_best_iso_freq(iso_bw, iso_bw_nvdis, iso_bw_vi);
+}
+EXPORT_SYMBOL_GPL(bwmgr_get_lowest_iso_emc_freq);
+
+/* tegra_bwmgr_get_max_iso_bw
+ * This function returns the max iso bw.
+ * This is applicable from t19x onwards, where max_iso is different
+ * based on clients requesting.
+ * This should not be called on pre t19x and returns 0 in those cases
+ */
+u32 tegra_bwmgr_get_max_iso_bw(enum tegra_iso_client client)
+{
+	if (bwmgr.ops->get_max_iso_bw)
+		return bwmgr.ops->get_max_iso_bw(client);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(tegra_bwmgr_get_max_iso_bw);
+
+int bwmgr_iso_bw_percentage_max(void)
+{
+	return bwmgr_iso_bw_percentage;
+}
+EXPORT_SYMBOL_GPL(bwmgr_iso_bw_percentage_max);
+
+unsigned long bwmgr_freq_to_bw(unsigned long freq)
+{
+	return bwmgr.ops->freq_to_bw(freq);
+}
+EXPORT_SYMBOL_GPL(bwmgr_freq_to_bw);
+
+unsigned long bwmgr_bw_to_freq(unsigned long bw)
+{
+	return bwmgr.ops->bw_to_freq(bw);
+}
+EXPORT_SYMBOL_GPL(bwmgr_bw_to_freq);
+
+u32 bwmgr_dvfs_latency(u32 ufreq)
+{
+	return bwmgr.ops->dvfs_latency(ufreq);
+}
+EXPORT_SYMBOL_GPL(bwmgr_dvfs_latency);
+
+/* Get maximum throttle state supported by bwmgr cooling device. */
+static int dram_ref_alert_cdev_max_state(struct thermal_cooling_device *tcd,
+			unsigned long *state)
+{
+	struct dram_refresh_alrt *alert_data = tcd->devdata;
+
+	if (!alert_data)
+		return -EINVAL;
+
+	*state = (unsigned long)alert_data->max_cooling_state;
+	return 0;
+}
+
+/* Get current throttle state of the bwmgr cooling device. */
+static int dram_ref_alert_cdev_cur_state(struct thermal_cooling_device *tcd,
+			unsigned long *state)
+{
+	struct dram_refresh_alrt *alert_data = tcd->devdata;
+
+	if (!alert_data)
+		return -EINVAL;
+
+	*state = alert_data->cur_state;
+	return 0;
+}
+
+static int tegra_bwmgr_update_efficiency(unsigned long cur_state,
+				unsigned long prev_state)
+{
+	int ret = 0;
+
+#ifdef CONFIG_TRACEPOINTS
+	trace_tegra_bwmgr_update_efficiency(
+			cur_state, prev_state);
+#endif /* CONFIG_TRACEPOINTS */
+
+	/* At this point, the thermal framework has indicated that
+	 * the trip point has been crossed for AO-therm zone. However,
+	 * this does not guarantee dram refresh rate has been changed.
+	 * talk to bpmp at this point to find out if dram refresh rate
+	 * has changed or not. This will be implemented once the bpmp
+	 * IPC's are ready.For now update efficiency.
+	 */
+	if (!bwmgr_lock()) {
+		pr_err("bwmgr: %s failed\n", __func__);
+		return -EINVAL;
+	}
+
+	if (bwmgr.override) {
+		bwmgr_unlock();
+		return 0;
+	}
+
+	if (bwmgr.ops->update_efficiency)
+		bwmgr.ops->update_efficiency(cur_state);
+
+	if (!clk_update_disabled)
+		ret = bwmgr_update_clk();
+
+	if (!bwmgr_unlock()) {
+		pr_err("bwmgr: %s failed.\n", __func__);
+		return -EINVAL;
+	}
+
+	return ret;
+}
+
+/* Set current throttle state of the bwmgr cooling device. */
+static int dram_ref_alert_cdev_set_state(struct thermal_cooling_device *tcd,
+				unsigned long state)
+{
+	int ret = 0;
+	unsigned long prev_state;
+	struct dram_refresh_alrt *alert_data = tcd->devdata;
+
+	if (!alert_data)
+		return -EINVAL;
+
+	prev_state = alert_data->cur_state;
+	alert_data->cur_state = state;
+
+	ret = tegra_bwmgr_update_efficiency(state, prev_state);
+
+	return ret;
+}
+
+/*
+ * Cooling device operations.
+ */
+static struct thermal_cooling_device_ops dram_ref_alert_cdev_ops = {
+	.get_max_state = dram_ref_alert_cdev_max_state,
+	.get_cur_state = dram_ref_alert_cdev_cur_state,
+	.set_cur_state = dram_ref_alert_cdev_set_state,
+};
+
+int __init bwmgr_init(void)
+{
+	int i;
+	struct device_node *dn;
+	long round_rate;
+	struct clk *emc_master_clk;
+
+	mutex_init(&bwmgr.lock);
+
+	if (tegra_get_chip_id() == TEGRA210)
+		bwmgr.ops = bwmgr_eff_init_t21x();
+	else if (tegra_get_chip_id() == TEGRA186)
+		bwmgr.ops = bwmgr_eff_init_t18x();
+	else if (tegra_get_chip_id() == TEGRA194)
+		bwmgr.ops = bwmgr_eff_init_t19x();
+	else
+		/*
+		 * Fall back to t19x if we are running on a new chip.
+		 */
+		bwmgr.ops = bwmgr_eff_init_t19x();
+
+	dn = of_find_compatible_node(NULL, NULL, "nvidia,bwmgr");
+	if (dn == NULL) {
+		pr_err("bwmgr: dt node not found.\n");
+		return -ENODEV;
+	}
+
+	bwmgr.emc_clk = of_clk_get(dn, 0);
+	if (IS_ERR_OR_NULL(bwmgr.emc_clk)) {
+		pr_err("bwmgr: couldn't find emc clock.\n");
+		bwmgr.emc_clk = NULL;
+		WARN_ON(true);
+		return -ENODEV;
+	}
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 14, 0)
+	clk_prepare_enable(bwmgr.emc_clk);
+#endif
+
+	emc_master_clk = bwmgr.emc_clk;
+	if (of_property_read_bool(dn, "nvidia,bwmgr-use-shared-master"))
+		emc_master_clk = clk_get_parent(emc_master_clk);
+
+	round_rate = clk_round_rate(emc_master_clk, 0);
+	if (round_rate < 0) {
+		bwmgr.emc_min_rate = 0;
+		pr_err("bwmgr: couldn't get emc clock min rate.\n");
+	} else
+		bwmgr.emc_min_rate = (unsigned long)round_rate;
+
+	/* Use LONG_MAX as downstream functions treats rate arg as signed */
+	round_rate = clk_round_rate(emc_master_clk, LONG_MAX);
+	if (round_rate < 0) {
+		bwmgr.emc_max_rate = 0;
+		pr_err("bwmgr: couldn't get emc clock max rate.\n");
+	} else
+		bwmgr.emc_max_rate = (unsigned long)round_rate;
+
+	/* On some pre-si platforms max rate is acquired via DT */
+	if (tegra_platform_is_sim() || tegra_platform_is_fpga()) {
+		if (of_property_read_u64(dn, "max_rate_Hz",
+					(u64 *) &round_rate) == 0) {
+			pr_err("bwmgr: using max rate from device tree.\n");
+			bwmgr.emc_max_rate = round_rate;
+		}
+	}
+
+	for (i = 0; i < TEGRA_BWMGR_CLIENT_COUNT; i++)
+		purge_client(bwmgr.bwmgr_client + i);
+
+	bwmgr_debugfs_init();
+	pmqos_bwmgr_init();
+
+	/* Check status property is okay or not. */
+	if (of_device_is_available(dn))
+		bwmgr.status = true;
+	else
+		bwmgr.status = false;
+
+	return 0;
+}
+subsys_initcall_sync(bwmgr_init);
+
+void __exit bwmgr_exit(void)
+{
+	int i;
+
+	for (i = 0; i < TEGRA_BWMGR_CLIENT_COUNT; i++)
+		purge_client(bwmgr.bwmgr_client + i);
+
+	bwmgr.emc_clk = NULL;
+	mutex_destroy(&bwmgr.lock);
+
+	if (galert_data)
+		thermal_cooling_device_unregister(galert_data->cdev);
+
+	kfree(galert_data);
+}
+module_exit(bwmgr_exit);
+
+static int __init bwmgr_cooling_init(void)
+{
+	struct device_node *dn;
+	char *cdev_type;
+	const char *str;
+	int ret = 0;
+
+	galert_data = kzalloc(sizeof(struct dram_refresh_alrt),
+					GFP_KERNEL);
+	if (!galert_data)
+		return -ENOMEM;
+
+	dn = of_find_compatible_node(NULL, NULL, "nvidia,bwmgr");
+	if (dn == NULL) {
+		pr_err("bwmgr: dt node not found.\n");
+		ret = -ENODEV;
+		goto error;
+	}
+
+	if (of_property_read_string(dn, "cdev-type", &str) == 0) {
+		cdev_type = (char *)str;
+	} else {
+		pr_info("bwmgr: missing cdev-type property\n");
+		goto error;
+	}
+
+	if (of_property_read_u32(dn, "cooling-max-state",
+				&(galert_data->max_cooling_state))) {
+		pr_err("bwmgr: missing max_cooling_state property\n");
+		ret = -EINVAL;
+		goto error;
+	}
+
+	galert_data->cur_state = 0;
+	galert_data->cdev = thermal_of_cooling_device_register(dn, cdev_type,
+				galert_data, &dram_ref_alert_cdev_ops);
+
+	if (IS_ERR(galert_data->cdev)) {
+		ret = PTR_ERR(galert_data->cdev);
+		pr_err("bwmgr: failed to register to thermal framework\n");
+		goto error;
+	}
+
+	return 0;
+
+error:
+	kfree(galert_data);
+	return ret;
+}
+late_initcall(bwmgr_cooling_init);
+/* thermal_init is fs_init, make bwmgr_cooling_init late_init as it
+ * depends on thermal_init
+ */
+
+#ifdef CONFIG_DEBUG_FS
+static struct tegra_bwmgr_client *bwmgr_debugfs_client_handle;
+static struct dentry *debugfs_dir;
+static struct dentry *debugfs_node_floor;
+static struct dentry *debugfs_node_cap;
+static struct dentry *debugfs_node_iso_cap;
+static struct dentry *debugfs_node_bw;
+static struct dentry *debugfs_node_iso_bw;
+static struct dentry *debugfs_node_emc_rate;
+static struct dentry *debugfs_node_emc_min;
+static struct dentry *debugfs_node_emc_max;
+static struct dentry *debugfs_node_core_emc_rate;
+static struct dentry *debugfs_node_clients_info;
+static struct dentry *debugfs_node_dram_channels;
+
+static int bwmgr_debugfs_emc_rate_set(void *data, u64 val)
+{
+	int ret = 0;
+
+	if (!bwmgr_lock())
+		return -EPERM;
+
+	if (val == 0) {
+		bwmgr.override = false;
+		bwmgr_update_clk();
+	} else if (bwmgr.emc_clk) {
+		bwmgr.override = true;
+		ret = clk_set_rate(bwmgr.emc_clk, val);
+	}
+
+	if (!bwmgr_unlock())
+		return -EPERM;
+
+	return ret;
+}
+
+static int bwmgr_debugfs_emc_rate_get(void *data, u64 *val)
+{
+	*val = tegra_bwmgr_get_emc_rate();
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(fops_debugfs_emc_rate, bwmgr_debugfs_emc_rate_get,
+		bwmgr_debugfs_emc_rate_set, "%llu\n");
+
+static int bwmgr_debugfs_core_emc_rate_get(void *data, u64 *val)
+{
+	*val = tegra_bwmgr_get_core_emc_rate();
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(fops_debugfs_core_emc_rate,
+	bwmgr_debugfs_core_emc_rate_get, NULL, "%llu\n");
+
+static int bwmgr_debugfs_dram_channels_get(void *data, u64 *val)
+{
+	*val = bwmgr_dram_num_channels;
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(fops_debugfs_dram_channels,
+	bwmgr_debugfs_dram_channels_get, NULL, "%llu\n");
+
+static int bwmgr_debugfs_floor_set(void *data, u64 val)
+{
+	tegra_bwmgr_set_emc(bwmgr_debugfs_client_handle, val,
+			TEGRA_BWMGR_SET_EMC_FLOOR);
+	return 0;
+}
+
+static int bwmgr_debugfs_floor_get(void *data, u64 *val)
+{
+	*val = bwmgr_debugfs_client_handle->floor;
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(fops_debugfs_floor, bwmgr_debugfs_floor_get,
+		bwmgr_debugfs_floor_set, "%llu\n");
+
+static int bwmgr_debugfs_cap_set(void *data, u64 val)
+{
+	tegra_bwmgr_set_emc(bwmgr_debugfs_client_handle, val,
+			TEGRA_BWMGR_SET_EMC_CAP);
+	return 0;
+}
+
+static int bwmgr_debugfs_cap_get(void *data, u64 *val)
+{
+	*val = bwmgr_debugfs_client_handle->cap;
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(fops_debugfs_cap, bwmgr_debugfs_cap_get,
+		bwmgr_debugfs_cap_set, "%llu\n");
+
+static int bwmgr_debugfs_iso_cap_set(void *data, u64 val)
+{
+	tegra_bwmgr_set_emc(bwmgr_debugfs_client_handle, val,
+			TEGRA_BWMGR_SET_EMC_ISO_CAP);
+	return 0;
+}
+
+static int bwmgr_debugfs_iso_cap_get(void *data, u64 *val)
+{
+	*val = bwmgr_debugfs_client_handle->iso_cap;
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(fops_debugfs_iso_cap, bwmgr_debugfs_iso_cap_get,
+		bwmgr_debugfs_iso_cap_set, "%llu\n");
+
+static int bwmgr_debugfs_bw_set(void *data, u64 val)
+{
+	tegra_bwmgr_set_emc(bwmgr_debugfs_client_handle, val,
+			TEGRA_BWMGR_SET_EMC_SHARED_BW);
+	return 0;
+}
+
+static int bwmgr_debugfs_bw_get(void *data, u64 *val)
+{
+	*val = bwmgr_debugfs_client_handle->bw;
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(fops_debugfs_bw, bwmgr_debugfs_bw_get,
+		bwmgr_debugfs_bw_set, "%llu\n");
+
+static int bwmgr_debugfs_iso_bw_set(void *data, u64 val)
+{
+	tegra_bwmgr_set_emc(bwmgr_debugfs_client_handle, val,
+			TEGRA_BWMGR_SET_EMC_SHARED_BW_ISO);
+	return 0;
+}
+
+static int bwmgr_debugfs_iso_bw_get(void *data, u64 *val)
+{
+	*val = bwmgr_debugfs_client_handle->iso_bw;
+	return 0;
+}
+
+static int bwmgr_clients_info_show(struct seq_file *s, void *data)
+{
+	int i;
+
+	if (!bwmgr_lock()) {
+		pr_err("bwmgr: %s failed\n", __func__);
+		return -EINVAL;
+	}
+	seq_printf(s, "%15s%15s%15s%15s%15s%15s (Khz)\n", "Client",
+			"Floor", "SharedBw", "SharedIsoBw", "Cap",
+			"IsoCap");
+	for (i = 0; i < TEGRA_BWMGR_CLIENT_COUNT; i++) {
+		seq_printf(s, "%14s%s%15lu%15lu%15lu%15lu%15lu\n",
+				tegra_bwmgr_client_names[i],
+				bwmgr.bwmgr_client[i].refcount ? "*" : " ",
+				bwmgr.bwmgr_client[i].floor / 1000,
+				bwmgr.bwmgr_client[i].bw / 1000,
+				bwmgr.bwmgr_client[i].iso_bw / 1000,
+				bwmgr.bwmgr_client[i].cap / 1000,
+				bwmgr.bwmgr_client[i].iso_cap / 1000);
+	}
+	seq_printf(s, "Total BW requested                              : %lu (Khz)\n",
+				 debug_info.bw / 1000);
+	seq_printf(s, "Total ISO_BW requested                          : %lu (Khz)\n",
+				 debug_info.iso_bw / 1000);
+	seq_printf(s, "Effective floor request                         : %lu (Khz)\n",
+				 debug_info.floor / 1000);
+	seq_printf(s, "Effective NON_ISO_CAP                           : %lu (Khz)\n",
+				 debug_info.non_iso_cap / 1000);
+	seq_printf(s, "Effective ISO_CAP                               : %lu (Khz)\n",
+				 debug_info.iso_cap / 1000);
+	seq_printf(s, "Total BW + ISO_BW                               : %lu (Khz)\n",
+				 (debug_info.bw + debug_info.iso_bw) / 1000);
+	seq_printf(s, "Total BW+ISO_BW after applying efficieny numbers: %lu (Khz)\n",
+				 debug_info.total_bw_aftr_eff / 1000);
+	seq_printf(s, "Total ISO_BW after applying efficiency          : %lu (Khz)\n",
+				 debug_info.iso_bw_aftr_eff / 1000);
+	seq_printf(s, "EMC calculated rate                             : %lu (Khz)\n",
+				 debug_info.calc_freq / 1000);
+	seq_printf(s, "EMC requested(rounded) rate                     : %lu (Khz)\n",
+				 debug_info.req_freq / 1000);
+	seq_printf(s, "EMC current rate                                : %lu (Khz)\n",
+				 tegra_bwmgr_get_emc_rate() / 1000);
+	if (!bwmgr_unlock()) {
+		pr_err("bwmgr: %s failed\n", __func__);
+		return -EINVAL;
+	}
+	return 0;
+}
+DEFINE_SIMPLE_ATTRIBUTE(fops_debugfs_iso_bw, bwmgr_debugfs_iso_bw_get,
+		bwmgr_debugfs_iso_bw_set, "%llu\n");
+
+static int bwmgr_clients_info_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, bwmgr_clients_info_show, inode->i_private);
+}
+
+static const struct file_operations fops_bwmgr_clients_info = {
+	.open = bwmgr_clients_info_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = single_release,
+};
+
+static void bwmgr_debugfs_init(void)
+{
+	bwmgr_debugfs_client_handle =
+		tegra_bwmgr_register(TEGRA_BWMGR_CLIENT_DEBUG);
+
+	if (IS_ERR_OR_NULL(bwmgr_debugfs_client_handle)) {
+		bwmgr_debugfs_client_handle = NULL;
+		pr_err("bwmgr: could not register bwmgr debugfs client\n");
+		return;
+	}
+
+	debugfs_dir = debugfs_create_dir("tegra_bwmgr", NULL);
+	if (debugfs_dir) {
+		debugfs_create_bool(
+			"clk_update_disabled", S_IRWXU, debugfs_dir,
+			&clk_update_disabled);
+		debugfs_node_emc_min = debugfs_create_u64(
+			"emc_min_rate", S_IRUSR, debugfs_dir,
+			(u64 *) &bwmgr.emc_min_rate);
+		debugfs_node_emc_max = debugfs_create_u64(
+			"emc_max_rate", S_IRUSR, debugfs_dir,
+			(u64 *) &bwmgr.emc_max_rate);
+		debugfs_node_core_emc_rate = debugfs_create_file(
+			"core_emc_rate", S_IRUSR, debugfs_dir, NULL,
+			 &fops_debugfs_core_emc_rate);
+		debugfs_node_emc_rate = debugfs_create_file
+			("emc_rate", S_IRUSR, debugfs_dir, NULL,
+			 &fops_debugfs_emc_rate);
+		debugfs_node_floor = debugfs_create_file
+			("debug_client_floor", S_IRWXU, debugfs_dir, NULL,
+			 &fops_debugfs_floor);
+		debugfs_node_cap = debugfs_create_file
+			("debug_client_cap", S_IRWXU, debugfs_dir, NULL,
+			 &fops_debugfs_cap);
+		debugfs_node_iso_cap = debugfs_create_file
+			("debug_client_iso_cap", S_IRWXU, debugfs_dir, NULL,
+			 &fops_debugfs_iso_cap);
+		debugfs_node_bw = debugfs_create_file
+			("debug_client_bw", S_IRWXU, debugfs_dir, NULL,
+			 &fops_debugfs_bw);
+		debugfs_node_iso_bw = debugfs_create_file
+			("debug_client_iso_bw", S_IRWXU, debugfs_dir, NULL,
+			 &fops_debugfs_iso_bw);
+		debugfs_node_clients_info = debugfs_create_file
+			("bwmgr_clients_info", S_IRUGO, debugfs_dir, NULL,
+			 &fops_bwmgr_clients_info);
+		debugfs_node_dram_channels = debugfs_create_file(
+			"num_dram_channels", S_IRUSR, debugfs_dir, NULL,
+			 &fops_debugfs_dram_channels);
+	} else
+		pr_err("bwmgr: error creating bwmgr debugfs dir.\n");
+
+	if (!bwmgr_lock()) {
+		pr_err("bwmgr: %s failed\n", __func__);
+		return;
+	}
+	debug_info.non_iso_cap = bwmgr.emc_max_rate;
+	debug_info.iso_cap = bwmgr.emc_max_rate;
+	if (!bwmgr_unlock()) {
+		pr_err("bwmgr: %s failed\n", __func__);
+		return;
+	}
+}
+
+#else
+static void bwmgr_debugfs_init(void) {};
+#endif /* CONFIG_DEBUG_FS */
diff --git a/drivers/platform/tegra/mc/fixed_point.c b/drivers/platform/tegra/mc/fixed_point.c
new file mode 100644
index 000000000000..0e3697aed09d
--- /dev/null
+++ b/drivers/platform/tegra/mc/fixed_point.c
@@ -0,0 +1,600 @@
+/*
+ * Copyright (C) 2017-2018, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+#include <asm/bug.h>
+#include "fixed_point.h"
+
+
+#define FIX_PT_CHK_MATCH(chk_type, op1, op2) \
+	do { \
+		if (op1 != op2) { \
+			pr_err("%s: op %s do not match: %d != %d\n", \
+				__func__, chk_type, op1, op2); \
+			(*error) |= 1; \
+			WARN_ON(1); \
+		} \
+	} while (0)
+
+#define FIX_PT_CHK_MATCH_PREC(prec1, prec2) \
+	FIX_PT_CHK_MATCH("precisions", prec1, prec2)
+
+#define FIX_PT_CHK_MATCH_MASK(prec1, prec2) \
+	FIX_PT_CHK_MATCH("masks", prec1, prec2)
+
+struct fixed_point fixed_point_init(
+	unsigned int int_part,
+	unsigned int frac_part,
+	unsigned int int_prec,
+	unsigned int frac_prec,
+	unsigned int *error)
+{
+	struct fixed_point ret_fp;
+	unsigned int max_prec = (sizeof(unsigned int) * 8);
+
+	if (int_prec > max_prec) {
+		pr_err("%s: int_prec too large: %d > %d\n",
+			__func__, int_prec, max_prec);
+		(*error) |= 1;
+		WARN_ON(1);
+	} else if (int_prec == (sizeof(unsigned int) * 8))
+		ret_fp.int_mask = ((unsigned int)(-1));
+	else
+		ret_fp.int_mask = (1 << int_prec) - 1;
+
+	if (frac_prec > max_prec) {
+		pr_err("%s: frac_prec too large: %d > %d\n",
+			__func__, frac_prec, max_prec);
+		(*error) |= 1;
+		WARN_ON(1);
+	} else if (frac_prec == (sizeof(unsigned int) * 8))
+		ret_fp.frac_mask = ((unsigned int)(-1));
+	else
+		ret_fp.frac_mask = (1 << frac_prec) - 1;
+
+	ret_fp.int_part = int_part & ret_fp.int_mask;
+	ret_fp.frac_part = frac_part & ret_fp.frac_mask;
+	ret_fp.int_prec = int_prec;
+	ret_fp.frac_prec = frac_prec;
+
+	return ret_fp;
+}
+
+struct fixed_point fixed_point_shift_left(
+	struct fixed_point fp_arg,
+	unsigned int places,
+	unsigned int *error)
+{
+	struct fixed_point ret_fp;
+	unsigned int frac_mask;
+	unsigned int frac_shift;
+
+	if (places == 0)
+		return fp_arg;
+
+	ret_fp = fixed_point_init(
+		0,
+		0,
+		fp_arg.int_prec,
+		fp_arg.frac_prec,
+		error);
+
+	frac_mask = (places >= fp_arg.frac_prec) ? 0 :
+		(((((unsigned int)(1 << places)) - 1) << (fp_arg.frac_prec - places)) &
+			fp_arg.frac_mask);
+	frac_shift = (places >= fp_arg.frac_prec) ? 0 :
+		(fp_arg.frac_prec - places);
+
+	ret_fp.int_part = (places < fp_arg.int_prec) ?
+		((fp_arg.int_part << places) & fp_arg.int_mask) : 0;
+	ret_fp.int_part |= ((fp_arg.frac_part & frac_mask) >> frac_shift);
+	ret_fp.frac_part = (places < fp_arg.frac_prec) ?
+		((fp_arg.frac_part << places) & fp_arg.frac_mask) : 0;
+
+	return ret_fp;
+}
+
+struct fixed_point fixed_point_shift_right(
+	struct fixed_point fp_arg,
+	unsigned int places,
+	unsigned int *error)
+{
+	struct fixed_point ret_fp;
+	unsigned int int_mask = 0;
+	unsigned int frac_shift = 0;
+	int sign_ext = 0;
+
+	if (places == 0)
+		return fp_arg;
+
+	ret_fp = fixed_point_init(
+		0,
+		0,
+		fp_arg.int_prec,
+		fp_arg.frac_prec,
+		error);
+
+	ret_fp.int_part = (places < fp_arg.int_prec) ?
+		((fp_arg.int_part >> places) & fp_arg.int_mask) : 0;
+	if (fp_arg.int_part & (1 << (fp_arg.int_prec - 1))) { /* sign extend */
+		sign_ext = 1;
+		if (places < fp_arg.int_prec) {
+			ret_fp.int_part |=
+				((((1 << places) - 1) <<
+				(fp_arg.int_prec - places)) & fp_arg.int_mask);
+		} else {
+			ret_fp.int_part =
+				((unsigned int)(-1)) & ret_fp.int_mask;
+		}
+	}
+	ret_fp.frac_part = (places < fp_arg.frac_prec) ?
+		((fp_arg.frac_part >> places) & fp_arg.frac_mask) : 0;
+
+	if (places < fp_arg.frac_prec) {
+		int_mask = fp_arg.int_mask >> (fp_arg.int_prec - places);
+		frac_shift = fp_arg.frac_prec - places;
+		ret_fp.frac_part |=
+			(((fp_arg.int_part & int_mask) << frac_shift) &
+				fp_arg.frac_mask);
+	} else if (places < (fp_arg.int_prec + fp_arg.frac_prec)) {
+		int_mask = (fp_arg.int_mask << (places - fp_arg.frac_prec)) &
+			fp_arg.int_mask;
+		frac_shift = places - fp_arg.frac_prec;
+		ret_fp.frac_part |=
+			(((fp_arg.int_part & int_mask) >> frac_shift) &
+				fp_arg.frac_mask);
+		if (sign_ext) {
+			ret_fp.frac_part |=
+				(fp_arg.frac_mask <<
+					(fp_arg.frac_prec -
+					(places - fp_arg.frac_prec)));
+		}
+	} else {
+		if (sign_ext)
+			ret_fp.frac_part = fp_arg.frac_mask;
+	}
+
+
+	return ret_fp;
+}
+
+struct fixed_point fixed_point_negate(
+	struct fixed_point fp_arg,
+	unsigned int *error)
+{
+	struct fixed_point ret_fp;
+	struct fixed_point fp_one;
+
+	ret_fp = fixed_point_init(
+		0,
+		0,
+		fp_arg.int_prec,
+		fp_arg.frac_prec,
+		error);
+
+	ret_fp.int_part = ~fp_arg.int_part;
+	ret_fp.frac_part = ~fp_arg.frac_part;
+
+	fp_one.int_prec = fp_arg.int_prec;
+	fp_one.frac_prec = fp_arg.frac_prec;
+	fp_one.int_mask = fp_arg.int_mask;
+	fp_one.frac_mask = fp_arg.frac_mask;
+
+	fp_one.int_part = 0;
+	fp_one.frac_part = 1;
+
+	ret_fp = fixed_point_add(ret_fp, fp_one, error);
+
+	return ret_fp;
+}
+
+struct fixed_point fixed_point_add(
+	struct fixed_point fp_arg1,
+	struct fixed_point fp_arg2,
+	unsigned int *error)
+{
+	struct fixed_point ret_fp;
+	unsigned int frac_carry_out;
+	unsigned int frac1_msb;
+	unsigned int frac2_msb;
+	unsigned int sum_msb;
+
+	FIX_PT_CHK_MATCH_PREC(
+		fp_arg1.int_prec,
+		fp_arg2.int_prec);
+	FIX_PT_CHK_MATCH_PREC(
+		fp_arg1.frac_prec,
+		fp_arg2.frac_prec);
+	FIX_PT_CHK_MATCH_MASK(
+		fp_arg1.int_mask,
+		fp_arg2.int_mask);
+	FIX_PT_CHK_MATCH_MASK(
+		fp_arg1.frac_mask,
+		fp_arg2.frac_mask);
+
+	ret_fp = fixed_point_init(
+		0,
+		0,
+		fp_arg1.int_prec,
+		fp_arg1.frac_prec,
+		error);
+
+	ret_fp.frac_part = (fp_arg1.frac_part + fp_arg2.frac_part) &
+		fp_arg1.frac_mask;
+
+	frac1_msb = (fp_arg1.frac_part >> (fp_arg1.frac_prec - 1)) & 1;
+	frac2_msb = (fp_arg2.frac_part >> (fp_arg2.frac_prec - 1)) & 1;
+	sum_msb = (ret_fp.frac_part >> (fp_arg1.frac_prec - 1)) & 1;
+	frac_carry_out = ((frac1_msb & frac2_msb) |
+				((frac1_msb | frac2_msb) & ~sum_msb)) & 1;
+
+	ret_fp.int_part = (fp_arg1.int_part +
+					   fp_arg2.int_part +
+					   frac_carry_out) & fp_arg1.int_mask;
+
+	return ret_fp;
+}
+
+struct fixed_point fixed_point_sub(
+	struct fixed_point minuend_arg,
+	struct fixed_point subtrahend_arg,
+	unsigned int *error)
+{
+	struct fixed_point neg_subtrahend =
+		fixed_point_negate(subtrahend_arg, error);
+
+	return fixed_point_add(minuend_arg, neg_subtrahend, error);
+}
+
+struct fixed_point fixed_point_mult(
+	struct fixed_point fp_arg1,
+	struct fixed_point fp_arg2,
+	unsigned int *error)
+{
+	struct fixed_point ret_fp;
+	struct fixed_point tmp_fp1;
+	struct fixed_point tmp_fp2;
+	int i;
+
+	FIX_PT_CHK_MATCH_PREC(
+		fp_arg1.int_prec,
+		fp_arg2.int_prec);
+	FIX_PT_CHK_MATCH_PREC(
+		fp_arg1.frac_prec,
+		fp_arg2.frac_prec);
+	FIX_PT_CHK_MATCH_MASK(
+		fp_arg1.int_mask,
+		fp_arg2.int_mask);
+	FIX_PT_CHK_MATCH_MASK(
+		fp_arg1.frac_mask,
+		fp_arg2.frac_mask);
+
+	ret_fp = fixed_point_init(
+		0,
+		0,
+		fp_arg1.int_prec,
+		fp_arg1.frac_prec,
+		error);
+
+	tmp_fp2 = fp_arg2;
+
+	for (i = 0; i < fp_arg2.frac_prec; i++) {
+		ret_fp = fixed_point_shift_right(ret_fp, 1, error);
+		if (tmp_fp2.frac_part & 1)
+			ret_fp = fixed_point_add(ret_fp, fp_arg1, error);
+		tmp_fp2 = fixed_point_shift_right(tmp_fp2, 1, error);
+	}
+
+	ret_fp = fixed_point_shift_right(ret_fp, 1, error);
+	tmp_fp1 = fp_arg1;
+	for (i = fp_arg2.frac_prec;
+		i < (fp_arg2.int_prec + fp_arg2.frac_prec - 1); i++) {
+		if (tmp_fp2.frac_part & 1)
+			ret_fp = fixed_point_add(ret_fp, tmp_fp1, error);
+		tmp_fp2 = fixed_point_shift_right(tmp_fp2, 1, error);
+		tmp_fp1 = fixed_point_shift_left(tmp_fp1, 1, error);
+	}
+
+	if (tmp_fp2.frac_part & 1)
+		ret_fp = fixed_point_sub(ret_fp, tmp_fp1, error);
+
+	return ret_fp;
+}
+
+struct fixed_point fixed_point_div(
+	struct fixed_point dividend_arg,
+	struct fixed_point divisor_arg,
+	unsigned int *error)
+{
+	struct fixed_point ret_fp;
+	struct fixed_point tmp_dividend;
+	struct fixed_point tmp_divisor;
+	struct fixed_point tmp_accum;
+	int negate_num = 0;
+	int i;
+
+	FIX_PT_CHK_MATCH_PREC(
+		dividend_arg.int_prec,
+		divisor_arg.int_prec);
+	FIX_PT_CHK_MATCH_PREC(
+		dividend_arg.frac_prec,
+		divisor_arg.frac_prec);
+	FIX_PT_CHK_MATCH_MASK(
+		dividend_arg.int_mask,
+		divisor_arg.int_mask);
+	FIX_PT_CHK_MATCH_MASK(
+		dividend_arg.frac_mask,
+		divisor_arg.frac_mask);
+
+	if (fixed_point_eq(divisor_arg,
+			fixed_point_init(
+				0,
+				0,
+				dividend_arg.int_prec,
+				dividend_arg.frac_prec,
+				error),
+			error
+		   )
+		){
+
+		if (dividend_arg.int_part &
+			(1 << (dividend_arg.int_prec - 1))) {
+			ret_fp = fixed_point_init(
+				1 << (dividend_arg.int_prec - 1),
+				0,
+				dividend_arg.int_prec,
+				dividend_arg.frac_prec,
+				error);
+		} else {
+			ret_fp = fixed_point_init(
+				(1 << (dividend_arg.int_prec - 1)) - 1,
+				dividend_arg.frac_mask,
+				dividend_arg.int_prec,
+				dividend_arg.frac_prec,
+				error);
+		}
+
+		return ret_fp;
+	}
+
+
+	ret_fp = fixed_point_init(
+		0,
+		0,
+		dividend_arg.int_prec,
+		dividend_arg.frac_prec,
+		error);
+
+	tmp_accum = fixed_point_init(
+		0,
+		0,
+		dividend_arg.int_prec,
+		dividend_arg.frac_prec,
+		error);
+
+	if (dividend_arg.int_part & (1 << (dividend_arg.int_prec - 1))) {
+		tmp_dividend = fixed_point_negate(dividend_arg, error);
+		negate_num++;
+	} else {
+		tmp_dividend = dividend_arg;
+	}
+
+	if (divisor_arg.int_part & (1 << (dividend_arg.int_prec - 1))) {
+		tmp_divisor = fixed_point_negate(divisor_arg, error);
+		negate_num++;
+	} else {
+		tmp_divisor = divisor_arg;
+	}
+
+	negate_num = negate_num % 2;
+
+	for (i = 0;
+		i < (dividend_arg.int_prec + dividend_arg.frac_prec);
+		i++) {
+		struct fixed_point next_dividend_shifted =
+			fixed_point_shift_right(tmp_dividend,
+				dividend_arg.int_prec +
+				dividend_arg.frac_prec - i - 1,
+				error);
+		tmp_accum = fixed_point_shift_left(tmp_accum, 1, error);
+		tmp_accum.frac_part |= (next_dividend_shifted.frac_part & 1);
+
+		ret_fp = fixed_point_shift_left(ret_fp, 1, error);
+		if (fixed_point_loet(tmp_divisor, tmp_accum, error)) {
+			tmp_accum =
+				fixed_point_sub(tmp_accum, tmp_divisor, error);
+			ret_fp.frac_part |= 1;
+		}
+	}
+
+	for (i = 0;
+		i < dividend_arg.frac_prec;
+		i++) {
+		struct fixed_point next_dividend_shifted =
+			fixed_point_shift_left(tmp_dividend,
+				i + 1,
+				error);
+		tmp_accum = fixed_point_shift_left(tmp_accum, 1, error);
+		tmp_accum.frac_part |= (next_dividend_shifted.frac_part & 1);
+
+		ret_fp = fixed_point_shift_left(ret_fp, 1, error);
+		if (fixed_point_loet(tmp_divisor, tmp_accum, error)) {
+			tmp_accum =
+				fixed_point_sub(tmp_accum, tmp_divisor, error);
+			ret_fp.frac_part |= 1;
+		}
+	}
+
+	if (negate_num)
+		ret_fp = fixed_point_negate(ret_fp, error);
+
+	return ret_fp;
+}
+
+int fixed_point_lt(
+	struct fixed_point fp_lhs_arg,
+	struct fixed_point fp_rhs_arg,
+	unsigned int *error)
+{
+	unsigned int int_lhs_msb;
+	unsigned int int_rhs_msb;
+
+	FIX_PT_CHK_MATCH_PREC(
+		fp_lhs_arg.int_prec,
+		fp_rhs_arg.int_prec);
+	FIX_PT_CHK_MATCH_PREC(
+		fp_lhs_arg.frac_prec,
+		fp_rhs_arg.frac_prec);
+	FIX_PT_CHK_MATCH_MASK(
+		fp_lhs_arg.int_mask,
+		fp_rhs_arg.int_mask);
+	FIX_PT_CHK_MATCH_MASK(
+		fp_lhs_arg.frac_mask,
+		fp_rhs_arg.frac_mask);
+
+	int_lhs_msb = (fp_lhs_arg.int_part >> (fp_lhs_arg.int_prec - 1)) & 1;
+	int_rhs_msb = (fp_rhs_arg.int_part >> (fp_rhs_arg.int_prec - 1)) & 1;
+
+	if ((int_lhs_msb == 1) && (int_rhs_msb == 0))
+		return 1;
+
+	if ((int_lhs_msb == 0) && (int_rhs_msb == 1))
+		return 0;
+
+	/* both are positive or both are negative */
+	if (fp_lhs_arg.int_part < fp_rhs_arg.int_part)
+		return 1;
+
+	if (fp_lhs_arg.int_part > fp_rhs_arg.int_part)
+		return 0;
+
+	if (fp_lhs_arg.frac_part < fp_rhs_arg.frac_part)
+		return 1;
+
+	if (fp_lhs_arg.frac_part > fp_rhs_arg.frac_part)
+		return 0;
+
+	/* equal */
+	return 0;
+}
+
+int fixed_point_gt(
+	struct fixed_point fp_lhs_arg,
+	struct fixed_point fp_rhs_arg,
+	unsigned int *error)
+{
+
+	return fixed_point_lt(fp_rhs_arg, fp_lhs_arg, error);
+}
+
+int fixed_point_loet(
+	struct fixed_point fp_lhs_arg,
+	struct fixed_point fp_rhs_arg,
+	unsigned int *error)
+{
+	return fixed_point_lt(fp_lhs_arg, fp_rhs_arg, error) |
+		fixed_point_eq(fp_lhs_arg, fp_rhs_arg, error);
+}
+
+int fixed_point_goet(
+	struct fixed_point fp_lhs_arg,
+	struct fixed_point fp_rhs_arg,
+	unsigned int *error)
+{
+	return fixed_point_gt(fp_lhs_arg, fp_rhs_arg, error) |
+		fixed_point_eq(fp_lhs_arg, fp_rhs_arg, error);
+}
+
+int fixed_point_eq(
+	struct fixed_point fp_lhs_arg,
+	struct fixed_point fp_rhs_arg,
+	unsigned int *error)
+{
+	FIX_PT_CHK_MATCH_PREC(
+		fp_lhs_arg.int_prec,
+		fp_rhs_arg.int_prec);
+	FIX_PT_CHK_MATCH_PREC(
+		fp_lhs_arg.frac_prec,
+		fp_rhs_arg.frac_prec);
+	FIX_PT_CHK_MATCH_MASK(
+		fp_lhs_arg.int_mask,
+		fp_rhs_arg.int_mask);
+	FIX_PT_CHK_MATCH_MASK(
+		fp_lhs_arg.frac_mask,
+		fp_rhs_arg.frac_mask);
+
+	if (fp_lhs_arg.int_part != fp_rhs_arg.int_part)
+		return 0;
+
+	if (fp_lhs_arg.frac_part != fp_rhs_arg.frac_part)
+		return 0;
+
+	return 1;
+}
+
+int fixed_point_to_int(
+	struct fixed_point fp_arg,
+	unsigned int *error)
+{
+	int ret_int;
+
+	if (fp_arg.int_part & (1 << (fp_arg.int_prec - 1))) /* sign extend */
+		ret_int = 0 - ((int)fixed_point_negate(fp_arg, error).int_part);
+	else
+		ret_int = fp_arg.int_part;
+
+	return ret_int;
+}
+
+int fixed_point_ceil(
+	struct fixed_point fp_arg,
+	unsigned int *error)
+{
+	int ret_int;
+
+	if (fp_arg.int_part & (1 << (fp_arg.int_prec - 1))) { /* negative */
+		struct fixed_point neg_fp = fixed_point_negate(fp_arg, error);
+		if (neg_fp.frac_part != 0)
+			ret_int = 0 - ((int)neg_fp.int_part) + 1;
+		else
+			ret_int = neg_fp.int_part;
+	} else {
+		if (fp_arg.frac_part != 0)
+			ret_int = fp_arg.int_part + 1;
+		else
+			ret_int = fp_arg.int_part;
+	}
+
+	return ret_int;
+}
+
+struct fixed_point fixed_point_min(
+	struct fixed_point fp_arg1,
+	struct fixed_point fp_arg2,
+	unsigned int *error)
+{
+	if (fixed_point_lt(fp_arg1, fp_arg2, error))
+		return fp_arg1;
+	else
+		return fp_arg2;
+}
+
+struct fixed_point fixed_point_max(
+	struct fixed_point fp_arg1,
+	struct fixed_point fp_arg2,
+	unsigned int *error)
+{
+	if (fixed_point_gt(fp_arg1, fp_arg2, error))
+		return fp_arg1;
+	else
+		return fp_arg2;
+}
diff --git a/drivers/platform/tegra/mc/fixed_point.h b/drivers/platform/tegra/mc/fixed_point.h
new file mode 100644
index 000000000000..ef5c5da20618
--- /dev/null
+++ b/drivers/platform/tegra/mc/fixed_point.h
@@ -0,0 +1,118 @@
+/*
+ * Copyright (C) 2018, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#ifndef _FIXED_POINT_H
+#define _FIXED_POINT_H
+
+struct fixed_point {
+	unsigned int int_part;
+	unsigned int frac_part;
+	unsigned int int_prec;
+	unsigned int frac_prec;
+	unsigned int int_mask;
+	unsigned int frac_mask;
+};
+
+struct fixed_point fixed_point_init(
+	unsigned int int_part,
+	unsigned int frac_part,
+	unsigned int int_prec,
+	unsigned int frac_prec,
+	unsigned int *error);
+
+struct fixed_point fixed_point_shift_left(
+	struct fixed_point fp_arg,
+	unsigned int places,
+	unsigned int *error);
+
+struct fixed_point fixed_point_shift_right(
+	struct fixed_point fp_arg,
+	unsigned int places,
+	unsigned int *error);
+
+struct fixed_point fixed_point_negate(
+	struct fixed_point fp_arg,
+	unsigned int *error);
+
+struct fixed_point fixed_point_add(
+	struct fixed_point fp_arg1,
+	struct fixed_point fp_arg2,
+	unsigned int *error);
+
+/* returns difference = minuend - subtrahend */
+struct fixed_point fixed_point_sub(
+	struct fixed_point minuend_arg,
+	struct fixed_point subtrahend_arg,
+	unsigned int *error);
+
+struct fixed_point fixed_point_mult(
+	struct fixed_point fp_arg1,
+	struct fixed_point fp_arg2,
+	unsigned int *error);
+
+/* returns quotient = dividend / divisor*/
+struct fixed_point fixed_point_div(
+	struct fixed_point dividend_arg,
+	struct fixed_point divisor_arg,
+	unsigned int *error);
+
+/* Return 1 is lhs < rhs, 0 otherwise */
+int fixed_point_lt(
+	struct fixed_point fp_lhs_arg,
+	struct fixed_point fp_rhs_arg,
+	unsigned int *error);
+
+/* Return 1 is lhs > rhs, 0 otherwise */
+int fixed_point_gt(
+	struct fixed_point fp_lhs_arg,
+	struct fixed_point fp_rhs_arg,
+	unsigned int *error);
+
+/* Return 1 is lhs <= rhs, 0 otherwise */
+int fixed_point_loet(
+	struct fixed_point fp_lhs_arg,
+	struct fixed_point fp_rhs_arg,
+	unsigned int *error);
+
+/* Return 1 is lhs >= rhs, 0 otherwise */
+int fixed_point_goet(
+	struct fixed_point fp_lhs_arg,
+	struct fixed_point fp_rhs_arg,
+	unsigned int *error);
+
+/* Return 1 is lhs == rhs, 0 otherwise */
+int fixed_point_eq(
+	struct fixed_point fp_lhs_arg,
+	struct fixed_point fp_rhs_arg,
+	unsigned int *error);
+
+int fixed_point_to_int(
+	struct fixed_point fp_arg,
+	unsigned int *error);
+
+int fixed_point_ceil(
+	struct fixed_point fp_arg,
+	unsigned int *error);
+
+struct fixed_point fixed_point_min(
+	struct fixed_point fp_arg1,
+	struct fixed_point fp_arg2,
+	unsigned int *error);
+
+struct fixed_point fixed_point_max(
+	struct fixed_point fp_arg1,
+	struct fixed_point fp_arg2,
+	unsigned int *error);
+
+#endif /* _FIXED_POINT_H */
diff --git a/drivers/platform/tegra/mc/isomgr-pre_t19x.c b/drivers/platform/tegra/mc/isomgr-pre_t19x.c
new file mode 100644
index 000000000000..285063c72dc3
--- /dev/null
+++ b/drivers/platform/tegra/mc/isomgr-pre_t19x.c
@@ -0,0 +1,466 @@
+/*
+ * arch/arm/mach-tegra/isomgr-pre_t19x.c
+ *
+ * Copyright (c) 2018, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#define pr_fmt(fmt)	"%s(): " fmt, __func__
+
+#ifdef CONFIG_COMMON_CLK
+#include <linux/platform/tegra/bwmgr_mc.h>
+#else
+#include <linux/platform/tegra/mc.h>
+#include <linux/clk.h>
+#include <linux/platform/tegra/clock.h>
+#endif
+#include <linux/platform/tegra/emc_bwmgr.h>
+#include <linux/platform/tegra/isomgr.h>
+#include <linux/io.h>
+#include <soc/tegra/chip-id.h>
+
+/* This file contains platform specific isomgr
+ * code for all chips prior to T194.
+ */
+
+#define ISOMGR_DEBUG 1
+
+#if ISOMGR_DEBUG
+#define SANITY_CHECK_AVAIL_BW() { \
+	int t = 0; \
+	int idx = 0; \
+	for (idx = 0; idx < TEGRA_ISO_CLIENT_COUNT; idx++) { \
+		if (isomgr_clients[idx].real_bw >= \
+		   isomgr_clients[idx].margin_bw) \
+			t += isomgr_clients[idx].real_bw; \
+		else \
+			t += isomgr_clients[idx].margin_bw; \
+	} \
+	if (t + isomgr.avail_bw != isomgr.max_iso_bw) { \
+		pr_err("bw mismatch, line=%d\n", __LINE__); \
+		pr_err("t+isomgr.avail_bw=%d, isomgr.max_iso_bw=%d\n", \
+			t + isomgr.avail_bw, isomgr.max_iso_bw); \
+		return false; \
+	} \
+}
+#else
+#define SANITY_CHECK_AVAIL_BW()
+#endif
+
+static int iso_bw_percentage = 100;
+
+static struct isoclient_info tegra_null_isoclients[] = {
+	/* This must be last entry*/
+	{
+		.client = TEGRA_ISO_CLIENT_COUNT,
+		.name = NULL,
+	},
+};
+
+static struct isoclient_info tegra11x_isoclients[] = {
+	{
+		.client = TEGRA_ISO_CLIENT_DISP_0,
+		.name = "disp_0",
+		.dev_name = "tegradc.0",
+		.emc_clk_name = "emc",
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_DISP_1,
+		.name = "disp_1",
+		.dev_name = "tegradc.1",
+		.emc_clk_name = "emc",
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_VI_0,
+		.name = "vi_0",
+		.dev_name = "vi",
+		.emc_clk_name = "emc",
+	},
+	/* This must be last entry*/
+	{
+		.client = TEGRA_ISO_CLIENT_COUNT,
+		.name = NULL,
+	},
+};
+
+static struct isoclient_info tegra14x_isoclients[] = {
+	{
+		.client = TEGRA_ISO_CLIENT_DISP_0,
+		.name = "disp_0",
+		.dev_name = "tegradc.0",
+		.emc_clk_name = "emc",
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_DISP_1,
+		.name = "disp_1",
+		.dev_name = "tegradc.1",
+		.emc_clk_name = "emc",
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_VI_0,
+		.name = "vi_0",
+		.dev_name = "vi",
+		.emc_clk_name = "emc",
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_BBC_0,
+		.name = "bbc_0",
+		.dev_name = "tegra_bb.0",
+		.emc_clk_name = "emc_bw",
+	},
+	/* This must be last entry*/
+	{
+		.client = TEGRA_ISO_CLIENT_COUNT,
+		.name = NULL,
+	},
+};
+
+static struct isoclient_info tegra12x_isoclients[] = {
+	{
+		.client = TEGRA_ISO_CLIENT_DISP_0,
+		.name = "disp_0",
+		.dev_name = "tegradc.0",
+		.emc_clk_name = "emc",
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_DISP_1,
+		.name = "disp_1",
+		.dev_name = "tegradc.1",
+		.emc_clk_name = "emc",
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_VI_0,
+		.name = "vi_0",
+		.dev_name = "tegra_vi",
+		.emc_clk_name = "emc",
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_ISP_A,
+		.name = "isp_a",
+		.dev_name = "tegra_isp.0",
+		.emc_clk_name = "emc",
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_ISP_B,
+		.name = "isp_b",
+		.dev_name = "tegra_isp.1",
+		.emc_clk_name = "emc",
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_TEGRA_CAMERA,
+		.name = "tegra_camera",
+		.dev_name = "tegra_camera_ctrl",
+		.emc_clk_name = "iso.emc",
+	},
+	/* This must be last entry*/
+	{
+		.client = TEGRA_ISO_CLIENT_COUNT,
+		.name = NULL,
+	},
+};
+
+static struct isoclient_info tegra21x_isoclients[] = {
+	{
+		.client = TEGRA_ISO_CLIENT_DISP_0,
+		.name = "disp_0",
+		.dev_name = "tegradc.0",
+		.emc_clk_name = "emc",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_DISP0,
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_DISP_1,
+		.name = "disp_1",
+		.dev_name = "tegradc.1",
+		.emc_clk_name = "emc",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_DISP1,
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_VI_0,
+		.name = "vi_0",
+		.dev_name = "tegra_vi",
+		.emc_clk_name = "emc",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_VI,
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_ISP_A,
+		.name = "isp_a",
+		.dev_name = "tegra_isp.0",
+		.emc_clk_name = "emc",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_ISPA,
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_ISP_B,
+		.name = "isp_b",
+		.dev_name = "tegra_isp.1",
+		.emc_clk_name = "emc",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_ISPB,
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_TEGRA_CAMERA,
+		.name = "tegra_camera",
+		.dev_name = "tegra_camera_ctrl",
+		.emc_clk_name = "iso.emc",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_CAMERA,
+	},
+	/* This must be last entry*/
+	{
+		.client = TEGRA_ISO_CLIENT_COUNT,
+		.name = NULL,
+	},
+};
+
+static struct isoclient_info tegra18x_isoclients[] = {
+	{
+		.client = TEGRA_ISO_CLIENT_DISP_0,
+		.name = "disp_0",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_DISP0,
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_DISP_1,
+		.name = "disp_1",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_DISP1,
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_DISP_2,
+		.name = "disp_2",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_DISP2,
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_ISP_A,
+		.name = "isp_a",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_ISPA,
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_TEGRA_CAMERA,
+		.name = "camera",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_CAMERA,
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_APE_ADMA,
+		.name = "ape_adma",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_APE_ADMA,
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_EQOS,
+		.name = "eqos",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_EQOS,
+	},
+	/* This must be last entry*/
+	{
+		.client = TEGRA_ISO_CLIENT_COUNT,
+		.name = NULL,
+	},
+};
+
+static struct isoclient_info *get_iso_client_info(int *length)
+{
+	enum tegra_chipid cid;
+	struct isoclient_info *cinfo;
+	int i, len;
+
+	cid = tegra_get_chip_id();
+	switch (cid) {
+	case TEGRA114:
+		cinfo = tegra11x_isoclients;
+		len = ARRAY_SIZE(tegra11x_isoclients);
+		iso_bw_percentage = 50;
+		for (i = 0; i < TEGRA_ISO_CLIENT_COUNT; i++)
+			isomgr_clients[i].limit_bw_percentage = 100;
+		break;
+	case TEGRA148:
+		cinfo = tegra14x_isoclients;
+		len = ARRAY_SIZE(tegra14x_isoclients);
+		iso_bw_percentage = 50;
+		for (i = 0; i < TEGRA_ISO_CLIENT_COUNT; i++)
+			isomgr_clients[i].limit_bw_percentage = 100;
+		break;
+	case TEGRA124:
+	case TEGRA132:
+		cinfo = tegra12x_isoclients;
+		len = ARRAY_SIZE(tegra12x_isoclients);
+		iso_bw_percentage = 50;
+		for (i = 0; i < TEGRA_ISO_CLIENT_COUNT; i++)
+			isomgr_clients[i].limit_bw_percentage = 100;
+		break;
+	case TEGRA210:
+		cinfo = tegra21x_isoclients;
+		iso_bw_percentage = 45; /* Hack: Should be determined based on
+					 * DRAM type
+					 */
+		len = ARRAY_SIZE(tegra21x_isoclients);
+		for (i = 0; i < TEGRA_ISO_CLIENT_COUNT; i++)
+			isomgr_clients[i].limit_bw_percentage = 100;
+		break;
+	case TEGRA186:
+		cinfo = tegra18x_isoclients;
+		len = ARRAY_SIZE(tegra18x_isoclients);
+		for (i = 0; i < TEGRA_ISO_CLIENT_COUNT; i++) {
+			if (i == TEGRA_ISO_CLIENT_TEGRA_CAMERA)
+				isomgr_clients[i].limit_bw_percentage = 10;
+			else
+				isomgr_clients[i].limit_bw_percentage = 100;
+		}
+		break;
+	default:
+		cinfo = tegra_null_isoclients;
+		len = 0;
+		break;
+	}
+
+	if (length)
+		*length = len;
+
+	return cinfo;
+}
+
+static void pre_t19x_iso_plat_init(void)
+{
+	unsigned int max_emc_clk;
+	unsigned int max_emc_bw;
+
+	if (!isomgr.max_iso_bw) {
+#ifdef CONFIG_COMMON_CLK
+		max_emc_clk = tegra_bwmgr_get_max_emc_rate() / 1000;
+		max_emc_bw = bwmgr_freq_to_bw(max_emc_clk);
+		isomgr.max_iso_bw = max_emc_bw *
+			bwmgr_iso_bw_percentage_max() / 100;
+#else
+		/* With DVFS disabled, bus children cannot get real
+		 * max emc freq supported Only the root parent EMC
+		 * node is set to max possible rate
+		 */
+		max_emc_clk = clk_round_rate(clk_get_parent(isomgr.emc_clk),
+						ULONG_MAX) / 1000;
+		max_emc_bw = tegra_emc_freq_req_to_bw(max_emc_clk);
+		/* ISO clients can use iso_bw_percentage of max emc bw. */
+		isomgr.max_iso_bw = max_emc_bw * iso_bw_percentage / 100;
+#endif
+		pr_info("iso emc max clk=%dKHz\n", max_emc_clk);
+		pr_info("max_iso_bw=%dKB\n", isomgr.max_iso_bw);
+		isomgr.avail_bw = isomgr.max_iso_bw;
+	}
+}
+
+static void pre_t19x_iso_plat_unregister(struct isomgr_client *cp)
+{
+	if (cp->real_bw > cp->margin_bw)
+		isomgr.avail_bw += cp->real_bw;
+	else
+		isomgr.avail_bw += cp->margin_bw;
+}
+
+static bool pre_t19x_iso_plat_reserve(struct isomgr_client *cp, u32 bw,
+					enum tegra_iso_client client)
+{
+	u64 bw_check;
+	u32 max_emc_bw;
+
+	if (bw <= cp->margin_bw)
+		goto bw_limit_check;
+
+	if (bw > cp->dedi_bw &&
+	  bw > isomgr.avail_bw + cp->real_bw - isomgr.sleep_bw)
+		return false;
+
+bw_limit_check:
+	/* During reserve, check if BW request is within limit_bw_percentage%
+	 * of max emc bw. Using max emc bw to find if the request is possible
+	 * when we raise the freq to max possible value. If not, the reserve
+	 * call will fail
+	 */
+#ifdef CONFIG_COMMON_CLK
+	max_emc_bw = bwmgr_freq_to_bw(tegra_bwmgr_get_max_emc_rate() / 1000);
+#else
+	max_emc_bw = tegra_emc_freq_req_to_bw(
+		clk_round_rate(clk_get_parent(isomgr.emc_clk), ULONG_MAX)
+		/ 1000);
+#endif
+	bw_check = ((u64)max_emc_bw * (u64)(cp->limit_bw_percentage) / 100);
+	if (bw > bw_check)
+		return false;
+	else
+		return true;
+
+}
+
+static bool pre_t19x_iso_plat_realize(struct isomgr_client *cp)
+{
+	s32 delta_bw = 0;
+
+	if (cp->margin_bw < cp->real_bw)
+		isomgr.avail_bw += cp->real_bw - cp->margin_bw;
+
+	cp->real_bw = 0;
+	cp->realize = true;
+
+	if (unlikely(isomgr.avail_bw > isomgr.max_iso_bw)) {
+		pr_err("isomgr: iso_plat_realize: avail_bw > max_iso_bw\n");
+		return false;
+	}
+
+	if (cp->rsvd_bw <= cp->margin_bw) {
+		if (unlikely(cp->sleep_bw)) {
+			pr_err
+			("isomgr_realize: rsvd_bw < margin_bw, sleep_bw = 1\n");
+			return false;
+		}
+		cp->real_bw = cp->rsvd_bw; /* reservation has been realized */
+		cp->real_mf = cp->rsvd_mf; /* minimum frequency realized */
+	} else if (cp->rsvd_bw <= isomgr.avail_bw + cp->margin_bw) {
+		delta_bw = cp->rsvd_bw - cp->margin_bw;
+		isomgr.avail_bw -= delta_bw;
+		cp->real_bw = cp->rsvd_bw; /* reservation has been realized */
+		cp->real_mf = cp->rsvd_mf; /* minimum frequency realized */
+		if (cp->sleep_bw) {
+			isomgr.sleep_bw -= delta_bw;
+			cp->sleep_bw -= delta_bw;
+			if (unlikely(cp->sleep_bw)) {
+				pr_err
+				("isomgr:rsvd_bw < margin_bw, sleep_bw = 1\n");
+				return false;
+			}
+		}
+		if (unlikely(isomgr.avail_bw < 0)) {
+			pr_err("isomgr: iso_plat_realize: avail_bw < 0\n");
+			return false;
+		}
+		SANITY_CHECK_AVAIL_BW();
+	} else {
+		return false;
+	}
+
+	return true;
+}
+
+static bool pre_t19x_iso_plat_register(u32 dedi_bw, enum tegra_iso_client client)
+{
+	if (unlikely(dedi_bw > isomgr.max_iso_bw - isomgr.dedi_bw)) {
+		pr_err("iso bandwidth %uKB is not available, client %s\n",
+			dedi_bw, cname[client]);
+		return false;
+	}
+	return true;
+}
+
+static struct isomgr_ops isomgr_ops_pre_t19x = {
+	.isomgr_plat_init = pre_t19x_iso_plat_init,
+	.isomgr_plat_register = pre_t19x_iso_plat_register,
+	.isomgr_plat_unregister = pre_t19x_iso_plat_unregister,
+	.isomgr_plat_reserve = pre_t19x_iso_plat_reserve,
+	.isomgr_plat_realize = pre_t19x_iso_plat_realize,
+};
+
+struct isomgr_ops *pre_t19x_isomgr_init(void)
+{
+	isoclient_info = get_iso_client_info(&isoclients);
+	return &isomgr_ops_pre_t19x;
+}
diff --git a/drivers/platform/tegra/mc/isomgr-t19x.c b/drivers/platform/tegra/mc/isomgr-t19x.c
new file mode 100644
index 000000000000..f31607bbb82c
--- /dev/null
+++ b/drivers/platform/tegra/mc/isomgr-t19x.c
@@ -0,0 +1,249 @@
+/*
+ * arch/arm/mach-tegra/isomgr-t19x.c
+ *
+ * Copyright (c) 2018, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#define pr_fmt(fmt)	"%s(): " fmt, __func__
+
+#ifdef CONFIG_COMMON_CLK
+#include <linux/platform/tegra/bwmgr_mc.h>
+#else
+#include <linux/platform/tegra/mc.h>
+#include <linux/clk.h>
+#include <linux/platform/tegra/clock.h>
+#endif
+#include <linux/platform/tegra/emc_bwmgr.h>
+#include <linux/platform/tegra/isomgr.h>
+#include <linux/io.h>
+#include <soc/tegra/chip-id.h>
+
+static struct isoclient_info tegra19x_isoclients[] = {
+	{
+		.client = TEGRA_ISO_CLIENT_DISP_0,
+		.name = "disp_0",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_DISP0,
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_DISP_1,
+		.name = "disp_1",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_DISP1,
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_DISP_2,
+		.name = "disp_2",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_DISP2,
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_ISP_A,
+		.name = "isp_a",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_ISPA,
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_TEGRA_CAMERA,
+		.name = "camera",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_CAMERA,
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_APE_ADMA,
+		.name = "ape_adma",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_APE_ADMA,
+	},
+	{
+		.client = TEGRA_ISO_CLIENT_EQOS,
+		.name = "eqos",
+		.bwmgr_id = TEGRA_BWMGR_CLIENT_EQOS,
+	},
+	/* This must be last entry*/
+	{
+		.client = TEGRA_ISO_CLIENT_COUNT,
+		.name = NULL,
+	},
+};
+
+static struct isoclient_info *t19x_get_iso_client_info(int *length)
+{
+	struct isoclient_info *cinfo;
+	int i, len;
+
+	cinfo = tegra19x_isoclients;
+	len = ARRAY_SIZE(tegra19x_isoclients);
+	for (i = 0; i < TEGRA_ISO_CLIENT_COUNT; i++)
+		isomgr_clients[i].limit_bw_percentage = 100;
+
+	if (length)
+		*length = len;
+
+	return cinfo;
+}
+
+/* This function is used to find out if a isomgr request is possible
+ * This is basically a wrapper for bwmgr_get_lowest_iso_emc_freq, which walks
+ * all the supported DRAM clock frequencies and returns the lowest freq which
+ * satisfies the bw requirement. It returns 0 if request cannot be supported
+ *
+ * This function is called from both isomgr_register and isomgr_reserve
+ *
+ * @ reserve - call made from tegra_isomgr_reserve
+ * @ register_bw - bw requested by isomgr client during register KB/s
+ * @ reserve_bw - bw requested by isomgr client during reserve KB/s
+ * @ regclient - iso client passed to register
+ * @ resclient - iso client which is calling reserve
+ *
+ * returns true if request can be satisfied or else false
+ */
+static bool is_isomgr_request_possible(bool reserve, u32 register_bw,
+				u32 reserve_bw, enum tegra_iso_client regclient,
+				enum tegra_iso_client resclient)
+{
+	u32 min_freq = 0; //KHz
+	unsigned long iso_bw_other = 0; //Hz
+	unsigned long iso_bw_total = 0; //Hz
+	unsigned long iso_bw_nvdis = 0; //Hz
+	unsigned long iso_bw_vi = 0; //Hz
+	unsigned long ret = 0;
+	int i;
+	enum tegra_iso_client curr_res_cli = resclient;
+	u32 cur_req_bw = 0;
+	enum tegra_iso_client cur_iso_client;
+
+	if (!reserve) { //tegra_isomgr_register
+		cur_req_bw = register_bw;
+		cur_iso_client = regclient;
+	} else { //tegra_isomgr_reserve
+		cur_req_bw = reserve_bw;
+		cur_iso_client = resclient;
+	}
+
+	min_freq = bwmgr_bw_to_freq(cur_req_bw);
+
+	if ((cur_iso_client == TEGRA_ISO_CLIENT_DISP_0) ||
+	   (cur_iso_client == TEGRA_ISO_CLIENT_DISP_1) ||
+	   (cur_iso_client == TEGRA_ISO_CLIENT_DISP_2))
+		iso_bw_nvdis = min_freq * 1000;
+
+	else if (cur_iso_client == TEGRA_ISO_CLIENT_TEGRA_CAMERA)
+		iso_bw_vi = min_freq * 1000;
+
+	else
+		iso_bw_other = min_freq * 1000;
+
+	if (reserve) {
+		//bw requests reserved and realized by other ISO clients
+		for (i = 0; i < isoclients; i++) {
+			if (isoclient_info[i].name) {
+				resclient = isoclient_info[i].client;
+
+				/* bw req of client calling is considered,
+				 * skip rest of loop.
+				 */
+				if (curr_res_cli == resclient)
+					continue;
+
+				if ((resclient == TEGRA_ISO_CLIENT_DISP_0) ||
+				   (resclient == TEGRA_ISO_CLIENT_DISP_1) ||
+				   (resclient == TEGRA_ISO_CLIENT_DISP_2))
+					iso_bw_nvdis +=
+					(max(isomgr_clients[resclient].rsvd_mf,
+					isomgr_clients[resclient].real_mf)
+					* 1000);
+
+				else if ((resclient ==
+					TEGRA_ISO_CLIENT_TEGRA_CAMERA))
+					iso_bw_vi +=
+					(max(isomgr_clients[resclient].rsvd_mf,
+					isomgr_clients[resclient].real_mf)
+					* 1000);
+
+				else
+					iso_bw_other +=
+					(max(isomgr_clients[resclient].rsvd_mf,
+					isomgr_clients[resclient].real_mf)
+					* 1000);
+			}
+		}
+	}
+
+	iso_bw_total = iso_bw_nvdis + iso_bw_vi + iso_bw_other;
+
+	ret = bwmgr_get_lowest_iso_emc_freq(iso_bw_total, iso_bw_nvdis,
+						iso_bw_vi); //inputs in Hz
+	if (!ret)
+		return false;
+
+	return true;
+}
+
+static void t19x_iso_plat_init(void)
+{
+}
+
+static void t19x_iso_plat_unregister(struct isomgr_client *cp)
+{
+}
+
+static bool t19x_iso_plat_reserve(struct isomgr_client *cp, u32 bw,
+					enum tegra_iso_client client)
+{
+	if (is_isomgr_request_possible(1, 0, bw, 0, client))
+		return true;
+	else
+		return false;
+}
+
+static bool t19x_iso_plat_realize(struct isomgr_client *cp)
+{
+	/* Nothing specific to do in realize, update internal variables */
+	cp->real_bw = 0;
+	cp->realize = true;
+
+	cp->real_bw = cp->rsvd_bw; /* reservation has been realized */
+	cp->real_mf = cp->rsvd_mf; /* minimum frequency realized */
+
+	return true;
+}
+
+static bool t19x_iso_plat_register(u32 dedi_bw, enum tegra_iso_client client)
+{
+	if (is_isomgr_request_possible(0, dedi_bw, 0, client, 0))
+		return true;
+	else
+		return false;
+}
+
+static u32 t19x_iso_max_bw(enum tegra_iso_client client)
+{
+	return tegra_bwmgr_get_max_iso_bw(client);
+}
+
+static struct isomgr_ops isomgr_ops_t19x = {
+	.isomgr_plat_init = t19x_iso_plat_init,
+	.isomgr_plat_register = t19x_iso_plat_register,
+	.isomgr_plat_unregister = t19x_iso_plat_unregister,
+	.isomgr_plat_reserve = t19x_iso_plat_reserve,
+	.isomgr_plat_realize = t19x_iso_plat_realize,
+	.isomgr_max_iso_bw = t19x_iso_max_bw,
+};
+
+struct isomgr_ops *t19x_isomgr_init(void)
+{
+	isoclient_info = t19x_get_iso_client_info(&isoclients);
+
+	/* On T194, camera cannot tolerate emc frequency changes when active.
+	 * Set emc floor to max when camera is active to avoid
+	 * frequency switching
+	 */
+	isomgr_camera_max_floor_req = 1;
+
+	return &isomgr_ops_t19x;
+}
diff --git a/drivers/platform/tegra/mc/isomgr.c b/drivers/platform/tegra/mc/isomgr.c
new file mode 100644
index 000000000000..63c0b5deea8b
--- /dev/null
+++ b/drivers/platform/tegra/mc/isomgr.c
@@ -0,0 +1,1125 @@
+/*
+ * arch/arm/mach-tegra/isomgr.c
+ *
+ * Copyright (c) 2012-2018, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#define pr_fmt(fmt)	"%s(): " fmt, __func__
+
+#include <linux/delay.h>
+#include <linux/types.h>
+#include <linux/compiler.h>
+#include <linux/kernel.h>
+#include <linux/mutex.h>
+#include <linux/completion.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/kobject.h>
+#include <linux/sysfs.h>
+#include <linux/printk.h>
+#include <linux/err.h>
+#include <linux/kref.h>
+#include <linux/sched.h>
+#include <linux/version.h>
+#include <soc/tegra/chip-id.h>
+#include <asm/processor.h>
+#include <asm/current.h>
+
+#include <linux/platform/tegra/isomgr.h>
+
+#include <linux/platform/tegra/emc_bwmgr.h>
+#ifdef CONFIG_COMMON_CLK
+#include <linux/platform/tegra/bwmgr_mc.h>
+#else
+#include <linux/platform/tegra/mc.h>
+#include <linux/clk.h>
+#include <linux/platform/tegra/clock.h>
+#endif
+
+#define CREATE_TRACE_POINTS
+#include <trace/events/isomgr.h>
+
+#define ISOMGR_SYSFS_VERSION 0	/* increment on change */
+
+#define VALIDATE_HANDLE() \
+do { \
+	if (unlikely(!cp || !is_client_valid(client) || \
+		     cp->magic != ISOMGR_MAGIC)) { \
+		pr_err("bad handle %p\n", handle); \
+		goto validation_fail; \
+	} \
+} while (0)
+
+#define VALIDATE_CLIENT() \
+do { \
+	if (unlikely(!is_client_valid(client))) { \
+		pr_err("invalid client %d\n", client); \
+		goto validation_fail; \
+	} \
+} while (0)
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 14, 0)
+#define OBJ_REF_SET		refcount_set
+#define OBJ_REF_READ		refcount_read
+#define OBJ_REF_INC_NOT_ZERO	refcount_inc_not_zero
+#else
+#define OBJ_REF_SET		atomic_set
+#define OBJ_REF_READ		atomic_read
+#define OBJ_REF_INC_NOT_ZERO	atomic_inc_not_zero
+#endif
+
+/* To allow test code take over control */
+static bool test_mode;
+
+char *cname[] = {
+	"disp_0",
+	"disp_1",
+	"disp_2",
+	"vi_0",
+	"vi_1",
+	"isp_a",
+	"isp_b",
+	"bbc_0",
+	"tegra_camera_ctrl",
+	"ape_adma",
+	"eqos",
+	"unknown"
+};
+
+struct isoclient_info *isoclient_info;
+/*platform specific flag for requesting max emc floor req for camera client*/
+u8 isomgr_camera_max_floor_req;
+int isoclients;
+bool client_valid[TEGRA_ISO_CLIENT_COUNT];
+struct isomgr_client isomgr_clients[TEGRA_ISO_CLIENT_COUNT];
+struct isomgr isomgr = {
+	.max_iso_bw = CONFIG_TEGRA_ISOMGR_POOL_KB_PER_SEC,
+	.avail_bw = CONFIG_TEGRA_ISOMGR_POOL_KB_PER_SEC,
+};
+
+/* get minimum MC frequency for client that can support this BW and LT */
+static inline u32 mc_min_freq(u32 ubw, u32 ult) /* in KB/sec and usec */
+{
+	unsigned int min_freq = 0;
+
+	/* ult==0 means ignore LT (effectively infinite) */
+	if (ubw == 0)
+		goto out;
+
+#ifdef CONFIG_COMMON_CLK
+	min_freq = bwmgr_bw_to_freq(ubw);
+#else
+	min_freq = tegra_emc_bw_to_freq_req(ubw);
+#endif
+
+out:
+	return min_freq; /* return value in KHz*/
+}
+
+/* get dvfs switch latency for client requiring this frequency */
+static inline u32 mc_dvfs_latency(u32 ufreq)
+{
+#ifdef CONFIG_COMMON_CLK
+	return bwmgr_dvfs_latency(ufreq);
+#else
+	return tegra_emc_dvfs_latency(ufreq); /* return value in usec */
+#endif
+}
+
+static inline bool isomgr_lock(void)
+{
+	/* disallow rentrance, avoid deadlock */
+	if (unlikely(isomgr.task == current)) {
+		pr_err("isomgr: lock deadlock ?\n");
+		dump_stack();
+		return false;
+	}
+	mutex_lock(&isomgr.lock);
+	isomgr.task = current;
+	return true;
+}
+
+static inline bool isomgr_unlock(void)
+{
+	/* detect mismatched calls */
+	if (unlikely(isomgr.task != current)) {
+		pr_err("isomgr: unlock mismatch ?\n");
+		dump_stack();
+		return false;
+	}
+	isomgr.task = NULL;
+	mutex_unlock(&isomgr.lock);
+	return true;
+}
+
+/* call with isomgr_lock held. */
+static void update_mc_clock(void)
+{
+	int i;
+	u64 floor_freq;
+	unsigned long emc_max_rate = tegra_bwmgr_get_max_emc_rate();
+
+	/*If we get the lock, it means lock was not taken and hence we return*/
+	if (unlikely(mutex_trylock(&isomgr.lock))) {
+		pr_err("isomgr: %s called without lock\n", __func__);
+		WARN_ON(true);
+		return;
+	}
+	/* determine worst case freq to satisfy LT */
+	isomgr.lt_mf = 0;
+	for (i = 0; i < TEGRA_ISO_CLIENT_COUNT; i++)
+		isomgr.lt_mf = max(isomgr.lt_mf, isomgr_clients[i].real_mf);
+
+	/* request the floor freq to satisfy LT */
+	if (isomgr.lt_mf_rq != isomgr.lt_mf) {
+#ifdef CONFIG_COMMON_CLK
+		if (!tegra_bwmgr_set_emc(isomgr.bwmgr_handle,
+				isomgr.lt_mf * 1000,
+				TEGRA_BWMGR_SET_EMC_FLOOR))
+			isomgr.lt_mf_rq = isomgr.lt_mf;
+#else
+		if (!clk_set_rate(isomgr.emc_clk, isomgr.lt_mf * 1000)) {
+
+			if (isomgr.lt_mf_rq == 0)
+				clk_enable(isomgr.emc_clk);
+			isomgr.lt_mf_rq = isomgr.lt_mf;
+			if (isomgr.lt_mf_rq == 0)
+				clk_disable(isomgr.emc_clk);
+		}
+#endif
+	}
+
+	for (i = 0; i < TEGRA_ISO_CLIENT_COUNT; i++) {
+
+		/*max emc floor req when camera is active for t194 */
+		if (i == TEGRA_ISO_CLIENT_TEGRA_CAMERA) {
+			if (isomgr_camera_max_floor_req) {
+				if (isomgr_clients[i].real_mf)
+					tegra_bwmgr_set_emc(
+						isomgr_clients[i].bwmgr_handle,
+						emc_max_rate,
+						TEGRA_BWMGR_SET_EMC_FLOOR);
+				else
+					tegra_bwmgr_set_emc(
+						isomgr_clients[i].bwmgr_handle,
+						0,
+						TEGRA_BWMGR_SET_EMC_FLOOR);
+			}
+		}
+
+		if (isomgr_clients[i].real_mf != isomgr_clients[i].real_mf_rq) {
+			/* Ignore clocks for clients that are non-existent. */
+#ifdef CONFIG_COMMON_CLK
+			if (!isomgr_clients[i].bwmgr_handle)
+				continue;
+			/* Each client's request is limited to
+			 * limit_bw_percentage% of current DRAM BW. A floor
+			 * request is made by each client to hold DRAM freq
+			 * high enough such that
+			 * DRAM_freq > client's req_bw/limit_bw_percentage
+			 */
+			if (isomgr_clients[i].limit_bw_percentage != 100) {
+				floor_freq = (u64)isomgr_clients[i].real_mf
+					* 1000 * 100;
+				floor_freq = floor_freq /
+				(u64)isomgr_clients[i].limit_bw_percentage;
+				tegra_bwmgr_set_emc(
+					isomgr_clients[i].bwmgr_handle,
+					floor_freq,
+					TEGRA_BWMGR_SET_EMC_FLOOR);
+			}
+			if (!tegra_bwmgr_set_emc(
+					isomgr_clients[i].bwmgr_handle,
+					isomgr_clients[i].real_mf * 1000,
+					TEGRA_BWMGR_SET_EMC_SHARED_BW_ISO))
+				isomgr_clients[i].real_mf_rq =
+					isomgr_clients[i].real_mf;
+#else
+			if (!isomgr_clients[i].emc_clk)
+				continue;
+
+			if (clk_set_rate(isomgr_clients[i].emc_clk,
+					 isomgr_clients[i].real_mf * 1000))
+				continue;
+
+			if (isomgr_clients[i].real_mf_rq == 0)
+				clk_enable(isomgr_clients[i].emc_clk);
+			isomgr_clients[i].real_mf_rq =
+				isomgr_clients[i].real_mf;
+			if (isomgr_clients[i].real_mf_rq == 0)
+				clk_disable(isomgr_clients[i].emc_clk);
+#endif
+		}
+	}
+}
+
+static void purge_isomgr_client(struct isomgr_client *cp)
+{
+	cp->magic = 0;
+	OBJ_REF_SET(&cp->kref.refcount, 0);
+	cp->dedi_bw = 0;
+	cp->rsvd_bw = 0;
+	cp->real_bw = 0;
+	cp->rsvd_mf = 0;
+	cp->real_mf = 0;
+	cp->renegotiate = NULL;
+	cp->realize = false;
+	cp->priv = NULL;
+	cp->sleep_bw = 0;
+	cp->margin_bw = 0;
+}
+
+/* This function should be called with isomgr lock */
+static void unregister_iso_client(struct kref *kref)
+{
+	struct isomgr_client *cp = container_of(kref,
+					struct isomgr_client, kref);
+	int client = cp - &isomgr_clients[0];
+
+	/*If we get the lock, it means lock was not taken and hence we return*/
+	if (unlikely(mutex_trylock(&isomgr.lock))) {
+		pr_err("isomgr: unregister_iso_client called without lock\n");
+		WARN_ON(true);
+		return;
+	}
+
+	trace_tegra_isomgr_unregister_iso_client(cname[client], "enter");
+	if (unlikely(cp->realize)) {
+		pr_err
+		("isomgr: %s called while realize in progress\n", __func__);
+		goto fail;
+	}
+
+	if (isomgr.ops->isomgr_plat_unregister)
+		isomgr.ops->isomgr_plat_unregister(cp);
+
+	isomgr.dedi_bw -= cp->dedi_bw;
+	purge_isomgr_client(cp);
+	update_mc_clock();
+
+	trace_tegra_isomgr_unregister_iso_client(cname[client], "exit");
+	return;
+
+fail:
+	trace_tegra_isomgr_unregister_iso_client(cname[client], "exit fail");
+}
+
+static bool is_client_valid(enum tegra_iso_client client)
+{
+	if (unlikely(client < 0 ||
+			client >= TEGRA_ISO_CLIENT_COUNT ||
+			!client_valid[client] ||
+#ifdef CONFIG_COMMON_CLK
+			!isomgr_clients[client].bwmgr_handle))
+#else
+			!isomgr_clients[client].emc_clk))
+#endif
+		return false;
+	return true;
+}
+
+static tegra_isomgr_handle __tegra_isomgr_register(
+			enum tegra_iso_client client, u32 udedi_bw,
+			tegra_isomgr_renegotiate renegotiate, void *priv)
+{
+	s32 dedi_bw = udedi_bw;
+	bool ret = 0;
+	struct isomgr_client *cp = NULL;
+
+	VALIDATE_CLIENT();
+	trace_tegra_isomgr_register(client, dedi_bw, renegotiate,
+		priv, cname[client], "enter");
+
+	if (unlikely(!udedi_bw && !renegotiate))
+		goto validation_fail;
+
+	if (!isomgr_lock()) {
+		pr_err("isomgr: %s failed for %s\n",
+			__func__, cname[client]);
+		goto validation_fail;
+	}
+	cp = &isomgr_clients[client];
+
+	if (unlikely(OBJ_REF_READ(&cp->kref.refcount)))
+		goto fail_unlock;
+
+	if (isomgr.ops->isomgr_plat_register) {
+		ret = isomgr.ops->isomgr_plat_register(dedi_bw, client);
+		if (!ret)
+			goto fail_unlock;
+	}
+
+	purge_isomgr_client(cp);
+	cp->magic = ISOMGR_MAGIC;
+	kref_init(&cp->kref);
+	cp->dedi_bw = dedi_bw;
+	cp->renegotiate = renegotiate;
+	cp->priv = priv;
+	isomgr.dedi_bw += dedi_bw;
+
+	if (!isomgr_unlock()) {
+		pr_err("isomgr: %s failed for %s\n",
+			__func__, cname[client]);
+		goto validation_fail;
+	}
+	trace_tegra_isomgr_register(client, dedi_bw, renegotiate,
+		priv, cname[client], "exit");
+	return (tegra_isomgr_handle)cp;
+
+fail_unlock:
+	if (!isomgr_unlock()) {
+		pr_err("isomgr: %s failed for %s\n",
+			__func__, cname[client]);
+	}
+validation_fail:
+	trace_tegra_isomgr_register(client, dedi_bw, renegotiate,
+		priv, cname[client], "inv_args_exit");
+	return ERR_PTR(-EINVAL);
+}
+
+/**
+ * tegra_isomgr_register - register an ISO BW client.
+ *
+ * @client	client to register as an ISO client.
+ * @udedi_bw	minimum bw client can work at. This bw is guarnteed to be
+ *		available for client when ever client need it. Client can
+ *		always request for more bw and client can get it based on
+ *		availability of bw in the system. udedi_bw is specified in KB.
+ * @renegotiate	callback function to be called to renegotiate for bw.
+ *		client with no renegotiate callback provided can't allocate
+ *		bw more than udedi_bw.
+ *		Client with renegotiate callback can allocate more than
+ *		udedi_bw and release it during renegotiate callback, when
+ *		other clients in the system need their bw back.
+ *		renegotiate callback is called in two cases. 1. The isomgr
+ *		has excess bw, checking client to see if they need more bw.
+ *		2. The isomgr is out of bw and other clients need their udedi_bw
+ *		back. In this case, the client, which is using higher bw need to
+ *		release the bw and fallback to low(udedi_bw) bw use case.
+ * @priv	pointer to renegotiate callback function.
+ *
+ * @return	returns valid handle on successful registration.
+ * @retval	-EINVAL invalid arguments passed.
+ */
+tegra_isomgr_handle tegra_isomgr_register(enum tegra_iso_client client,
+					  u32 udedi_bw,
+					  tegra_isomgr_renegotiate renegotiate,
+					  void *priv)
+{
+	if (test_mode)
+		return (tegra_isomgr_handle)1;
+	return __tegra_isomgr_register(client, udedi_bw, renegotiate, priv);
+}
+EXPORT_SYMBOL(tegra_isomgr_register);
+
+static void __tegra_isomgr_unregister(tegra_isomgr_handle handle)
+{
+	struct isomgr_client *cp = (struct isomgr_client *)handle;
+	int client = cp - &isomgr_clients[0];
+
+	VALIDATE_HANDLE();
+	if (!isomgr_lock()) {
+		pr_err("isomgr: %s failed for %s\n",
+			__func__, cname[client]);
+		goto validation_fail;
+	}
+	trace_tegra_isomgr_unregister(handle, cname[client]);
+	kref_put(&cp->kref, unregister_iso_client);
+	if (!isomgr_unlock()) {
+		pr_err("isomgr: %s failed for %s\n",
+			__func__, cname[client]);
+	}
+validation_fail:
+	return;
+}
+
+/**
+ * tegra_isomgr_unregister - unregister an ISO BW client.
+ *
+ * @handle	handle acquired during tegra_isomgr_register.
+ */
+void tegra_isomgr_unregister(tegra_isomgr_handle handle)
+{
+	if (test_mode)
+		return;
+	__tegra_isomgr_unregister(handle);
+}
+EXPORT_SYMBOL(tegra_isomgr_unregister);
+
+static u32 __tegra_isomgr_reserve(tegra_isomgr_handle handle,
+			 u32 ubw, u32 ult)
+{
+	s32 bw = ubw;
+	bool ret = 0;
+	u32 mf, dvfs_latency = 0;
+	struct isomgr_client *cp = (struct isomgr_client *) handle;
+	int client = cp - &isomgr_clients[0];
+
+	VALIDATE_HANDLE();
+
+	if (!isomgr_lock()) {
+		pr_err("isomgr: %s failed for %s\n",
+			__func__, cname[client]);
+		goto validation_fail;
+	}
+	if (unlikely(!OBJ_REF_INC_NOT_ZERO(&cp->kref.refcount)))
+		goto handle_unregistered;
+
+	if (cp->rsvd_bw == ubw && cp->lti == ult) {
+		kref_put(&cp->kref, unregister_iso_client);
+		if (!isomgr_unlock()) {
+			pr_err("isomgr: %s failed for %s\n",
+				__func__, cname[client]);
+			goto validation_fail;
+		}
+		return cp->lto;
+	}
+
+	trace_tegra_isomgr_reserve(handle, ubw, ult, cname[client], "enter");
+
+	if (unlikely(cp->realize))
+		goto out;
+
+	if (unlikely(!cp->renegotiate && bw > cp->dedi_bw))
+		goto out;
+
+	if (isomgr.ops->isomgr_plat_reserve) {
+		ret = isomgr.ops->isomgr_plat_reserve(cp, bw,
+				(enum tegra_iso_client)client);
+		if (!ret)
+			goto out;
+	}
+
+	/* Look up MC's min freq that could satisfy requested BW and LT */
+	mf = mc_min_freq(ubw, ult);
+	/* Look up MC's dvfs latency at min freq */
+	dvfs_latency = mc_dvfs_latency(mf);
+
+	cp->lti = ult;		/* remember client spec'd LT (usec) */
+	cp->lto = dvfs_latency;	/* remember MC calculated LT (usec) */
+	cp->rsvd_mf = mf;	/* remember associated min freq */
+	cp->rsvd_bw = bw;
+out:
+	kref_put(&cp->kref, unregister_iso_client);
+	if (!isomgr_unlock()) {
+		pr_err("isomgr: %s failed for %s\n",
+			__func__, cname[client]);
+		goto validation_fail;
+	}
+	trace_tegra_isomgr_reserve(handle, ubw, ult, cname[client],
+		dvfs_latency ? "exit" : "rsrv_fail_exit");
+	return dvfs_latency;
+handle_unregistered:
+	if (!isomgr_unlock()) {
+		pr_err("isomgr: %s failed for %s\n",
+			__func__, cname[client]);
+		goto validation_fail;
+	}
+	trace_tegra_isomgr_reserve(handle, ubw, ult,
+		cname[client], "inv_handle_exit");
+	return dvfs_latency;
+validation_fail:
+	trace_tegra_isomgr_reserve(handle, ubw, ult, "unk", "inv_handle_exit");
+	return dvfs_latency;
+}
+
+/**
+ * tegra_isomgr_reserve - reserve bw for the ISO client.
+ *
+ * @handle	handle acquired during tegra_isomgr_register.
+ * @ubw		bandwidth in KBps.
+ * @ult		latency that can be tolerated by client in usec.
+ *
+ * returns dvfs latency thresh in usec.
+ * return 0 indicates that reserve failed.
+ */
+u32 tegra_isomgr_reserve(tegra_isomgr_handle handle,
+			 u32 ubw, u32 ult)
+{
+	if (test_mode)
+		return 1;
+	return __tegra_isomgr_reserve(handle, ubw, ult);
+}
+EXPORT_SYMBOL(tegra_isomgr_reserve);
+
+static u32 __tegra_isomgr_realize(tegra_isomgr_handle handle)
+{
+	u32 dvfs_latency = 0;
+	bool ret = 0;
+	struct isomgr_client *cp = (struct isomgr_client *) handle;
+	int client = cp - &isomgr_clients[0];
+
+	VALIDATE_HANDLE();
+
+	if (!isomgr_lock()) {
+		pr_err("isomgr: %s failed for %s\n",
+			__func__, cname[client]);
+		goto validation_fail;
+	}
+	if (unlikely(!OBJ_REF_INC_NOT_ZERO(&cp->kref.refcount)))
+		goto handle_unregistered;
+
+	if (cp->rsvd_bw == cp->real_bw && cp->rsvd_mf == cp->real_mf) {
+		kref_put(&cp->kref, unregister_iso_client);
+		if (!isomgr_unlock()) {
+			pr_err("isomgr: %s failed for %s\n",
+				__func__, cname[client]);
+			goto validation_fail;
+		}
+		return cp->lto;
+	}
+
+	trace_tegra_isomgr_realize(handle, cname[client], "enter");
+
+	if (isomgr.ops->isomgr_plat_realize) {
+		ret = isomgr.ops->isomgr_plat_realize(cp);
+		if (!ret)
+			goto out;
+	}
+
+	dvfs_latency = (u32)cp->lto;
+	cp->realize = false;
+	update_mc_clock();
+
+out:
+	kref_put(&cp->kref, unregister_iso_client);
+	if (!isomgr_unlock()) {
+		pr_err("isomgr: %s failed for %s\n",
+			__func__, cname[client]);
+		goto validation_fail;
+	}
+	trace_tegra_isomgr_realize(handle, cname[client],
+		dvfs_latency ? "exit" : "real_fail_exit");
+	return dvfs_latency;
+handle_unregistered:
+	if (!isomgr_unlock()) {
+		pr_err("isomgr: %s failed for %s\n",
+			__func__, cname[client]);
+		goto validation_fail;
+	}
+	trace_tegra_isomgr_realize(handle, cname[client], "inv_handle_exit");
+	return dvfs_latency;
+validation_fail:
+	trace_tegra_isomgr_realize(handle, "unk", "inv_handle_exit");
+	return dvfs_latency;
+}
+
+/**
+ * tegra_isomgr_realize - realize the bw reserved by client.
+ *
+ * @handle	handle acquired during tegra_isomgr_register.
+ *
+ * returns dvfs latency thresh in usec.
+ * return 0 indicates that realize failed.
+ */
+u32 tegra_isomgr_realize(tegra_isomgr_handle handle)
+{
+	if (test_mode)
+		return 1;
+	return __tegra_isomgr_realize(handle);
+}
+EXPORT_SYMBOL(tegra_isomgr_realize);
+
+static int __tegra_isomgr_set_margin(enum tegra_iso_client client,
+					u32 bw, bool wait)
+{
+	int ret = -EINVAL;
+	s32 high_bw;
+	struct isomgr_client *cp = NULL;
+
+	trace_tegra_isomgr_set_margin(client, bw, wait, "enter");
+	VALIDATE_CLIENT();
+
+	if (!isomgr_lock()) {
+		pr_err("isomgr: %s failed for %s\n",
+			__func__, cname[client]);
+		goto validation_fail;
+	}
+	cp = &isomgr_clients[client];
+	if (unlikely(!OBJ_REF_INC_NOT_ZERO(&cp->kref.refcount)))
+		goto handle_unregistered;
+
+	if (bw > cp->dedi_bw)
+		goto out;
+
+	if (bw <= cp->real_bw) {
+		if (cp->margin_bw > cp->real_bw)
+			isomgr.avail_bw += cp->margin_bw - cp->real_bw;
+		cp->margin_bw = bw;
+	} else if (bw <= cp->margin_bw) {
+		if (unlikely(cp->margin_bw > cp->real_bw)) {
+			pr_err("isomgr: set_margin: margin_bw > real_bw\n");
+			ret = -EINVAL;
+			goto out;
+		}
+		isomgr.avail_bw += cp->margin_bw - bw;
+		cp->margin_bw = bw;
+		if (unlikely(cp->margin_bw > cp->real_bw)) {
+			pr_err("isomgr: set_margin: margin_bw > real_bw\n");
+			ret = -EINVAL;
+			goto out;
+		}
+	} else if (bw > cp->margin_bw) {
+		high_bw = (cp->margin_bw > cp->real_bw) ?
+				cp->margin_bw : cp->real_bw;
+		if (bw - high_bw <= isomgr.avail_bw - isomgr.sleep_bw) {
+			isomgr.avail_bw -= bw - high_bw;
+			cp->margin_bw = bw;
+		} else {
+			ret = -EINVAL;
+			goto out;
+		}
+	}
+	ret = 0;
+out:
+	kref_put(&cp->kref, unregister_iso_client);
+	if (!isomgr_unlock()) {
+		pr_err("isomgr: %s failed for %s\n",
+			__func__, cname[client]);
+		goto validation_fail;
+	}
+	trace_tegra_isomgr_set_margin(client, bw, wait,
+					ret ? "fail_exit" : "exit");
+	return ret;
+handle_unregistered:
+	if (!isomgr_unlock()) {
+		pr_err("isomgr: %s failed for %s\n",
+			__func__, cname[client]);
+	}
+validation_fail:
+	trace_tegra_isomgr_set_margin(client, bw, wait, "inv_arg_fail");
+	return ret;
+}
+
+/**
+ * This sets bw aside for the client specified.
+ * This bw can never be used for other clients needs.
+ * margin bw, if not zero, should always be greater than equal to
+ * reserved/realized bw.
+ *
+ * @client client
+ * @bw bw margin KB.
+ * @wait if true and bw is not available, it would wait till bw is available.
+ *	  if false, it would return immediately with success or failure.
+ *
+ * @retval  0 operation is successful.
+ * @retval -ENOMEM Iso Bw requested is not avialable.
+ * @retval -EINVAL Invalid arguments, bw is less than reserved/realized bw.
+ */
+int tegra_isomgr_set_margin(enum tegra_iso_client client, u32 bw, bool wait)
+{
+	if (test_mode)
+		return 0;
+	return __tegra_isomgr_set_margin(client, bw, wait);
+}
+EXPORT_SYMBOL(tegra_isomgr_set_margin);
+
+static int __tegra_isomgr_get_imp_time(enum tegra_iso_client client, u32 bw)
+{
+	int ret = -EINVAL;
+
+	if (unlikely(!is_client_valid(client)))
+		return ret;
+
+	/* FIXME: get this from renegotiable clients(display driver). */
+	ret = 100;
+	if (isomgr.avail_bw >= bw)
+		ret = 0;
+	trace_tegra_isomgr_get_imp_time(client, bw, ret, cname[client]);
+	return ret;
+}
+
+/**
+ * Returns the imp time required to realize the bw request.
+ * The time returned is an approximate. It is possible that imp
+ * time is returned as zero and still realize would be blocked for
+ * non-zero time in realize call.
+ *
+ * @client	client id
+ * @bw		bw in KB/sec
+ *
+ * @returns	time in milliseconds.
+ * @retval	-EINVAL, client id is invalid.
+ */
+int tegra_isomgr_get_imp_time(enum tegra_iso_client client, u32 bw)
+{
+	if (test_mode)
+		return 0;
+	return __tegra_isomgr_get_imp_time(client, bw);
+}
+EXPORT_SYMBOL(tegra_isomgr_get_imp_time);
+
+static u32 __tegra_isomgr_get_available_iso_bw(void)
+{
+	trace_tegra_isomgr_get_available_iso_bw(isomgr.avail_bw);
+	return isomgr.avail_bw;
+}
+
+/**
+ * Returns available iso bw at the time of calling this API.
+ *
+ * @returns	available bw in KB/sec.
+ */
+u32 tegra_isomgr_get_available_iso_bw(void)
+{
+	if (test_mode)
+		return UINT_MAX;
+	return __tegra_isomgr_get_available_iso_bw();
+}
+EXPORT_SYMBOL(tegra_isomgr_get_available_iso_bw);
+
+static u32 __tegra_isomgr_get_total_iso_bw(enum tegra_iso_client client)
+{
+	u32 bw;
+
+	if (isomgr.ops->isomgr_max_iso_bw) /*t19x and later*/
+		bw = isomgr.ops->isomgr_max_iso_bw(client);
+	else /*t18x and before*/
+		bw = isomgr.max_iso_bw;
+
+	trace_tegra_isomgr_get_total_iso_bw(bw);
+	return bw;
+}
+
+/**
+ * Returns total iso bw in the system.
+ *
+ * @returns	total bw in KB/sec.
+ */
+u32 tegra_isomgr_get_total_iso_bw(enum tegra_iso_client client)
+{
+	if (test_mode)
+		return UINT_MAX;
+	return __tegra_isomgr_get_total_iso_bw(client);
+}
+EXPORT_SYMBOL(tegra_isomgr_get_total_iso_bw);
+
+#ifdef CONFIG_TEGRA_ISOMGR_SYSFS
+static ssize_t isomgr_show(struct kobject *kobj,
+	struct kobj_attribute *attr, char *buf);
+
+static const struct kobj_attribute lt_mf_attr =
+	__ATTR(lt_mf, 0444, isomgr_show, NULL);
+static const struct kobj_attribute avail_bw_attr =
+	__ATTR(avail_bw, 0444, isomgr_show, NULL);
+static const struct kobj_attribute max_iso_bw_attr =
+	__ATTR(max_iso_bw, 0444, isomgr_show, NULL);
+static const struct kobj_attribute version_attr =
+	__ATTR(version, 0444, isomgr_show, NULL);
+
+static const struct attribute *isomgr_attrs[] = {
+	&lt_mf_attr.attr,
+	&avail_bw_attr.attr,
+	&max_iso_bw_attr.attr,
+	&version_attr.attr,
+	NULL
+};
+
+static ssize_t isomgr_show(struct kobject *kobj,
+	struct kobj_attribute *attr, char *buf)
+{
+	ssize_t rval = 0;
+
+	if (attr == &lt_mf_attr)
+		rval = sprintf(buf, "%dKHz\n", isomgr.lt_mf);
+	else if (attr == &avail_bw_attr)
+		rval = sprintf(buf, "%dKB\n", isomgr.avail_bw);
+	else if (attr == &max_iso_bw_attr)
+		rval = sprintf(buf, "%dKB\n", isomgr.max_iso_bw);
+	else if (attr == &version_attr)
+		rval = sprintf(buf, "%d\n", ISOMGR_SYSFS_VERSION);
+	return rval;
+}
+
+static ssize_t isomgr_client_show(struct kobject *kobj,
+	struct kobj_attribute *attr, char *buf)
+{
+	int client = ((char *)attr - (char *)isomgr_clients) /
+			sizeof(struct isomgr_client);
+	struct isomgr_client *cp =
+			(struct isomgr_client *)&isomgr_clients[client];
+	ssize_t rval = 0;
+
+	if (attr == &cp->client_attrs.dedi_bw)
+		rval = sprintf(buf, "%dKB\n", cp->dedi_bw);
+	else if (attr == &cp->client_attrs.rsvd_bw)
+		rval = sprintf(buf, "%dKB\n", cp->rsvd_bw);
+	else if (attr == &cp->client_attrs.real_bw)
+		rval = sprintf(buf, "%dKB\n", cp->real_bw);
+	else if (attr == &cp->client_attrs.lti)
+		rval = sprintf(buf, "%dus\n", cp->lti);
+	else if (attr == &cp->client_attrs.lto)
+		rval = sprintf(buf, "%dus\n", cp->lto);
+	else if (attr == &cp->client_attrs.rsvd_mf)
+		rval = sprintf(buf, "%dKHz\n", cp->rsvd_mf);
+	else if (attr == &cp->client_attrs.real_mf)
+		rval = sprintf(buf, "%dKHz\n", cp->real_mf);
+	else if (attr == &cp->client_attrs.sleep_bw)
+		rval = sprintf(buf, "%dKB\n", cp->sleep_bw);
+	else if (attr == &cp->client_attrs.margin_bw)
+		rval = sprintf(buf, "%dKB\n", cp->margin_bw);
+	return rval;
+}
+
+static const struct isomgr_client_attrs client_attrs = {
+	__ATTR(dedi_bw, 0444, isomgr_client_show, NULL),
+	__ATTR(rsvd_bw, 0444, isomgr_client_show, NULL),
+	__ATTR(real_bw, 0444, isomgr_client_show, NULL),
+	__ATTR(lti,     0444, isomgr_client_show, NULL),
+	__ATTR(lto,     0444, isomgr_client_show, NULL),
+	__ATTR(rsvd_mf, 0444, isomgr_client_show, NULL),
+	__ATTR(real_mf, 0444, isomgr_client_show, NULL),
+	__ATTR(sleep_bw, 0444, isomgr_client_show, NULL),
+	__ATTR(margin_bw, 0444, isomgr_client_show, NULL),
+};
+
+#define NCATTRS (sizeof(client_attrs) / sizeof(struct kobj_attribute))
+static const struct attribute *client_attr_list[][NCATTRS+1] = {
+#define CLIENT_ATTR(i)\
+	{\
+		&isomgr_clients[i].client_attrs.dedi_bw.attr,\
+		&isomgr_clients[i].client_attrs.rsvd_bw.attr,\
+		&isomgr_clients[i].client_attrs.real_bw.attr,\
+		&isomgr_clients[i].client_attrs.lti.attr,\
+		&isomgr_clients[i].client_attrs.lto.attr,\
+		&isomgr_clients[i].client_attrs.rsvd_mf.attr,\
+		&isomgr_clients[i].client_attrs.real_mf.attr,\
+		&isomgr_clients[i].client_attrs.sleep_bw.attr,\
+		&isomgr_clients[i].client_attrs.margin_bw.attr,\
+		NULL\
+	},
+	CLIENT_ATTR(0)
+	CLIENT_ATTR(1)
+	CLIENT_ATTR(2)
+	CLIENT_ATTR(3)
+	CLIENT_ATTR(4)
+	CLIENT_ATTR(5)
+	CLIENT_ATTR(6)
+	CLIENT_ATTR(7)
+	CLIENT_ATTR(8)
+	CLIENT_ATTR(9)
+	CLIENT_ATTR(10)
+	CLIENT_ATTR(11)
+};
+
+static void isomgr_create_client(int client, const char *name)
+{
+	struct isomgr_client *cp = &isomgr_clients[client];
+
+	/* If this error hits, more CLIENT_ATTR(x) need to be added
+	 * in the above array client_attr_list.
+	 */
+	BUILD_BUG_ON(TEGRA_ISO_CLIENT_COUNT > 11);
+	if (unlikely(!isomgr.kobj)) {
+		pr_err("isomgr: create_client failed, isomgr.kobj is null\n");
+		return;
+	}
+	if (unlikely(cp->client_kobj)) {
+		pr_err("isomgr: create_client failed, client_kobj is null\n");
+		return;
+	}
+	cp->client_kobj = kobject_create_and_add(name, isomgr.kobj);
+	if (!cp->client_kobj) {
+		pr_err("failed to create sysfs client dir\n");
+		return;
+	}
+	cp->client_attrs = client_attrs;
+	if (sysfs_create_files(cp->client_kobj, &client_attr_list[client][0])) {
+		pr_err("failed to create sysfs client files\n");
+		kobject_del(cp->client_kobj);
+		return;
+	}
+}
+
+static void isomgr_create_sysfs(void)
+{
+	int i;
+
+	if (unlikely(isomgr.kobj)) {
+		pr_err("isomgr: create_sysfs failed, isomgr.kobj exists\n");
+		return;
+	}
+	isomgr.kobj = kobject_create_and_add("isomgr", kernel_kobj);
+	if (!isomgr.kobj) {
+		pr_err("failed to create kobject\n");
+		return;
+	}
+	if (sysfs_create_files(isomgr.kobj, isomgr_attrs)) {
+		pr_err("failed to create sysfs files\n");
+		kobject_del(isomgr.kobj);
+		isomgr.kobj = NULL;
+		return;
+	}
+
+	for (i = 0; i < isoclients; i++) {
+		if (isoclient_info[i].name)
+			isomgr_create_client(isoclient_info[i].client,
+					     isoclient_info[i].name);
+	}
+}
+#else
+static inline void isomgr_create_sysfs(void) {};
+#endif /* CONFIG_TEGRA_ISOMGR_SYSFS */
+
+int __init isomgr_init(void)
+{
+	int i;
+
+	mutex_init(&isomgr.lock);
+
+	if (tegra_get_chip_id() == TEGRA194)
+		isomgr.ops = t19x_isomgr_init();
+	else
+		isomgr.ops = pre_t19x_isomgr_init();
+
+	for (i = 0; ; i++) {
+		if (isoclient_info[i].name)
+			client_valid[isoclient_info[i].client] = true;
+		else
+			break;
+	}
+
+#ifdef CONFIG_COMMON_CLK
+	isomgr.bwmgr_handle = tegra_bwmgr_register(TEGRA_BWMGR_CLIENT_ISOMGR);
+	if (IS_ERR_OR_NULL(isomgr.bwmgr_handle)) {
+		pr_err("couldn't get handle from bwmgr. disabling isomgr.\n");
+#else
+	isomgr.emc_clk = clk_get_sys("iso", "emc");
+	if (IS_ERR_OR_NULL(isomgr.emc_clk)) {
+		pr_err("couldn't find iso emc clock. disabling isomgr.\n");
+#endif
+		test_mode = 1;
+		return 0;
+	}
+
+	isomgr.ops->isomgr_plat_init();
+
+	for (i = 0; i < isoclients; i++) {
+		if (isoclient_info[i].name) {
+			enum tegra_iso_client c = isoclient_info[i].client;
+
+			OBJ_REF_SET(&isomgr_clients[c].kref.refcount, 0);
+			init_completion(&isomgr_clients[c].cmpl);
+#ifdef CONFIG_COMMON_CLK
+			isomgr_clients[c].bwmgr_handle = tegra_bwmgr_register(
+					isoclient_info[i].bwmgr_id);
+
+			if (IS_ERR_OR_NULL(isomgr_clients[c].bwmgr_handle)) {
+				pr_err("couldn't get %s's bwmgr handle\n",
+						isoclient_info[i].name);
+				isomgr_clients[c].bwmgr_handle = NULL;
+#else
+			isomgr_clients[c].emc_clk = clk_get_sys(
+					isoclient_info[i].dev_name,
+					isoclient_info[i].emc_clk_name);
+
+			if (IS_ERR_OR_NULL(isomgr_clients[c].emc_clk)) {
+				pr_err("couldn't find %s %s clock",
+					isoclient_info[i].dev_name,
+					isoclient_info[i].emc_clk_name);
+
+				isomgr_clients[c].emc_clk = NULL;
+#endif
+				return 0;
+			}
+		}
+	}
+
+	isomgr_create_sysfs();
+	return 0;
+}
+#ifdef CONFIG_COMMON_CLK
+fs_initcall(isomgr_init);
+#endif
+
+int tegra_isomgr_enable_test_mode(void)
+{
+	int i;
+	struct isomgr_client *cp = NULL;
+
+	if (!isomgr_lock()) {
+		pr_err("isomgr: enable_test_mode lock deadlock\n");
+		return -EINVAL;
+	}
+	test_mode = 1;
+	if (!isomgr_unlock()) {
+		pr_err("isomgr: enable_test_mode unlock mismatch\n");
+		return -EINVAL;
+	}
+	for (i = 0; i < TEGRA_ISO_CLIENT_COUNT; i++) {
+		if (!client_valid[i])
+			continue;
+		cp = &isomgr_clients[i];
+retry:
+		__tegra_isomgr_unregister(cp);
+		if (OBJ_REF_READ(&cp->kref.refcount))
+			goto retry;
+	}
+	return 0;
+}
+EXPORT_SYMBOL(tegra_isomgr_enable_test_mode);
+
+tegra_isomgr_handle test_tegra_isomgr_register(enum tegra_iso_client client,
+					  u32 dedicated_bw,	/* KB/sec */
+					  tegra_isomgr_renegotiate renegotiate,
+					  void *priv)
+{
+	return __tegra_isomgr_register(client, dedicated_bw, renegotiate, priv);
+}
+EXPORT_SYMBOL(test_tegra_isomgr_register);
+
+void test_tegra_isomgr_unregister(tegra_isomgr_handle handle)
+{
+	return __tegra_isomgr_unregister(handle);
+}
+EXPORT_SYMBOL(test_tegra_isomgr_unregister);
+
+/* bw in KB/sec and lt in usec*/
+u32 test_tegra_isomgr_reserve(tegra_isomgr_handle handle,
+			 u32 bw, u32 lt)
+{
+	return __tegra_isomgr_reserve(handle, bw, lt);
+}
+EXPORT_SYMBOL(test_tegra_isomgr_reserve);
+
+u32 test_tegra_isomgr_realize(tegra_isomgr_handle handle)
+{
+	return __tegra_isomgr_realize(handle);
+}
+EXPORT_SYMBOL(test_tegra_isomgr_realize);
+
+int test_tegra_isomgr_set_margin(enum tegra_iso_client client,
+				u32 bw, bool wait)
+{
+	return __tegra_isomgr_set_margin(client, bw, wait);
+}
+EXPORT_SYMBOL(test_tegra_isomgr_set_margin);
+
+int test_tegra_isomgr_get_imp_time(enum tegra_iso_client client, u32 bw)
+{
+	return __tegra_isomgr_get_imp_time(client, bw);
+}
+EXPORT_SYMBOL(test_tegra_isomgr_get_imp_time);
+
+u32 test_tegra_isomgr_get_available_iso_bw(void)
+{
+	return __tegra_isomgr_get_available_iso_bw();
+}
+EXPORT_SYMBOL(test_tegra_isomgr_get_available_iso_bw);
+
+u32 test_tegra_isomgr_get_total_iso_bw(enum tegra_iso_client client)
+{
+	return __tegra_isomgr_get_total_iso_bw(client);
+}
+EXPORT_SYMBOL(test_tegra_isomgr_get_total_iso_bw);
diff --git a/drivers/platform/tegra/mc/la_priv.h b/drivers/platform/tegra/mc/la_priv.h
new file mode 100644
index 000000000000..02e5db8e6df8
--- /dev/null
+++ b/drivers/platform/tegra/mc/la_priv.h
@@ -0,0 +1,645 @@
+/*
+ * arch/arm/mach-tegra/la_priv.h
+ *
+ * Copyright (C) 2012-2018, NVIDIA CORPORATION.  All rights reserved.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#ifndef _MACH_TEGRA_LA_PRIV_H_
+#define _MACH_TEGRA_LA_PRIV_H_
+
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0A_LOW_SHIFT		0
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0A_LOW_MASK		\
+	(0xff << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0A_LOW_SHIFT)
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0A_HIGH_SHIFT	16
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0A_HIGH_MASK		\
+	(0xff << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0A_HIGH_SHIFT)
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0AB_LOW_SHIFT	0
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0AB_LOW_MASK		\
+	(0xff << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0AB_LOW_SHIFT)
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0AB_HIGH_SHIFT	16
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0AB_HIGH_MASK	\
+	(0xff << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0AB_HIGH_SHIFT)
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0B_LOW_SHIFT		0
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0B_LOW_MASK		\
+	(0xff << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0B_LOW_SHIFT)
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0B_HIGH_SHIFT	16
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0B_HIGH_MASK		\
+	(0xff << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0B_HIGH_SHIFT)
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0BB_LOW_SHIFT	0
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0BB_LOW_MASK		\
+	(0xff << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0BB_LOW_SHIFT)
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0BB_HIGH_SHIFT	16
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0BB_HIGH_MASK	\
+	(0xff << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0BB_HIGH_SHIFT)
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0C_LOW_SHIFT		0
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0C_LOW_MASK		\
+	(0xff << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0C_LOW_SHIFT)
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0C_HIGH_SHIFT	16
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0C_HIGH_MASK		\
+	(0xff << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0C_HIGH_SHIFT)
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0CB_LOW_SHIFT	0
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0CB_LOW_MASK		\
+	(0xff << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0CB_LOW_SHIFT)
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0CB_HIGH_SHIFT	16
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0CB_HIGH_MASK	\
+	(0xff << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0CB_HIGH_SHIFT)
+
+#define EMEM_PTSA_RATE_WIDTH		12
+#define MAX_DDA_RATE			0xfff
+
+#define LA_FP_FACTOR			1000U
+#define LA_REAL_TO_FP(val)		((val) * LA_FP_FACTOR)
+#define LA_FP_TO_REAL(val)		((val) / LA_FP_FACTOR)
+#define LA_ADDITIONAL_FP_FACTOR		10U
+#define LA_FP_TO_FPA(val)		((val) * LA_ADDITIONAL_FP_FACTOR)
+#define LA_FPA_TO_FP(val)		((val) / LA_ADDITIONAL_FP_FACTOR)
+#define LA_FPA_TO_REAL(val)		((val) / LA_FP_FACTOR /		\
+					 LA_ADDITIONAL_FP_FACTOR)
+#define LA_REAL_TO_FPA(val)		((val) * LA_FP_FACTOR *	\
+					 LA_ADDITIONAL_FP_FACTOR)
+
+#define MASK(x) \
+	((0xFFFFFFFFUL >> (31 - (1 ? x) + (0 ? x))) << (0 ? x))
+#define SHIFT(x) \
+	(0 ? x)
+#define ID(id) \
+	TEGRA_LA_##id
+
+#define VALIDATE_ID(id, p) \
+do { \
+	if (id >= TEGRA_LA_MAX_ID || (p)->id_to_index[(id)] == 0xFFFF) { \
+		WARN_ONCE(1, "%s: invalid Id=%d", __func__, (id)); \
+		return -EINVAL; \
+	} \
+	BUG_ON((p)->la_info_array[(p)->id_to_index[(id)]].id != (id)); \
+} while (0)
+
+#define VALIDATE_BW(bw_in_mbps) \
+do { \
+	if (bw_in_mbps >= 4096) \
+		return -EINVAL; \
+} while (0)
+
+#define VALIDATE_THRESHOLDS(tl, tm, th) \
+do { \
+	if ((tl) > 100 || (tm) > 100 || (th) > 100) \
+		return -EINVAL; \
+} while (0)
+
+#define LAST_DISP_CLIENT_ID	ID(DISPLAYD)
+#define NUM_DISP_CLIENTS	(LAST_DISP_CLIENT_ID - FIRST_DISP_CLIENT_ID + 1)
+#define DISP_CLIENT_ID(id)	(ID(id) - FIRST_DISP_CLIENT_ID)
+
+#define FIRST_CAMERA_CLIENT_ID	ID(VI_W)
+#define LAST_CAMERA_CLIENT_ID	ID(ISP_WBB)
+#define NUM_CAMERA_CLIENTS	(LAST_CAMERA_CLIENT_ID - \
+				FIRST_CAMERA_CLIENT_ID + \
+				1)
+#define CAMERA_IDX(id)		(ID(id) - FIRST_CAMERA_CLIENT_ID)
+#define CAMERA_LA_IDX(id)	(id - FIRST_CAMERA_CLIENT_ID)
+#define AGG_CAMERA_ID(id)	TEGRA_LA_AGG_CAMERA_##id
+
+#define MC_LA_MAX_VALUE					255U
+#define MC_PTSA_MIN_DEFAULT_MASK			0x3f
+#define MC_PTSA_MAX_DEFAULT_MASK			0x3f
+#define MC_PTSA_RATE_DEFAULT_MASK			0xfff
+
+#define LA_USEC_TO_NSEC_FACTOR				1000
+#define LA_HZ_TO_MHZ_FACTOR				1000000
+
+/*
+ * Setup macro for la_client_info array.
+ */
+#define LA(f, e, a, r, i, ss, la, clk)			\
+{							\
+	.fifo_size_in_atoms = f,			\
+	.expiration_in_ns = e,				\
+	.reg_addr = MC_LATENCY_ALLOWANCE_ ## a,		\
+	.mask = MASK(r),				\
+	.shift = SHIFT(r),				\
+	.id = ID(i),					\
+	.name = __stringify(i),				\
+	.scaling_supported = ss,			\
+	.init_la = la,					\
+	.la_ref_clk_mhz = clk				\
+}
+
+/*
+ * Several macros for initializing and accessing/modifying the PTSA registers.
+ */
+#define MC_SET_INIT_PTSA(p, client, min, max)				\
+	do {								\
+		(p)->client ## _ptsa_min = (unsigned int)(min) &	\
+			MC_PTSA_MIN_DEFAULT_MASK;			\
+		(p)->client ## _ptsa_max = (unsigned int)(max) &	\
+			MC_PTSA_MAX_DEFAULT_MASK;			\
+	} while (0)
+
+#define READ_PTSA_MIN_MAX(p, field, reg)				\
+	do {								\
+		(p)->field ##_ptsa_min = mc_readl(MC_ ## reg ## _PTSA_MIN); \
+		(p)->field ##_ptsa_max = mc_readl(MC_ ## reg ## _PTSA_MAX); \
+	} while (0)
+#define READ_PTSA_MIN_MAX_RATE(p, field, reg)				\
+	do {								\
+		(p)->field ##_ptsa_min = mc_readl(MC_ ## reg ## _PTSA_MIN); \
+		(p)->field ##_ptsa_max = mc_readl(MC_ ## reg ## _PTSA_MAX); \
+		(p)->field ##_ptsa_rate = mc_readl(MC_ ## reg ## _PTSA_RATE); \
+	} while (0)
+
+#define WRITE_PTSA_MIN_MAX(p, field, reg)				\
+	do {								\
+		mc_writel((p)->field ##_ptsa_min, MC_ ## reg ## _PTSA_MIN); \
+		mc_writel((p)->field ##_ptsa_max, MC_ ## reg ## _PTSA_MAX); \
+	} while (0)
+#define WRITE_PTSA_MIN_MAX_RATE(p, field, reg)				\
+	do {								\
+		mc_writel((p)->field ##_ptsa_min, MC_ ## reg ## _PTSA_MIN); \
+		mc_writel((p)->field ##_ptsa_max, MC_ ## reg ## _PTSA_MAX); \
+		mc_writel((p)->field ##_ptsa_rate, MC_ ## reg ## _PTSA_RATE); \
+	} while (0)
+
+/*
+ * Some common functions for both t12x and t21x.
+ */
+struct la_client_info;
+void program_la(struct la_client_info *ci, int la);
+void program_scaled_la_t21x(struct la_client_info *ci, int la);
+int la_suspend(void);
+void la_resume(void);
+
+/*
+ * Note about fixed point arithmetic:
+ * ----------------------------------
+ * This file contains fixed point values and arithmetic due to the need to use
+ * floating point values. All fixed point values have the "_fp" or "_FP" suffix
+ * in their name. Macros used to convert between real and fixed point values are
+ * listed below:
+ *    - LA_FP_FACTOR
+ *    - LA_REAL_TO_FP(val)
+ *    - LA_FP_TO_REAL(val)
+ *
+ * Some scenarios require additional accuracy than what can be provided with
+ * T12X_LA_FP_FACTOR. For these special cases we use the following additional
+ * fixed point factor:- T12X_LA_ADDITIONAL_FP_FACTOR. Fixed point values which
+ * use the addtional fixed point factor have a suffix of "_fpa" or "_FPA" in
+ * their name. Macros used to convert between fpa values and other forms (i.e.
+ * fp and real) are as follows:
+ *    - LA_FP_TO_FPA(val)
+ *    - LA_FPA_TO_FP(val)
+ *    - LA_FPA_TO_REAL(val)
+ *    - LA_REAL_TO_FPA(val)
+ */
+
+static inline unsigned int la_real_to_fp(unsigned int val)
+{
+	return val * LA_FP_FACTOR;
+}
+
+static inline unsigned int la_fp_to_real(unsigned int val)
+{
+	return val / LA_FP_FACTOR;
+}
+
+static inline bool is_display_client(enum tegra_la_id id)
+{
+	return ((id >= FIRST_DISP_CLIENT_ID) && (id <= LAST_DISP_CLIENT_ID));
+}
+
+static inline bool is_camera_client(enum tegra_la_id id)
+{
+	return ((id >= FIRST_CAMERA_CLIENT_ID) &&
+		(id <= LAST_CAMERA_CLIENT_ID));
+}
+
+/*
+ * TODO: this doesn't actually return an FP per se. It returns a value suitable
+ * for placing in the DDA register fields; therefor this function needs
+ * renaming.
+ */
+static inline unsigned int __fraction2dda_fp(unsigned int fraction_fpa,
+					     unsigned int div,
+					     unsigned int mask)
+{
+	unsigned int dda = 0;
+	int i = 0;
+	unsigned int r = 0;
+
+	fraction_fpa /= div;
+
+	for (i = 0; i < EMEM_PTSA_RATE_WIDTH; i++) {
+		fraction_fpa *= 2;
+		r = LA_FPA_TO_REAL(fraction_fpa);
+		dda = (dda << 1) | (unsigned int)(r);
+		fraction_fpa -= LA_REAL_TO_FPA(r);
+	}
+	if (fraction_fpa > 0) {
+		/* Do not round up if the calculated dda is at the mask value
+		   already, it will overflow */
+		if (dda != mask)
+			dda++;		/* to round up dda value */
+	}
+
+	return min(dda, (unsigned int)MAX_DDA_RATE);
+}
+
+static inline unsigned int fraction2dda_fp(unsigned int fraction_fp,
+					   unsigned int div,
+					   unsigned int mask) {
+	unsigned int fraction_fpa = LA_FP_TO_FPA(fraction_fp);
+
+	return __fraction2dda_fp(fraction_fpa, div, mask);
+}
+
+#define ENABLE_LA_DEBUG		0
+#define la_debug(fmt, ...)						\
+	do {								\
+		if (ENABLE_LA_DEBUG)					\
+			pr_info("la_debug: " fmt, ##__VA_ARGS__);	\
+	} while (0)
+
+/* The following enum defines IDs for aggregated camera clients. In some cases
+   we have to deal with groups of camera clients rather than individual
+   clients. */
+enum agg_camera_client_id {
+	TEGRA_LA_AGG_CAMERA_VE = 0,
+	TEGRA_LA_AGG_CAMERA_VE2,
+	TEGRA_LA_AGG_CAMERA_ISP,
+	TEGRA_LA_AGG_CAMERA_NUM_CLIENTS
+};
+
+enum la_client_type {
+	TEGRA_LA_DYNAMIC_READ_CLIENT,
+	TEGRA_LA_CONSTANT_READ_CLIENT,
+	TEGRA_LA_DISPLAY_READ_CLIENT,
+	TEGRA_LA_WRITE_CLIENT,
+	TEGRA_LA_HUB_READ_CLIENT,
+	TEGRA_LA_HUB_WRITE_CLIENT,
+	TEGRA_LA_CPU_READ_CLIENT,
+	TEGRA_LA_CIFLL_WRITE_CLIENT,
+	TEGRA_LA_WCAM_WRITE_CLIENT,
+	TEGRA_LA_NVLRHP_READ_CLIENT,
+	TEGRA_LA_GPU_READ_CLIENT,
+	TEGRA_LA_NUM_CLIENT_TYPES
+};
+
+enum la_traffic_type {
+	TEGRA_LA_HISO,
+	TEGRA_LA_SISO,
+	TEGRA_LA_NISO
+};
+
+struct la_client_info {
+	enum la_client_type client_type;
+	unsigned int fifo_size_in_atoms;
+	unsigned int expiration_in_ns;	/* worst case expiration value */
+	unsigned int reg_addr;
+	unsigned long mask;
+	unsigned long shift;
+	enum tegra_la_id id;
+	char *name;
+	bool scaling_supported;
+	unsigned int min_scaling_ratio;
+	unsigned int init_la;		/* initial la to set for client */
+	unsigned int la_set;
+	unsigned int la_ref_clk_mhz;
+};
+
+struct agg_camera_client_info {
+	unsigned int bw_fp;
+	unsigned int frac_fp;
+	unsigned int ptsa_min;
+	unsigned int ptsa_max;
+	bool is_hiso;
+};
+
+struct la_scaling_info {
+	unsigned int threshold_low;
+	unsigned int threshold_mid;
+	unsigned int threshold_high;
+	int scaling_ref_count;
+	int actual_la_to_set;
+	int la_set;
+};
+
+struct la_scaling_reg_info {
+	enum tegra_la_id id;
+	void *tl_reg_addr;
+	unsigned int tl_mask;
+	unsigned int tl_shift;
+	void *tm_reg_addr;
+	unsigned int tm_mask;
+	unsigned int tm_shift;
+	void *th_reg_addr;
+	unsigned int th_mask;
+	unsigned int th_shift;
+};
+
+struct ptsa_info {
+	unsigned int dis_ptsa_rate;
+	unsigned int dis_ptsa_min;
+	unsigned int dis_ptsa_max;
+	enum la_traffic_type dis_traffic_type;
+	unsigned int disb_ptsa_rate;
+	unsigned int disb_ptsa_min;
+	unsigned int disb_ptsa_max;
+	enum la_traffic_type disb_traffic_type;
+	unsigned int ve_ptsa_rate;
+	unsigned int ve_ptsa_min;
+	unsigned int ve_ptsa_max;
+	enum la_traffic_type ve_traffic_type;
+	unsigned int ve2_ptsa_rate;
+	unsigned int ve2_ptsa_min;
+	unsigned int ve2_ptsa_max;
+	enum la_traffic_type ve2_traffic_type;
+	unsigned int ring2_ptsa_rate;
+	unsigned int ring2_ptsa_min;
+	unsigned int ring2_ptsa_max;
+	enum la_traffic_type ring2_traffic_type;
+	unsigned int bbc_ptsa_rate;
+	unsigned int bbc_ptsa_min;
+	unsigned int bbc_ptsa_max;
+	enum la_traffic_type bbc_traffic_type;
+	unsigned int mpcorer_ptsa_rate;
+	unsigned int mpcorer_ptsa_min;
+	unsigned int mpcorer_ptsa_max;
+	enum la_traffic_type mpcorer_traffic_type;
+	unsigned int ftop_ptsa_min;
+	unsigned int ftop_ptsa_max;
+	unsigned int ftop_ptsa_rate;
+	enum la_traffic_type ftop_traffic_type;
+	unsigned int smmu_ptsa_rate;
+	unsigned int smmu_ptsa_min;
+	unsigned int smmu_ptsa_max;
+	enum la_traffic_type smmu_traffic_type;
+	unsigned int ring1_ptsa_rate;
+	unsigned int ring1_ptsa_min;
+	unsigned int ring1_ptsa_max;
+	enum la_traffic_type ring1_traffic_type;
+
+	unsigned int dis_extra_snap_level;
+	unsigned int heg_extra_snap_level;
+	unsigned int ptsa_grant_dec;
+	unsigned int bbcll_earb_cfg;
+
+	unsigned int isp_ptsa_rate;
+	unsigned int isp_ptsa_min;
+	unsigned int isp_ptsa_max;
+	enum la_traffic_type isp_traffic_type;
+	unsigned int a9avppc_ptsa_min;
+	unsigned int a9avppc_ptsa_max;
+	enum la_traffic_type a9avppc_traffic_type;
+	unsigned int avp_ptsa_min;
+	unsigned int avp_ptsa_max;
+	enum la_traffic_type avp_traffic_type;
+	unsigned int mse_ptsa_rate;
+	unsigned int mse_ptsa_min;
+	unsigned int mse_ptsa_max;
+	enum la_traffic_type mse_traffic_type;
+	unsigned int gk_ptsa_rate;
+	unsigned int gk_ptsa_min;
+	unsigned int gk_ptsa_max;
+	enum la_traffic_type gk_traffic_type;
+	unsigned int vicpc_ptsa_rate;
+	unsigned int vicpc_ptsa_min;
+	unsigned int vicpc_ptsa_max;
+	enum la_traffic_type vicpc_traffic_type;
+	unsigned int apb_ptsa_rate;
+	unsigned int apb_ptsa_min;
+	unsigned int apb_ptsa_max;
+	enum la_traffic_type apb_traffic_type;
+	unsigned int pcx_ptsa_rate;
+	unsigned int pcx_ptsa_min;
+	unsigned int pcx_ptsa_max;
+	enum la_traffic_type pcx_traffic_type;
+	unsigned int host_ptsa_rate;
+	unsigned int host_ptsa_min;
+	unsigned int host_ptsa_max;
+	enum la_traffic_type host_traffic_type;
+	unsigned int ahb_ptsa_min;
+	unsigned int ahb_ptsa_max;
+	enum la_traffic_type ahb_traffic_type;
+	unsigned int sax_ptsa_rate;
+	unsigned int sax_ptsa_min;
+	unsigned int sax_ptsa_max;
+	enum la_traffic_type sax_traffic_type;
+	unsigned int aud_ptsa_rate;
+	unsigned int aud_ptsa_min;
+	unsigned int aud_ptsa_max;
+	enum la_traffic_type aud_traffic_type;
+	unsigned int sd_ptsa_rate;
+	unsigned int sd_ptsa_min;
+	unsigned int sd_ptsa_max;
+	enum la_traffic_type sd_traffic_type;
+	unsigned int usbx_ptsa_rate;
+	unsigned int usbx_ptsa_min;
+	unsigned int usbx_ptsa_max;
+	enum la_traffic_type usbx_traffic_type;
+	unsigned int usbd_ptsa_rate;
+	unsigned int usbd_ptsa_min;
+	unsigned int usbd_ptsa_max;
+	enum la_traffic_type usbd_traffic_type;
+
+	/* Tegra12x */
+	unsigned int r0_dis_ptsa_min;
+	unsigned int r0_dis_ptsa_max;
+	enum la_traffic_type r0_dis_traffic_type;
+	unsigned int r0_disb_ptsa_min;
+	unsigned int r0_disb_ptsa_max;
+	enum la_traffic_type r0_disb_traffic_type;
+	unsigned int vd_ptsa_min;
+	unsigned int vd_ptsa_max;
+	enum la_traffic_type vd_traffic_type;
+
+	/* Tegra18x */
+	unsigned int aondmapc_ptsa_rate;
+	unsigned int aondmapc_ptsa_min;
+	unsigned int aondmapc_ptsa_max;
+	enum la_traffic_type aondmapc_traffic_type;
+	unsigned int aonpc_ptsa_rate;
+	unsigned int aonpc_ptsa_min;
+	unsigned int aonpc_ptsa_max;
+	enum la_traffic_type aonpc_traffic_type;
+	unsigned int apedmapc_ptsa_rate;
+	unsigned int apedmapc_ptsa_min;
+	unsigned int apedmapc_ptsa_max;
+	enum la_traffic_type apedmapc_traffic_type;
+	unsigned int bpmpdmapc_ptsa_rate;
+	unsigned int bpmpdmapc_ptsa_min;
+	unsigned int bpmpdmapc_ptsa_max;
+	enum la_traffic_type bpmpdmapc_traffic_type;
+	unsigned int bpmppc_ptsa_rate;
+	unsigned int bpmppc_ptsa_min;
+	unsigned int bpmppc_ptsa_max;
+	enum la_traffic_type bpmppc_traffic_type;
+	unsigned int dfd_ptsa_rate;
+	unsigned int dfd_ptsa_min;
+	unsigned int dfd_ptsa_max;
+	enum la_traffic_type dfd_traffic_type;
+	unsigned int eqospc_ptsa_rate;
+	unsigned int eqospc_ptsa_min;
+	unsigned int eqospc_ptsa_max;
+	enum la_traffic_type eqospc_traffic_type;
+	unsigned int hdapc_ptsa_rate;
+	unsigned int hdapc_ptsa_min;
+	unsigned int hdapc_ptsa_max;
+	enum la_traffic_type hdapc_traffic_type;
+	unsigned int mll_mpcorer_ptsa_rate;
+	unsigned int mll_mpcorer_ptsa_min;
+	unsigned int mll_mpcorer_ptsa_max;
+	enum la_traffic_type mll_mpcorer_traffic_type;
+	unsigned int mse2_ptsa_rate;
+	unsigned int mse2_ptsa_min;
+	unsigned int mse2_ptsa_max;
+	enum la_traffic_type mse2_traffic_type;
+	unsigned int nic_ptsa_rate;
+	unsigned int nic_ptsa_min;
+	unsigned int nic_ptsa_max;
+	enum la_traffic_type nic_traffic_type;
+	unsigned int nvd_ptsa_rate;
+	unsigned int nvd_ptsa_min;
+	unsigned int nvd_ptsa_max;
+	enum la_traffic_type nvd_traffic_type;
+	unsigned int nvd3_ptsa_rate;
+	unsigned int nvd3_ptsa_min;
+	unsigned int nvd3_ptsa_max;
+	enum la_traffic_type nvd3_traffic_type;
+	unsigned int roc_dma_r_ptsa_rate;
+	unsigned int roc_dma_r_ptsa_min;
+	unsigned int roc_dma_r_ptsa_max;
+	enum la_traffic_type roc_dma_r_traffic_type;
+	unsigned int ring1_rd_b_ptsa_rate;
+	unsigned int ring1_rd_b_ptsa_min;
+	unsigned int ring1_rd_b_ptsa_max;
+	enum la_traffic_type ring1_rd_b_traffic_type;
+	unsigned int ring1_rd_nb_ptsa_rate;
+	unsigned int ring1_rd_nb_ptsa_min;
+	unsigned int ring1_rd_nb_ptsa_max;
+	enum la_traffic_type ring1_rd_nb_traffic_type;
+	unsigned int ring1_wr_b_ptsa_rate;
+	unsigned int ring1_wr_b_ptsa_min;
+	unsigned int ring1_wr_b_ptsa_max;
+	enum la_traffic_type ring1_wr_b_traffic_type;
+	unsigned int ring1_wr_nb_ptsa_rate;
+	unsigned int ring1_wr_nb_ptsa_min;
+	unsigned int ring1_wr_nb_ptsa_max;
+	enum la_traffic_type ring1_wr_nb_traffic_type;
+	unsigned int scedmapc_ptsa_rate;
+	unsigned int scedmapc_ptsa_min;
+	unsigned int scedmapc_ptsa_max;
+	enum la_traffic_type scedmapc_traffic_type;
+	unsigned int scepc_ptsa_rate;
+	unsigned int scepc_ptsa_min;
+	unsigned int scepc_ptsa_max;
+	enum la_traffic_type scepc_traffic_type;
+	unsigned int sdm_ptsa_rate;
+	unsigned int sdm_ptsa_min;
+	unsigned int sdm_ptsa_max;
+	enum la_traffic_type sdm_traffic_type;
+	unsigned int sdm1_ptsa_rate;
+	unsigned int sdm1_ptsa_min;
+	unsigned int sdm1_ptsa_max;
+	enum la_traffic_type sdm1_traffic_type;
+	unsigned int ufshcpc_ptsa_rate;
+	unsigned int ufshcpc_ptsa_min;
+	unsigned int ufshcpc_ptsa_max;
+	enum la_traffic_type ufshcpc_traffic_type;
+	unsigned int vicpc3_ptsa_rate;
+	unsigned int vicpc3_ptsa_min;
+	unsigned int vicpc3_ptsa_max;
+	enum la_traffic_type vicpc3_traffic_type;
+
+	/* Tegra21x */
+	unsigned int jpg_ptsa_rate;
+	unsigned int jpg_ptsa_min;
+	unsigned int jpg_ptsa_max;
+	enum la_traffic_type jpg_traffic_type;
+	unsigned int gk2_ptsa_rate;
+	unsigned int gk2_ptsa_min;
+	unsigned int gk2_ptsa_max;
+	enum la_traffic_type gk2_traffic_type;
+};
+
+
+struct la_chip_specific {
+	int ns_per_tick;
+	int atom_size;
+	int la_max_value;
+	spinlock_t lock;
+	int la_info_array_size;
+	struct la_client_info *la_info_array;
+	unsigned short id_to_index[ID(MAX_ID) + 1];
+	unsigned int disp_bw_array[NUM_DISP_CLIENTS];
+	struct disp_client disp_clients[NUM_DISP_CLIENTS];
+	unsigned int bbc_bw_array[ID(BBCLLR) - ID(BBCR) + 1];
+	unsigned int camera_bw_array[NUM_CAMERA_CLIENTS];
+	struct agg_camera_client_info
+			agg_camera_array[TEGRA_LA_AGG_CAMERA_NUM_CLIENTS];
+	struct la_scaling_info scaling_info[ID(MAX_ID)];
+	int la_scaling_enable_count;
+	struct dentry *latency_debug_dir;
+	struct ptsa_info ptsa_info;
+	bool disable_la;
+	bool disable_ptsa;
+	struct la_to_dc_params la_params;
+	bool disable_disp_ptsa;
+	bool disable_bbc_ptsa;
+
+	void (*init_ptsa)(void);
+	void (*update_display_ptsa_rate)(unsigned int *disp_bw_array);
+	int (*update_camera_ptsa_rate)(enum tegra_la_id id,
+					unsigned int bw_mbps,
+					int is_hiso);
+	int (*set_disp_la)(enum tegra_la_id id,
+				unsigned long emc_freq_hz,
+				unsigned int bw_mbps,
+				struct dc_to_la_params disp_params);
+	int (*check_disp_la)(enum tegra_la_id id,
+				unsigned long emc_freq_hz,
+				unsigned int bw_mbps,
+				struct dc_to_la_params disp_params);
+	int (*set_init_la)(enum tegra_la_id id, unsigned int bw_mbps);
+	int (*set_dynamic_la)(enum tegra_la_id id, unsigned int bw_mbps);
+	int (*enable_la_scaling)(enum tegra_la_id id,
+				unsigned int threshold_low,
+				unsigned int threshold_mid,
+				unsigned int threshold_high);
+	void (*disable_la_scaling)(enum tegra_la_id id);
+	void (*save_ptsa)(void);
+	void (*program_ptsa)(void);
+	void (*save_non_la_ptsa)(void);
+	void (*program_non_la_ptsa)(void);
+	int (*suspend)(void);
+	void (*resume)(void);
+	void (*mc_pcie_init)(void);
+	void (*la_cleanup)(void);
+};
+
+
+void tegra_la_get_t3_specific(struct la_chip_specific *cs);
+void tegra_la_get_t14x_specific(struct la_chip_specific *cs);
+void tegra_la_get_t11x_specific(struct la_chip_specific *cs);
+void tegra_la_get_t12x_specific(struct la_chip_specific *cs);
+void tegra_la_get_t21x_specific(struct la_chip_specific *cs);
+#ifdef CONFIG_ARCH_TEGRA_18x_SOC
+void tegra_la_get_t18x_specific(struct la_chip_specific *cs);
+#else
+static inline void tegra_la_get_t18x_specific(struct la_chip_specific *cs) {}
+#endif
+#ifdef CONFIG_ARCH_TEGRA_19x_SOC
+void tegra_la_get_t19x_specific(struct la_chip_specific *cs);
+#else
+static inline void tegra_la_get_t19x_specific(struct la_chip_specific *cs) {}
+#endif
+
+#endif /* _MACH_TEGRA_LA_PRIV_H_ */
diff --git a/drivers/platform/tegra/mc/latency_allowance.c b/drivers/platform/tegra/mc/latency_allowance.c
new file mode 100644
index 000000000000..d8fce6f540c7
--- /dev/null
+++ b/drivers/platform/tegra/mc/latency_allowance.c
@@ -0,0 +1,813 @@
+/*
+ * arch/arm/mach-tegra/latency_allowance.c
+ *
+ * Copyright (C) 2011-2020, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#include <linux/types.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/debugfs.h>
+#include <linux/moduleparam.h>
+#include <linux/seq_file.h>
+#include <linux/err.h>
+#include <linux/spinlock_types.h>
+#include <linux/spinlock.h>
+#include <linux/stringify.h>
+#include <linux/clk.h>
+#include <linux/clk/tegra.h>
+#include <linux/syscore_ops.h>
+#include <linux/platform/tegra/common.h>
+#include <soc/tegra/fuse.h>
+#include <asm/bug.h>
+#include <asm/io.h>
+#include <asm/string.h>
+
+#include <linux/platform/tegra/mc-regs-t21x.h>
+#include <linux/platform/tegra/latency_allowance.h>
+#include <linux/platform/tegra/mc.h>
+
+#include "la_priv.h"
+
+#define TEST_LA_CODE		0
+/* Bug 995270 */
+#define HACK_LA_FIFO 1
+static int default_set_la(enum tegra_la_id id, unsigned int bw_mbps);
+
+static struct la_chip_specific cs;
+module_param_named(disable_la, cs.disable_la, bool, S_IRUGO | S_IWUSR);
+module_param_named(disable_ptsa, cs.disable_ptsa, bool, S_IRUGO | S_IWUSR);
+module_param_named(disable_disp_ptsa,
+	cs.disable_disp_ptsa, bool, S_IRUGO | S_IWUSR);
+module_param_named(disable_bbc_ptsa,
+	cs.disable_bbc_ptsa, bool, S_IRUGO | S_IWUSR);
+
+#ifdef CONFIG_DEBUG_FS
+static int la_ptsa_debugfs_init(void);
+#endif
+
+static void init_chip_specific(void)
+{
+	int cid;
+
+	if (!tegra_platform_is_silicon())
+		return;
+
+	cs.set_init_la = default_set_la;
+	memset(&cs.id_to_index[0], 0xFF, sizeof(cs.id_to_index));
+	spin_lock_init(&cs.lock);
+
+	cid = tegra_get_chip_id();
+
+	switch (cid) {
+	case TEGRA194:
+		tegra_la_get_t19x_specific(&cs);
+		break;
+	case TEGRA186:
+		tegra_la_get_t18x_specific(&cs);
+		break;
+	case TEGRA210:
+		tegra_la_get_t21x_specific(&cs);
+		break;
+	default:
+		cs.set_init_la = NULL;
+	}
+#ifdef CONFIG_DEBUG_FS
+	la_ptsa_debugfs_init();
+#endif
+}
+
+struct la_to_dc_params tegra_get_la_to_dc_params(void)
+{
+	return cs.la_params;
+}
+
+static void set_la(struct la_client_info *ci, int la)
+{
+	unsigned long reg_read;
+	unsigned long reg_write;
+	int idx = cs.id_to_index[ci->id];
+
+	spin_lock(&cs.lock);
+	reg_read = mc_readl(ci->reg_addr);
+	reg_write = (reg_read & ~ci->mask) |
+			(la << ci->shift);
+	mc_writel(reg_write, ci->reg_addr);
+	cs.scaling_info[idx].la_set = la;
+	ci->la_set = la;
+	la_debug("name=%s, reg=0x%x, read=0x%x, write=0x%x\n", ci->name,
+		(u32)ci->reg_addr, (u32)reg_read, (u32)reg_write);
+	spin_unlock(&cs.lock);
+}
+
+static int default_set_la(enum tegra_la_id id, unsigned int bw_mbps)
+{
+	int ideal_la;
+	int la_to_set;
+	unsigned int fifo_size_in_atoms;
+	int bytes_per_atom = cs.atom_size;
+	const int fifo_scale = 4;		/* 25% of the FIFO */
+	struct la_client_info *ci;
+	int idx = cs.id_to_index[id];
+
+	if (!tegra_platform_is_silicon())
+		return 0;
+
+	VALIDATE_ID(id, &cs);
+	VALIDATE_BW(bw_mbps);
+
+	ci = &cs.la_info_array[idx];
+	fifo_size_in_atoms = ci->fifo_size_in_atoms;
+
+#ifdef CONFIG_TEGRA_MC_PTSA
+	if (id >= TEGRA_LA_DISPLAY_0A && id <= TEGRA_LA_DISPLAY_HCB) {
+		cs.disp_bw_array[id - TEGRA_LA_DISPLAY_0A] = bw_mbps;
+		if (cs.update_display_ptsa_rate)
+			cs.update_display_ptsa_rate(cs.disp_bw_array);
+	}
+#endif
+#if HACK_LA_FIFO
+	/* pretend that our FIFO is only as deep as the lowest fullness
+	 * we expect to see */
+	if (id >= ID(DISPLAY_0A) && id <= ID(DISPLAY_HCB))
+		fifo_size_in_atoms /= fifo_scale;
+#endif
+
+	if (bw_mbps == 0) {
+		la_to_set = cs.la_max_value;
+	} else {
+		ideal_la = (fifo_size_in_atoms * bytes_per_atom * 1000) /
+			   (bw_mbps * cs.ns_per_tick);
+		la_to_set = ideal_la -
+				(ci->expiration_in_ns / cs.ns_per_tick) - 1;
+	}
+
+	la_debug("\n%s:id=%d,idx=%d, bw=%dmbps, la_to_set=%d\n",
+		__func__, id, idx, bw_mbps, la_to_set);
+	la_to_set = (la_to_set < 0) ? 0 : la_to_set;
+	cs.scaling_info[idx].actual_la_to_set = la_to_set;
+	la_to_set = (la_to_set > cs.la_max_value) ? cs.la_max_value : la_to_set;
+
+	set_la(ci, la_to_set);
+	return 0;
+}
+
+static void program_scaled_la(struct la_client_info *ci, int la)
+{
+	if (tegra_get_chip_id() == TEGRA210)
+		program_scaled_la_t21x(ci, la);
+}
+
+void program_la(struct la_client_info *ci, int la)
+{
+	u32 reg_read;
+	u32 reg_write;
+
+	if (la > cs.la_max_value) {
+		pr_err("la > cs.la_max_value\n");
+		WARN_ON(1);
+		return;
+	}
+
+	spin_lock(&cs.lock);
+	reg_read = mc_readl(ci->reg_addr);
+	reg_write = (reg_read & ~ci->mask) |
+			(la << ci->shift);
+	mc_writel(reg_write, ci->reg_addr);
+	ci->la_set = la;
+	la_debug("name=%s, reg_addr=0x%x, read=0x%x, write=0x%x\n", ci->name,
+		(u32)(uintptr_t)ci->reg_addr, (u32)reg_read, (u32)reg_write);
+
+	program_scaled_la(ci, la);
+
+	spin_unlock(&cs.lock);
+}
+
+int la_suspend(void)
+{
+	int i = 0;
+	struct la_client_info *ci = NULL;
+
+	/* stashing LA and PTSA from registers is necessary
+	 * in order to get latest values programmed by DVFS.
+	 */
+	for (i = 0; i < cs.la_info_array_size; i++) {
+		ci = &cs.la_info_array[i];
+		ci->la_set = (mc_readl(ci->reg_addr) & ci->mask) >>
+				ci->shift;
+	}
+
+	cs.save_ptsa();
+
+	if (cs.save_non_la_ptsa)
+		cs.save_non_la_ptsa();
+
+	return 0;
+}
+
+void la_resume(void)
+{
+	int i;
+
+	for (i = 0; i < cs.la_info_array_size; i++) {
+		if (cs.la_info_array[i].la_set)
+			program_la(&cs.la_info_array[i],
+					cs.la_info_array[i].la_set);
+	}
+
+	cs.program_ptsa();
+
+	if (cs.program_non_la_ptsa)
+		cs.program_non_la_ptsa();
+}
+
+int tegra_set_disp_latency_allowance(enum tegra_la_id id,
+					unsigned long emc_freq_hz,
+					unsigned int bw_mbps,
+					struct dc_to_la_params disp_params) {
+	if (cs.set_disp_la)
+		return cs.set_disp_la(id, emc_freq_hz, bw_mbps, disp_params);
+	else if (cs.set_dynamic_la)
+		return cs.set_dynamic_la(id, bw_mbps);
+	return 0;
+}
+
+/*
+ * Check if the passed bandwidth is possible.
+ *
+ * Returns zero if there is a possible LA value that can satifsy @bw_mbps at
+ * @emc_freq_hz. If no function has been defined for the active chip then this
+ * this function returns true (i.e 0).
+ */
+int tegra_check_disp_latency_allowance(enum tegra_la_id id,
+					   unsigned long emc_freq_hz,
+					   unsigned int bw_mbps,
+					   struct dc_to_la_params disp_params) {
+	if (cs.check_disp_la)
+		return cs.check_disp_la(id, emc_freq_hz, bw_mbps, disp_params);
+	return 0;
+}
+
+/* Sets latency allowance based on clients memory bandwitdh requirement.
+ * Bandwidth passed is in mega bytes per second.
+ */
+int tegra_set_latency_allowance(enum tegra_la_id id, unsigned int bw_mbps)
+{
+	if (cs.set_dynamic_la)
+		return cs.set_dynamic_la(id, bw_mbps);
+	return 0;
+}
+EXPORT_SYMBOL(tegra_set_latency_allowance);
+
+int tegra_set_camera_ptsa(enum tegra_la_id id,
+			unsigned int bw_mbps,
+			int is_hiso)
+{
+	if (cs.update_camera_ptsa_rate)
+		return cs.update_camera_ptsa_rate(id, bw_mbps, is_hiso);
+	else if (cs.set_dynamic_la)
+		return cs.set_dynamic_la(id, bw_mbps);
+	return 0;
+}
+
+/* Thresholds for scaling are specified in % of fifo freeness.
+ * If threshold_low is specified as 20%, it means when the fifo free
+ * between 0 to 20%, use la as programmed_la.
+ * If threshold_mid is specified as 50%, it means when the fifo free
+ * between 20 to 50%, use la as programmed_la/2 .
+ * If threshold_high is specified as 80%, it means when the fifo free
+ * between 50 to 80%, use la as programmed_la/4.
+ * When the fifo is free between 80 to 100%, use la as 0(highest priority).
+ */
+int tegra_enable_latency_scaling(enum tegra_la_id id,
+					unsigned int threshold_low,
+					unsigned int threshold_mid,
+					unsigned int threshold_high)
+{
+	if (cs.enable_la_scaling)
+		return cs.enable_la_scaling(id, threshold_low,
+			threshold_mid, threshold_high);
+	return 0;
+}
+
+void tegra_disable_latency_scaling(enum tegra_la_id id)
+{
+	if (cs.disable_la_scaling) {
+		cs.disable_la_scaling(id);
+	}
+}
+
+void tegra_latency_allowance_update_tick_length(unsigned int new_ns_per_tick)
+{
+	int i = 0;
+	int la;
+	unsigned long reg_read;
+	unsigned long reg_write;
+	unsigned long scale_factor = new_ns_per_tick / cs.ns_per_tick;
+
+	if (scale_factor > 1) {
+		spin_lock(&cs.lock);
+		cs.ns_per_tick = new_ns_per_tick;
+		for (i = 0; i < cs.la_info_array_size - 1; i++) {
+			reg_read = mc_readl(cs.la_info_array[i].reg_addr);
+			la = ((reg_read & cs.la_info_array[i].mask) >>
+				cs.la_info_array[i].shift) / scale_factor;
+
+			reg_write = (reg_read & ~cs.la_info_array[i].mask) |
+					(la << cs.la_info_array[i].shift);
+			mc_writel(reg_write, cs.la_info_array[i].reg_addr);
+			cs.scaling_info[i].la_set = la;
+		}
+		spin_unlock(&cs.lock);
+	}
+}
+
+static int la_regs_show(struct seq_file *s, void *unused)
+{
+	int i;
+	unsigned long la;
+
+	/* iterate the list, but don't print MAX_ID */
+	for (i = 0; i < cs.la_info_array_size - 1; i++) {
+		la = (mc_readl(cs.la_info_array[i].reg_addr) &
+			cs.la_info_array[i].mask) >> cs.la_info_array[i].shift;
+		seq_printf(s, "%-16s: %4lu\n", cs.la_info_array[i].name, la);
+	}
+
+	return 0;
+}
+
+static int dbg_la_regs_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, la_regs_show, inode->i_private);
+}
+
+static const struct file_operations regs_fops = {
+	.open           = dbg_la_regs_open,
+	.read           = seq_read,
+	.llseek         = seq_lseek,
+	.release        = single_release,
+};
+
+static int __init tegra_latency_allowance_debugfs_init(void)
+{
+	if (cs.latency_debug_dir)
+		return 0;
+
+	cs.latency_debug_dir = debugfs_create_dir("tegra_latency", NULL);
+
+	debugfs_create_file("la_info", S_IRUGO, cs.latency_debug_dir, NULL,
+		&regs_fops);
+
+	return 0;
+}
+
+static int tegra_la_suspend(void)
+{
+	if (cs.suspend)
+		return cs.suspend();
+	return 0;
+}
+
+static void tegra_la_resume(void)
+{
+	int i;
+
+	if (cs.resume) {
+		cs.resume();
+		return;
+	}
+	for (i = 0; i < cs.la_info_array_size; i++) {
+		if (cs.la_info_array[i].la_set)
+			set_la(&cs.la_info_array[i],
+				cs.la_info_array[i].la_set);
+	}
+	if (cs.init_ptsa)
+		cs.init_ptsa();
+}
+
+static struct syscore_ops tegra_la_syscore_ops = {
+	.suspend = tegra_la_suspend,
+	.resume = tegra_la_resume,
+};
+
+static __init int tegra_la_syscore_init(void)
+{
+	register_syscore_ops(&tegra_la_syscore_ops);
+	return 0;
+}
+
+static int __init tegra_latency_allowance_init(void)
+{
+	unsigned int i;
+	int ret = 0;
+
+	init_chip_specific();
+
+	for (i = 0; i < cs.la_info_array_size; i++)
+		cs.id_to_index[cs.la_info_array[i].id] = i;
+
+	for (i = 0; i < cs.la_info_array_size; i++) {
+		if (cs.set_init_la) {
+			ret = cs.set_init_la(cs.la_info_array[i].id, 0);
+			if (ret < 0) {
+				if (cs.la_cleanup)
+					cs.la_cleanup();
+				return -1;
+			}
+		} else if (cs.la_info_array[i].init_la) {
+			set_la(&cs.la_info_array[i],
+				cs.la_info_array[i].init_la);
+		}
+	}
+
+	if (cs.init_ptsa)
+		cs.init_ptsa();
+
+	pr_info("la/ptsa driver initialized.\n");
+	return 0;
+}
+
+late_initcall(tegra_latency_allowance_debugfs_init);
+subsys_initcall(tegra_la_syscore_init);
+
+/* Must happen after MC init which is done by device tree. */
+fs_initcall(tegra_latency_allowance_init);
+
+static void __exit tegra_latency_allowance_exit(void)
+{
+	if (cs.la_cleanup)
+		cs.la_cleanup();
+}
+module_exit(tegra_latency_allowance_exit);
+
+/* Must be called after LA/PTSA init */
+void mc_pcie_init(void)
+{
+	if (cs.mc_pcie_init)
+		cs.mc_pcie_init();
+}
+EXPORT_SYMBOL(mc_pcie_init);
+
+#ifdef CONFIG_DEBUG_FS
+
+#include <linux/debugfs.h>
+#include <linux/uaccess.h>
+
+static unsigned long debugfs_display_emc_freq_hz;
+static unsigned int debugfs_display_bw_mbps;
+static int debugfs_camera_la_id;
+static unsigned int debugfs_camera_bw_mbps;
+static int debugfs_camera_is_hiso;
+static int debugfs_other_la_id;
+static unsigned int debugfs_other_bw_mbps;
+
+static int display_emc_freq_hz_get(void *data, u64 *val)
+{
+	*val = (u64) debugfs_display_emc_freq_hz;
+	return 0;
+}
+
+static int display_emc_freq_hz_set(void *data, u64 val)
+{
+	debugfs_display_emc_freq_hz = val;
+	return 0;
+}
+
+static int display_bw_mbps_get(void *data, u64 *val)
+{
+	*val = (u64) debugfs_display_bw_mbps;
+	return 0;
+}
+
+static int display_bw_mbps_set(void *data, u64 val)
+{
+	debugfs_display_bw_mbps = (u32) val;
+	return 0;
+}
+
+static int display_set_la_ptsa_set(void *data, u64 val)
+{
+	struct dc_to_la_params disp_params = {0};
+
+	if (cs.set_disp_la(ID(NVDISPLAYR),
+				debugfs_display_emc_freq_hz,
+				debugfs_display_bw_mbps,
+				disp_params))
+		return -1;
+	return 0;
+}
+
+static int camera_la_id_get(void *data, u64 *val)
+{
+	*val = (u64) debugfs_camera_la_id;
+	return 0;
+}
+
+static int camera_la_id_set(void *data, u64 val)
+{
+	debugfs_camera_la_id = (u32) val;
+	return 0;
+}
+
+static int camera_bw_mbps_get(void *data, u64 *val)
+{
+	*val = (u64) debugfs_camera_bw_mbps;
+	return 0;
+}
+
+static int camera_bw_mbps_set(void *data, u64 val)
+{
+	debugfs_camera_bw_mbps = (u32) val;
+	return 0;
+}
+
+static int camera_is_hiso_get(void *data, u64 *val)
+{
+	*val = (u64) debugfs_camera_is_hiso;
+	return 0;
+}
+
+static int camera_is_hiso_set(void *data, u64 val)
+{
+	debugfs_camera_is_hiso = (u32) val;
+	return 0;
+}
+
+static int camera_set_ptsa_set(void *data, u64 val)
+{
+	if (cs.update_camera_ptsa_rate(debugfs_camera_la_id,
+				debugfs_camera_bw_mbps,
+				debugfs_camera_is_hiso))
+		return -1;
+	return 0;
+}
+
+static int other_la_id_get(void *data, u64 *val)
+{
+	*val = (u64) debugfs_other_la_id;
+	return 0;
+}
+
+static int other_la_id_set(void *data, u64 val)
+{
+	debugfs_other_la_id = (u32) val;
+	return 0;
+}
+
+static int other_bw_mbps_get(void *data, u64 *val)
+{
+	*val = (u64) debugfs_other_bw_mbps;
+	return 0;
+}
+
+static int other_bw_mbps_set(void *data, u64 val)
+{
+	debugfs_other_bw_mbps = (u32) val;
+	return 0;
+}
+
+static int other_set_la_ptsa_set(void *data, u64 val)
+{
+	if (cs.set_dynamic_la(debugfs_other_la_id,
+				debugfs_other_bw_mbps))
+		return -1;
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(display_emc_freq_hz_fops,
+		display_emc_freq_hz_get,
+		display_emc_freq_hz_set,
+		"%llu\n");
+DEFINE_SIMPLE_ATTRIBUTE(display_bw_mbps_fops,
+		display_bw_mbps_get,
+		display_bw_mbps_set,
+		"%llu\n");
+DEFINE_SIMPLE_ATTRIBUTE(display_set_la_ptsa_fops,
+		NULL,
+		display_set_la_ptsa_set,
+		"%llu\n");
+DEFINE_SIMPLE_ATTRIBUTE(camera_la_id_fops,
+		camera_la_id_get,
+		camera_la_id_set,
+		"%llu\n");
+DEFINE_SIMPLE_ATTRIBUTE(camera_bw_mbps_fops,
+		camera_bw_mbps_get,
+		camera_bw_mbps_set,
+		"%llu\n");
+DEFINE_SIMPLE_ATTRIBUTE(camera_is_hiso_fops,
+		camera_is_hiso_get,
+		camera_is_hiso_set,
+		"%llu\n");
+DEFINE_SIMPLE_ATTRIBUTE(camera_set_ptsa_fops,
+		NULL,\
+		camera_set_ptsa_set,
+		"%llu\n");
+DEFINE_SIMPLE_ATTRIBUTE(other_la_id_fops,
+		other_la_id_get,
+		other_la_id_set,
+		"%llu\n");
+DEFINE_SIMPLE_ATTRIBUTE(other_bw_mbps_fops,
+		other_bw_mbps_get,
+		other_bw_mbps_set,
+		"%llu\n");
+DEFINE_SIMPLE_ATTRIBUTE(other_set_la_ptsa_fops,
+		NULL,
+		other_set_la_ptsa_set,
+		"%llu\n");
+
+static int la_ptsa_debugfs_init(void)
+{
+	struct dentry *la_ptsa_debugfs_root;
+	struct dentry *display_dir;
+	struct dentry *camera_dir;
+	struct dentry *other_dir;
+
+	la_ptsa_debugfs_root = debugfs_create_dir("tegra_la_ptsa", NULL);
+	if (!la_ptsa_debugfs_root) {
+		pr_err("%s: Couldn't create the LA\\PTSA root debugfs node.\n",
+				__func__);
+		return -1;
+	}
+
+	/* Display nodes*/
+	display_dir = debugfs_create_dir("display", la_ptsa_debugfs_root);
+	if (!display_dir) {
+		pr_err("%s: Couldn't create the \"display\" debugfs node.\n",
+				__func__);
+		return -1;
+	}
+	if (!debugfs_create_file("emc_freq_hz",
+				S_IRUGO | S_IWUSR,
+				display_dir,
+				NULL,
+				&display_emc_freq_hz_fops)) {
+		pr_err("%s: Couldn't create the display \"emc_freq_hz\" debugfs node.\n",
+				__func__);
+		return -1;
+	}
+	if (!debugfs_create_file("bw_mbps",
+				S_IRUGO | S_IWUSR,
+				display_dir,
+				NULL,
+				&display_bw_mbps_fops)) {
+		pr_err("%s: Couldn't create the display \"bw_mbps\" debugfs node.\n",
+				__func__);
+		return -1;
+	}
+	if (!debugfs_create_file("set_la_ptsa",
+				S_IWUSR,
+				display_dir,
+				NULL,
+				&display_set_la_ptsa_fops)) {
+		pr_err("%s: Couldn't create the display \"set_la_ptsa\" debugfs node.\n",
+				__func__);
+		return -1;
+	}
+
+	/* Camera nodes*/
+	camera_dir = debugfs_create_dir("camera", la_ptsa_debugfs_root);
+	if (!camera_dir) {
+		pr_err("%s: Couldn't create the \"camera\" debugfs node.\n",
+				__func__);
+		return -1;
+	}
+	if (!debugfs_create_file("la_id",
+				S_IRUGO | S_IWUSR,
+				camera_dir,
+				NULL,
+				&camera_la_id_fops)) {
+		pr_err("%s: Couldn't create the camera \"la_id\" debugfs node.\n",
+				__func__);
+		return -1;
+	}
+	if (!debugfs_create_file("bw_mbps",
+				S_IRUGO | S_IWUSR,
+				camera_dir,
+				NULL,
+				&camera_bw_mbps_fops)) {
+		pr_err("%s: Couldn't create the camera \"bw_mbps\" debugfs node.\n",
+				__func__);
+		return -1;
+	}
+	if (!debugfs_create_file("is_hiso",
+				S_IRUGO | S_IWUSR,
+				camera_dir,
+				NULL,
+				&camera_is_hiso_fops)) {
+		pr_err("%s: Couldn't create the camera \"is_hiso\" debugfs node.\n",
+				__func__);
+		return -1;
+	}
+	if (!debugfs_create_file("set_ptsa",
+				S_IWUSR,
+				camera_dir,
+				NULL,
+				&camera_set_ptsa_fops)) {
+		pr_err("%s: Couldn't create the camera \"set_ptsa\" debugfs node.\n",
+				__func__);
+		return -1;
+	}
+
+	/* Non-display nodes */
+	other_dir = debugfs_create_dir("other", la_ptsa_debugfs_root);
+	if (!other_dir) {
+		pr_err("%s: Couldn't create the \"other\" debugfs node.\n",
+				__func__);
+		return -1;
+	}
+	if (!debugfs_create_file("la_id",
+				S_IRUGO | S_IWUSR,
+				other_dir,
+				NULL,
+				&other_la_id_fops)) {
+		pr_err("%s: Couldn't create the other \"la_id\" debugfs node.\n",
+				__func__);
+		return -1;
+	}
+	if (!debugfs_create_file("bw_mbps",
+				S_IRUGO | S_IWUSR,
+				other_dir,
+				NULL,
+				&other_bw_mbps_fops)) {
+		pr_err("%s: Couldn't create the other \"bw_mbps\" debugfs node.\n",
+				__func__);
+		return -1;
+	}
+	if (!debugfs_create_file("set_la_ptsa",
+				S_IWUSR,
+				other_dir,
+				NULL,
+				&other_set_la_ptsa_fops)) {
+		pr_err("%s: Couldn't create the other \"set_la_ptsa\" debugfs node.\n",
+				__func__);
+		return -1;
+	}
+
+	return 0;
+}
+
+#endif // "CONFIG_DEBUG_FS"
+
+
+#if TEST_LA_CODE
+#define PRINT_ID_IDX_MAPPING 0
+static int __init test_la(void)
+{
+	int i;
+	int err;
+	enum tegra_la_id id = 0;
+	int repeat_count = 5;
+
+#if PRINT_ID_IDX_MAPPING
+	for (i = 0; i < ID(MAX_ID); i++)
+		pr_info("ID=0x%x, Idx=0x%x", i, cs.id_to_index[i]);
+#endif
+
+	do {
+		for (id = 0; id < TEGRA_LA_MAX_ID; id++) {
+			err = tegra_set_latency_allowance(id, 200);
+			if (err)
+				la_debug("\n***tegra_set_latency_allowance,"
+						" err=%d", err);
+		}
+
+		for (id = 0; id < TEGRA_LA_MAX_ID; id++) {
+			if (id >= ID(DISPLAY_0AB) && id <= ID(DISPLAY_HCB))
+				continue;
+			if (id >= ID(VI_WSB) && id <= ID(VI_WY))
+				continue;
+			err = tegra_enable_latency_scaling(id, 20, 50, 80);
+			if (err)
+				la_debug("\n***tegra_enable_latency_scaling,"
+						" err=%d", err);
+		}
+
+		la_debug("la_scaling_enable_count =%d",
+				cs.la_scaling_enable_count);
+		for (id = 0; id < TEGRA_LA_MAX_ID; id++) {
+			if (id >= ID(DISPLAY_0AB) && id <= ID(DISPLAY_HCB))
+				continue;
+			if (id >= ID(VI_WSB) && id <= ID(VI_WY))
+				continue;
+			tegra_disable_latency_scaling(id);
+		}
+		la_debug("la_scaling_enable_count=%d",
+				cs.la_scaling_enable_count);
+	} while (--repeat_count);
+	return 0;
+}
+
+late_initcall(test_la);
+#endif
diff --git a/drivers/platform/tegra/mc/mc-regs-t19x.h b/drivers/platform/tegra/mc/mc-regs-t19x.h
new file mode 100644
index 000000000000..b94268d3ea04
--- /dev/null
+++ b/drivers/platform/tegra/mc/mc-regs-t19x.h
@@ -0,0 +1,1113 @@
+/*
+ * Copyright (C) 2017-2018, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.	See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#ifndef __MACH_TEGRA_MC_REGS_T19X_H__
+#define __MACH_TEGRA_MC_REGS_T19X_H__
+
+/* Auto generated. Do not edit. */
+
+#define MC_AONPC_PTSA_MAX_0	0x77c
+#define MC_AONPC_PTSA_MAX_0_PTSA_MAX_AONPC_DEFAULT_MASK	0x7ff
+#define MC_AONPC_PTSA_MIN_0	0x778
+#define MC_AONPC_PTSA_MIN_0_PTSA_MIN_AONPC_DEFAULT_MASK	0x7ff
+#define MC_AONPC_PTSA_RATE_0	0x774
+#define MC_AONPC_PTSA_RATE_0_PTSA_RATE_AONPC_DEFAULT_MASK	0xfff
+#define MC_APB_PTSA_MAX_0	0x4f0
+#define MC_APB_PTSA_MAX_0_PTSA_MAX_APB_DEFAULT_MASK	0x7ff
+#define MC_APB_PTSA_MIN_0	0x4ec
+#define MC_APB_PTSA_MIN_0_PTSA_MIN_APB_DEFAULT_MASK	0x7ff
+#define MC_APB_PTSA_RATE_0	0x4e8
+#define MC_APB_PTSA_RATE_0_PTSA_RATE_APB_DEFAULT_MASK	0xfff
+#define MC_AUD_PTSA_MAX_0	0x550
+#define MC_AUD_PTSA_MAX_0_PTSA_MAX_AUD_DEFAULT_MASK	0x7ff
+#define MC_AUD_PTSA_MIN_0	0x54c
+#define MC_AUD_PTSA_MIN_0_PTSA_MIN_AUD_DEFAULT_MASK	0x7ff
+#define MC_AUD_PTSA_RATE_0	0x548
+#define MC_AUD_PTSA_RATE_0_PTSA_RATE_AUD_DEFAULT_MASK	0xfff
+#define MC_BPMPPC_PTSA_MAX_0	0x764
+#define MC_BPMPPC_PTSA_MAX_0_PTSA_MAX_BPMPPC_DEFAULT_MASK	0x7ff
+#define MC_BPMPPC_PTSA_MIN_0	0x760
+#define MC_BPMPPC_PTSA_MIN_0_PTSA_MIN_BPMPPC_DEFAULT_MASK	0x7ff
+#define MC_BPMPPC_PTSA_RATE_0	0x75c
+#define MC_BPMPPC_PTSA_RATE_0_PTSA_RATE_BPMPPC_DEFAULT_MASK	0xfff
+#define MC_CIFLL_ISO_PTSA_MAX_0	0x1120
+#define MC_CIFLL_ISO_PTSA_MAX_0_PTSA_MAX_CIFLL_ISO_DEFAULT_MASK	0x7ff
+#define MC_CIFLL_ISO_PTSA_MIN_0	0x111c
+#define MC_CIFLL_ISO_PTSA_MIN_0_PTSA_MIN_CIFLL_ISO_DEFAULT_MASK	0x7ff
+#define MC_CIFLL_ISO_PTSA_RATE_0	0x1124
+#define MC_CIFLL_ISO_PTSA_RATE_0_PTSA_RATE_CIFLL_ISO_DEFAULT_MASK	0xfff
+#define MC_CIFLL_NISO_PTSA_MAX_0	0x1108
+#define MC_CIFLL_NISO_PTSA_MAX_0_PTSA_MAX_CIFLL_NISO_DEFAULT_MASK	0x7ff
+#define MC_CIFLL_NISO_PTSA_MIN_0	0x1104
+#define MC_CIFLL_NISO_PTSA_MIN_0_PTSA_MIN_CIFLL_NISO_DEFAULT_MASK	0x7ff
+#define MC_CIFLL_NISO_PTSA_RATE_0	0x110c
+#define MC_CIFLL_NISO_PTSA_RATE_0_PTSA_RATE_CIFLL_NISO_DEFAULT_MASK	0xfff
+#define MC_CIFLL_NVLRHP_LATENCY_ALLOWANCE_0	0x189c
+#define MC_CIFLL_RING0X_PTSA_MAX_0	0x112c
+#define MC_CIFLL_RING0X_PTSA_MAX_0_PTSA_MAX_CIFLL_RING0X_DEFAULT_MASK	0x7ff
+#define MC_CIFLL_RING0X_PTSA_MIN_0	0x1128
+#define MC_CIFLL_RING0X_PTSA_MIN_0_PTSA_MIN_CIFLL_RING0X_DEFAULT_MASK	0x7ff
+#define MC_CIFLL_RING0X_PTSA_RATE_0	0x1130
+#define MC_CIFLL_RING0X_PTSA_RATE_0_PTSA_RATE_CIFLL_RING0X_DEFAULT_MASK 0xfff
+#define MC_CIFLL_SISO_PTSA_MAX_0	0x1114
+#define MC_CIFLL_SISO_PTSA_MAX_0_PTSA_MAX_CIFLL_SISO_DEFAULT_MASK	0x7ff
+#define MC_CIFLL_SISO_PTSA_MIN_0	0x1110
+#define MC_CIFLL_SISO_PTSA_MIN_0_PTSA_MIN_CIFLL_SISO_DEFAULT_MASK	0x7ff
+#define MC_CIFLL_SISO_PTSA_RATE_0	0x1118
+#define MC_CIFLL_SISO_PTSA_RATE_0_PTSA_RATE_CIFLL_SISO_DEFAULT_MASK	0xfff
+#define MC_CLIENT_ORDER_ID_0_0	0x2a00
+#define MC_CLIENT_ORDER_ID_10_0	0x2a28
+#define MC_CLIENT_ORDER_ID_12_0	0x2a30
+#define MC_CLIENT_ORDER_ID_13_0	0x2a34
+#define MC_CLIENT_ORDER_ID_14_0	0x2a38
+#define MC_CLIENT_ORDER_ID_15_0	0x2a3c
+#define MC_CLIENT_ORDER_ID_16_0	0x2a40
+#define MC_CLIENT_ORDER_ID_17_0	0x2a44
+#define MC_CLIENT_ORDER_ID_18_0	0x2a48
+#define MC_CLIENT_ORDER_ID_19_0	0x2a4c
+#define MC_CLIENT_ORDER_ID_20_0	0x2a50
+#define MC_CLIENT_ORDER_ID_21_0	0x2a54
+#define MC_CLIENT_ORDER_ID_22_0	0x2a58
+#define MC_CLIENT_ORDER_ID_23_0	0x2a5c
+#define MC_CLIENT_ORDER_ID_24_0	0x2a60
+#define MC_CLIENT_ORDER_ID_25_0	0x2a64
+#define MC_CLIENT_ORDER_ID_26_0	0x2a68
+#define MC_CLIENT_ORDER_ID_27_0	0x2a6c
+#define MC_CLIENT_ORDER_ID_27_0_PCIE0W_ORDER_ID_ORDER_ID2	2
+#define MC_CLIENT_ORDER_ID_27_0_PCIE0W_ORDER_ID_RANGE	5:4
+#define MC_CLIENT_ORDER_ID_27_0_PCIE1W_ORDER_ID_RANGE	13:12
+#define MC_CLIENT_ORDER_ID_27_0_PCIE2AW_ORDER_ID_RANGE	21:20
+#define MC_CLIENT_ORDER_ID_27_0_PCIE3W_ORDER_ID_RANGE	29:28
+#define MC_CLIENT_ORDER_ID_28_0	0x2a70
+#define MC_CLIENT_ORDER_ID_28_0_PCIE4W_ORDER_ID_ORDER_ID3	3
+#define MC_CLIENT_ORDER_ID_28_0_PCIE4W_ORDER_ID_RANGE	5:4
+#define MC_CLIENT_ORDER_ID_28_0_PCIE5W_ORDER_ID_ORDER_ID1	1
+#define MC_CLIENT_ORDER_ID_28_0_PCIE5W_ORDER_ID_RANGE	13:12
+#define MC_CLIENT_ORDER_ID_29_0	0x2a74
+#define MC_CLIENT_ORDER_ID_2_0	0x2a08
+#define MC_CLIENT_ORDER_ID_30_0	0x2d00
+#define MC_CLIENT_ORDER_ID_31_0	0x2d04
+#define MC_CLIENT_ORDER_ID_3_0	0x2a0c
+#define MC_CLIENT_ORDER_ID_4_0	0x2a10
+#define MC_CLIENT_ORDER_ID_5_0	0x2a14
+#define MC_CLIENT_ORDER_ID_6_0	0x2a18
+#define MC_CLIENT_ORDER_ID_7_0	0x2a1c
+#define MC_CLIENT_ORDER_ID_8_0	0x2a20
+#define MC_CLIENT_ORDER_ID_9_0	0x2a24
+#define MC_CLIENT_ORDER_ID_9_0_XUSB_HOSTW_ORDER_ID_ORDER_ID3	3
+#define MC_CLIENT_ORDER_ID_9_0_XUSB_HOSTW_ORDER_ID_RANGE	13:12
+#define MC_CONFIG_TSA_SINGLE_ARB_ENABLE_0	0xfe8
+#define MC_CONFIG_TSA_SINGLE_ARB_ENABLE_0_SINGLE_ARB_ENABLE_ENABLE	1
+#define MC_CONFIG_TSA_SINGLE_ARB_ENABLE_0_SINGLE_ARB_ENABLE_RANGE	0:0
+#define MC_DIS_PTSA_MAX_0	0x424
+#define MC_DIS_PTSA_MAX_0_PTSA_MAX_DIS_DEFAULT_MASK	0x7ff
+#define MC_DIS_PTSA_MIN_0	0x420
+#define MC_DIS_PTSA_MIN_0_PTSA_MIN_DIS_DEFAULT_MASK	0x7ff
+#define MC_DIS_PTSA_RATE_0	0x41c
+#define MC_DIS_PTSA_RATE_0_PTSA_RATE_DIS_DEFAULT_MASK	0xfff
+#define MC_DLA0FALPC_PTSA_MAX_0	0x3174
+#define MC_DLA0FALPC_PTSA_MAX_0_PTSA_MAX_DLA0FALPC_DEFAULT_MASK	0x7ff
+#define MC_DLA0FALPC_PTSA_MIN_0	0x3170
+#define MC_DLA0FALPC_PTSA_MIN_0_PTSA_MIN_DLA0FALPC_DEFAULT_MASK	0x7ff
+#define MC_DLA0FALPC_PTSA_RATE_0	0x316c
+#define MC_DLA0FALPC_PTSA_RATE_0_PTSA_RATE_DLA0FALPC_DEFAULT_MASK	0xfff
+#define MC_DLA0XA2_PTSA_MAX_0	0x3938
+#define MC_DLA0XA2_PTSA_MAX_0_PTSA_MAX_DLA0XA2_DEFAULT_MASK	0x7ff
+#define MC_DLA0XA2_PTSA_MIN_0	0x3934
+#define MC_DLA0XA2_PTSA_MIN_0_PTSA_MIN_DLA0XA2_DEFAULT_MASK	0x7ff
+#define MC_DLA0XA2_PTSA_RATE_0	0x3930
+#define MC_DLA0XA2_PTSA_RATE_0_PTSA_RATE_DLA0XA2_DEFAULT_MASK	0xfff
+#define MC_DLA0XA3_PTSA_MAX_0	0x3368
+#define MC_DLA0XA3_PTSA_MAX_0_PTSA_MAX_DLA0XA3_DEFAULT_MASK	0x7ff
+#define MC_DLA0XA3_PTSA_MIN_0	0x3364
+#define MC_DLA0XA3_PTSA_MIN_0_PTSA_MIN_DLA0XA3_DEFAULT_MASK	0x7ff
+#define MC_DLA0XA3_PTSA_RATE_0	0x3360
+#define MC_DLA0XA3_PTSA_RATE_0_PTSA_RATE_DLA0XA3_DEFAULT_MASK	0xfff
+#define MC_DLA0XA_PTSA_MAX_0	0x7e8
+#define MC_DLA0XA_PTSA_MAX_0_PTSA_MAX_DLA0XA_DEFAULT_MASK	0x7ff
+#define MC_DLA0XA_PTSA_MIN_0	0x7e4
+#define MC_DLA0XA_PTSA_MIN_0_PTSA_MIN_DLA0XA_DEFAULT_MASK	0x7ff
+#define MC_DLA0XA_PTSA_RATE_0	0x7e0
+#define MC_DLA0XA_PTSA_RATE_0_PTSA_RATE_DLA0XA_DEFAULT_MASK	0xfff
+#define MC_DLA1FALPC_PTSA_MAX_0	0x3308
+#define MC_DLA1FALPC_PTSA_MAX_0_PTSA_MAX_DLA1FALPC_DEFAULT_MASK	0x7ff
+#define MC_DLA1FALPC_PTSA_MIN_0	0x3304
+#define MC_DLA1FALPC_PTSA_MIN_0_PTSA_MIN_DLA1FALPC_DEFAULT_MASK	0x7ff
+#define MC_DLA1FALPC_PTSA_RATE_0	0x3300
+#define MC_DLA1FALPC_PTSA_RATE_0_PTSA_RATE_DLA1FALPC_DEFAULT_MASK	0xfff
+#define MC_DLA1XA2_PTSA_MAX_0	0x3944
+#define MC_DLA1XA2_PTSA_MAX_0_PTSA_MAX_DLA1XA2_DEFAULT_MASK	0x7ff
+#define MC_DLA1XA2_PTSA_MIN_0	0x3940
+#define MC_DLA1XA2_PTSA_MIN_0_PTSA_MIN_DLA1XA2_DEFAULT_MASK	0x7ff
+#define MC_DLA1XA2_PTSA_RATE_0	0x393c
+#define MC_DLA1XA2_PTSA_RATE_0_PTSA_RATE_DLA1XA2_DEFAULT_MASK	0xfff
+#define MC_DLA1XA3_PTSA_MAX_0	0x3374
+#define MC_DLA1XA3_PTSA_MAX_0_PTSA_MAX_DLA1XA3_DEFAULT_MASK	0x7ff
+#define MC_DLA1XA3_PTSA_MIN_0	0x3370
+#define MC_DLA1XA3_PTSA_MIN_0_PTSA_MIN_DLA1XA3_DEFAULT_MASK	0x7ff
+#define MC_DLA1XA3_PTSA_RATE_0	0x336c
+#define MC_DLA1XA3_PTSA_RATE_0_PTSA_RATE_DLA1XA3_DEFAULT_MASK	0xfff
+#define MC_DLA1XA_PTSA_MAX_0	0x7f4
+#define MC_DLA1XA_PTSA_MAX_0_PTSA_MAX_DLA1XA_DEFAULT_MASK	0x7ff
+#define MC_DLA1XA_PTSA_MIN_0	0x7f0
+#define MC_DLA1XA_PTSA_MIN_0_PTSA_MIN_DLA1XA_DEFAULT_MASK	0x7ff
+#define MC_DLA1XA_PTSA_RATE_0	0x7ec
+#define MC_DLA1XA_PTSA_RATE_0_PTSA_RATE_DLA1XA_DEFAULT_MASK	0xfff
+#define MC_EMEM_ADR_CFG_CHANNEL_ENABLE_0	0xdf8
+#define MC_EMEM_ARB_MISC2_0	0xc8
+#define MC_EMEM_ARB_MISC2_0_BACKING_RD_ON_ALL_64BYTE_WR_ENABLE	1
+#define MC_EMEM_ARB_MISC2_0_BACKING_RD_ON_ALL_64BYTE_WR_RANGE	2:2
+#define MC_EMEM_ARB_MISC2_0_DL_ONLY_ARB_ENABLE	1
+#define MC_EMEM_ARB_MISC2_0_DL_ONLY_ARB_RANGE	31:31
+#define MC_EMEM_ARB_MISC2_0_SYNC_MON_DISABLE	0
+#define MC_EMEM_ARB_MISC2_0_SYNC_MON_ENABLE	1
+#define MC_EMEM_ARB_MISC2_0_SYNC_MON_RANGE	30:30
+#define MC_EMEM_ARB_MISC3_0	0x23c
+#define MC_EMEM_ARB_MISC3_0_BC2AA_HOLDOFF_MAX_THRESHOLD_R_RANGE	6:0
+#define MC_EMEM_ARB_MISC3_0_BC2AA_HOLDOFF_MAX_THRESHOLD_W_RANGE	14:8
+#define MC_EMEM_ARB_MISC3_0_BC2AA_HOLDOFF_MIN_THRESHOLD_R_RANGE	19:16
+#define MC_EMEM_ARB_MISC3_0_BC2AA_HOLDOFF_MIN_THRESHOLD_W_RANGE	23:20
+#define MC_EMEM_ARB_OVERRIDE_0	0xe8
+#define MC_EMEM_ARB_OVERRIDE_0_TS2AA_HOLDOFF_OVERRIDE_DISABLE	0
+#define MC_EMEM_ARB_OVERRIDE_0_TS2AA_HOLDOFF_OVERRIDE_ENABLE	1
+#define MC_EMEM_ARB_OVERRIDE_0_TS2AA_HOLDOFF_OVERRIDE_RANGE	8:8
+#define MC_EMEM_ARB_REFPB_HP_CTRL_0	0x6f0
+#define MC_EMEM_ARB_REFPB_HP_CTRL_0_REFPB_THRESH_DISABLE_HP_RANGE	14:8
+#define MC_EMEM_ARB_REFPB_HP_CTRL_0_REFPB_THRESH_ENABLE_HP_RANGE	6:0
+#define MC_EQOSPC_PTSA_MAX_0	0x758
+#define MC_EQOSPC_PTSA_MAX_0_PTSA_MAX_EQOSPC_DEFAULT_MASK	0x7ff
+#define MC_EQOSPC_PTSA_MIN_0	0x754
+#define MC_EQOSPC_PTSA_MIN_0_PTSA_MIN_EQOSPC_DEFAULT_MASK	0x7ff
+#define MC_EQOSPC_PTSA_RATE_0	0x750
+#define MC_EQOSPC_PTSA_RATE_0_PTSA_RATE_EQOSPC_DEFAULT_MASK	0xfff
+#define MC_FREE_BANK_QUEUES_0	0xea4
+#define MC_FREE_BANK_QUEUES_0_HP_CPU_THROTTLE_EN_DISABLE	0
+#define MC_FREE_BANK_QUEUES_0_HP_CPU_THROTTLE_EN_ENABLE	1
+#define MC_FREE_BANK_QUEUES_0_HP_CPU_THROTTLE_EN_RANGE	16:16
+#define MC_FTOP_PTSA_RATE_0_PTSA_RATE_FTOP_DEFAULT_MASK	0xfff
+#define MC_HDAPC_PTSA_MAX_0	0x630
+#define MC_HDAPC_PTSA_MAX_0_PTSA_MAX_HDAPC_DEFAULT_MASK	0x7ff
+#define MC_HDAPC_PTSA_MIN_0	0x62c
+#define MC_HDAPC_PTSA_MIN_0_PTSA_MIN_HDAPC_DEFAULT_MASK	0x7ff
+#define MC_HDAPC_PTSA_RATE_0	0x628
+#define MC_HDAPC_PTSA_RATE_0_PTSA_RATE_HDAPC_DEFAULT_MASK	0xfff
+#define MC_HOST_PTSA_MAX_0	0x520
+#define MC_HOST_PTSA_MAX_0_PTSA_MAX_HOST_DEFAULT_MASK	0x7ff
+#define MC_HOST_PTSA_MIN_0	0x51c
+#define MC_HOST_PTSA_MIN_0_PTSA_MIN_HOST_DEFAULT_MASK	0x7ff
+#define MC_HOST_PTSA_RATE_0	0x518
+#define MC_HOST_PTSA_RATE_0_PTSA_RATE_HOST_DEFAULT_MASK	0xfff
+#define MC_HUB2MCF_REQ_DDA_ENABLE_0	0xfc0
+#define MC_HUB2MCF_REQ_DDA_ENABLE_0_HUBINT_DDA_ENABLE_DISABLED	0
+#define MC_HUB2MCF_REQ_DDA_ENABLE_0_HUBINT_DDA_ENABLE_ENABLED	1
+#define MC_HUB2MCF_REQ_DDA_ENABLE_0_HUBINT_DDA_ENABLE_RANGE	2:2
+#define MC_HUB2MCF_REQ_DDA_ENABLE_0_HUBORD_DDA_ENABLE_DISABLED	0
+#define MC_HUB2MCF_REQ_DDA_ENABLE_0_HUBORD_DDA_ENABLE_ENABLED	1
+#define MC_HUB2MCF_REQ_DDA_ENABLE_0_HUBORD_DDA_ENABLE_RANGE	1:1
+#define MC_HUB2MCF_REQ_DDA_ENABLE_0_HUB_DDA_ENABLE_DISABLED	0
+#define MC_HUB2MCF_REQ_DDA_ENABLE_0_HUB_DDA_ENABLE_ENABLED	1
+#define MC_HUB2MCF_REQ_DDA_ENABLE_0_HUB_DDA_ENABLE_RANGE	0:0
+#define MC_HUBINT_HUB2MCF_REQ_DDA_MAX_0	0xfbc
+#define MC_HUBINT_HUB2MCF_REQ_DDA_MAX_0_HUBINT_DDA_MAX_DEFAULT_MASK	0x7ff
+#define MC_HUBINT_HUB2MCF_REQ_DDA_RATE_0	0xfb0
+#define MC_HUBINT_HUB2MCF_REQ_DDA_RATE_0_HUBINT_DDA_RATE_DEFAULT_MASK	0xfff
+#define MC_HUBORD_HUB2MCF_REQ_DDA_MAX_0	0xfb8
+#define MC_HUBORD_HUB2MCF_REQ_DDA_MAX_0_HUBORD_DDA_MAX_DEFAULT_MASK	0x7ff
+#define MC_HUBORD_HUB2MCF_REQ_DDA_RATE_0	0xfac
+#define MC_HUBORD_HUB2MCF_REQ_DDA_RATE_0_HUBORD_DDA_RATE_DEFAULT_MASK	0xfff
+#define MC_HUB_HUB2MCF_REQ_DDA_MAX_0	0xfb4
+#define MC_HUB_HUB2MCF_REQ_DDA_MAX_0_HUB_DDA_MAX_DEFAULT_MASK	0x7ff
+#define MC_HUB_HUB2MCF_REQ_DDA_RATE_0	0xfa8
+#define MC_HUB_HUB2MCF_REQ_DDA_RATE_0_HUB_DDA_RATE_DEFAULT_MASK	0xfff
+#define MC_HUB_VC_ARB_SEL_0	0x2954
+#define MC_HUB_VC_ARB_SEL_0_ISO_WT_RANGE	6:2
+#define MC_HUB_VC_ARB_SEL_0_NISO_WT_RANGE	16:12
+#define MC_HUB_VC_ARB_SEL_0_SISO_WT_RANGE	11:7
+#define MC_HUB_VC_ARB_SEL_0_VC_ARB_TYPE_RANGE	1:0
+#define MC_ISP2PC_PTSA_MAX_0	0x4b08
+#define MC_ISP2PC_PTSA_MAX_0_PTSA_MAX_ISP2PC_DEFAULT_MASK	0x7ff
+#define MC_ISP2PC_PTSA_MIN_0	0x4b04
+#define MC_ISP2PC_PTSA_MIN_0_PTSA_MIN_ISP2PC_DEFAULT_MASK	0x7ff
+#define MC_ISP2PC_PTSA_RATE_0	0x4b00
+#define MC_ISP2PC_PTSA_RATE_0_PTSA_RATE_ISP2PC_DEFAULT_MASK	0xfff
+#define MC_ISPPC_PTSA_MAX_0	0x3a74
+#define MC_ISPPC_PTSA_MAX_0_PTSA_MAX_ISPPC_DEFAULT_MASK	0x7ff
+#define MC_ISPPC_PTSA_MIN_0	0x3a70
+#define MC_ISPPC_PTSA_MIN_0_PTSA_MIN_ISPPC_DEFAULT_MASK	0x7ff
+#define MC_ISPPC_PTSA_RATE_0	0x3a6c
+#define MC_ISPPC_PTSA_RATE_0_PTSA_RATE_ISPPC_DEFAULT_MASK	0xfff
+#define MC_ISP_PTSA_MAX_0	0x4a8
+#define MC_ISP_PTSA_MAX_0_PTSA_MAX_ISP_DEFAULT_MASK	0x7ff
+#define MC_ISP_PTSA_MIN_0	0x4a4
+#define MC_ISP_PTSA_MIN_0_PTSA_MIN_ISP_DEFAULT_MASK	0x7ff
+#define MC_ISP_PTSA_RATE_0	0x4a0
+#define MC_ISP_PTSA_RATE_0_PTSA_RATE_ISP_DEFAULT_MASK	0xfff
+#define MC_JPG_PTSA_MAX_0	0x58c
+#define MC_JPG_PTSA_MAX_0_PTSA_MAX_JPG_DEFAULT_MASK	0x7ff
+#define MC_JPG_PTSA_MIN_0	0x588
+#define MC_JPG_PTSA_MIN_0_PTSA_MIN_JPG_DEFAULT_MASK	0x7ff
+#define MC_JPG_PTSA_RATE_0	0x584
+#define MC_JPG_PTSA_RATE_0_PTSA_RATE_JPG_DEFAULT_MASK	0xfff
+#define MC_LATENCY_ALLOWANCE_AONDMA_0_0	0x718
+#define MC_LATENCY_ALLOWANCE_AON_0_0	0x714
+#define MC_LATENCY_ALLOWANCE_APEDMA_0_0	0x724
+#define MC_LATENCY_ALLOWANCE_APE_0_0	0x3dc
+#define MC_LATENCY_ALLOWANCE_AXIAP_0_0	0x3a0
+#define MC_LATENCY_ALLOWANCE_AXIS_0_0	0x3f8
+#define MC_LATENCY_ALLOWANCE_BPMPDMA_0_0	0x710
+#define MC_LATENCY_ALLOWANCE_BPMP_0_0	0x70c
+#define MC_LATENCY_ALLOWANCE_CIFLL_WR_0_0	0x1100
+#define MC_LATENCY_ALLOWANCE_DLA0_0_0	0x1020
+#define MC_LATENCY_ALLOWANCE_DLA0_1_0	0x1024
+#define MC_LATENCY_ALLOWANCE_DLA0_2_0	0x1a18
+#define MC_LATENCY_ALLOWANCE_DLA1_0_0	0x1028
+#define MC_LATENCY_ALLOWANCE_DLA1_1_0	0x102c
+#define MC_LATENCY_ALLOWANCE_EQOS_0_0	0x700
+#define MC_LATENCY_ALLOWANCE_ETR_0_0	0x3ec
+#define MC_LATENCY_ALLOWANCE_HC_0_0	0x310
+#define MC_LATENCY_ALLOWANCE_HDA_0_0	0x318
+#define MC_LATENCY_ALLOWANCE_ISP2_0_0	0x370
+#define MC_LATENCY_ALLOWANCE_ISP2_1_0	0x374
+#define MC_LATENCY_ALLOWANCE_ISP3_0_0	0x1a14
+#define MC_LATENCY_ALLOWANCE_MIU0_0_0	0x1054
+#define MC_LATENCY_ALLOWANCE_MIU1_0_0	0x1058
+#define MC_LATENCY_ALLOWANCE_MIU2_0_0	0x105c
+#define MC_LATENCY_ALLOWANCE_MIU3_0_0	0x1060
+#define MC_LATENCY_ALLOWANCE_MIU4_0_0	0x1a34
+#define MC_LATENCY_ALLOWANCE_MIU5_0_0	0x1a38
+#define MC_LATENCY_ALLOWANCE_MIU6_0_0	0x1a3c
+#define MC_LATENCY_ALLOWANCE_MIU7_0_0	0x1a40
+#define MC_LATENCY_ALLOWANCE_MPCORE_0_0	0x320
+#define MC_LATENCY_ALLOWANCE_NVDEC_0_0	0x3d8
+#define MC_LATENCY_ALLOWANCE_NVDEC_1_0	0x72c
+#define MC_LATENCY_ALLOWANCE_NVDEC_2_0	0x1a30
+#define MC_LATENCY_ALLOWANCE_NVDISPLAY_0_0	0x708
+#define MC_LATENCY_ALLOWANCE_NVENC_0_0	0x328
+#define MC_LATENCY_ALLOWANCE_NVENC_1_0	0x1050
+#define MC_LATENCY_ALLOWANCE_NVENC_2_0	0x1a28
+#define MC_LATENCY_ALLOWANCE_NVJPG_0_0	0x3e4
+#define MC_LATENCY_ALLOWANCE_PCIE0_0_0	0x1064
+#define MC_LATENCY_ALLOWANCE_PCIE1_0_0	0x1a00
+#define MC_LATENCY_ALLOWANCE_PCIE2_0_0	0x1a04
+#define MC_LATENCY_ALLOWANCE_PCIE3_0_0	0x1a08
+#define MC_LATENCY_ALLOWANCE_PCIE4_0_0	0x1a0c
+#define MC_LATENCY_ALLOWANCE_PCIE5_0_0	0x1a10
+#define MC_LATENCY_ALLOWANCE_PCIE5_1_0	0x1a24
+#define MC_LATENCY_ALLOWANCE_PVA0_0_0	0x1030
+#define MC_LATENCY_ALLOWANCE_PVA0_1_0	0x1034
+#define MC_LATENCY_ALLOWANCE_PVA0_2_0	0x1038
+#define MC_LATENCY_ALLOWANCE_PVA0_3_0	0x1a1c
+#define MC_LATENCY_ALLOWANCE_PVA1_0_0	0x103c
+#define MC_LATENCY_ALLOWANCE_PVA1_1_0	0x1040
+#define MC_LATENCY_ALLOWANCE_PVA1_2_0	0x1044
+#define MC_LATENCY_ALLOWANCE_PVA1_3_0	0x1a20
+#define MC_LATENCY_ALLOWANCE_RCEDMA_0_0	0x104c
+#define MC_LATENCY_ALLOWANCE_RCE_0_0	0x1048
+#define MC_LATENCY_ALLOWANCE_ROC_DMA_R_0_0	0xeac
+#define MC_LATENCY_ALLOWANCE_SATA_0_0	0x350
+#define MC_LATENCY_ALLOWANCE_SCEDMA_0_0	0x720
+#define MC_LATENCY_ALLOWANCE_SCE_0_0	0x71c
+#define MC_LATENCY_ALLOWANCE_SDMMCAB_0_0	0x3c4
+#define MC_LATENCY_ALLOWANCE_SDMMCA_0_0	0x3b8
+#define MC_LATENCY_ALLOWANCE_SDMMC_0_0	0x3c0
+#define MC_LATENCY_ALLOWANCE_SE_0_0	0x3e0
+#define MC_LATENCY_ALLOWANCE_TSECB_0_0	0x3f0
+#define MC_LATENCY_ALLOWANCE_TSEC_0_0	0x390
+#define MC_LATENCY_ALLOWANCE_UFSHC_0_0	0x704
+#define MC_LATENCY_ALLOWANCE_VI2_0_0	0x398
+#define MC_LATENCY_ALLOWANCE_VIC_0_0	0x394
+#define MC_LATENCY_ALLOWANCE_VIC_1_0	0x728
+#define MC_LATENCY_ALLOWANCE_VIFAL_0_0	0x101c
+#define MC_LATENCY_ALLOWANCE_WCAM_0	0xe5c
+#define MC_LATENCY_ALLOWANCE_XUSB_0_0	0x37c
+#define MC_LATENCY_ALLOWANCE_XUSB_1_0	0x380
+#define MC_MC_SMMU_ISO_TBU_CCHK_REQ_PRI_CTRL_0	0x2968
+#define MC_MC_SMMU_ISO_TBU_CCHK_REQ_PRI_CTRL_0_ISO_TBU_CCHK_EN_CTRL_RANGE	9:8
+#define MC_MC_SMMU_PTC2H_REQ_MAPPING_0	0x2970
+#define MC_MC_SMMU_PTC2H_REQ_MAPPING_0_PTC22H_REQ_MAPPING_RANGE	9:8
+#define MC_MC_SMMU_PTC2H_REQ_MAPPING_OVERRIDE_0	0x296c
+#define MC_MC_SMMU_PTC2H_REQ_MAPPING_OVERRIDE_0_PTC22H_REQ_MAPPING_OVERRIDE_ENABLE	1
+#define MC_MC_SMMU_PTC2H_REQ_MAPPING_OVERRIDE_0_PTC22H_REQ_MAPPING_OVERRIDE_RANGE	8:8
+#define MC_MIU0_PTSA_MAX_0	0x3144
+#define MC_MIU0_PTSA_MAX_0_PTSA_MAX_MIU0_DEFAULT_MASK	0x7ff
+#define MC_MIU0_PTSA_MIN_0	0x3140
+#define MC_MIU0_PTSA_MIN_0_PTSA_MIN_MIU0_DEFAULT_MASK	0x7ff
+#define MC_MIU0_PTSA_RATE_0	0x313c
+#define MC_MIU0_PTSA_RATE_0_PTSA_RATE_MIU0_DEFAULT_MASK	0xfff
+#define MC_MIU1_PTSA_MAX_0	0x3150
+#define MC_MIU1_PTSA_MAX_0_PTSA_MAX_MIU1_DEFAULT_MASK	0x7ff
+#define MC_MIU1_PTSA_MIN_0	0x314c
+#define MC_MIU1_PTSA_MIN_0_PTSA_MIN_MIU1_DEFAULT_MASK	0x7ff
+#define MC_MIU1_PTSA_RATE_0	0x3148
+#define MC_MIU1_PTSA_RATE_0_PTSA_RATE_MIU1_DEFAULT_MASK	0xfff
+#define MC_MIU2_PTSA_MAX_0	0x315c
+#define MC_MIU2_PTSA_MAX_0_PTSA_MAX_MIU2_DEFAULT_MASK	0x7ff
+#define MC_MIU2_PTSA_MIN_0	0x3158
+#define MC_MIU2_PTSA_MIN_0_PTSA_MIN_MIU2_DEFAULT_MASK	0x7ff
+#define MC_MIU2_PTSA_RATE_0	0x3154
+#define MC_MIU2_PTSA_RATE_0_PTSA_RATE_MIU2_DEFAULT_MASK	0xfff
+#define MC_MIU3_PTSA_MAX_0	0x3168
+#define MC_MIU3_PTSA_MAX_0_PTSA_MAX_MIU3_DEFAULT_MASK	0x7ff
+#define MC_MIU3_PTSA_MIN_0	0x3164
+#define MC_MIU3_PTSA_MIN_0_PTSA_MIN_MIU3_DEFAULT_MASK	0x7ff
+#define MC_MIU3_PTSA_RATE_0	0x3160
+#define MC_MIU3_PTSA_RATE_0_PTSA_RATE_MIU3_DEFAULT_MASK	0xfff
+#define MC_MIU4_PTSA_MAX_0	0x4b44
+#define MC_MIU4_PTSA_MAX_0_PTSA_MAX_MIU4_DEFAULT_MASK	0x7ff
+#define MC_MIU4_PTSA_MIN_0	0x4b40
+#define MC_MIU4_PTSA_MIN_0_PTSA_MIN_MIU4_DEFAULT_MASK	0x7ff
+#define MC_MIU4_PTSA_RATE_0	0x4b3c
+#define MC_MIU4_PTSA_RATE_0_PTSA_RATE_MIU4_DEFAULT_MASK	0xfff
+#define MC_MIU5_PTSA_MAX_0	0x4b50
+#define MC_MIU5_PTSA_MAX_0_PTSA_MAX_MIU5_DEFAULT_MASK	0x7ff
+#define MC_MIU5_PTSA_MIN_0	0x4b4c
+#define MC_MIU5_PTSA_MIN_0_PTSA_MIN_MIU5_DEFAULT_MASK	0x7ff
+#define MC_MIU5_PTSA_RATE_0	0x4b48
+#define MC_MIU5_PTSA_RATE_0_PTSA_RATE_MIU5_DEFAULT_MASK	0xfff
+#define MC_MIU6_PTSA_MAX_0	0x4b5c
+#define MC_MIU6_PTSA_MAX_0_PTSA_MAX_MIU6_DEFAULT_MASK	0x7ff
+#define MC_MIU6_PTSA_MIN_0	0x4b58
+#define MC_MIU6_PTSA_MIN_0_PTSA_MIN_MIU6_DEFAULT_MASK	0x7ff
+#define MC_MIU6_PTSA_RATE_0	0x4b54
+#define MC_MIU6_PTSA_RATE_0_PTSA_RATE_MIU6_DEFAULT_MASK	0xfff
+#define MC_MIU7_PTSA_MAX_0	0x4b68
+#define MC_MIU7_PTSA_MAX_0_PTSA_MAX_MIU7_DEFAULT_MASK	0x7ff
+#define MC_MIU7_PTSA_MIN_0	0x4b64
+#define MC_MIU7_PTSA_MIN_0_PTSA_MIN_MIU7_DEFAULT_MASK	0x7ff
+#define MC_MIU7_PTSA_RATE_0	0x4b60
+#define MC_MIU7_PTSA_RATE_0_PTSA_RATE_MIU7_DEFAULT_MASK	0xfff
+#define MC_MLL_MPCORER_PTSA_MAX_0	0x454
+#define MC_MLL_MPCORER_PTSA_MAX_0_PTSA_MAX_MLL_MPCORER_DEFAULT_MASK	0x7ff
+#define MC_MLL_MPCORER_PTSA_MIN_0	0x450
+#define MC_MLL_MPCORER_PTSA_MIN_0_PTSA_MIN_MLL_MPCORER_DEFAULT_MASK	0x7ff
+#define MC_MLL_MPCORER_PTSA_RATE_0	0x44c
+#define MC_MLL_MPCORER_PTSA_RATE_0_PTSA_RATE_MLL_MPCORER_DEFAULT_MASK	0xfff
+#define MC_MSE2_PTSA_MAX_0	0x7d0
+#define MC_MSE2_PTSA_MAX_0_PTSA_MAX_MSE2_DEFAULT_MASK	0x7ff
+#define MC_MSE2_PTSA_MIN_0	0x7cc
+#define MC_MSE2_PTSA_MIN_0_PTSA_MIN_MSE2_DEFAULT_MASK	0x7ff
+#define MC_MSE2_PTSA_RATE_0	0x7c8
+#define MC_MSE2_PTSA_RATE_0_PTSA_RATE_MSE2_DEFAULT_MASK	0xfff
+#define MC_MSE3_PTSA_MAX_0	0x3138
+#define MC_MSE3_PTSA_MAX_0_PTSA_MAX_MSE3_DEFAULT_MASK	0x7ff
+#define MC_MSE3_PTSA_MIN_0	0x3134
+#define MC_MSE3_PTSA_MIN_0_PTSA_MIN_MSE3_DEFAULT_MASK	0x7ff
+#define MC_MSE3_PTSA_RATE_0	0x3130
+#define MC_MSE3_PTSA_RATE_0_PTSA_RATE_MSE3_DEFAULT_MASK	0xfff
+#define MC_MSEA_PTSA_MAX_0	0x3a50
+#define MC_MSEA_PTSA_MAX_0_PTSA_MAX_MSEA_DEFAULT_MASK	0x7ff
+#define MC_MSEA_PTSA_MIN_0	0x3a4c
+#define MC_MSEA_PTSA_MIN_0_PTSA_MIN_MSEA_DEFAULT_MASK	0x7ff
+#define MC_MSEA_PTSA_RATE_0	0x3a48
+#define MC_MSEA_PTSA_RATE_0_PTSA_RATE_MSEA_DEFAULT_MASK	0xfff
+#define MC_MSEB1_PTSA_MAX_0	0x3a68
+#define MC_MSEB1_PTSA_MAX_0_PTSA_MAX_MSEB1_DEFAULT_MASK	0x7ff
+#define MC_MSEB1_PTSA_MIN_0	0x3a64
+#define MC_MSEB1_PTSA_MIN_0_PTSA_MIN_MSEB1_DEFAULT_MASK	0x7ff
+#define MC_MSEB1_PTSA_RATE_0	0x3a60
+#define MC_MSEB1_PTSA_RATE_0_PTSA_RATE_MSEB1_DEFAULT_MASK	0xfff
+#define MC_MSEB_PTSA_MAX_0	0x3a5c
+#define MC_MSEB_PTSA_MAX_0_PTSA_MAX_MSEB_DEFAULT_MASK	0x7ff
+#define MC_MSEB_PTSA_MIN_0	0x3a58
+#define MC_MSEB_PTSA_MIN_0_PTSA_MIN_MSEB_DEFAULT_MASK	0x7ff
+#define MC_MSEB_PTSA_RATE_0	0x3a54
+#define MC_MSEB_PTSA_RATE_0_PTSA_RATE_MSEB_DEFAULT_MASK	0xfff
+#define MC_MSE_PTSA_MAX_0	0x4cc
+#define MC_MSE_PTSA_MAX_0_PTSA_MAX_MSE_DEFAULT_MASK	0x7ff
+#define MC_MSE_PTSA_MIN_0	0x4c8
+#define MC_MSE_PTSA_MIN_0_PTSA_MIN_MSE_DEFAULT_MASK	0x7ff
+#define MC_MSE_PTSA_RATE_0	0x4c4
+#define MC_MSE_PTSA_RATE_0_PTSA_RATE_MSE_DEFAULT_MASK	0xfff
+#define MC_MSSNVLINK_DGPU_LATENCY_ALLOWANCE_0	0x1894
+#define MC_MSSNVLINK_IGPU_LATENCY_ALLOWANCE_0	0x1890
+#define MC_NIC_PTSA_MAX_0	0x740
+#define MC_NIC_PTSA_MAX_0_PTSA_MAX_NIC_DEFAULT_MASK	0x7ff
+#define MC_NIC_PTSA_MIN_0	0x73c
+#define MC_NIC_PTSA_MIN_0_PTSA_MIN_NIC_DEFAULT_MASK	0x7ff
+#define MC_NIC_PTSA_RATE_0	0x738
+#define MC_NIC_PTSA_RATE_0_PTSA_RATE_NIC_DEFAULT_MASK	0xfff
+#define MC_NVD2_PTSA_MAX_0	0x3a20
+#define MC_NVD2_PTSA_MAX_0_PTSA_MAX_NVD2_DEFAULT_MASK	0x7ff
+#define MC_NVD2_PTSA_MIN_0	0x3a1c
+#define MC_NVD2_PTSA_MIN_0_PTSA_MIN_NVD2_DEFAULT_MASK	0x7ff
+#define MC_NVD2_PTSA_RATE_0	0x3a18
+#define MC_NVD2_PTSA_RATE_0_PTSA_RATE_NVD2_DEFAULT_MASK	0xfff
+#define MC_NVD3_PTSA_MAX_0	0x7c4
+#define MC_NVD3_PTSA_MAX_0_PTSA_MAX_NVD3_DEFAULT_MASK	0x7ff
+#define MC_NVD3_PTSA_MIN_0	0x7c0
+#define MC_NVD3_PTSA_MIN_0_PTSA_MIN_NVD3_DEFAULT_MASK	0x7ff
+#define MC_NVD3_PTSA_RATE_0	0x7bc
+#define MC_NVD3_PTSA_RATE_0_PTSA_RATE_NVD3_DEFAULT_MASK	0xfff
+#define MC_NVD4_PTSA_MAX_0	0x4b20
+#define MC_NVD4_PTSA_MAX_0_PTSA_MAX_NVD4_DEFAULT_MASK	0x7ff
+#define MC_NVD4_PTSA_MIN_0	0x4b1c
+#define MC_NVD4_PTSA_MIN_0_PTSA_MIN_NVD4_DEFAULT_MASK	0x7ff
+#define MC_NVD4_PTSA_RATE_0	0x4b18
+#define MC_NVD4_PTSA_RATE_0_PTSA_RATE_NVD4_DEFAULT_MASK	0xfff
+#define MC_NVD5_PTSA_MAX_0	0x4b2c
+#define MC_NVD5_PTSA_MAX_0_PTSA_MAX_NVD5_DEFAULT_MASK	0x7ff
+#define MC_NVD5_PTSA_MIN_0	0x4b28
+#define MC_NVD5_PTSA_MIN_0_PTSA_MIN_NVD5_DEFAULT_MASK	0x7ff
+#define MC_NVD5_PTSA_RATE_0	0x4b24
+#define MC_NVD5_PTSA_RATE_0_PTSA_RATE_NVD5_DEFAULT_MASK	0xfff
+#define MC_NVD6_PTSA_MAX_0	0x4b38
+#define MC_NVD6_PTSA_MAX_0_PTSA_MAX_NVD6_DEFAULT_MASK	0x7ff
+#define MC_NVD6_PTSA_MIN_0	0x4b34
+#define MC_NVD6_PTSA_MIN_0_PTSA_MIN_NVD6_DEFAULT_MASK	0x7ff
+#define MC_NVD6_PTSA_RATE_0	0x4b30
+#define MC_NVD6_PTSA_RATE_0_PTSA_RATE_NVD6_DEFAULT_MASK	0xfff
+#define MC_NVD_PTSA_MAX_0	0x580
+#define MC_NVD_PTSA_MAX_0_PTSA_MAX_NVD_DEFAULT_MASK	0x7ff
+#define MC_NVD_PTSA_MIN_0	0x57c
+#define MC_NVD_PTSA_MIN_0_PTSA_MIN_NVD_DEFAULT_MASK	0x7ff
+#define MC_NVD_PTSA_RATE_0	0x578
+#define MC_NVD_PTSA_RATE_0_PTSA_RATE_NVD_DEFAULT_MASK	0xfff
+#define MC_PCFIFO_CLIENT_CONFIG0_0	0xdd0
+#define MC_PCFIFO_CLIENT_CONFIG1_0	0xdd4
+#define MC_PCFIFO_CLIENT_CONFIG1_0_PCFIFO_HDAW_ORDERED_CLIENT_ORDERED	1
+#define MC_PCFIFO_CLIENT_CONFIG1_0_PCFIFO_HDAW_ORDERED_CLIENT_RANGE	21:21
+#define MC_PCFIFO_CLIENT_CONFIG1_0_PCFIFO_SATAW_ORDERED_CLIENT_ORDERED	1
+#define MC_PCFIFO_CLIENT_CONFIG1_0_PCFIFO_SATAW_ORDERED_CLIENT_RANGE	29:29
+#define MC_PCFIFO_CLIENT_CONFIG2_0	0xdd8
+#define MC_PCFIFO_CLIENT_CONFIG2_0_PCFIFO_XUSB_DEVW_ORDERED_CLIENT_ORDERED	1
+#define MC_PCFIFO_CLIENT_CONFIG2_0_PCFIFO_XUSB_DEVW_ORDERED_CLIENT_RANGE	13:13
+#define MC_PCFIFO_CLIENT_CONFIG3_0	0xddc
+#define MC_PCFIFO_CLIENT_CONFIG4_0	0xde0
+#define MC_PCFIFO_CLIENT_CONFIG5_0	0xbf4
+#define MC_PCFIFO_CLIENT_CONFIG6_0	0xb90
+#define MC_PCFIFO_CLIENT_CONFIG6_0_PCFIFO_PCIE1W_ORDERED_CLIENT_ORDERED	1
+#define MC_PCFIFO_CLIENT_CONFIG6_0_PCFIFO_PCIE1W_ORDERED_CLIENT_RANGE	27:27
+#define MC_PCFIFO_CLIENT_CONFIG6_0_PCFIFO_PCIE1W_ORDERED_CLIENT_UNORDERED	0
+#define MC_PCFIFO_CLIENT_CONFIG6_0_PCFIFO_PCIE2AW_ORDERED_CLIENT_ORDERED	1
+#define MC_PCFIFO_CLIENT_CONFIG6_0_PCFIFO_PCIE2AW_ORDERED_CLIENT_RANGE	29:29
+#define MC_PCFIFO_CLIENT_CONFIG6_0_PCFIFO_PCIE2AW_ORDERED_CLIENT_UNORDERED	0
+#define MC_PCFIFO_CLIENT_CONFIG6_0_PCFIFO_PCIE3W_ORDERED_CLIENT_ORDERED	1
+#define MC_PCFIFO_CLIENT_CONFIG6_0_PCFIFO_PCIE3W_ORDERED_CLIENT_RANGE	31:31
+#define MC_PCFIFO_CLIENT_CONFIG6_0_PCFIFO_PCIE3W_ORDERED_CLIENT_UNORDERED	0
+#define MC_PCFIFO_CLIENT_CONFIG7_0	0xacc
+#define MC_PCIE0X2_PTSA_MAX_0	0x4b14
+#define MC_PCIE0X2_PTSA_MAX_0_PTSA_MAX_PCIE0X2_DEFAULT_MASK	0x7ff
+#define MC_PCIE0X2_PTSA_MIN_0	0x4b10
+#define MC_PCIE0X2_PTSA_MIN_0_PTSA_MIN_PCIE0X2_DEFAULT_MASK	0x7ff
+#define MC_PCIE0X2_PTSA_RATE_0	0x4b0c
+#define MC_PCIE0X2_PTSA_RATE_0_PTSA_RATE_PCIE0X2_DEFAULT_MASK	0xfff
+#define MC_PCIE0XA_PTSA_MAX_0	0x3508
+#define MC_PCIE0XA_PTSA_MAX_0_PTSA_MAX_PCIE0XA_DEFAULT_MASK	0x7ff
+#define MC_PCIE0XA_PTSA_MIN_0	0x3504
+#define MC_PCIE0XA_PTSA_MIN_0_PTSA_MIN_PCIE0XA_DEFAULT_MASK	0x7ff
+#define MC_PCIE0XA_PTSA_RATE_0	0x3500
+#define MC_PCIE0XA_PTSA_RATE_0_PTSA_RATE_PCIE0XA_DEFAULT_MASK	0xfff
+#define MC_PCIE0X_PTSA_MAX_0	0x3314
+#define MC_PCIE0X_PTSA_MAX_0_PTSA_MAX_PCIE0X_DEFAULT_MASK	0x7ff
+#define MC_PCIE0X_PTSA_MIN_0	0x3310
+#define MC_PCIE0X_PTSA_MIN_0_PTSA_MIN_PCIE0X_DEFAULT_MASK	0x7ff
+#define MC_PCIE0X_PTSA_RATE_0	0x330c
+#define MC_PCIE0X_PTSA_RATE_0_PTSA_RATE_PCIE0X_DEFAULT_MASK	0xfff
+#define MC_PCIE1XA_PTSA_MAX_0	0x3514
+#define MC_PCIE1XA_PTSA_MAX_0_PTSA_MAX_PCIE1XA_DEFAULT_MASK	0x7ff
+#define MC_PCIE1XA_PTSA_MIN_0	0x3510
+#define MC_PCIE1XA_PTSA_MIN_0_PTSA_MIN_PCIE1XA_DEFAULT_MASK	0x7ff
+#define MC_PCIE1XA_PTSA_RATE_0	0x350c
+#define MC_PCIE1XA_PTSA_RATE_0_PTSA_RATE_PCIE1XA_DEFAULT_MASK	0xfff
+#define MC_PCIE1X_PTSA_MAX_0	0x3320
+#define MC_PCIE1X_PTSA_MAX_0_PTSA_MAX_PCIE1X_DEFAULT_MASK	0x7ff
+#define MC_PCIE1X_PTSA_MIN_0	0x331c
+#define MC_PCIE1X_PTSA_MIN_0_PTSA_MIN_PCIE1X_DEFAULT_MASK	0x7ff
+#define MC_PCIE1X_PTSA_RATE_0	0x3318
+#define MC_PCIE1X_PTSA_RATE_0_PTSA_RATE_PCIE1X_DEFAULT_MASK	0xfff
+#define MC_PCIE4XA_PTSA_MAX_0	0x3538
+#define MC_PCIE4XA_PTSA_MAX_0_PTSA_MAX_PCIE4XA_DEFAULT_MASK	0x7ff
+#define MC_PCIE4XA_PTSA_MIN_0	0x3534
+#define MC_PCIE4XA_PTSA_MIN_0_PTSA_MIN_PCIE4XA_DEFAULT_MASK	0x7ff
+#define MC_PCIE4XA_PTSA_RATE_0	0x3530
+#define MC_PCIE4XA_PTSA_RATE_0_PTSA_RATE_PCIE4XA_DEFAULT_MASK	0xfff
+#define MC_PCIE4X_PTSA_MAX_0	0x3344
+#define MC_PCIE4X_PTSA_MAX_0_PTSA_MAX_PCIE4X_DEFAULT_MASK	0x7ff
+#define MC_PCIE4X_PTSA_MIN_0	0x3340
+#define MC_PCIE4X_PTSA_MIN_0_PTSA_MIN_PCIE4X_DEFAULT_MASK	0x7ff
+#define MC_PCIE4X_PTSA_RATE_0	0x333c
+#define MC_PCIE4X_PTSA_RATE_0_PTSA_RATE_PCIE4X_DEFAULT_MASK	0xfff
+#define MC_PCIE5X2_PTSA_MAX_0	0x3a08
+#define MC_PCIE5X2_PTSA_MAX_0_PTSA_MAX_PCIE5X2_DEFAULT_MASK	0x7ff
+#define MC_PCIE5X2_PTSA_MIN_0	0x3a04
+#define MC_PCIE5X2_PTSA_MIN_0_PTSA_MIN_PCIE5X2_DEFAULT_MASK	0x7ff
+#define MC_PCIE5X2_PTSA_RATE_0	0x3a00
+#define MC_PCIE5X2_PTSA_RATE_0_PTSA_RATE_PCIE5X2_DEFAULT_MASK	0xfff
+#define MC_PCIE5XA_PTSA_MAX_0	0x3544
+#define MC_PCIE5XA_PTSA_MAX_0_PTSA_MAX_PCIE5XA_DEFAULT_MASK	0x7ff
+#define MC_PCIE5XA_PTSA_MIN_0	0x3540
+#define MC_PCIE5XA_PTSA_MIN_0_PTSA_MIN_PCIE5XA_DEFAULT_MASK	0x7ff
+#define MC_PCIE5XA_PTSA_RATE_0	0x353c
+#define MC_PCIE5XA_PTSA_RATE_0_PTSA_RATE_PCIE5XA_DEFAULT_MASK	0xfff
+#define MC_PCIE5X_PTSA_MAX_0	0x3350
+#define MC_PCIE5X_PTSA_MAX_0_PTSA_MAX_PCIE5X_DEFAULT_MASK	0x7ff
+#define MC_PCIE5X_PTSA_MIN_0	0x334c
+#define MC_PCIE5X_PTSA_MIN_0_PTSA_MIN_PCIE5X_DEFAULT_MASK	0x7ff
+#define MC_PCIE5X_PTSA_RATE_0	0x3348
+#define MC_PCIE5X_PTSA_RATE_0_PTSA_RATE_PCIE5X_DEFAULT_MASK	0xfff
+#define MC_PTSA_MINMAX_DEFAULT_MASK 0x3f
+#define MC_PVA0XA2_PTSA_MAX_0	0x3950
+#define MC_PVA0XA2_PTSA_MAX_0_PTSA_MAX_PVA0XA2_DEFAULT_MASK	0x7ff
+#define MC_PVA0XA2_PTSA_MIN_0	0x394c
+#define MC_PVA0XA2_PTSA_MIN_0_PTSA_MIN_PVA0XA2_DEFAULT_MASK	0x7ff
+#define MC_PVA0XA2_PTSA_RATE_0	0x3948
+#define MC_PVA0XA2_PTSA_RATE_0_PTSA_RATE_PVA0XA2_DEFAULT_MASK	0xfff
+#define MC_PVA0XA3_PTSA_MAX_0	0x3550
+#define MC_PVA0XA3_PTSA_MAX_0_PTSA_MAX_PVA0XA3_DEFAULT_MASK	0x7ff
+#define MC_PVA0XA3_PTSA_MIN_0	0x354c
+#define MC_PVA0XA3_PTSA_MIN_0_PTSA_MIN_PVA0XA3_DEFAULT_MASK	0x7ff
+#define MC_PVA0XA3_PTSA_RATE_0	0x3548
+#define MC_PVA0XA3_PTSA_RATE_0_PTSA_RATE_PVA0XA3_DEFAULT_MASK	0xfff
+#define MC_PVA0XA_PTSA_MAX_0	0x3108
+#define MC_PVA0XA_PTSA_MAX_0_PTSA_MAX_PVA0XA_DEFAULT_MASK	0x7ff
+#define MC_PVA0XA_PTSA_MIN_0	0x3104
+#define MC_PVA0XA_PTSA_MIN_0_PTSA_MIN_PVA0XA_DEFAULT_MASK	0x7ff
+#define MC_PVA0XA_PTSA_RATE_0	0x3100
+#define MC_PVA0XA_PTSA_RATE_0_PTSA_RATE_PVA0XA_DEFAULT_MASK	0xfff
+#define MC_PVA0XB2_PTSA_MAX_0	0x395c
+#define MC_PVA0XB2_PTSA_MAX_0_PTSA_MAX_PVA0XB2_DEFAULT_MASK	0x7ff
+#define MC_PVA0XB2_PTSA_MIN_0	0x3958
+#define MC_PVA0XB2_PTSA_MIN_0_PTSA_MIN_PVA0XB2_DEFAULT_MASK	0x7ff
+#define MC_PVA0XB2_PTSA_RATE_0	0x3954
+#define MC_PVA0XB2_PTSA_RATE_0_PTSA_RATE_PVA0XB2_DEFAULT_MASK	0xfff
+#define MC_PVA0XB3_PTSA_MAX_0	0x3568
+#define MC_PVA0XB3_PTSA_MAX_0_PTSA_MAX_PVA0XB3_DEFAULT_MASK	0x7ff
+#define MC_PVA0XB3_PTSA_MIN_0	0x3564
+#define MC_PVA0XB3_PTSA_MIN_0_PTSA_MIN_PVA0XB3_DEFAULT_MASK	0x7ff
+#define MC_PVA0XB3_PTSA_RATE_0	0x3560
+#define MC_PVA0XB3_PTSA_RATE_0_PTSA_RATE_PVA0XB3_DEFAULT_MASK	0xfff
+#define MC_PVA0XB_PTSA_MAX_0	0x355c
+#define MC_PVA0XB_PTSA_MAX_0_PTSA_MAX_PVA0XB_DEFAULT_MASK	0x7ff
+#define MC_PVA0XB_PTSA_MIN_0	0x3558
+#define MC_PVA0XB_PTSA_MIN_0_PTSA_MIN_PVA0XB_DEFAULT_MASK	0x7ff
+#define MC_PVA0XB_PTSA_RATE_0	0x3554
+#define MC_PVA0XB_PTSA_RATE_0_PTSA_RATE_PVA0XB_DEFAULT_MASK	0xfff
+#define MC_PVA0XC_PTSA_MAX_0	0x3574
+#define MC_PVA0XC_PTSA_MAX_0_PTSA_MAX_PVA0XC_DEFAULT_MASK	0x7ff
+#define MC_PVA0XC_PTSA_MIN_0	0x3570
+#define MC_PVA0XC_PTSA_MIN_0_PTSA_MIN_PVA0XC_DEFAULT_MASK	0x7ff
+#define MC_PVA0XC_PTSA_RATE_0	0x356c
+#define MC_PVA0XC_PTSA_RATE_0_PTSA_RATE_PVA0XC_DEFAULT_MASK	0xfff
+#define MC_PVA1XA2_PTSA_MAX_0	0x3968
+#define MC_PVA1XA2_PTSA_MAX_0_PTSA_MAX_PVA1XA2_DEFAULT_MASK	0x7ff
+#define MC_PVA1XA2_PTSA_MIN_0	0x3964
+#define MC_PVA1XA2_PTSA_MIN_0_PTSA_MIN_PVA1XA2_DEFAULT_MASK	0x7ff
+#define MC_PVA1XA2_PTSA_RATE_0	0x3960
+#define MC_PVA1XA2_PTSA_RATE_0_PTSA_RATE_PVA1XA2_DEFAULT_MASK	0xfff
+#define MC_PVA1XA3_PTSA_MAX_0	0x3908
+#define MC_PVA1XA3_PTSA_MAX_0_PTSA_MAX_PVA1XA3_DEFAULT_MASK	0x7ff
+#define MC_PVA1XA3_PTSA_MIN_0	0x3904
+#define MC_PVA1XA3_PTSA_MIN_0_PTSA_MIN_PVA1XA3_DEFAULT_MASK	0x7ff
+#define MC_PVA1XA3_PTSA_RATE_0	0x3900
+#define MC_PVA1XA3_PTSA_RATE_0_PTSA_RATE_PVA1XA3_DEFAULT_MASK	0xfff
+#define MC_PVA1XA_PTSA_MAX_0	0x3114
+#define MC_PVA1XA_PTSA_MAX_0_PTSA_MAX_PVA1XA_DEFAULT_MASK	0x7ff
+#define MC_PVA1XA_PTSA_MIN_0	0x3110
+#define MC_PVA1XA_PTSA_MIN_0_PTSA_MIN_PVA1XA_DEFAULT_MASK	0x7ff
+#define MC_PVA1XA_PTSA_RATE_0	0x310c
+#define MC_PVA1XA_PTSA_RATE_0_PTSA_RATE_PVA1XA_DEFAULT_MASK	0xfff
+#define MC_PVA1XB2_PTSA_MAX_0	0x3974
+#define MC_PVA1XB2_PTSA_MAX_0_PTSA_MAX_PVA1XB2_DEFAULT_MASK	0x7ff
+#define MC_PVA1XB2_PTSA_MIN_0	0x3970
+#define MC_PVA1XB2_PTSA_MIN_0_PTSA_MIN_PVA1XB2_DEFAULT_MASK	0x7ff
+#define MC_PVA1XB2_PTSA_RATE_0	0x396c
+#define MC_PVA1XB2_PTSA_RATE_0_PTSA_RATE_PVA1XB2_DEFAULT_MASK	0xfff
+#define MC_PVA1XB3_PTSA_MAX_0	0x3920
+#define MC_PVA1XB3_PTSA_MAX_0_PTSA_MAX_PVA1XB3_DEFAULT_MASK	0x7ff
+#define MC_PVA1XB3_PTSA_MIN_0	0x391c
+#define MC_PVA1XB3_PTSA_MIN_0_PTSA_MIN_PVA1XB3_DEFAULT_MASK	0x7ff
+#define MC_PVA1XB3_PTSA_RATE_0	0x3918
+#define MC_PVA1XB3_PTSA_RATE_0_PTSA_RATE_PVA1XB3_DEFAULT_MASK	0xfff
+#define MC_PVA1XB_PTSA_MAX_0	0x3914
+#define MC_PVA1XB_PTSA_MAX_0_PTSA_MAX_PVA1XB_DEFAULT_MASK	0x7ff
+#define MC_PVA1XB_PTSA_MIN_0	0x3910
+#define MC_PVA1XB_PTSA_MIN_0_PTSA_MIN_PVA1XB_DEFAULT_MASK	0x7ff
+#define MC_PVA1XB_PTSA_RATE_0	0x390c
+#define MC_PVA1XB_PTSA_RATE_0_PTSA_RATE_PVA1XB_DEFAULT_MASK	0xfff
+#define MC_PVA1XC_PTSA_MAX_0	0x392c
+#define MC_PVA1XC_PTSA_MAX_0_PTSA_MAX_PVA1XC_DEFAULT_MASK	0x7ff
+#define MC_PVA1XC_PTSA_MIN_0	0x3928
+#define MC_PVA1XC_PTSA_MIN_0_PTSA_MIN_PVA1XC_DEFAULT_MASK	0x7ff
+#define MC_PVA1XC_PTSA_RATE_0	0x3924
+#define MC_PVA1XC_PTSA_RATE_0_PTSA_RATE_PVA1XC_DEFAULT_MASK	0xfff
+#define MC_RCEPC_PTSA_MAX_0	0x3120
+#define MC_RCEPC_PTSA_MAX_0_PTSA_MAX_RCEPC_DEFAULT_MASK	0x7ff
+#define MC_RCEPC_PTSA_MIN_0	0x311c
+#define MC_RCEPC_PTSA_MIN_0_PTSA_MIN_RCEPC_DEFAULT_MASK	0x7ff
+#define MC_RCEPC_PTSA_RATE_0	0x3118
+#define MC_RCEPC_PTSA_RATE_0_PTSA_RATE_RCEPC_DEFAULT_MASK	0xfff
+#define MC_RING1_PTSA_RATE_0_PTSA_RATE_RING1_DEFAULT_MASK	0xfff
+#define MC_RING1_RD_B_PTSA_RATE_0_PTSA_RATE_RING1_RD_B_DEFAULT_MASK	0xfff
+#define MC_RING1_RD_NB_PTSA_RATE_0_PTSA_RATE_RING1_RD_NB_DEFAULT_MASK	0xfff
+#define MC_RING1_WR_B_PTSA_RATE_0_PTSA_RATE_RING1_WR_B_DEFAULT_MASK	0xfff
+#define MC_RING1_WR_NB_PTSA_RATE_0_PTSA_RATE_RING1_WR_NB_DEFAULT_MASK	0xfff
+#define MC_RING2_PTSA_MAX_0	0x448
+#define MC_RING2_PTSA_MAX_0_PTSA_MAX_RING2_DEFAULT_MASK	0x7ff
+#define MC_RING2_PTSA_MIN_0	0x444
+#define MC_RING2_PTSA_MIN_0_PTSA_MIN_RING2_DEFAULT_MASK	0x7ff
+#define MC_RING2_PTSA_RATE_0	0x440
+#define MC_RING2_PTSA_RATE_0_PTSA_RATE_RING2_DEFAULT_MASK	0xfff
+#define MC_ROC_DMA_R_PTSA_RATE_0_PTSA_RATE_ROC_DMA_R_DEFAULT_MASK	0xfff
+#define MC_SAX_PTSA_MAX_0	0x4c0
+#define MC_SAX_PTSA_MAX_0_PTSA_MAX_SAX_DEFAULT_MASK	0x7ff
+#define MC_SAX_PTSA_MIN_0	0x4bc
+#define MC_SAX_PTSA_MIN_0_PTSA_MIN_SAX_DEFAULT_MASK	0x7ff
+#define MC_SAX_PTSA_RATE_0	0x4b8
+#define MC_SAX_PTSA_RATE_0_PTSA_RATE_SAX_DEFAULT_MASK	0xfff
+#define MC_SCEPC_PTSA_MAX_0	0x794
+#define MC_SCEPC_PTSA_MAX_0_PTSA_MAX_SCEPC_DEFAULT_MASK	0x7ff
+#define MC_SCEPC_PTSA_MIN_0	0x790
+#define MC_SCEPC_PTSA_MIN_0_PTSA_MIN_SCEPC_DEFAULT_MASK	0x7ff
+#define MC_SCEPC_PTSA_RATE_0	0x78c
+#define MC_SCEPC_PTSA_RATE_0_PTSA_RATE_SCEPC_DEFAULT_MASK	0xfff
+#define MC_SDM_PTSA_MAX_0	0x624
+#define MC_SDM_PTSA_MAX_0_PTSA_MAX_SDM_DEFAULT_MASK	0x7ff
+#define MC_SDM_PTSA_MIN_0	0x620
+#define MC_SDM_PTSA_MIN_0_PTSA_MIN_SDM_DEFAULT_MASK	0x7ff
+#define MC_SDM_PTSA_RATE_0	0x61c
+#define MC_SDM_PTSA_RATE_0_PTSA_RATE_SDM_DEFAULT_MASK	0xfff
+#define MC_SD_PTSA_MAX_0	0x4d8
+#define MC_SD_PTSA_MAX_0_PTSA_MAX_SD_DEFAULT_MASK	0x7ff
+#define MC_SD_PTSA_MIN_0	0x4d4
+#define MC_SD_PTSA_MIN_0_PTSA_MIN_SD_DEFAULT_MASK	0x7ff
+#define MC_SD_PTSA_RATE_0	0x4d0
+#define MC_SD_PTSA_RATE_0_PTSA_RATE_SD_DEFAULT_MASK	0xfff
+#define MC_SMMU_SMMU_PTSA_MAX_0	0x460
+#define MC_SMMU_SMMU_PTSA_MAX_0_PTSA_MAX_SMMU_SMMU_DEFAULT_MASK	0x7ff
+#define MC_SMMU_SMMU_PTSA_MIN_0	0x45c
+#define MC_SMMU_SMMU_PTSA_MIN_0_PTSA_MIN_SMMU_SMMU_DEFAULT_MASK	0x7ff
+#define MC_SMMU_SMMU_PTSA_RATE_0	0x458
+#define MC_SMMU_SMMU_PTSA_RATE_0_PTSA_RATE_SMMU_SMMU_DEFAULT_MASK	0xfff
+#define MC_TBU_CLIENT_STEERING_CONFIG_AONDMAR_0	0x14cc
+#define MC_TBU_CLIENT_STEERING_CONFIG_AONDMAW_0	0x14d4
+#define MC_TBU_CLIENT_STEERING_CONFIG_AONR_0	0x14bc
+#define MC_TBU_CLIENT_STEERING_CONFIG_AONW_0	0x14c4
+#define MC_TBU_CLIENT_STEERING_CONFIG_APEDMAR_0	0x14fc
+#define MC_TBU_CLIENT_STEERING_CONFIG_APEDMAW_0	0x1504
+#define MC_TBU_CLIENT_STEERING_CONFIG_APER_0	0x13d4
+#define MC_TBU_CLIENT_STEERING_CONFIG_APEW_0	0x13dc
+#define MC_TBU_CLIENT_STEERING_CONFIG_AXIAPR_0	0x1414
+#define MC_TBU_CLIENT_STEERING_CONFIG_AXIAPW_0	0x141c
+#define MC_TBU_CLIENT_STEERING_CONFIG_AXISR_0	0x1464
+#define MC_TBU_CLIENT_STEERING_CONFIG_AXISW_0	0x146c
+#define MC_TBU_CLIENT_STEERING_CONFIG_BPMPDMAR_0	0x14ac
+#define MC_TBU_CLIENT_STEERING_CONFIG_BPMPDMAW_0	0x14b4
+#define MC_TBU_CLIENT_STEERING_CONFIG_BPMPR_0	0x149c
+#define MC_TBU_CLIENT_STEERING_CONFIG_BPMPW_0	0x14a4
+#define MC_TBU_CLIENT_STEERING_CONFIG_DLA0FALRDB_0	0x1600
+#define MC_TBU_CLIENT_STEERING_CONFIG_DLA0FALWRB_0	0x1610
+#define MC_TBU_CLIENT_STEERING_CONFIG_DLA0RDA1_0	0x1750
+#define MC_TBU_CLIENT_STEERING_CONFIG_DLA0RDA_0	0x15f8
+#define MC_TBU_CLIENT_STEERING_CONFIG_DLA0WRA_0	0x1608
+#define MC_TBU_CLIENT_STEERING_CONFIG_DLA1FALRDB_0	0x1620
+#define MC_TBU_CLIENT_STEERING_CONFIG_DLA1FALWRB_0	0x1630
+#define MC_TBU_CLIENT_STEERING_CONFIG_DLA1RDA1_0	0x1758
+#define MC_TBU_CLIENT_STEERING_CONFIG_DLA1RDA_0	0x1618
+#define MC_TBU_CLIENT_STEERING_CONFIG_DLA1WRA_0	0x1628
+#define MC_TBU_CLIENT_STEERING_CONFIG_EQOSR_0	0x1474
+#define MC_TBU_CLIENT_STEERING_CONFIG_EQOSW_0	0x147c
+#define MC_TBU_CLIENT_STEERING_CONFIG_ETRR_0	0x1424
+#define MC_TBU_CLIENT_STEERING_CONFIG_ETRW_0	0x142c
+#define MC_TBU_CLIENT_STEERING_CONFIG_HDAR_0	0x10ac
+#define MC_TBU_CLIENT_STEERING_CONFIG_HDAW_0	0x11ac
+#define MC_TBU_CLIENT_STEERING_CONFIG_HOST1XDMAR_0	0x10b4
+#define MC_TBU_CLIENT_STEERING_CONFIG_ISPFALR_0	0x122c
+#define MC_TBU_CLIENT_STEERING_CONFIG_ISPFALW_0	0x1728
+#define MC_TBU_CLIENT_STEERING_CONFIG_ISPRA1_0	0x1798
+#define MC_TBU_CLIENT_STEERING_CONFIG_ISPRA_0	0x1224
+#define MC_TBU_CLIENT_STEERING_CONFIG_ISPWA_0	0x1234
+#define MC_TBU_CLIENT_STEERING_CONFIG_ISPWB_0	0x123c
+#define MC_TBU_CLIENT_STEERING_CONFIG_MIU0R_0	0x1534
+#define MC_TBU_CLIENT_STEERING_CONFIG_MIU0W_0	0x153c
+#define MC_TBU_CLIENT_STEERING_CONFIG_MIU1R_0	0x1544
+#define MC_TBU_CLIENT_STEERING_CONFIG_MIU1W_0	0x154c
+#define MC_TBU_CLIENT_STEERING_CONFIG_MIU2R_0	0x1574
+#define MC_TBU_CLIENT_STEERING_CONFIG_MIU2W_0	0x157c
+#define MC_TBU_CLIENT_STEERING_CONFIG_MIU3R_0	0x1584
+#define MC_TBU_CLIENT_STEERING_CONFIG_MIU3W_0	0x1590
+#define MC_TBU_CLIENT_STEERING_CONFIG_MIU4R_0	0x1598
+#define MC_TBU_CLIENT_STEERING_CONFIG_MIU4W_0	0x15a0
+#define MC_TBU_CLIENT_STEERING_CONFIG_MIU5R_0	0x17e8
+#define MC_TBU_CLIENT_STEERING_CONFIG_MIU5W_0	0x17f0
+#define MC_TBU_CLIENT_STEERING_CONFIG_MIU6R_0	0x17f8
+#define MC_TBU_CLIENT_STEERING_CONFIG_MIU6W_0	0x4c00
+#define MC_TBU_CLIENT_STEERING_CONFIG_MIU7R_0	0x100c
+#define MC_TBU_CLIENT_STEERING_CONFIG_MIU7W_0	0x1014
+#define MC_TBU_CLIENT_STEERING_CONFIG_MPCORER_0	0x113c
+#define MC_TBU_CLIENT_STEERING_CONFIG_MPCOREW_0	0x11cc
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVDEC1SRD1_0	0x17d8
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVDEC1SRD_0	0x17d0
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVDEC1SWR_0	0x17e0
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVDECSRD1_0	0x151c
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVDECSRD_0	0x13c4
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVDECSWR_0	0x13cc
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVDISPLAYR1_0	0x150c
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVDISPLAYR_0	0x1494
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVENC1SRD1_0	0x1790
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVENC1SRD_0	0x16b8
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVENC1SWR_0	0x16c0
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVENCSRD1_0	0x1788
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVENCSRD_0	0x10e4
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVENCSWR_0	0x115c
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVJPGSRD_0	0x13f4
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVJPGSWR_0	0x13fc
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE0R1_0	0x17a0
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE0R_0	0x16c8
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE0W_0	0x16d0
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE0W_0_PCIE0W_NORMAL_TBUID_OVERRIDE_RANGE	0:0
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE0W_0_PCIE0W_NORMAL_TBUID_RANGE	5:4
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE0W_0_PCIE0W_SO_DEV_TBUID_RANGE	9:8
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE1R_0	0x16d8
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE1W_0	0x16e0
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE1W_0_PCIE1W_NORMAL_TBUID_OVERRIDE_RANGE	0:0
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE1W_0_PCIE1W_NORMAL_TBUID_RANGE	5:4
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE1W_0_PCIE1W_SO_DEV_TBUID_RANGE	9:8
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE2AR_0	0x16e8
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE2AW_0	0x16f0
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE2AW_0_PCIE2AW_NORMAL_TBUID_OVERRIDE_RANGE	0:0
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE2AW_0_PCIE2AW_NORMAL_TBUID_RANGE	5:4
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE2AW_0_PCIE2AW_SO_DEV_TBUID_RANGE	9:8
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE3R_0	0x16f8
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE3W_0	0x1700
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE3W_0_PCIE3W_NORMAL_TBUID_OVERRIDE_RANGE	0:0
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE3W_0_PCIE3W_NORMAL_TBUID_RANGE	5:4
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE3W_0_PCIE3W_SO_DEV_TBUID_RANGE	9:8
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE4R_0	0x1708
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE4W_0	0x1710
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE4W_0_PCIE4W_NORMAL_TBUID_OVERRIDE_RANGE	0:0
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE4W_0_PCIE4W_NORMAL_TBUID_RANGE	5:4
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE4W_0_PCIE4W_SO_DEV_TBUID_RANGE	9:8
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE5R1_0	0x1780
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE5R_0	0x1718
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE5W_0	0x1720
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE5W_0_PCIE5W_NORMAL_TBUID_OVERRIDE_RANGE	0:0
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE5W_0_PCIE5W_NORMAL_TBUID_RANGE	5:4
+#define MC_TBU_CLIENT_STEERING_CONFIG_PCIE5W_0_PCIE5W_SO_DEV_TBUID_RANGE	9:8
+#define MC_TBU_CLIENT_STEERING_CONFIG_PTCR_0	0x1004
+#define MC_TBU_CLIENT_STEERING_CONFIG_PVA0RDA1_0	0x1760
+#define MC_TBU_CLIENT_STEERING_CONFIG_PVA0RDA_0	0x1638
+#define MC_TBU_CLIENT_STEERING_CONFIG_PVA0RDB1_0	0x1768
+#define MC_TBU_CLIENT_STEERING_CONFIG_PVA0RDB_0	0x1640
+#define MC_TBU_CLIENT_STEERING_CONFIG_PVA0RDC_0	0x1648
+#define MC_TBU_CLIENT_STEERING_CONFIG_PVA0WRA_0	0x1650
+#define MC_TBU_CLIENT_STEERING_CONFIG_PVA0WRB_0	0x1658
+#define MC_TBU_CLIENT_STEERING_CONFIG_PVA0WRC_0	0x1660
+#define MC_TBU_CLIENT_STEERING_CONFIG_PVA1RDA1_0	0x1770
+#define MC_TBU_CLIENT_STEERING_CONFIG_PVA1RDA_0	0x1668
+#define MC_TBU_CLIENT_STEERING_CONFIG_PVA1RDB1_0	0x1778
+#define MC_TBU_CLIENT_STEERING_CONFIG_PVA1RDB_0	0x1670
+#define MC_TBU_CLIENT_STEERING_CONFIG_PVA1RDC_0	0x1678
+#define MC_TBU_CLIENT_STEERING_CONFIG_PVA1WRA_0	0x1680
+#define MC_TBU_CLIENT_STEERING_CONFIG_PVA1WRB_0	0x1688
+#define MC_TBU_CLIENT_STEERING_CONFIG_PVA1WRC_0	0x1690
+#define MC_TBU_CLIENT_STEERING_CONFIG_RCEDMAR_0	0x16a8
+#define MC_TBU_CLIENT_STEERING_CONFIG_RCEDMAW_0	0x16b0
+#define MC_TBU_CLIENT_STEERING_CONFIG_RCER_0	0x1698
+#define MC_TBU_CLIENT_STEERING_CONFIG_RCEW_0	0x16a0
+#define MC_TBU_CLIENT_STEERING_CONFIG_SATAR_0	0x10fc
+#define MC_TBU_CLIENT_STEERING_CONFIG_SATAW_0	0x11ec
+#define MC_TBU_CLIENT_STEERING_CONFIG_SATAW_0_SATAW_NORMAL_TBUID_OVERRIDE_RANGE	0:0
+#define MC_TBU_CLIENT_STEERING_CONFIG_SATAW_0_SATAW_NORMAL_TBUID_RANGE	5:4
+#define MC_TBU_CLIENT_STEERING_CONFIG_SATAW_0_SATAW_SO_DEV_TBUID_RANGE	9:8
+#define MC_TBU_CLIENT_STEERING_CONFIG_SCEDMAR_0	0x14ec
+#define MC_TBU_CLIENT_STEERING_CONFIG_SCEDMAW_0	0x14f4
+#define MC_TBU_CLIENT_STEERING_CONFIG_SCER_0	0x14dc
+#define MC_TBU_CLIENT_STEERING_CONFIG_SCEW_0	0x14e4
+#define MC_TBU_CLIENT_STEERING_CONFIG_SDMMCRAB_0	0x131c
+#define MC_TBU_CLIENT_STEERING_CONFIG_SDMMCRA_0	0x1304
+#define MC_TBU_CLIENT_STEERING_CONFIG_SDMMCR_0	0x1314
+#define MC_TBU_CLIENT_STEERING_CONFIG_SDMMCWAB_0	0x133c
+#define MC_TBU_CLIENT_STEERING_CONFIG_SDMMCWA_0	0x1324
+#define MC_TBU_CLIENT_STEERING_CONFIG_SDMMCW_0	0x1334
+#define MC_TBU_CLIENT_STEERING_CONFIG_SESRD_0	0x1404
+#define MC_TBU_CLIENT_STEERING_CONFIG_SESWR_0	0x140c
+#define MC_TBU_CLIENT_STEERING_CONFIG_TSECSRDB_0	0x1434
+#define MC_TBU_CLIENT_STEERING_CONFIG_TSECSRD_0	0x12a4
+#define MC_TBU_CLIENT_STEERING_CONFIG_TSECSWRB_0	0x143c
+#define MC_TBU_CLIENT_STEERING_CONFIG_TSECSWR_0	0x12ac
+#define MC_TBU_CLIENT_STEERING_CONFIG_UFSHCR_0	0x1484
+#define MC_TBU_CLIENT_STEERING_CONFIG_UFSHCW_0	0x148c
+#define MC_TBU_CLIENT_STEERING_CONFIG_VICSRD1_0	0x1514
+#define MC_TBU_CLIENT_STEERING_CONFIG_VICSRD_0	0x1364
+#define MC_TBU_CLIENT_STEERING_CONFIG_VICSWR_0	0x136c
+#define MC_TBU_CLIENT_STEERING_CONFIG_VIFALR_0	0x15e8
+#define MC_TBU_CLIENT_STEERING_CONFIG_VIFALW_0	0x15f0
+#define MC_TBU_CLIENT_STEERING_CONFIG_VIW_0	0x1394
+#define MC_TBU_CLIENT_STEERING_CONFIG_XUSB_DEVR_0	0x1264
+#define MC_TBU_CLIENT_STEERING_CONFIG_XUSB_DEVW_0	0x126c
+#define MC_TBU_CLIENT_STEERING_CONFIG_XUSB_DEVW_0_XUSB_DEVW_NORMAL_TBUID_OVERRIDE_RANGE	0:0
+#define MC_TBU_CLIENT_STEERING_CONFIG_XUSB_DEVW_0_XUSB_DEVW_NORMAL_TBUID_RANGE	5:4
+#define MC_TBU_CLIENT_STEERING_CONFIG_XUSB_DEVW_0_XUSB_DEVW_SO_DEV_TBUID_RANGE	9:8
+#define MC_TBU_CLIENT_STEERING_CONFIG_XUSB_HOSTR_0	0x1254
+#define MC_TBU_CLIENT_STEERING_CONFIG_XUSB_HOSTW_0	0x125c
+#define MC_TBU_CLIENT_STEERING_CONFIG_XUSB_HOSTW_0_XUSB_HOSTW_NORMAL_TBUID_OVERRIDE_RANGE	0:0
+#define MC_TBU_CLIENT_STEERING_CONFIG_XUSB_HOSTW_0_XUSB_HOSTW_NORMAL_TBUID_RANGE	5:4
+#define MC_TBU_CLIENT_STEERING_CONFIG_XUSB_HOSTW_0_XUSB_HOSTW_SO_DEV_TBUID_RANGE	9:8
+#define MC_TIMING_CONTROL_0	0xfc
+#define MC_TXN_OVERRIDE_CONFIG_AONDMAR_0	0x14c8
+#define MC_TXN_OVERRIDE_CONFIG_AONDMAW_0	0x14d0
+#define MC_TXN_OVERRIDE_CONFIG_AONR_0	0x14b8
+#define MC_TXN_OVERRIDE_CONFIG_AONW_0	0x14c0
+#define MC_TXN_OVERRIDE_CONFIG_APEDMAR_0	0x14f8
+#define MC_TXN_OVERRIDE_CONFIG_APEDMAW_0	0x1500
+#define MC_TXN_OVERRIDE_CONFIG_APER_0	0x13d0
+#define MC_TXN_OVERRIDE_CONFIG_APEW_0	0x13d8
+#define MC_TXN_OVERRIDE_CONFIG_AXIAPR_0	0x1410
+#define MC_TXN_OVERRIDE_CONFIG_AXIAPW_0	0x1418
+#define MC_TXN_OVERRIDE_CONFIG_AXISR_0	0x1460
+#define MC_TXN_OVERRIDE_CONFIG_AXISW_0	0x1468
+#define MC_TXN_OVERRIDE_CONFIG_BPMPDMAR_0	0x14a8
+#define MC_TXN_OVERRIDE_CONFIG_BPMPDMAW_0	0x14b0
+#define MC_TXN_OVERRIDE_CONFIG_BPMPR_0	0x1498
+#define MC_TXN_OVERRIDE_CONFIG_BPMPW_0	0x14a0
+#define MC_TXN_OVERRIDE_CONFIG_DLA0FALRDB_0	0x15fc
+#define MC_TXN_OVERRIDE_CONFIG_DLA0FALWRB_0	0x160c
+#define MC_TXN_OVERRIDE_CONFIG_DLA0RDA1_0	0x174c
+#define MC_TXN_OVERRIDE_CONFIG_DLA0RDA_0	0x15f4
+#define MC_TXN_OVERRIDE_CONFIG_DLA0WRA_0	0x1604
+#define MC_TXN_OVERRIDE_CONFIG_DLA1FALRDB_0	0x161c
+#define MC_TXN_OVERRIDE_CONFIG_DLA1FALWRB_0	0x162c
+#define MC_TXN_OVERRIDE_CONFIG_DLA1RDA1_0	0x1754
+#define MC_TXN_OVERRIDE_CONFIG_DLA1RDA_0	0x1614
+#define MC_TXN_OVERRIDE_CONFIG_DLA1WRA_0	0x1624
+#define MC_TXN_OVERRIDE_CONFIG_EQOSR_0	0x1470
+#define MC_TXN_OVERRIDE_CONFIG_EQOSW_0	0x1478
+#define MC_TXN_OVERRIDE_CONFIG_ETRR_0	0x1420
+#define MC_TXN_OVERRIDE_CONFIG_ETRW_0	0x1428
+#define MC_TXN_OVERRIDE_CONFIG_HDAR_0	0x10a8
+#define MC_TXN_OVERRIDE_CONFIG_HDAW_0	0x11a8
+#define MC_TXN_OVERRIDE_CONFIG_HOST1XDMAR_0	0x10b0
+#define MC_TXN_OVERRIDE_CONFIG_ISPFALR_0	0x1228
+#define MC_TXN_OVERRIDE_CONFIG_ISPFALW_0	0x1724
+#define MC_TXN_OVERRIDE_CONFIG_ISPRA1_0	0x1794
+#define MC_TXN_OVERRIDE_CONFIG_ISPRA_0	0x1220
+#define MC_TXN_OVERRIDE_CONFIG_ISPWA_0	0x1230
+#define MC_TXN_OVERRIDE_CONFIG_ISPWB_0	0x1238
+#define MC_TXN_OVERRIDE_CONFIG_MIU0R_0	0x1530
+#define MC_TXN_OVERRIDE_CONFIG_MIU0W_0	0x1538
+#define MC_TXN_OVERRIDE_CONFIG_MIU1R_0	0x1540
+#define MC_TXN_OVERRIDE_CONFIG_MIU1W_0	0x1548
+#define MC_TXN_OVERRIDE_CONFIG_MIU2R_0	0x1570
+#define MC_TXN_OVERRIDE_CONFIG_MIU2W_0	0x1578
+#define MC_TXN_OVERRIDE_CONFIG_MIU3R_0	0x1580
+#define MC_TXN_OVERRIDE_CONFIG_MIU3W_0	0x158c
+#define MC_TXN_OVERRIDE_CONFIG_MIU4R_0	0x1594
+#define MC_TXN_OVERRIDE_CONFIG_MIU4W_0	0x159c
+#define MC_TXN_OVERRIDE_CONFIG_MIU5R_0	0x17e4
+#define MC_TXN_OVERRIDE_CONFIG_MIU5W_0	0x17ec
+#define MC_TXN_OVERRIDE_CONFIG_MIU6R_0	0x17f4
+#define MC_TXN_OVERRIDE_CONFIG_MIU6W_0	0x17fc
+#define MC_TXN_OVERRIDE_CONFIG_MIU7R_0	0x1008
+#define MC_TXN_OVERRIDE_CONFIG_MIU7W_0	0x1010
+#define MC_TXN_OVERRIDE_CONFIG_MPCORER_0	0x1138
+#define MC_TXN_OVERRIDE_CONFIG_MPCOREW_0	0x11c8
+#define MC_TXN_OVERRIDE_CONFIG_NVDEC1SRD1_0	0x17d4
+#define MC_TXN_OVERRIDE_CONFIG_NVDEC1SRD_0	0x17cc
+#define MC_TXN_OVERRIDE_CONFIG_NVDEC1SWR_0	0x17dc
+#define MC_TXN_OVERRIDE_CONFIG_NVDECSRD1_0	0x1518
+#define MC_TXN_OVERRIDE_CONFIG_NVDECSRD_0	0x13c0
+#define MC_TXN_OVERRIDE_CONFIG_NVDECSWR_0	0x13c8
+#define MC_TXN_OVERRIDE_CONFIG_NVDISPLAYR1_0	0x1508
+#define MC_TXN_OVERRIDE_CONFIG_NVDISPLAYR_0	0x1490
+#define MC_TXN_OVERRIDE_CONFIG_NVENC1SRD1_0	0x178c
+#define MC_TXN_OVERRIDE_CONFIG_NVENC1SRD_0	0x16b4
+#define MC_TXN_OVERRIDE_CONFIG_NVENC1SWR_0	0x16bc
+#define MC_TXN_OVERRIDE_CONFIG_NVENCSRD1_0	0x1784
+#define MC_TXN_OVERRIDE_CONFIG_NVENCSRD_0	0x10e0
+#define MC_TXN_OVERRIDE_CONFIG_NVENCSWR_0	0x1158
+#define MC_TXN_OVERRIDE_CONFIG_NVJPGSRD_0	0x13f0
+#define MC_TXN_OVERRIDE_CONFIG_NVJPGSWR_0	0x13f8
+#define MC_TXN_OVERRIDE_CONFIG_PCIE0R1_0	0x179c
+#define MC_TXN_OVERRIDE_CONFIG_PCIE0R_0	0x16c4
+#define MC_TXN_OVERRIDE_CONFIG_PCIE0W_0	0x16cc
+#define MC_TXN_OVERRIDE_CONFIG_PCIE1R_0	0x16d4
+#define MC_TXN_OVERRIDE_CONFIG_PCIE1W_0	0x16dc
+#define MC_TXN_OVERRIDE_CONFIG_PCIE2AR_0	0x16e4
+#define MC_TXN_OVERRIDE_CONFIG_PCIE2AW_0	0x16ec
+#define MC_TXN_OVERRIDE_CONFIG_PCIE3R_0	0x16f4
+#define MC_TXN_OVERRIDE_CONFIG_PCIE3W_0	0x16fc
+#define MC_TXN_OVERRIDE_CONFIG_PCIE4R_0	0x1704
+#define MC_TXN_OVERRIDE_CONFIG_PCIE4W_0	0x170c
+#define MC_TXN_OVERRIDE_CONFIG_PCIE5R1_0	0x177c
+#define MC_TXN_OVERRIDE_CONFIG_PCIE5R_0	0x1714
+#define MC_TXN_OVERRIDE_CONFIG_PCIE5W_0	0x171c
+#define MC_TXN_OVERRIDE_CONFIG_PTCR_0	0x1000
+#define MC_TXN_OVERRIDE_CONFIG_PVA0RDA1_0	0x175c
+#define MC_TXN_OVERRIDE_CONFIG_PVA0RDA_0	0x1634
+#define MC_TXN_OVERRIDE_CONFIG_PVA0RDB1_0	0x1764
+#define MC_TXN_OVERRIDE_CONFIG_PVA0RDB_0	0x163c
+#define MC_TXN_OVERRIDE_CONFIG_PVA0RDC_0	0x1644
+#define MC_TXN_OVERRIDE_CONFIG_PVA0WRA_0	0x164c
+#define MC_TXN_OVERRIDE_CONFIG_PVA0WRB_0	0x1654
+#define MC_TXN_OVERRIDE_CONFIG_PVA0WRC_0	0x165c
+#define MC_TXN_OVERRIDE_CONFIG_PVA1RDA1_0	0x176c
+#define MC_TXN_OVERRIDE_CONFIG_PVA1RDA_0	0x1664
+#define MC_TXN_OVERRIDE_CONFIG_PVA1RDB1_0	0x1774
+#define MC_TXN_OVERRIDE_CONFIG_PVA1RDB_0	0x166c
+#define MC_TXN_OVERRIDE_CONFIG_PVA1RDC_0	0x1674
+#define MC_TXN_OVERRIDE_CONFIG_PVA1WRA_0	0x167c
+#define MC_TXN_OVERRIDE_CONFIG_PVA1WRB_0	0x1684
+#define MC_TXN_OVERRIDE_CONFIG_PVA1WRC_0	0x168c
+#define MC_TXN_OVERRIDE_CONFIG_RCEDMAR_0	0x16a4
+#define MC_TXN_OVERRIDE_CONFIG_RCEDMAW_0	0x16ac
+#define MC_TXN_OVERRIDE_CONFIG_RCER_0	0x1694
+#define MC_TXN_OVERRIDE_CONFIG_RCEW_0	0x169c
+#define MC_TXN_OVERRIDE_CONFIG_SATAR_0	0x10f8
+#define MC_TXN_OVERRIDE_CONFIG_SATAW_0	0x11e8
+#define MC_TXN_OVERRIDE_CONFIG_SCEDMAR_0	0x14e8
+#define MC_TXN_OVERRIDE_CONFIG_SCEDMAW_0	0x14f0
+#define MC_TXN_OVERRIDE_CONFIG_SCER_0	0x14d8
+#define MC_TXN_OVERRIDE_CONFIG_SCEW_0	0x14e0
+#define MC_TXN_OVERRIDE_CONFIG_SDMMCRAB_0	0x1318
+#define MC_TXN_OVERRIDE_CONFIG_SDMMCRA_0	0x1300
+#define MC_TXN_OVERRIDE_CONFIG_SDMMCR_0	0x1310
+#define MC_TXN_OVERRIDE_CONFIG_SDMMCWAB_0	0x1338
+#define MC_TXN_OVERRIDE_CONFIG_SDMMCWA_0	0x1320
+#define MC_TXN_OVERRIDE_CONFIG_SDMMCW_0	0x1330
+#define MC_TXN_OVERRIDE_CONFIG_SESRD_0	0x1400
+#define MC_TXN_OVERRIDE_CONFIG_SESWR_0	0x1408
+#define MC_TXN_OVERRIDE_CONFIG_TSECSRDB_0	0x1430
+#define MC_TXN_OVERRIDE_CONFIG_TSECSRD_0	0x12a0
+#define MC_TXN_OVERRIDE_CONFIG_TSECSWRB_0	0x1438
+#define MC_TXN_OVERRIDE_CONFIG_TSECSWR_0	0x12a8
+#define MC_TXN_OVERRIDE_CONFIG_UFSHCR_0	0x1480
+#define MC_TXN_OVERRIDE_CONFIG_UFSHCW_0	0x1488
+#define MC_TXN_OVERRIDE_CONFIG_VICSRD1_0	0x1510
+#define MC_TXN_OVERRIDE_CONFIG_VICSRD_0	0x1360
+#define MC_TXN_OVERRIDE_CONFIG_VICSWR_0	0x1368
+#define MC_TXN_OVERRIDE_CONFIG_VIFALR_0	0x15e4
+#define MC_TXN_OVERRIDE_CONFIG_VIFALW_0	0x15ec
+#define MC_TXN_OVERRIDE_CONFIG_VIW_0	0x1390
+#define MC_TXN_OVERRIDE_CONFIG_VIW_0_VIW_COH_PATH_OVERRIDE_NORMAL_FORCE_NON_COHERENT	1
+#define MC_TXN_OVERRIDE_CONFIG_VIW_0_VIW_COH_PATH_OVERRIDE_NORMAL_RANGE	9:8
+#define MC_TXN_OVERRIDE_CONFIG_VIW_0_VIW_COH_PATH_OVERRIDE_SO_DEV_FORCE_NON_COHERENT	1
+#define MC_TXN_OVERRIDE_CONFIG_VIW_0_VIW_COH_PATH_OVERRIDE_SO_DEV_RANGE	5:4
+#define MC_TXN_OVERRIDE_CONFIG_XUSB_DEVR_0	0x1260
+#define MC_TXN_OVERRIDE_CONFIG_XUSB_DEVW_0	0x1268
+#define MC_TXN_OVERRIDE_CONFIG_XUSB_HOSTR_0	0x1250
+#define MC_TXN_OVERRIDE_CONFIG_XUSB_HOSTW_0	0x1258
+#define MC_UFSHCPC2_PTSA_MAX_0	0x3a2c
+#define MC_UFSHCPC2_PTSA_MAX_0_PTSA_MAX_UFSHCPC2_DEFAULT_MASK	0x7ff
+#define MC_UFSHCPC2_PTSA_MIN_0	0x3a28
+#define MC_UFSHCPC2_PTSA_MIN_0_PTSA_MIN_UFSHCPC2_DEFAULT_MASK	0x7ff
+#define MC_UFSHCPC2_PTSA_RATE_0	0x3a24
+#define MC_UFSHCPC2_PTSA_RATE_0_PTSA_RATE_UFSHCPC2_DEFAULT_MASK	0xfff
+#define MC_UFSHCPC_PTSA_MAX_0	0x74c
+#define MC_UFSHCPC_PTSA_MAX_0_PTSA_MAX_UFSHCPC_DEFAULT_MASK	0x7ff
+#define MC_UFSHCPC_PTSA_MIN_0	0x748
+#define MC_UFSHCPC_PTSA_MIN_0_PTSA_MIN_UFSHCPC_DEFAULT_MASK	0x7ff
+#define MC_UFSHCPC_PTSA_RATE_0	0x744
+#define MC_UFSHCPC_PTSA_RATE_0_PTSA_RATE_UFSHCPC_DEFAULT_MASK	0xfff
+#define MC_USBD2_PTSA_MAX_0	0x3a44
+#define MC_USBD2_PTSA_MAX_0_PTSA_MAX_USBD2_DEFAULT_MASK	0x7ff
+#define MC_USBD2_PTSA_MIN_0	0x3a40
+#define MC_USBD2_PTSA_MIN_0_PTSA_MIN_USBD2_DEFAULT_MASK	0x7ff
+#define MC_USBD2_PTSA_RATE_0	0x3a3c
+#define MC_USBD2_PTSA_RATE_0_PTSA_RATE_USBD2_DEFAULT_MASK	0xfff
+#define MC_USBD_PTSA_MAX_0	0x538
+#define MC_USBD_PTSA_MAX_0_PTSA_MAX_USBD_DEFAULT_MASK	0x7ff
+#define MC_USBD_PTSA_MIN_0	0x534
+#define MC_USBD_PTSA_MIN_0_PTSA_MIN_USBD_DEFAULT_MASK	0x7ff
+#define MC_USBD_PTSA_RATE_0	0x530
+#define MC_USBD_PTSA_RATE_0_PTSA_RATE_USBD_DEFAULT_MASK	0xfff
+#define MC_USBX2_PTSA_MAX_0	0x3a38
+#define MC_USBX2_PTSA_MAX_0_PTSA_MAX_USBX2_DEFAULT_MASK	0x7ff
+#define MC_USBX2_PTSA_MIN_0	0x3a34
+#define MC_USBX2_PTSA_MIN_0_PTSA_MIN_USBX2_DEFAULT_MASK	0x7ff
+#define MC_USBX2_PTSA_RATE_0	0x3a30
+#define MC_USBX2_PTSA_RATE_0_PTSA_RATE_USBX2_DEFAULT_MASK	0xfff
+#define MC_USBX_PTSA_MAX_0	0x52c
+#define MC_USBX_PTSA_MAX_0_PTSA_MAX_USBX_DEFAULT_MASK	0x7ff
+#define MC_USBX_PTSA_MIN_0	0x528
+#define MC_USBX_PTSA_MIN_0_PTSA_MIN_USBX_DEFAULT_MASK	0x7ff
+#define MC_USBX_PTSA_RATE_0	0x524
+#define MC_USBX_PTSA_RATE_0_PTSA_RATE_USBX_DEFAULT_MASK	0xfff
+#define MC_VE_PTSA_MAX_0	0x43c
+#define MC_VE_PTSA_MAX_0_PTSA_MAX_VE_DEFAULT_MASK	0x7ff
+#define MC_VE_PTSA_MIN_0	0x438
+#define MC_VE_PTSA_MIN_0_PTSA_MIN_VE_DEFAULT_MASK	0x7ff
+#define MC_VE_PTSA_RATE_0	0x434
+#define MC_VE_PTSA_RATE_0_PTSA_RATE_VE_DEFAULT_MASK	0xfff
+#define MC_VICPC2_PTSA_MAX_0	0x3a14
+#define MC_VICPC2_PTSA_MAX_0_PTSA_MAX_VICPC2_DEFAULT_MASK	0x7ff
+#define MC_VICPC2_PTSA_MIN_0	0x3a10
+#define MC_VICPC2_PTSA_MIN_0_PTSA_MIN_VICPC2_DEFAULT_MASK	0x7ff
+#define MC_VICPC2_PTSA_RATE_0	0x3a0c
+#define MC_VICPC2_PTSA_RATE_0_PTSA_RATE_VICPC2_DEFAULT_MASK	0xfff
+#define MC_VICPC3_PTSA_MAX_0	0x7b8
+#define MC_VICPC3_PTSA_MAX_0_PTSA_MAX_VICPC3_DEFAULT_MASK	0x7ff
+#define MC_VICPC3_PTSA_MIN_0	0x7b4
+#define MC_VICPC3_PTSA_MIN_0_PTSA_MIN_VICPC3_DEFAULT_MASK	0x7ff
+#define MC_VICPC3_PTSA_RATE_0	0x7b0
+#define MC_VICPC3_PTSA_RATE_0_PTSA_RATE_VICPC3_DEFAULT_MASK	0xfff
+#define MC_VICPC_PTSA_MAX_0	0x55c
+#define MC_VICPC_PTSA_MAX_0_PTSA_MAX_VICPC_DEFAULT_MASK	0x7ff
+#define MC_VICPC_PTSA_MIN_0	0x558
+#define MC_VICPC_PTSA_MIN_0_PTSA_MIN_VICPC_DEFAULT_MASK	0x7ff
+#define MC_VICPC_PTSA_RATE_0	0x554
+#define MC_VICPC_PTSA_RATE_0_PTSA_RATE_VICPC_DEFAULT_MASK	0xfff
+
+#define EMC_FBIO_DATA_WIDTH	64
+#define EMC_CFG_0	0xc
+#define EMC_CFG_0_DRAM_ACPD_ACTIVE_POWERDOWN	1
+#define EMC_CFG_0_DRAM_ACPD_NO_POWERDOWN	0
+#define EMC_CFG_0_DRAM_ACPD_RANGE	29:29
+#define EMC_CFG_0_DYN_SELF_REF_DISABLED	0
+#define EMC_CFG_0_DYN_SELF_REF_ENABLED	1
+#define EMC_CFG_0_DYN_SELF_REF_RANGE	28:28
+#define EMC_TIMING_CONTROL_0	0x28
+#define EMC_FBIO_CFG5_0	0x104
+#define EMC_PMACRO_PAD_CFG_CTRL_0	0xc40
+
+#define PCIE_COMMON_APPL_COMMON_CONTROL_0	0x0
+#define PCIE_COMMON_APPL_COMMON_CONTROL_0_XBAR_CONFIG_RANGE	31:24
+
+#define MSSNVLINK_MASTER_MCF_DDA_0	0x360
+#define MSSNVLINK_MASTER_MCF_DDA_0_ENBL_DISABLE	0
+#define MSSNVLINK_MASTER_MCF_DDA_0_ENBL_ENABLE	1
+#define MSSNVLINK_MASTER_MCF_DDA_0_ENBL_RANGE	31:31
+#define MSSNVLINK_MASTER_MCF_DDA_0_MAX_RANGE	26:16
+#define MSSNVLINK_MASTER_MCF_DDA_0_RATE_RANGE	11:0
+
+#define NV_MC_EMEM_NUM_SLOTS	63
+#define NV_MC_EMEM_PTSA_RATE_WIDTH	12
+#define NV_MC_EMEM_PTSA_MINMAX_WIDTH	10
+#define EMC_FBIO_DATA_WIDTH 64
+#define DISPLAY_CATCHUP_FACTOR 1.1f
+#define MAX_NUM_DVFS_TIME_FREQS 104
+#define NV_AFIR2MC_SR_REORDER_DEPTH	136
+#define NV_AONDMAR2MC_SR_REORDER_DEPTH	32
+#define NV_APEDMAR2MC_SR_REORDER_DEPTH	24
+#define NV_AXISR2MC_SR_REORDER_DEPTH	32
+#define NV_BPMPDMAR2MC_SR_REORDER_DEPTH	32
+#define NV_EQOSR2MC_SR_REORDER_DEPTH	16
+#define NV_GPUSRD2MC_SR_REORDER_DEPTH	256
+#define NV_HOST1XDMAR2MC_SR_RDFIFODEPTH	32
+#define NV_ISPRA2MC_SR_REORDER_DEPTH	128
+#define NV_NVJPGSRD2MC_SR_RDFIFODEPTH	160
+#define NV_SATAR2MC_SR_REORDER_DEPTH	16
+#define NV_SCEDMAR2MC_SR_REORDER_DEPTH	32
+#define NV_SDMMCR2MC_SR_REORDER_DEPTH	24
+#define NV_SDMMCRA2MC_SR_REORDER_DEPTH	24
+#define NV_SDMMCRAA2MC_SR_REORDER_DEPTH	48
+#define NV_SDMMCRAB2MC_SR_REORDER_DEPTH	96
+#define NV_SESRD2MC_SR_RDFIFODEPTH	136
+#define NV_TSECSRD2MC_SR_RDFIFODEPTH	20
+#define NV_TSECSRDB2MC_SR_RDFIFODEPTH	20
+#define NV_UFSHCR2MC_SR_REORDER_DEPTH	72
+#define NV_VICSRD2MC_SR_RDFIFODEPTH	225
+#define NV_XUSB_DEVR2MC_SR_REORDER_DEPTH	40
+#define NV_XUSB_HOSTR2MC_SR_REORDER_DEPTH	72
+
+#endif
diff --git a/drivers/platform/tegra/mc/mc-t19x.c b/drivers/platform/tegra/mc/mc-t19x.c
new file mode 100644
index 000000000000..5b7da5adb249
--- /dev/null
+++ b/drivers/platform/tegra/mc/mc-t19x.c
@@ -0,0 +1,22 @@
+/*
+ * Copyright (C) 2017, NVIDIA Corporation.  All rights reserved.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#include <linux/mod_devicetable.h>
+
+const struct of_device_id tegra_mc_of_ids[] = {
+	{ .compatible = "nvidia,tegra-mc" },
+	{ .compatible = "nvidia,tegra-t18x-mc" },
+	{ .compatible = "nvidia,tegra-t19x-mc" },
+	{ }
+};
diff --git a/drivers/platform/tegra/mc/mc.c b/drivers/platform/tegra/mc/mc.c
new file mode 100644
index 000000000000..164ca1e743bd
--- /dev/null
+++ b/drivers/platform/tegra/mc/mc.c
@@ -0,0 +1,514 @@
+/*
+ * arch/arm/mach-tegra/mc.c
+ *
+ * Copyright (C) 2010 Google, Inc.
+ * Copyright (C) 2011-2022, NVIDIA Corporation.  All rights reserved.
+ *
+ * Author:
+ *	Erik Gilling <konkers@google.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#define pr_fmt(fmt) "mc: " fmt
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/export.h>
+#include <linux/spinlock.h>
+#include <linux/delay.h>
+#include <linux/debugfs.h>
+#include <linux/of_device.h>
+#include <linux/of_address.h>
+#include <linux/platform_device.h>
+
+#include <linux/platform/tegra/mc-regs-t21x.h>
+#include <linux/platform/tegra/mc.h>
+#include <linux/platform/tegra/mcerr.h>
+#include <linux/platform/tegra/tegra_emc.h>
+
+#include <linux/platform/tegra/bwmgr_mc.h>
+
+#include <soc/tegra/fuse.h>
+
+#define MC_CLIENT_HOTRESET_CTRL		0x200
+#define MC_CLIENT_HOTRESET_STAT		0x204
+#define MC_CLIENT_HOTRESET_CTRL_1	0x970
+#define MC_CLIENT_HOTRESET_STAT_1	0x974
+#define MC_LATENCY_ALLOWANCE_BASE	MC_LATENCY_ALLOWANCE_AFI_0
+
+#define MSSNVLINK_CYA_DESIGN_MODES		0x3c
+#define MSS_NVLINK_L3_ALLOC_HINT		(1 << 2)
+
+static DEFINE_SPINLOCK(tegra_mc_lock);
+int mc_channels;
+void __iomem *mc;
+void __iomem *mc_regs[MC_MAX_CHANNELS];
+unsigned int mssnvlink_hubs;
+void __iomem *mssnvlink_regs[MC_MAX_MSSNVLINK_HUBS];
+static u32 nvlink_reg_val[MC_MAX_MSSNVLINK_HUBS];
+
+u32 tegra_mc_readl(u32 reg)
+{
+	return mc_readl(reg);
+}
+EXPORT_SYMBOL(tegra_mc_readl);
+
+void tegra_mc_writel(u32 val, u32 reg)
+{
+	mc_writel(val, reg);
+}
+EXPORT_SYMBOL(tegra_mc_writel);
+
+/*
+ * Return carveout info for @co in @inf. If @nr is non-NULL then the number of
+ * carveouts are also place in @*nr. If both @inf and @nr are NULL then the
+ * validity of @co is checked and that is it.
+ */
+int mc_get_carveout_info(struct mc_carveout_info *inf, int *nr,
+			 enum carveout_desc co)
+{
+#define MC_SECURITY_CARVEOUT(carveout, infop)				\
+	do {								\
+		(infop)->desc = co;					\
+		(infop)->base = mc_readl(carveout ## _BOM) |		\
+			((u64)mc_readl(carveout ## _BOM_HI) & 0x3) << 32; \
+		(infop)->size = mc_readl(carveout ## _SIZE_128KB);	\
+		(infop)->size <<= 17; /* Convert to bytes. */		\
+	} while (0)
+
+	if (!mc) {
+		WARN(1, "Reading carveout info before MC init'ed!\n");
+		return 0;
+	}
+
+	if (co >= MC_NR_CARVEOUTS)
+		return -EINVAL;
+
+	if (nr)
+		*nr = MC_NR_CARVEOUTS;
+
+	if (!inf)
+		return 0;
+
+	switch (co) {
+	case MC_SECURITY_CARVEOUT1:
+#ifdef MC_SECURITY_CARVEOUT1_BOM
+		MC_SECURITY_CARVEOUT(MC_SECURITY_CARVEOUT1, inf);
+		break;
+#else
+		return -ENODEV;
+#endif
+	case MC_SECURITY_CARVEOUT2:
+#ifdef MC_SECURITY_CARVEOUT2_BOM
+		MC_SECURITY_CARVEOUT(MC_SECURITY_CARVEOUT2, inf);
+		break;
+#else
+		return -ENODEV;
+#endif
+	case MC_SECURITY_CARVEOUT4:
+#ifdef MC_SECURITY_CARVEOUT4_BOM
+		MC_SECURITY_CARVEOUT(MC_SECURITY_CARVEOUT4, inf);
+		break;
+#else
+		return -ENODEV;
+#endif
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(mc_get_carveout_info);
+
+/*
+ * API to convert BW in bytes/s to clock frequency.
+ *
+ * bw: Bandwidth to convert. It can be in any unit - the resulting frequency
+ *     will be in the same unit as passed. E.g KBps leads to KHz.
+ */
+unsigned long tegra_emc_bw_to_freq_req(unsigned long bw)
+{
+	return bwmgr_bw_to_freq(bw);
+}
+EXPORT_SYMBOL_GPL(tegra_emc_bw_to_freq_req);
+
+/*
+ * API to convert EMC clock frequency into theoretical available BW. This
+ * does not account for a realistic utilization of the EMC bus. That is the
+ * various overheads (refresh, bank commands, etc) that a real system sees
+ * are not computed.
+ *
+ * freq: Frequency to convert. Like tegra_emc_bw_to_freq_req() it will work
+ *       on any passed order of ten. The result will be on the same order.
+ */
+unsigned long tegra_emc_freq_req_to_bw(unsigned long freq)
+{
+	return bwmgr_freq_to_bw(freq);
+}
+EXPORT_SYMBOL_GPL(tegra_emc_freq_req_to_bw);
+
+#define HOTRESET_READ_COUNT	5
+static bool tegra_stable_hotreset_check(u32 stat_reg, u32 *stat)
+{
+	int i;
+	u32 cur_stat;
+	u32 prv_stat;
+	unsigned long flags;
+
+	spin_lock_irqsave(&tegra_mc_lock, flags);
+	prv_stat = mc_readl(stat_reg);
+	for (i = 0; i < HOTRESET_READ_COUNT; i++) {
+		cur_stat = mc_readl(stat_reg);
+		if (cur_stat != prv_stat) {
+			spin_unlock_irqrestore(&tegra_mc_lock, flags);
+			return false;
+		}
+	}
+	*stat = cur_stat;
+	spin_unlock_irqrestore(&tegra_mc_lock, flags);
+	return true;
+}
+
+int tegra_mc_flush(int id)
+{
+	u32 rst_ctrl, rst_stat;
+	u32 rst_ctrl_reg, rst_stat_reg;
+	unsigned long flags;
+	unsigned int timeout;
+	bool ret;
+
+	if (!mc)
+		return 0;
+
+	if (id < 32) {
+		rst_ctrl_reg = MC_CLIENT_HOTRESET_CTRL;
+		rst_stat_reg = MC_CLIENT_HOTRESET_STAT;
+	} else {
+		id %= 32;
+		rst_ctrl_reg = MC_CLIENT_HOTRESET_CTRL_1;
+		rst_stat_reg = MC_CLIENT_HOTRESET_STAT_1;
+	}
+
+	spin_lock_irqsave(&tegra_mc_lock, flags);
+
+	rst_ctrl = mc_readl(rst_ctrl_reg);
+	rst_ctrl |= (1 << id);
+	mc_writel(rst_ctrl, rst_ctrl_reg);
+
+	spin_unlock_irqrestore(&tegra_mc_lock, flags);
+
+	timeout = 0;
+	do {
+		bool exit = false;
+		udelay(10);
+		rst_stat = 0;
+		ret = tegra_stable_hotreset_check(rst_stat_reg, &rst_stat);
+
+		timeout++;
+
+		/* keep lower timeout if we are running in qt or fpga */
+		exit |= (timeout > 100) && (tegra_platform_is_qt() ||
+			tegra_platform_is_fpga());
+		/* otherwise have huge timeout (~1s) */
+		exit |= timeout > 100000;
+		if (exit) {
+			WARN(1, "%s flush %d timeout\n", __func__, id);
+			return -ETIMEDOUT;
+		}
+
+		if (!ret)
+			continue;
+	} while (!(rst_stat & (1 << id)));
+
+	return 0;
+}
+EXPORT_SYMBOL(tegra_mc_flush);
+
+int tegra_mc_flush_done(int id)
+{
+	u32 rst_ctrl;
+	u32 rst_ctrl_reg, rst_stat_reg;
+	unsigned long flags;
+
+	if (!mc)
+		return 0;
+
+	if (id < 32) {
+		rst_ctrl_reg = MC_CLIENT_HOTRESET_CTRL;
+		rst_stat_reg = MC_CLIENT_HOTRESET_STAT;
+	} else {
+		id %= 32;
+		rst_ctrl_reg = MC_CLIENT_HOTRESET_CTRL_1;
+		rst_stat_reg = MC_CLIENT_HOTRESET_STAT_1;
+	}
+
+	spin_lock_irqsave(&tegra_mc_lock, flags);
+
+	rst_ctrl = mc_readl(rst_ctrl_reg);
+	rst_ctrl &= ~(1 << id);
+	mc_writel(rst_ctrl, rst_ctrl_reg);
+
+	spin_unlock_irqrestore(&tegra_mc_lock, flags);
+	return 0;
+}
+EXPORT_SYMBOL(tegra_mc_flush_done);
+
+/*
+ * Map an MC register space. Each MC has a set of register ranges which must
+ * be parsed. The first starting address in the set of ranges is returned as
+ * it is expected that the DT file has the register ranges in ascending
+ * order.
+ *
+ * device 0 = global channel.
+ * device n = specific channel device-1, e.g device = 1 ==> channel 0.
+ */
+static void __iomem *tegra_mc_map_regs(struct platform_device *pdev, int device)
+{
+	struct resource res;
+	const void *prop;
+	void __iomem *regs;
+	void __iomem *regs_start = NULL;
+	u32 reg_ranges;
+	int i, start;
+
+	prop = of_get_property(pdev->dev.of_node, "reg-ranges", NULL);
+	if (!prop) {
+		pr_err("Failed to get MC MMIO region\n");
+		pr_err("  device = %d: missing reg-ranges\n", device);
+		return NULL;
+	}
+
+	reg_ranges = be32_to_cpup(prop);
+	start = device * reg_ranges;
+
+	for (i = 0; i < reg_ranges; i++) {
+		regs = of_iomap(pdev->dev.of_node, start + i);
+		if (!regs) {
+			pr_err("Failed to get MC MMIO region\n");
+			pr_err("  device = %d, range = %u\n", device, i);
+			return NULL;
+		}
+
+		if (i == 0)
+			regs_start = regs;
+	}
+
+	if (of_address_to_resource(pdev->dev.of_node, start, &res))
+		return NULL;
+
+	pr_info("mapped MMIO address: 0x%p -> 0x%lx\n",
+		regs_start, (unsigned long)res.start);
+
+	return regs_start;
+}
+
+/*
+ * Map mssnvlink igpu hubs. In t19x, 4 igpu links supported
+ */
+static void enable_mssnvlinks(struct platform_device *pdev)
+{
+	struct device_node *dn = NULL;
+	void __iomem *regs;
+	int ret = 0, i;
+	u32 reg_val;
+	bool disable_l3_alloc_hint = false;
+
+	/* MSSNVLINK support is available in silicon or fpga only */
+	if (!tegra_platform_is_silicon())
+		return;
+
+	dn = of_get_next_child(pdev->dev.of_node, NULL);
+	if (!dn) {
+		mssnvlink_hubs = UINT_MAX;
+		dev_info(&pdev->dev, "No mssnvlink node\n");
+		return;
+	}
+
+	ret = of_property_read_u32(dn, "mssnvlink_hubs", &mssnvlink_hubs);
+	if (ret) {
+		dev_err(&pdev->dev, "<mssnvlink_hubs> property missing in %s\n",
+			pdev->dev.of_node->name);
+			ret = -EINVAL;
+			goto err_out;
+	}
+
+	if (mssnvlink_hubs > MC_MAX_MSSNVLINK_HUBS || mssnvlink_hubs < 1) {
+		pr_err("Invalid number of mssnvlink hubs: %d\n", mssnvlink_hubs);
+		ret = -EINVAL;
+		goto err_out;
+	}
+
+	disable_l3_alloc_hint = of_property_read_bool(dn, "disable-nvlink-l3-alloc-hint");
+
+	for (i = 0; i < mssnvlink_hubs; i++) {
+		regs = of_iomap(dn, i);
+		if (!regs) {
+			dev_err(&pdev->dev, "Failed to get MSSNVLINK aperture: %d\n", i);
+			ret = PTR_ERR(regs);
+			goto err_out;
+		}
+		mssnvlink_regs[i] = regs;
+		reg_val = __raw_readl(regs + MSSNVLINK_CYA_DESIGN_MODES);
+		if (!disable_l3_alloc_hint)
+			reg_val |=  MSS_NVLINK_L3_ALLOC_HINT;
+		__raw_writel(reg_val, regs + MSSNVLINK_CYA_DESIGN_MODES);
+		nvlink_reg_val[i] = reg_val;
+	}
+
+err_out:
+	WARN_ON(ret);
+}
+
+__weak const struct of_device_id tegra_mc_of_ids[] = {
+	{ .compatible = "nvidia,tegra-mc" },
+	{ .compatible = "nvidia,tegra-t18x-mc" },
+	{ }
+};
+
+/*
+ * MC driver init.
+ */
+static int tegra_mc_probe(struct platform_device *pdev)
+{
+
+#if defined(CONFIG_TEGRA_MC_EARLY_ACK)
+	u32 reg;
+#endif
+	int i;
+	const void *prop;
+	struct dentry *mc_debugfs_dir = NULL;
+	struct tegra_mc_data *mc_data;
+	const struct of_device_id *match;
+
+	if (!pdev->dev.of_node)
+		return -EINVAL;
+
+	match = of_match_device(tegra_mc_of_ids, &pdev->dev);
+	if (!match) {
+		pr_err("Missing DT entry!\n");
+		return -EINVAL;
+	}
+
+	mc_data = (struct tegra_mc_data *)match->data;
+
+	/*
+	 * Channel count.
+	 */
+	prop = of_get_property(pdev->dev.of_node, "channels", NULL);
+	if (!prop)
+		mc_channels = 1;
+	else
+		mc_channels = be32_to_cpup(prop);
+
+	if (mc_channels > MC_MAX_CHANNELS || mc_channels < 1) {
+		pr_err("Invalid number of memory channels: %d\n", mc_channels);
+		return -EINVAL;
+	}
+
+	/*
+	 * IO mem.
+	 */
+	mc = tegra_mc_map_regs(pdev, 0);
+	if (!mc)
+		return -ENOMEM;
+
+	/* Populate the rest of the channels... */
+	if (mc_channels > 1) {
+		for (i = 1; i <= mc_channels; i++) {
+			mc_regs[i - 1] = tegra_mc_map_regs(pdev, i);
+			if (!mc_regs[i - 1])
+				return -ENOMEM;
+		}
+	} else {
+		/* Make channel 0 the same as the MC broadcast range. */
+		mc_regs[0] = mc;
+	}
+
+	enable_mssnvlinks(pdev);
+
+#if defined(CONFIG_TEGRA_MC_EARLY_ACK)
+	reg = mc_readl(MC_EMEM_ARB_OVERRIDE);
+	reg |= 3;
+#if defined(CONFIG_TEGRA_ERRATA_1157520)
+	if (tegra_revision == TEGRA_REVISION_A01)
+		reg &= ~2;
+#endif
+	mc_writel(reg, MC_EMEM_ARB_OVERRIDE);
+#endif
+
+#ifdef CONFIG_DEBUG_FS
+	mc_debugfs_dir = debugfs_create_dir("mc", NULL);
+	if (mc_debugfs_dir == NULL)
+		pr_err("Failed to make debugfs node: %ld\n",
+		       PTR_ERR(mc_debugfs_dir));
+#endif
+
+	tegra_mcerr_init(mc_debugfs_dir, pdev);
+
+	return 0;
+}
+
+static int tegra_mc_resume_early(struct device *dev)
+{
+	int i;
+
+	if (mssnvlink_hubs != UINT_MAX) {
+		for (i = 0; i < mssnvlink_hubs; i++)
+			__raw_writel(nvlink_reg_val[i],
+				mssnvlink_regs[i] + MSSNVLINK_CYA_DESIGN_MODES);
+	}
+	tegra_mcerr_resume();
+	return 0;
+}
+
+u32 __weak tegra_get_dvfs_clk_change_latency_nsec(unsigned long emc_freq_khz)
+{
+	return 2000;
+}
+
+static int tegra_mc_remove(struct platform_device *pdev)
+{
+	return 0;
+}
+
+static const struct dev_pm_ops tegra_mc_pm_ops = {
+	.resume_early = tegra_mc_resume_early,
+};
+
+static struct platform_driver mc_driver = {
+	.driver = {
+		.name	= "nv-tegra-mc",
+		.of_match_table = tegra_mc_of_ids,
+		.owner	= THIS_MODULE,
+		.pm     = &tegra_mc_pm_ops,
+	},
+
+	.probe		= tegra_mc_probe,
+	.remove		= tegra_mc_remove,
+};
+
+static int __init tegra_mc_init(void)
+{
+	int ret;
+
+	ret = platform_driver_register(&mc_driver);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+core_initcall(tegra_mc_init);
+
+static void __exit tegra_mc_fini(void)
+{
+}
+module_exit(tegra_mc_fini);
diff --git a/drivers/platform/tegra/mc/mc_addr_translate.c b/drivers/platform/tegra/mc/mc_addr_translate.c
new file mode 100644
index 000000000000..a8a6d587c383
--- /dev/null
+++ b/drivers/platform/tegra/mc/mc_addr_translate.c
@@ -0,0 +1,308 @@
+/*
+ * Copyright (c) 2015-2016, NVIDIA CORPORATION.  All rights reserved.
+ *
+ * NVIDIA CORPORATION and its licensors retain all intellectual property
+ * and proprietary rights in and to this software, related documentation
+ * and any modifications thereto.  Any use, reproduction, disclosure or
+ * distribution of this software and related documentation without an express
+ * license agreement from NVIDIA CORPORATION is strictly prohibited.
+ */
+#define pr_fmt(fmt) "ecc-cfg: " fmt
+
+#include <linux/kernel.h>
+#include <linux/seq_file.h>
+#include <linux/platform/tegra/mc-regs-t18x.h>
+#include <linux/platform/tegra/mc.h>
+#include <linux/platform/tegra/mcerr_ecc_t18x.h>
+#include <linux/platform/tegra/mc-regs-t18x.h>
+
+#define MASK(Y, Z)      ((0xFFFFFFFF >> (31-Y)) & (0xFFFFFFFF << Z))
+#define CALC(X, Y, Z)	((X & MASK(Y, Z)) >> Z)
+#define MCBIT(X, B)	CALC(X, B, B)
+#define ABIT(B)         MCBIT(addr, B)
+
+struct mc_cfg_t {
+	u32 col_bits;
+	u32 row_bits;
+	u32 bank_bits;
+	u32 channel_bits;
+	u32 chanpos;
+	u32 bankpos;
+	u32 all_bits;
+	u32 lsb_bits;
+	u32 ecc_bits;
+	u32 ecc_ratio;
+	u32 subp_bits;
+	u32 bank_mask[3];
+	u32 chanmask[2];
+	u32 addr_cfg_dev0;
+	u32 addr_cfg_dev1;
+	u32 addr_cfg0;
+	u32 emem_bom;
+};
+
+static struct mc_cfg_t mc_cfg;
+
+/* invoked via debugfs entry mc/ecc_err/cfg */
+int mc_ecc_config_dump(struct seq_file *s, void *v)
+{
+	seq_printf(s, "col_bits = %d\n", mc_cfg.col_bits);
+	seq_printf(s, "row_bits = %d\n", mc_cfg.row_bits);
+	seq_printf(s, "bank_bits = %d\n", mc_cfg.bank_bits);
+	seq_printf(s, "channel_bits = %d\n", mc_cfg.channel_bits);
+	seq_printf(s, "chanpos = %d,bankpos = %d\n", mc_cfg.chanpos,
+							mc_cfg.bankpos);
+	seq_printf(s, "all_bits = %d,lsb_bits = %d,subp_bits = %d\n",
+		mc_cfg.all_bits, mc_cfg.lsb_bits, mc_cfg.subp_bits);
+	seq_printf(s, "ecc_bits = %d,ecc_ratio = %d\n", mc_cfg.ecc_bits,
+						mc_cfg.ecc_ratio);
+	seq_printf(s, "bank_mask[0] = 0x%x\n", mc_cfg.bank_mask[0]);
+	seq_printf(s, "bank_mask[1] = 0x%x,bank_mask[2] = 0x%x\n",
+			mc_cfg.bank_mask[1], mc_cfg.bank_mask[2]);
+	seq_printf(s, "chanmask[0] = 0x%x,chanmask[1] = 0x%x\n",
+		mc_cfg.chanmask[0], mc_cfg.chanmask[1]);
+	seq_printf(s, "addr_cfg_dev0 = 0x%x,addr_cfg_dev1 = 0x%x\n",
+		mc_cfg.addr_cfg_dev0, mc_cfg.addr_cfg_dev1);
+	seq_printf(s, "addr_cfg0 = 0x%x\n", mc_cfg.addr_cfg0);
+	seq_printf(s, "emem_bom = 0x%x\n", mc_cfg.emem_bom);
+
+	return 0;
+}
+
+void mc_ecc_config_read(void)
+{
+	u32 max_chanbits = 2;
+	u32 chanpos, i;
+
+	/* FIXME check for replacing below constants with macros */
+
+	/* LPDDR4 have column bits always 10 */
+	mc_cfg.col_bits = 10;
+	/*16-bit sub-partition = 1,32-bit sub-partition =2:
+	For LPDDR4 it is always 16-bit sub-partition */
+	mc_cfg.lsb_bits = 1;
+	/*LPDDR4 device has always 8-banks*/
+	mc_cfg.bank_bits = 3;
+	mc_cfg.bankpos = 10;
+	/* 1/8 for ECC and 7/8 for Data */
+	mc_cfg.ecc_ratio = 7;
+	/*ecc_bits = log2(ecc_ratio+1)*/
+	mc_cfg.ecc_bits = 3;
+	/* For LPDDR4 it is always dual sub partition */
+	mc_cfg.subp_bits = 1;
+
+	mc_cfg.emem_bom = ((mc_readl(MC_EMEM_CFG) & 0x80000000) ==
+						0x80000000);
+	mc_cfg.addr_cfg_dev0 = mc_readl(MC_EMEM_ADR_CFG_DEV0);
+	mc_cfg.addr_cfg_dev1 = mc_readl(MC_EMEM_ADR_CFG_DEV1);
+	mc_cfg.addr_cfg0 = mc_readl(MC_EMEM_ADR_CFG);
+
+	mc_cfg.all_bits = (((mc_cfg.addr_cfg_dev0>>16) & 0x0f) + 22);
+
+	if (mc_cfg.all_bits == (12 + 22))
+		mc_cfg.all_bits = (8 + 22);
+	else if (mc_cfg.all_bits == (13 + 22))
+		mc_cfg.all_bits = (7 + 22);
+
+	mc_cfg.row_bits = (mc_cfg.all_bits - mc_cfg.bank_bits -  mc_cfg.col_bits
+						- mc_cfg.lsb_bits);
+
+	mc_cfg.bank_mask[0] = mc_readl(MC_EMEM_ADR_CFG_BANK_MASK_0);
+	mc_cfg.bank_mask[1] = mc_readl(MC_EMEM_ADR_CFG_BANK_MASK_1);
+	mc_cfg.bank_mask[2] = mc_readl(MC_EMEM_ADR_CFG_BANK_MASK_2);
+
+	mc_cfg.chanmask[0] = mc_readl(MC_EMEM_ADR_CFG_CHANNEL_MASK);
+	mc_cfg.chanmask[1] = mc_readl(MC_EMEM_ADR_CFG_CHANNEL_MASK_1);
+
+	mc_cfg.chanpos = (1 << (u32)31)-(u32)1;
+
+	for (i = 0; i < max_chanbits; i++) {
+
+		if (mc_cfg.chanmask[i] != 0) {
+
+			mc_cfg.channel_bits += 1;
+			for (chanpos = 0; ((1 << chanpos) &
+				mc_cfg.chanmask[i]) == 0; chanpos++)
+					;
+
+			if (mc_cfg.chanpos > chanpos)
+				mc_cfg.chanpos = chanpos;
+		}
+	}
+	if (mc_cfg.channel_bits == 0)
+		mc_cfg.chanpos = 0;
+}
+
+static u32 mc_reverse_masked_bank(u64 linear, int masked_bank, int bankpos,
+				int bankbits)
+{
+	u32 bank = 0;
+	u32 pre_bank = 0;
+	u32 pos = bankpos + bankbits;
+	u64 bank_bit;
+	u32 i, j;
+
+	for (i = (bankbits - 1); ((i >= 0) && (i < bankbits)); --i) {
+		pre_bank <<= 1;
+
+		bank_bit = (mc_cfg.bank_mask[i] & linear);
+		bank_bit &= ~((1ll << (bankpos+bankbits)) - 1);
+		while (bank_bit) {
+			pre_bank ^= bank_bit & 1;
+			bank_bit >>= 1;
+		}
+		pre_bank ^= (masked_bank>>i) & 1;
+	}
+
+	for (i = (bankbits - 1); ((i >= 0) && (i < bankbits)); --i) {
+		bank <<= 1;
+		pos -= 1;
+		for (j = (bankbits-1); ((j >= 0) && (j < bankbits)); --j) {
+			if ((mc_cfg.bank_mask[j]>>pos) & 1) {
+				bank |= (pre_bank>>j) & 1;
+				break;
+			}
+		}
+	}
+	return bank;
+}
+static u64 mc_generate_chan_offset(u64 addr, u32 chanbits)
+{
+	u32 chanoffset = 0;
+	u32 max_chanbits = 2;
+	u32 mask;
+	u64 cur_addr;
+	u32 i;
+
+	for (i = (max_chanbits - 1); ((i >= 0) && (i < 2)); i--) {
+		mask = mc_cfg.chanmask[i];
+		cur_addr = addr;
+		chanoffset = chanoffset << 1;
+		while (mask) {
+			if (mask & 1)
+				chanoffset ^= (cur_addr & 1);
+			mask = (mask >> 1);
+			cur_addr = (cur_addr >> 1);
+		}
+	}
+	return chanoffset & ~(-1<<chanbits);
+}
+static u64 mc_translate_update_ch(u64 addr, u32 ch)
+{
+	u32 cur_chan;
+	u32 chanbits = 2;
+	u32 chanpos = 10;
+	u32 chanoffset;
+
+	for (cur_chan = 0; (cur_chan < (1 << chanbits)); ++cur_chan) {
+
+		addr = ((addr >> (chanpos + chanbits)) << (chanpos + chanbits)
+		| (cur_chan & ((1 << chanbits) - 1)) << chanpos
+		| (addr & ((1 << chanpos) - 1)));
+
+		chanoffset = mc_generate_chan_offset(addr, chanbits);
+
+		if (chanoffset == ch)
+			break;
+	}
+	return addr;
+}
+
+static u64 mc_addr_translate_core(u64 addr, u32 device, u32 ch, u32 row,
+					u32 bank, u32 col, u32 subp, u32 lsb)
+{
+	u32 rcl = (mc_cfg.row_bits + mc_cfg.col_bits + mc_cfg.lsb_bits) - 1;
+	u32 rcls = rcl + mc_cfg.subp_bits;
+	u32 rclsb = rcls + mc_cfg.bank_bits;
+	u32 rclsbc = rclsb + mc_cfg.channel_bits;
+
+	addr = ((addr & ~(MASK(rcl, 0))) | ((CALC(row, mc_cfg.row_bits-1, 0) <<
+		(mc_cfg.col_bits+mc_cfg.lsb_bits)) |
+		(CALC(col, mc_cfg.col_bits-1, 0) << mc_cfg.lsb_bits) |
+		CALC(lsb, 0, 0)));
+
+	if (CALC(addr, 10, 8) == 0x7) {
+		addr = (addr & ~(MASK(rcl, 0))) | (((CALC(addr, rcl, 11) << 7) |
+			CALC(addr, 7, 0)));
+	} else {
+		addr = (addr & ~(MASK(rcl, 8))) | ((((CALC(addr, rcl, 11) *
+			mc_cfg.ecc_ratio)) + (CALC(addr, 10, 8))) << 8);
+	}
+
+	addr = (addr & ~(MASK(rcls, 0))) | (CALC(addr, rcl, 5) << 6) |
+		((subp ^ MCBIT(addr, 7) ^ MCBIT(addr, 5)) << 5) |
+		CALC(addr, 4, 0);
+
+	addr = (addr & ~(MASK(rclsb, 0))) | (CALC(addr, rcls, 10) << 13) |
+			(CALC(bank, 2, 0) << 10) | CALC(addr, 9, 0);
+
+	if (mc_cfg.channel_bits) {
+		addr = (addr & ~(MASK(rclsbc, 0))) |
+			(CALC(addr, rclsb, 10) << 12) |
+			(CALC(0, mc_cfg.channel_bits-1, 0) << 10) |
+			CALC(addr, 9, 0);
+	}
+	return addr;
+}
+
+static u64 mc_emem_bom(void)
+{
+	if (mc_cfg.emem_bom)
+		return 0x40000000;
+	else
+		return 0x80000000;
+}
+
+static u64 mc_device_size(void)
+{
+	/* Subp and lsb are each 1-bit */
+	u64 size = 1ll << (mc_cfg.channel_bits + mc_cfg.row_bits+
+			mc_cfg.bank_bits + mc_cfg.col_bits + 2);
+	return size;
+}
+
+static u64 mc_device_ecc_size(void)
+{
+	return mc_device_size()/(mc_cfg.ecc_ratio + 1);
+}
+
+static u64 mc_device_bom(u32 dev)
+{
+	if (dev == 0)
+		return mc_emem_bom();
+
+	return mc_device_bom(dev - 1) + mc_device_size() - mc_device_ecc_size();
+}
+
+static u64 mc_addr_translate_device(u64 addr, u32 col, u32 device, u32 ch)
+{
+	u64 device_bom = mc_device_bom(device);
+
+	addr = (u64)(((u64)CALC(addr, 31, 0)) + (device_bom));
+
+	addr = mc_translate_update_ch(addr, ch);
+
+	return addr;
+}
+
+u64 mc_addr_translate(u32 device, u32 ch, u32 row, u32 bank, u32 col, u32 subp,
+									u32 lsb)
+{
+	/* FIXME check for replacing below constants with macros */
+	u64 addr = 0;
+
+	addr = mc_addr_translate_core(addr, device, ch, row, bank,
+							col, subp, lsb);
+	addr = mc_addr_translate_device(addr, col, device, ch);
+
+	addr = ((addr >> (10 + 2)) << 10) | (addr & ((1 << 10) - 1));
+	bank = mc_reverse_masked_bank(addr, bank, 10, 3);
+
+	addr = 0;
+
+	addr = mc_addr_translate_core(addr, device, ch, row, bank,
+							col, subp, lsb);
+	addr = mc_addr_translate_device(addr, col, device, ch);
+
+	return addr;
+}
diff --git a/drivers/platform/tegra/mc/mcerr-t18x.c b/drivers/platform/tegra/mc/mcerr-t18x.c
new file mode 100644
index 000000000000..18778f20452f
--- /dev/null
+++ b/drivers/platform/tegra/mc/mcerr-t18x.c
@@ -0,0 +1,455 @@
+/*
+ * Tegra 18x SoC-specific mcerr code.
+ *
+ * Copyright (c) 2015-2018, NVIDIA Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ */
+
+#define pr_fmt(fmt) "mc-err: " fmt
+
+#include <linux/bitops.h>
+#include <linux/of.h>
+#include <linux/platform/tegra/mc-regs-t18x.h>
+#include <linux/platform/tegra/mcerr.h>
+#include <dt-bindings/memory/tegra-swgroup.h>
+#include <linux/interrupt.h>
+
+/*** Auto generated by `mcp.pl'. Do not modify! ***/
+
+static struct mc_client mc_clients[] = {
+	client("ptc", "csr_ptcr", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("afi", "csr_afir", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("hda", "csr_hdar", INVALID),
+	client("hc", "csr_host1xdmar", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("nvenc", "csr_nvencsrd", INVALID),
+	dummy_client,
+	dummy_client,
+	client("sata", "csr_satar", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("mpcore", "csr_mpcorer", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("nvenc", "csw_nvencswr", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("afi", "csw_afiw", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("hda", "csw_hdaw", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("mpcore", "csw_mpcorew", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("sata", "csw_sataw", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("isp2", "csr_ispra", INVALID),
+	dummy_client,
+	client("isp2", "csw_ispwa", INVALID),
+	client("isp2", "csw_ispwb", INVALID),
+	dummy_client,
+	dummy_client,
+	client("xusb_host", "csr_xusb_hostr", INVALID),
+	client("xusb_host", "csw_xusb_hostw", INVALID),
+	client("xusb_dev", "csr_xusb_devr", INVALID),
+	client("xusb_dev", "csw_xusb_devw", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("tsec", "csr_tsecsrd", INVALID),
+	client("tsec", "csw_tsecswr", INVALID),
+	dummy_client,
+	dummy_client,
+	client("gpu", "csr_gpusrd", INVALID),
+	client("gpu", "csw_gpuswr", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("sdmmc1a", "csr_sdmmcra", INVALID),
+	client("sdmmc2a", "csr_sdmmcraa", INVALID),
+	client("sdmmc3a", "csr_sdmmcr", INVALID),
+	client("sdmmc4a", "csr_sdmmcrab", INVALID),
+	client("sdmmc1a", "csw_sdmmcwa", INVALID),
+	client("sdmmc2a", "csw_sdmmcwaa", INVALID),
+	client("sdmmc3a", "csw_sdmmcw", INVALID),
+	client("sdmmc4a", "csw_sdmmcwab", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("vic", "csr_vicsrd", INVALID),
+	client("vic", "csw_vicswr", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("vi", "csw_viw", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("nvdec", "csr_nvdecsrd", INVALID),
+	client("nvdec", "csw_nvdecswr", INVALID),
+	client("ape", "csr_aper", INVALID),
+	client("ape", "csw_apew", INVALID),
+	dummy_client,
+	dummy_client,
+	client("nvjpg", "csr_nvjpgsrd", INVALID),
+	client("nvjpg", "csw_nvjpgswr", INVALID),
+	client("se", "csr_sesrd", INVALID),
+	client("se", "csw_seswr", INVALID),
+	dummy_client,
+	dummy_client,
+	client("etr", "csr_etrr", INVALID),
+	client("etr", "csw_etrw", INVALID),
+	client("tsecb", "csr_tsecsrdb", INVALID),
+	client("tsecb", "csw_tsecswrb", INVALID),
+	client("gpu", "csr_gpusrd2", INVALID),
+	client("gpu", "csw_gpuswr2", INVALID),
+	dummy_client,
+	dummy_client,
+	client("axis", "csr_axisr", INVALID),
+	client("axis", "csw_axisw", INVALID),
+	client("eqos", "csr_eqosr", INVALID),
+	client("eqos", "csw_eqosw", INVALID),
+	client("ufshc", "csr_ufshcr", INVALID),
+	client("ufshc", "csw_ufshcw", INVALID),
+	client("nvdisplay", "csr_nvdisplayr", INVALID),
+	client("bpmp", "csr_bpmpr", INVALID),
+	client("bpmp", "csw_bpmpw", INVALID),
+	client("bpmp", "csr_bpmpdmar", INVALID),
+	client("bpmp", "csw_bpmpdmaw", INVALID),
+	client("aon", "csr_aonr", INVALID),
+	client("aon", "csw_aonw", INVALID),
+	client("aon", "csr_aondmar", INVALID),
+	client("aon", "csw_aondmaw", INVALID),
+	client("sce", "csr_scer", INVALID),
+	client("sce", "csw_scew", INVALID),
+	client("sce", "csr_scedmar", INVALID),
+	client("sce", "csw_scedmaw", INVALID),
+	client("ape", "csr_apedmar", INVALID),
+	client("ape", "csw_apedmaw", INVALID),
+	client("nvdisplay", "csr_nvdisplayr1", INVALID),
+	client("vic", "csr_vicsrd1", INVALID),
+	client("nvdec", "csr_nvdecsrd1", INVALID),
+};
+static int mc_client_last = ARRAY_SIZE(mc_clients) - 1;
+/*** Done. ***/
+
+static const char *t186_intr_info[] = {
+	NULL,		/* Bit 0 */
+	NULL,
+	NULL,
+	NULL,
+	NULL,		/* Bit 4 */
+	NULL,
+	"decerr-emem",
+	NULL,
+	"secerr",	/* Bit 8 */
+	"arb-emem",
+	NULL,
+	NULL,
+	"decerr-vpr",	/* Bit 12 */
+	"decerr-sec",
+	NULL,
+	NULL,
+	"decerr-mts",	/* Bit 16 */
+	"decerr-gsc",
+	"scrub-ecc",
+	"wcam-err",
+	NULL,		/* Bit 20 */
+	NULL,
+	NULL,
+	NULL,
+	NULL,		/* Bit 24 */
+	NULL,
+	NULL,
+	NULL,
+	NULL,		/* Bit 28 */
+	NULL,
+	NULL,
+	NULL,
+};
+
+#define MC_INT_DECERR_MTS			(1<<16)
+#define MC_INT_WCAM_ERR				(1<<19)
+
+/* hub common int status */
+#define MC_HUBC_INT_SCRUB_ECC_WR_ACK		(1 << 0)
+
+/* reported in MC_INTSTATUS_0 */
+static const struct mc_error hub_mc_errors[] = {
+	MC_ERR(MC_INT_DECERR_EMEM,
+	       "EMEM address decode error",
+	       0, MC_ERR_STATUS, MC_ERR_ADR),
+	MC_ERR(MC_INT_SECURITY_VIOLATION,
+	       "non secure access to secure region",
+	       0, MC_ERR_STATUS, MC_ERR_ADR),
+	MC_ERR(MC_INT_DECERR_VPR,
+	       "MC request violates VPR requirements",
+	       E_VPR, MC_ERR_VPR_STATUS, MC_ERR_VPR_ADR),
+	MC_ERR(MC_INT_SECERR_SEC,
+	       "MC request violated SEC carveout requirements",
+	       0, MC_ERR_SEC_STATUS, MC_ERR_SEC_ADR),
+	MC_ERR(MC_INT_DECERR_MTS,
+	       "MTS carveout access violation",
+	       0, MC_ERR_MTS_STATUS, MC_ERR_MTS_ADR),
+	MC_ERR(MC_INT_DECERR_GENERALIZED_CARVEOUT,
+	       "GSC access violation", 0,
+	       MC_ERR_GENERALIZED_CARVEOUT_STATUS,
+	       MC_ERR_GENERALIZED_CARVEOUT_ADR),
+
+	/* combination interrupts */
+	MC_ERR(MC_INT_DECERR_EMEM | MC_INT_SECURITY_VIOLATION,
+	       "non secure access to secure region",
+	       0, MC_ERR_STATUS, MC_ERR_ADR),
+	MC_ERR(MC_INT_DECERR_GENERALIZED_CARVEOUT | MC_INT_DECERR_EMEM,
+	       "EMEM GSC access violation", 0,
+	       MC_ERR_GENERALIZED_CARVEOUT_STATUS,
+	       MC_ERR_GENERALIZED_CARVEOUT_ADR),
+
+	/* NULL terminate. */
+	MC_ERR(0, NULL, 0, 0, 0),
+};
+
+/* reported in MC_CH_INTSTATUS_0 */
+static const struct mc_error ch_mc_errors[] = {
+	MC_ERR(MC_INT_WCAM_ERR, "WCAM error", E_TWO_STATUS,
+	       MC_WCAM_IRQ_P0_STATUS0,
+	       MC_WCAM_IRQ_P1_STATUS0),
+
+	/* NULL terminate. */
+	MC_ERR(0, NULL, 0, 0, 0),
+};
+
+/* reported in MC_HUBC_INTSTATUS_0 */
+static const struct mc_error hubc_mc_errors[] = {
+	MC_ERR(MC_HUBC_INT_SCRUB_ECC_WR_ACK,
+	       "ECC scrub complete", E_NO_STATUS, 0, 0),
+
+	/* NULL terminate. */
+	MC_ERR(0, NULL, 0, 0, 0),
+};
+
+enum {
+	INTSTATUS_CH0 = 0,
+	INTSTATUS_CH1 = 1,
+	INTSTATUS_CH2 = 2,
+	INTSTATUS_CH3 = 3,
+	INTSTATUS_HUB0 = 16,
+	INTSTATUS_HUB1 = 17,
+	INTSTATUS_HUBC = 24,
+};
+
+#define MC_INTSTATUS_CLEAR 0x00033340
+#define MC_CH_INTSTATUS_CLEAR 0x00080200
+#define MC_HUBC_INTSTATUS_CLEAR 0x00000001
+#define MC_GLOBAL_INTSTATUS_CLEAR 0x0103000F
+
+static void clear_interrupt(unsigned int irq)
+{
+	mc_writel(MC_INTSTATUS_CLEAR, MC_INTSTATUS);
+	mc_writel(MC_CH_INTSTATUS_CLEAR, MC_CH_INTSTATUS);
+	mc_writel(MC_HUBC_INTSTATUS_CLEAR, MC_HUBC_INTSTATUS);
+	mc_writel(MC_GLOBAL_INTSTATUS_CLEAR, MC_GLOBAL_INTSTATUS);
+}
+
+static void log_fault(int src_chan, const struct mc_error *fault)
+{
+	phys_addr_t addr;
+	struct mc_client *client;
+	u32 status, write, secure, client_id;
+
+
+	if (fault->flags & E_VPR)
+		mcerr_pr("vpr base=%x:%x, size=%x, ctrl=%x, override:(%x, %x, %x, %x)\n",
+			 mc_readl(MC_VIDEO_PROTECT_BOM_ADR_HI),
+			 mc_readl(MC_VIDEO_PROTECT_BOM),
+			 mc_readl(MC_VIDEO_PROTECT_SIZE_MB),
+			 mc_readl(MC_VIDEO_PROTECT_REG_CTRL),
+			 mc_readl(MC_VIDEO_PROTECT_VPR_OVERRIDE),
+			 mc_readl(MC_VIDEO_PROTECT_VPR_OVERRIDE1),
+			 mc_readl(MC_VIDEO_PROTECT_GPU_OVERRIDE_0),
+			 mc_readl(MC_VIDEO_PROTECT_GPU_OVERRIDE_1));
+
+	if (fault->flags & E_NO_STATUS) {
+		mcerr_pr("MC fault - no status: %s\n", fault->msg);
+		return;
+	}
+
+	status = __mc_readl(src_chan, fault->stat_reg);
+	addr = __mc_readl(src_chan, fault->addr_reg);
+
+	if (fault->flags & E_TWO_STATUS) {
+		mcerr_pr("MC fault - %s\n", fault->msg);
+		mcerr_pr("status: 0x%08x status2: 0x%08llx\n",
+			status, addr);
+		return;
+	}
+
+	secure = !!(status & MC_ERR_STATUS_SECURE);
+	write = !!(status & MC_ERR_STATUS_WRITE);
+	client_id = status & 0xff;
+	client = &mc_clients[client_id <= mc_client_last ?
+			     client_id : mc_client_last];
+
+	/*
+	 * LPAE: make sure we get the extra 2 physical address bits available
+	 * and pass them down to the printing function.
+	 */
+	addr |= (((phys_addr_t)(status & MC_ERR_STATUS_ADR_HI)) << 12);
+
+	mcerr_pr("(%d) %s: %s\n", client->swgid, client->name, fault->msg);
+	mcerr_pr("  status = 0x%08x; addr = 0x%08llx\n", status,
+		 (long long unsigned int)addr);
+	mcerr_pr("  secure: %s, access-type: %s\n",
+		secure ? "yes" : "no", write ? "write" : "read");
+}
+
+static void log_mcerr_fault(unsigned int irq)
+{
+	int faults_handled = 0;
+	const struct mc_error *err;
+	int mc_channel = MC_BROADCAST_CHANNEL;
+	u32 int_status, ch_int_status, hubc_int_status;
+	u32 g_intstatus = mc_readl(MC_GLOBAL_INTSTATUS);
+
+	/*
+	 * If multiple interrupts come in just handle the first one we see. The
+	 * HW only keeps track of 1 interrupt's data and we don't know which
+	 * particular fault is actually being kept...
+	 */
+	if (g_intstatus & (BIT(INTSTATUS_CH0)) ||
+	    g_intstatus & (BIT(INTSTATUS_HUB0))) {
+		mc_channel = 0;
+	} else if (g_intstatus & (BIT(INTSTATUS_CH1)) ||
+		   g_intstatus & (BIT(INTSTATUS_HUB1))) {
+		mc_channel = 1;
+	} else if (g_intstatus & (BIT(INTSTATUS_CH2))) {
+		mc_channel = 2;
+	} else if (g_intstatus & (BIT(INTSTATUS_CH3))) {
+		mc_channel = 3;
+	} else if (g_intstatus & (BIT(INTSTATUS_HUBC))) {
+		mc_channel = MC_BROADCAST_CHANNEL;
+	} else {
+#ifdef CONFIG_TEGRA_MC_TRACE_PRINTK
+		trace_printk("mcerr: unknown source (intstatus = 0x%08x)\n",
+			     g_intstatus);
+#endif
+		return;
+	}
+
+	int_status = __mc_readl(mc_channel, MC_INTSTATUS);
+	ch_int_status = __mc_readl(mc_channel, MC_CH_INTSTATUS);
+	hubc_int_status = __mc_readl(mc_channel, MC_HUBC_INTSTATUS);
+
+	for (err = hub_mc_errors; err->sig && err->msg; err++) {
+		if ((int_status & mc_int_mask) != err->sig)
+			continue;
+		log_fault(mc_channel, err);
+		__mc_writel(mc_channel, int_status, MC_INTSTATUS);
+		faults_handled++;
+		break;
+	}
+
+	for (err = ch_mc_errors; err->sig && err->msg; err++) {
+		if ((ch_int_status) != err->sig)
+			continue;
+		log_fault(mc_channel, err);
+		__mc_writel(mc_channel, ch_int_status, MC_CH_INTSTATUS);
+		faults_handled++;
+		break;
+	}
+
+	for (err = hubc_mc_errors; err->sig && err->msg; err++) {
+		if ((hubc_int_status) != err->sig)
+			continue;
+		log_fault(mc_channel, err);
+		__mc_writel(mc_channel, hubc_int_status, MC_HUBC_INTSTATUS);
+		faults_handled++;
+		break;
+	}
+
+	if (!faults_handled)
+		pr_err("unknown mcerr fault, int_status=0x%08x, "
+			"ch_int_status=0x%08x, hubc_int_status=0x%08x\n",
+			int_status, ch_int_status, hubc_int_status);
+}
+
+static struct mcerr_ops mcerr_ops = {
+	.nr_clients = ARRAY_SIZE(mc_clients),
+	.intr_descriptions = t186_intr_info,
+	.clear_interrupt = clear_interrupt,
+	.log_mcerr_fault = log_mcerr_fault,
+	.mc_clients = mc_clients,
+};
+
+static struct mcerr_ops *t18x_mcerr_of_setup(struct device_node *np)
+{
+	pr_info("mcerr ops are set to t18x\n");
+	return &mcerr_ops;
+}
+
+MCERR_OF_DECLARE(mcerr_of, "nvidia,tegra-t18x-mc", t18x_mcerr_of_setup);
diff --git a/drivers/platform/tegra/mc/mcerr-t19x.c b/drivers/platform/tegra/mc/mcerr-t19x.c
new file mode 100644
index 000000000000..a4725e0129cb
--- /dev/null
+++ b/drivers/platform/tegra/mc/mcerr-t19x.c
@@ -0,0 +1,643 @@
+/*
+ * Tegra 19x SoC-specific mcerr code.
+ *
+ * Copyright (c) 2017, NVIDIA Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ */
+
+#define pr_fmt(fmt) "mc-err: " fmt
+
+#include <linux/bitops.h>
+#include <linux/of.h>
+#include <linux/platform/tegra/mc-regs-t19x.h>
+#include <linux/platform/tegra/mcerr.h>
+#include <dt-bindings/memory/tegra-swgroup.h>
+#include <linux/interrupt.h>
+
+/*** Auto generated by `mcp.pl'. Do not modify! ***/
+
+static struct mc_client mc_clients[] = {
+	client("ptc", "csr_ptcr", INVALID),
+	client("miu", "csr_miu7r", INVALID),
+	client("miu", "csw_miu7w", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("hda", "csr_hdar", INVALID),
+	client("hc", "csr_host1xdmar", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("nvenc", "csr_nvencsrd", INVALID),
+	dummy_client,
+	dummy_client,
+	client("sata", "csr_satar", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("mpcore", "csr_mpcorer", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("nvenc", "csw_nvencswr", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("hda", "csw_hdaw", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("mpcore", "csw_mpcorew", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("sata", "csw_sataw", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("ispa", "csr_ispra", INVALID),
+	client("ispfal", "csr_ispfalr", INVALID),
+	client("isp2", "csw_ispwa", INVALID),
+	client("isp2a", "csw_ispwb", INVALID),
+	dummy_client,
+	dummy_client,
+	client("xusb_host", "csr_xusb_hostr", INVALID),
+	client("xusb_host", "csw_xusb_hostw", INVALID),
+	client("xusb_dev", "csr_xusb_devr", INVALID),
+	client("xusb_dev", "csw_xusb_devw", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("tsec", "csr_tsecsrd", INVALID),
+	client("tsec", "csw_tsecswr", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("sdmmc1a", "csr_sdmmcra", INVALID),
+	dummy_client,
+	client("sdmmc3a", "csr_sdmmcr", INVALID),
+	client("sdmmc4a", "csr_sdmmcrab", INVALID),
+	client("sdmmc1a", "csw_sdmmcwa", INVALID),
+	dummy_client,
+	client("sdmmc3a", "csw_sdmmcw", INVALID),
+	client("sdmmc4a", "csw_sdmmcwab", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("vic", "csr_vicsrd", INVALID),
+	client("vic", "csw_vicswr", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("vi", "csw_viw", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("nvdec", "csr_nvdecsrd", INVALID),
+	client("nvdec", "csw_nvdecswr", INVALID),
+	client("ape", "csr_aper", INVALID),
+	client("ape", "csw_apew", INVALID),
+	dummy_client,
+	dummy_client,
+	client("nvjpg", "csr_nvjpgsrd", INVALID),
+	client("nvjpg", "csw_nvjpgswr", INVALID),
+	client("se", "csr_sesrd", INVALID),
+	client("se", "csw_seswr", INVALID),
+	client("axiap", "csr_axiapr", INVALID),
+	client("axiap", "csw_axiapw", INVALID),
+	client("etr", "csr_etrr", INVALID),
+	client("etr", "csw_etrw", INVALID),
+	client("tsecb", "csr_tsecsrdb", INVALID),
+	client("tsecb", "csw_tsecswrb", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("axis", "csr_axisr", INVALID),
+	client("axis", "csw_axisw", INVALID),
+	client("eqos", "csr_eqosr", INVALID),
+	client("eqos", "csw_eqosw", INVALID),
+	client("ufshc", "csr_ufshcr", INVALID),
+	client("ufshc", "csw_ufshcw", INVALID),
+	client("nvdisplay", "csr_nvdisplayr", INVALID),
+	client("bpmp", "csr_bpmpr", INVALID),
+	client("bpmp", "csw_bpmpw", INVALID),
+	client("bpmpdma", "csr_bpmpdmar", INVALID),
+	client("bpmpdma", "csw_bpmpdmaw", INVALID),
+	client("aon", "csr_aonr", INVALID),
+	client("aon", "csw_aonw", INVALID),
+	client("aondma", "csr_aondmar", INVALID),
+	client("aondma", "csw_aondmaw", INVALID),
+	client("sce", "csr_scer", INVALID),
+	client("sce", "csw_scew", INVALID),
+	client("scedma", "csr_scedmar", INVALID),
+	client("scedma", "csw_scedmaw", INVALID),
+	client("apedma", "csr_apedmar", INVALID),
+	client("apedma", "csw_apedmaw", INVALID),
+	client("nvdisplay", "csr_nvdisplayr1", INVALID),
+	client("vic", "csr_vicsrd1", INVALID),
+	client("nvdec", "csr_nvdecsrd1", INVALID),
+	dummy_client,
+	dummy_client,
+	client("miu", "csr_miu0r", INVALID),
+	client("miu", "csw_miu0w", INVALID),
+	client("miu", "csr_miu1r", INVALID),
+	client("miu", "csw_miu1w", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("miu", "csr_miu2r", INVALID),
+	client("miu", "csw_miu2w", INVALID),
+	client("miu", "csr_miu3r", INVALID),
+	client("miu", "csw_miu3w", INVALID),
+	client("miu", "csr_miu4r", INVALID),
+	client("miu", "csw_miu4w", INVALID),
+	client("NA", "csr_dpmur", INVALID),
+	client("NA", "csw_dpmuw", INVALID),
+	client("NA", "csr_nvl0r", INVALID),
+	client("NA", "csw_nvl0w", INVALID),
+	client("NA", "csr_nvl1r", INVALID),
+	client("NA", "csw_nvl1w", INVALID),
+	client("NA", "csr_nvl2r", INVALID),
+	client("NA", "csw_nvl2w", INVALID),
+	client("vifal", "csr_vifalr", INVALID),
+	client("vifal", "csw_vifalw", INVALID),
+	client("dlaa", "csr_dla0rda", INVALID),
+	client("dlaa", "csr_dla0falrdb", INVALID),
+	client("dlaa", "csw_dla0wra", INVALID),
+	client("dlaa", "csw_dla0falwrb", INVALID),
+	client("dla1a", "csr_dla1rda", INVALID),
+	client("dla1a", "csr_dla1falrdb", INVALID),
+	client("dla1a", "csw_dla1wra", INVALID),
+	client("dla1a", "csw_dla1falwrb", INVALID),
+	client("pva0a", "csr_pva0rda", INVALID),
+	client("pva0b", "csr_pva0rdb", INVALID),
+	client("pva0c", "csr_pva0rdc", INVALID),
+	client("pva0a", "csw_pva0wra", INVALID),
+	client("pva0b", "csw_pva0wrb", INVALID),
+	client("pva0c", "csw_pva0wrc", INVALID),
+	client("pva1a", "csr_pva1rda", INVALID),
+	client("pva1b", "csr_pva1rdb", INVALID),
+	client("pva1c", "csr_pva1rdc", INVALID),
+	client("pva1a", "csw_pva1wra", INVALID),
+	client("pva1b", "csw_pva1wrb", INVALID),
+	client("pva1c", "csw_pva1wrc", INVALID),
+	client("rce", "csr_rcer", INVALID),
+	client("rce", "csw_rcew", INVALID),
+	client("rcedma", "csr_rcedmar", INVALID),
+	client("rcedma", "csw_rcedmaw", INVALID),
+	client("nvencb", "csr_nvenc1srd", INVALID),
+	client("nvencb", "csw_nvenc1swr", INVALID),
+	client("pcie0a", "csr_pcie0r", INVALID),
+	client("pcie0a2", "csw_pcie0w", INVALID),
+	client("pcie", "csr_pcie1r", INVALID),
+	client("pcie", "csw_pcie1w", INVALID),
+	client("pcie2a", "csr_pcie2ar", INVALID),
+	client("pcie2a", "csw_pcie2aw", INVALID),
+	client("pcie3", "csr_pcie3r", INVALID),
+	client("pcie3a", "csw_pcie3w", INVALID),
+	client("pcie4a", "csr_pcie4r", INVALID),
+	client("pcie4a", "csw_pcie4w", INVALID),
+	client("pcie5a", "csr_pcie5r", INVALID),
+	client("pcie5a", "csw_pcie5w", INVALID),
+	client("ispfal", "csw_ispfalw", INVALID),
+	client("NA", "csr_nvl3r", INVALID),
+	client("NA", "csw_nvl3w", INVALID),
+	client("NA", "csr_nvl4r", INVALID),
+	client("NA", "csw_nvl4w", INVALID),
+	client("dlaa", "csr_dla0rda1", INVALID),
+	client("dla1a", "csr_dla1rda1", INVALID),
+	client("pva0a", "csr_pva0rda1", INVALID),
+	client("pva0b", "csr_pva0rdb1", INVALID),
+	client("pva1a", "csr_pva1rda1", INVALID),
+	client("pva1b", "csr_pva1rdb1", INVALID),
+	client("pcie5a", "csr_pcie5r1", INVALID),
+	client("nvenc", "csr_nvencsrd1", INVALID),
+	client("nvencb", "csr_nvenc1srd1", INVALID),
+	client("ispa", "csr_ispra1", INVALID),
+	client("pcie0a", "csr_pcie0r1", INVALID),
+	client("NA", "csr_nvl0rhp", INVALID),
+	client("NA", "csr_nvl1rhp", INVALID),
+	client("NA", "csr_nvl2rhp", INVALID),
+	client("NA", "csr_nvl3rhp", INVALID),
+	client("NA", "csr_nvl4rhp", INVALID),
+	client("nvdec2a", "csr_nvdec1srd", INVALID),
+	client("nvdec2a", "csr_nvdec1srd1", INVALID),
+	client("nvdec2a", "csw_nvdec1swr", INVALID),
+	client("miu", "csr_miu5r", INVALID),
+	client("miu", "csw_miu5w", INVALID),
+	client("miu", "csr_miu6r", INVALID),
+	client("miu", "csw_miu6w", INVALID),
+};
+static int mc_client_last = ARRAY_SIZE(mc_clients) - 1;
+/*** Done. ***/
+
+static const char *intr_info[] = {
+	NULL,		/* Bit 0 */
+	NULL,
+	NULL,
+	NULL,
+	NULL,		/* Bit 4 */
+	NULL,
+	"decerr-emem",
+	NULL,
+	"secerr",	/* Bit 8 */
+	"arb-emem",
+	NULL,
+	NULL,
+	"decerr-vpr",	/* Bit 12 */
+	"decerr-sec",
+	NULL,
+	NULL,
+	"decerr-mts",	/* Bit 16 */
+	"decerr-gsc",
+	"scrub-ecc",
+	"wcam-err",
+	"decerr-route",	/* Bit 20 */
+	NULL,
+	NULL,
+	NULL,
+	NULL,		/* Bit 24 */
+	NULL,
+	NULL,
+	NULL,
+	NULL,		/* Bit 28 */
+	NULL,
+	NULL,
+	NULL,
+};
+
+enum {
+	/* GLOBAL_INTSTATUS_0 bits */
+	GIS_CH0 = 0,
+	GIS_CH1 = 1,
+	GIS_CH2 = 2,
+	GIS_CH3 = 3,
+	GIS_CH4 = 4,
+	GIS_CH5 = 5,
+	GIS_CH6 = 6,
+	GIS_CH7 = 7,
+	GIS_SLICE0 = 8,
+	GIS_SLICE1 = 9,
+	GIS_SLICE2 = 10,
+	GIS_SLICE3 = 11,
+	GIS_HUB0 = 16,
+	GIS_HUB1 = 17,
+	GIS_HUB2 = 18,
+	GIS_HUB3 = 19,
+	GIS_nvlink0 = 20,
+	GIS_nvlink1 = 21,
+	GIS_nvlink2 = 22,
+	GIS_nvlink3 = 23,
+	GIS_nvlink4 = 24,
+	GIS_HUBC = 25,
+	GIS_SBS = 26,
+	GIS_CH_MASK = 0xFF,
+	GIS_SLICE_MASK = 0xF00,
+	GIS_HUB_MASK = 0xF0000,
+	GIS_NVLINK_MASK = 0x1F00000,
+
+	/* GLOBAL_INTSTATUS_1 bits */
+	GIS_1_CH8 = 0,
+	GIS_1_CH9 = 1,
+	GIS_1_CH10 = 2,
+	GIS_1_CH11 = 3,
+	GIS_1_CH12 = 4,
+	GIS_1_CH13 = 5,
+	GIS_1_CH14 = 6,
+	GIS_1_CH15 = 7,
+	GIS_1_CH_MASK = 0xFF,
+
+	/* MC Intr clear enums */
+	INTSTATUS_CLEAR = 0x00133340,
+	HUBC_INTSTATUS_CLEAR = 0x00000001,
+	HUB_INTSTATUS_CLEAR = 0x00000003,
+	GLOBAL_INTSTATUS_CLEAR = 0x07FF0FFF,
+	GLOBAL_INTSTATUS_1_CLEAR = 0x000000FF,
+	CH_INTSTATUS_CLEAR = 0x00080200,
+	SBS_INTSTATUS_CLEAR = 0x00000007,
+
+	/* MC Intr bits */
+	MC_INT_DECERR_MTS = (1<<16),
+	MC_INT_WCAM_ERR = (1<<19),
+	MC_INT_DECERR_ROUTE_SANITY = (1<<20),
+	MC_HUB_INT_HUB_COALESCER_ERR = (1<<1),
+	MC_HUB_INT_ILLEGAL_HUB_REQ = (1<<0),
+	MC_HUBC_INT_SCRUB_ECC_WR_ACK = (1 << 0),
+
+	MC_SBS_INT_FILL_FIFO_ISO_OF = (1<<0),
+	MC_SBS_INT_FILL_FIFO_SISO_OF = (1<<1),
+	MC_SBS_INT_FILL_FIFO_NISO_OF = (1<<2),
+
+	MC_ERR_STATUS_ADR_HI_BITS = (0xFF << 20)
+};
+
+/* reported in MC_INTSTATUS_0 */
+static const struct mc_error slice_mc_errors[] = {
+	MC_ERR_HI(MC_INT_DECERR_EMEM,
+	       "EMEM address decode error",
+	       0, MC_ERR_STATUS, MC_ERR_ADR, MC_ERR_ADR_HI),
+	MC_ERR_HI(MC_INT_SECURITY_VIOLATION,
+	       "non secure access to secure region",
+	       0, MC_ERR_STATUS, MC_ERR_ADR, MC_ERR_ADR_HI),
+	MC_ERR(MC_INT_DECERR_VPR,
+	       "MC request violates VPR requirements",
+	       E_VPR, MC_ERR_VPR_STATUS, MC_ERR_VPR_ADR),
+	MC_ERR(MC_INT_SECERR_SEC,
+	       "MC request violated SEC carveout requirements",
+	       0, MC_ERR_SEC_STATUS, MC_ERR_SEC_ADR),
+	MC_ERR(MC_INT_DECERR_MTS,
+	       "MTS carveout access violation",
+	       0, MC_ERR_MTS_STATUS, MC_ERR_MTS_ADR),
+	MC_ERR_GSC(MC_INT_DECERR_GENERALIZED_CARVEOUT,
+	       "GSC access violation", 0,
+	       MC_ERR_GENERALIZED_CARVEOUT_STATUS,
+	       MC_ERR_GENERALIZED_CARVEOUT_ADR,
+	       MC_ERR_GENERALIZED_CARVEOUT_STATUS_1),
+	MC_ERR(MC_INT_DECERR_ROUTE_SANITY,
+		"Route Sanity error", 0,
+		MC_ERR_ROUTE_SANITY_STATUS,
+		MC_ERR_ROUTE_SANITY_ADR),
+
+	/* combination interrupts */
+	MC_ERR_HI(MC_INT_DECERR_EMEM | MC_INT_SECURITY_VIOLATION,
+	       "non secure access to secure region",
+	       0, MC_ERR_STATUS, MC_ERR_ADR, MC_ERR_ADR_HI),
+	MC_ERR(MC_INT_DECERR_GENERALIZED_CARVEOUT | MC_INT_DECERR_EMEM,
+	       "EMEM GSC access violation", 0,
+	       MC_ERR_GENERALIZED_CARVEOUT_STATUS,
+	       MC_ERR_GENERALIZED_CARVEOUT_ADR),
+
+	/* NULL terminate. */
+	MC_ERR(0, NULL, 0, 0, 0),
+};
+
+/* reported in MC_CH_INTSTATUS_0 */
+static const struct mc_error ch_mc_errors[] = {
+	MC_ERR(MC_INT_WCAM_ERR, "WCAM error", E_TWO_STATUS,
+	       MC_WCAM_IRQ_P0_STATUS0,
+	       MC_WCAM_IRQ_P1_STATUS0),
+
+	/* NULL terminate. */
+	MC_ERR(0, NULL, 0, 0, 0),
+};
+
+/* reported in MC_HUBC_INTSTATUS_0 */
+static const struct mc_error hubc_mc_errors[] = {
+	MC_ERR(MC_HUBC_INT_SCRUB_ECC_WR_ACK,
+	       "ECC scrub complete", E_NO_STATUS, 0, 0),
+
+	/* NULL terminate. */
+	MC_ERR(0, NULL, 0, 0, 0),
+};
+
+/* reported in MC_HUB_INTSTATUS_0 */
+static const struct mc_error hub_mc_errors[] = {
+	MC_ERR_HI(MC_HUB_INT_HUB_COALESCER_ERR,
+	       "Hub coalescer error", 0,
+	       MC_COALESCE_ERR_STATUS, MC_COALESCE_ERR_ADR,
+	       MC_COALESCE_ERR_ADR_HI),
+	MC_ERR_HI(MC_HUB_INT_ILLEGAL_HUB_REQ,
+	       "Illegal Hub Request", 0,
+	       MC_COALESCE_ERR_STATUS, MC_COALESCE_ERR_ADR,
+	       MC_COALESCE_ERR_ADR_HI),
+
+	/* NULL terminate. */
+	MC_ERR(0, NULL, 0, 0, 0),
+};
+
+/* reported in MC_SBS_INTSTATUS_0 */
+static const struct mc_error sbs_mc_errors[] = {
+	MC_ERR(MC_SBS_INT_FILL_FIFO_ISO_OF,
+	       "SBS ISO fifo overflow", 0, E_NO_STATUS, 0),
+	MC_ERR(MC_SBS_INT_FILL_FIFO_SISO_OF,
+	       "SBS SISO fifo overflow", 0, E_NO_STATUS, 0),
+	MC_ERR(MC_SBS_INT_FILL_FIFO_NISO_OF,
+	       "SBS NISO fifo overflow", 0, E_NO_STATUS, 0),
+
+	/* NULL terminate. */
+	MC_ERR(0, NULL, 0, 0, 0),
+};
+
+static void clear_interrupt(unsigned int irq)
+{
+	/* The mcerr throttling mechanism would call clear interrupt.
+	 * clear interrupt recovers the system from continuous mc error
+	 * interrupt as well in case an error is not handled right.
+	 */
+	mc_writel(INTSTATUS_CLEAR, MC_INTSTATUS);
+	mc_writel(HUBC_INTSTATUS_CLEAR, MC_HUBC_INTSTATUS);
+	mc_writel(HUB_INTSTATUS_CLEAR, MC_HUB_INTSTATUS);
+	mc_writel(CH_INTSTATUS_CLEAR, MC_CH_INTSTATUS);
+	mc_writel(SBS_INTSTATUS_CLEAR, MC_MSS_SBS_INTSTATUS);
+	mc_writel(GLOBAL_INTSTATUS_CLEAR, MC_GLOBAL_INTSTATUS);
+	mc_writel(GLOBAL_INTSTATUS_1_CLEAR, MC_GLOBAL_INTSTATUS_1);
+}
+
+static void log_fault(int src_chan, const struct mc_error *fault)
+{
+	phys_addr_t addr;
+	struct mc_client *client;
+	u32 status, write, secure, client_id;
+	u32 gsc_status_1, high_addr_reg = 0;
+
+
+	if (fault->flags & E_VPR)
+		mcerr_pr("vpr base=%x:%x, size=%x, ctrl=%x, override:(%x, %x, %x, %x)\n",
+			 mc_readl(MC_VIDEO_PROTECT_BOM_ADR_HI),
+			 mc_readl(MC_VIDEO_PROTECT_BOM),
+			 mc_readl(MC_VIDEO_PROTECT_SIZE_MB),
+			 mc_readl(MC_VIDEO_PROTECT_REG_CTRL),
+			 mc_readl(MC_VIDEO_PROTECT_VPR_OVERRIDE),
+			 mc_readl(MC_VIDEO_PROTECT_VPR_OVERRIDE1),
+			 mc_readl(MC_VIDEO_PROTECT_GPU_OVERRIDE_0),
+			 mc_readl(MC_VIDEO_PROTECT_GPU_OVERRIDE_1));
+
+	if (fault->flags & E_NO_STATUS) {
+		mcerr_pr("MC fault - no status: %s\n", fault->msg);
+		return;
+	}
+
+	status = __mc_readl(src_chan, fault->stat_reg);
+	addr = __mc_readl(src_chan, fault->addr_reg);
+
+	if (fault->flags & E_TWO_STATUS) {
+		mcerr_pr("MC fault - %s\n", fault->msg);
+		mcerr_pr("status: 0x%08x status2: 0x%08llx\n",
+			status, addr);
+		return;
+	}
+
+	secure = !!(status & MC_ERR_STATUS_SECURE);
+	write = !!(status & MC_ERR_STATUS_WRITE);
+	client_id = status & 0xff;
+	client = &mc_clients[client_id <= mc_client_last
+			     ? client_id : mc_client_last];
+
+	if (fault->flags & E_GSC) {
+		high_addr_reg = __mc_readl(src_chan, fault->addr_hi_reg);
+		addr |= ((phys_addr_t)(high_addr_reg >> 16) << 32);
+	} else if (fault->flags & E_ADR_HI_REG) {
+		high_addr_reg = __mc_readl(src_chan, fault->addr_hi_reg);
+		addr |= ((phys_addr_t)high_addr_reg << 32);
+	} else {
+		addr |= (((phys_addr_t)(status & MC_ERR_STATUS_ADR_HI_BITS)) << 12);
+	}
+
+	mcerr_pr("(%d) %s: %s\n", client->swgid, client->name, fault->msg);
+	mcerr_pr("  status = 0x%08x; addr = 0x%08llx; hi_adr_reg=%x08\n",
+		status, (long long unsigned int)addr, high_addr_reg);
+	mcerr_pr("  secure: %s, access-type: %s\n",
+		secure ? "yes" : "no", write ? "write" : "read");
+	if (fault->flags & E_GSC) {
+		gsc_status_1 = __mc_readl(src_chan, fault->addr_hi_reg);
+		mcerr_pr("gsc_id=%d, gsc_co_id=%d\n",
+			((status >> 8) & 0x7) | ((gsc_status_1 & 3) << 3),
+			((status >> 24) & 0x7) | (((gsc_status_1 >> 7) & 0x3) << 3));
+	}
+}
+
+#define LOG_FAULT(n, m, r) \
+	for (err = n##_mc_errors; \
+	     n##_int_status && err->sig && err->msg; err++) { \
+		if ((n##_int_status & m) != err->sig) \
+			continue; \
+		log_fault(mc_channel, err); \
+		__mc_writel(mc_channel, n##_int_status, MC##r##INTSTATUS); \
+		faults_handled++; \
+		break; \
+	} \
+
+static void log_mcerr_fault(unsigned int irq)
+{
+	int faults_handled = 0;
+	const struct mc_error *err;
+	int mc_channel = MC_BROADCAST_CHANNEL;
+	u32 slice_int_status, ch_int_status, hubc_int_status;
+	u32 sbs_int_status, hub_int_status;
+	u32 g_intstatus = mc_readl(MC_GLOBAL_INTSTATUS);
+	u32 g_intstatus_1 = mc_readl(MC_GLOBAL_INTSTATUS_1);
+
+	/*
+	 * If multiple interrupts come in just handle the first one we see. The
+	 * HW only keeps track of 1 interrupt's data and we don't know which
+	 * particular fault is actually being kept...
+	 */
+
+	if (g_intstatus & GIS_CH_MASK) {
+		mc_channel = __ffs(g_intstatus & GIS_CH_MASK);
+	} else if (g_intstatus & GIS_SLICE_MASK){
+		mc_channel = __ffs((g_intstatus & GIS_SLICE_MASK) >> GIS_SLICE0);
+	} else if (g_intstatus & GIS_HUB_MASK) {
+		mc_channel = __ffs((g_intstatus & GIS_HUB_MASK) >> GIS_HUB0);
+	} else if (g_intstatus & GIS_NVLINK_MASK) {
+		mc_channel = __ffs((g_intstatus & GIS_NVLINK_MASK) >> GIS_nvlink0);
+	} else if (g_intstatus & BIT(GIS_HUBC)) {
+		mc_channel = MC_BROADCAST_CHANNEL;
+	} else if (g_intstatus & BIT(GIS_SBS)) {
+		mc_channel = MC_BROADCAST_CHANNEL;
+	} else if (g_intstatus_1 & GIS_1_CH_MASK) {
+		mc_channel = 8 + __ffs(g_intstatus_1 & GIS_1_CH_MASK);
+	} else {
+		mcerr_pr("mcerr: unknown intr source intstatus = 0x%08x, "
+			 "intstatus_1 = 0x%08x\n", g_intstatus, g_intstatus_1);
+		return;
+	}
+
+	slice_int_status = __mc_readl(mc_channel, MC_INTSTATUS);
+	ch_int_status = __mc_readl(mc_channel, MC_CH_INTSTATUS);
+	hubc_int_status = __mc_readl(mc_channel, MC_HUBC_INTSTATUS);
+	sbs_int_status = __mc_readl(mc_channel, MC_MSS_SBS_INTSTATUS);
+	hub_int_status = __mc_readl(mc_channel, MC_HUB_INTSTATUS);
+
+	LOG_FAULT(slice, mc_int_mask, _);
+	LOG_FAULT(hub, U32_MAX, _HUB_);
+	LOG_FAULT(ch, U32_MAX, _CH_);
+	LOG_FAULT(hubc, U32_MAX, _HUBC_);
+	LOG_FAULT(sbs, U32_MAX, _MSS_SBS_);
+
+	if (faults_handled) {
+		mc_writel(g_intstatus, MC_GLOBAL_INTSTATUS);
+		mc_writel(g_intstatus_1, MC_GLOBAL_INTSTATUS_1);
+	} else {
+		pr_err("unknown mcerr fault, int_status=0x%08x, "
+			"ch_int_status=0x%08x, hubc_int_status=0x%08x "
+			"sbs_int_status=0x%08x, hub_int_status=0x%08x\n",
+			slice_int_status, ch_int_status, hubc_int_status,
+			sbs_int_status, hub_int_status);
+	}
+}
+
+static struct mcerr_ops mcerr_ops = {
+	.nr_clients = ARRAY_SIZE(mc_clients),
+	.intr_descriptions = intr_info,
+	.clear_interrupt = clear_interrupt,
+	.log_mcerr_fault = log_mcerr_fault,
+	.mc_clients = mc_clients,
+};
+
+static struct mcerr_ops *t18x_mcerr_of_setup(struct device_node *np)
+{
+	pr_info("mcerr ops are set to t19x\n");
+	return &mcerr_ops;
+}
+
+MCERR_OF_DECLARE(mcerr_of, "nvidia,tegra-t19x-mc", t18x_mcerr_of_setup);
diff --git a/drivers/platform/tegra/mc/mcerr-t21.c b/drivers/platform/tegra/mc/mcerr-t21.c
new file mode 100644
index 000000000000..6aafa4b90555
--- /dev/null
+++ b/drivers/platform/tegra/mc/mcerr-t21.c
@@ -0,0 +1,494 @@
+/*
+ * Tegra 12x SoC-specific mcerr code.
+ *
+ * Copyright (c) 2014-2017, NVIDIA Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ */
+
+#define pr_fmt(fmt) "mc-err: " fmt
+
+#include <linux/of.h>
+#include <linux/moduleparam.h>
+#include <linux/version.h>
+#if LINUX_VERSION_CODE > KERNEL_VERSION(4, 13, 0)
+#include <linux/sched/clock.h>
+#endif
+#include <linux/platform/tegra/mc-regs-t21x.h>
+#include <linux/platform/tegra/mcerr.h>
+#include <dt-bindings/memory/tegra-swgroup.h>
+
+/*** Auto generated by `mcp.pl'. Do not modify! ***/
+
+static struct mc_client mc_clients[] = {
+	client("ptc", "csr_ptcr", INVALID),
+	client("dc", "csr_display0a", DC),
+	client("dcb", "csr_display0ab", DCB),
+	client("dc", "csr_display0b", DC),
+	client("dcb", "csr_display0bb", DCB),
+	client("dc", "csr_display0c", DC),
+	client("dcb", "csr_display0cb", DCB),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("afi", "csr_afir", AFI),
+	client("avpc", "csr_avpcarm7r", AVPC),
+	client("dc", "csr_displayhc", DC),
+	client("dcb", "csr_displayhcb", DCB),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("hda", "csr_hdar", HDA),
+	client("hc", "csr_host1xdmar", HC),
+	client("hc", "csr_host1xr", HC),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("nvenc", "csr_nvencsrd", NVENC),
+	client("ppcs", "csr_ppcsahbdmar", PPCS),
+	client("ppcs", "csr_ppcsahbslvr", PPCS),
+	client("sata", "csr_satar", SATA),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("mpcore", "csr_mpcorer", INVALID),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("nvenc", "csw_nvencswr", NVENC),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("afi", "csw_afiw", AFI),
+	client("avpc", "csw_avpcarm7w", AVPC),
+	dummy_client,
+	dummy_client,
+	client("hda", "csw_hdaw", HDA),
+	client("hc", "csw_host1xw", HC),
+	dummy_client,
+	dummy_client,
+	client("mpcore", "csw_mpcorew", INVALID),
+	dummy_client,
+	client("ppcs", "csw_ppcsahbdmaw", PPCS),
+	client("ppcs", "csw_ppcsahbslvw", PPCS),
+	client("sata", "csw_sataw", SATA),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("isp2", "csr_ispra", ISP2),
+	dummy_client,
+	client("isp2", "csw_ispwa", ISP2),
+	client("isp2", "csw_ispwb", ISP2),
+	dummy_client,
+	dummy_client,
+	client("xusb_host", "csr_xusb_hostr", XUSB_HOST),
+	client("xusb_host", "csw_xusb_hostw", XUSB_HOST),
+	client("xusb_dev", "csr_xusb_devr", XUSB_DEV),
+	client("xusb_dev", "csw_xusb_devw", XUSB_DEV),
+	client("isp2b/se2", "csr_isprab/csr_se2srd", ISP2B), /* isp2b is replaced with se2 on T210b01 */
+	dummy_client,
+	client("isp2b/se2", "csw_ispw/csw_se2swr", ISP2B),
+	client("isp2b/se2", "csw_ispwbb/unused", ISP2B),
+	dummy_client,
+	dummy_client,
+	client("tsec", "csr_tsecsrd", TSEC),
+	client("tsec", "csw_tsecswr", TSEC),
+	client("a9avp", "csr_a9avpscr", A9AVP),
+	client("a9avp", "csw_a9avpscw", A9AVP),
+	client("gpu", "csr_gpusrd", GPU),
+	client("gpu", "csw_gpuswr", GPU),
+	client("dc", "csr_displayt", DC),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("sdmmc1a", "csr_sdmmcra", SDMMC1A),
+	client("sdmmc2a", "csr_sdmmcraa", SDMMC2A),
+	client("sdmmc3a", "csr_sdmmcr", SDMMC3A),
+	client("sdmmc4a", "csr_sdmmcrab", SDMMC4A),
+	client("sdmmc1a", "csw_sdmmcwa", SDMMC1A),
+	client("sdmmc2a", "csw_sdmmcwaa", SDMMC2A),
+	client("sdmmc3a", "csw_sdmmcw", SDMMC3A),
+	client("sdmmc4a", "csw_sdmmcwab", SDMMC4A),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("vic", "csr_vicsrd", VIC),
+	client("vic", "csw_vicswr", VIC),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("vi", "csw_viw", VI),
+	client("dc", "csr_displayd", DC),
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	dummy_client,
+	client("nvdec", "csr_nvdecsrd", NVDEC),
+	client("nvdec", "csw_nvdecswr", NVDEC),
+	client("ape", "csr_aper", INVALID),
+	client("ape", "csw_apew", INVALID),
+	dummy_client,
+	dummy_client,
+	client("nvjpg", "csr_nvjpgsrd", NVJPG),
+	client("nvjpg", "csw_nvjpgswr", NVJPG),
+	client("se", "csr_sesrd", SE),
+	client("se", "csw_seswr", SE),
+	client("axiap", "csr_axiapr", INVALID),
+	client("axiap", "csw_axiapw", INVALID),
+	client("etr", "csr_etrr", INVALID),
+	client("etr", "csw_etrw", INVALID),
+	client("tsecb", "csr_tsecsrdb", TSECB),
+	client("tsecb", "csw_tsecswrb", TSECB),
+	client("gpu", "csr_gpusrd2", GPU),
+	client("gpu", "csw_gpuswr2", GPU),
+};
+static int mc_client_last = ARRAY_SIZE(mc_clients) - 1;
+/*** Done. ***/
+
+static const char *t210_intr_info[] = {
+	NULL,		/* Bit 0 */
+	NULL,
+	NULL,
+	NULL,
+	NULL,		/* Bit 4 */
+	NULL,
+	"decerr-emem",
+	NULL,
+	"secerr",	/* Bit 8 */
+	"arb-emem",
+	"smmu-err",
+	"apb_err",
+	"decerr-vpr",	/* Bit 12 */
+	"decerr-sec",
+	NULL,
+	NULL,
+	"decerr-mts",	/* Bit 16 */
+	"decerr-gsc",
+	NULL,
+	NULL,
+	NULL,		/* Bit 20 */
+	NULL,
+	"decerr-untranslated", /* specific to t210b01 */
+	NULL,
+	NULL,		/* Bit 24 */
+	NULL,
+	NULL,
+	NULL,
+	NULL,		/* Bit 28 */
+	NULL,
+	NULL,
+	NULL,
+};
+
+/*
+ * Some platforms report SMMU errors via the SMMU driver.
+ */
+static const char *const smmu_page_attrib[] = {
+	"nr-nw-s",
+	"nr-nw-ns",
+	"nr-wr-s",
+	"nr-wr-ns",
+	"rd-nw-s",
+	"rd-nw-ns",
+	"rd-wr-s",
+	"rd-wr-ns"
+};
+
+#define MC_INT_DECERR_UNTRANSLATED_VIOLATION		(1<<22)
+
+#define MC_ERR_SMMU_MASK		(0x7 << 25)
+#define MC_ERR_SMMU_BITS(err)		(((err) & MC_ERR_SMMU_MASK) >> 25)
+
+#define MC_INT_INVALID_SMMU_PAGE		(1<<10)
+#define MC_INT_INVALID_APB_ASID_UPDATE		(1<<11)
+
+/*
+ * Table of known errors and their interrupt signatures.
+ */
+static const struct mc_error mc_errors[] = {
+	MC_ERR(MC_INT_DECERR_EMEM,
+	       "EMEM address decode error",
+	       0, MC_ERR_STATUS, MC_ERR_ADR),
+	MC_ERR(MC_INT_DECERR_VPR,
+	       "MC request violates VPR requirements",
+	       E_VPR, MC_ERR_VPR_STATUS, MC_ERR_VPR_ADR),
+	MC_ERR(MC_INT_SECURITY_VIOLATION,
+	       "non secure access to secure region",
+	       0, MC_ERR_STATUS, MC_ERR_ADR),
+	MC_ERR(MC_INT_DECERR_EMEM | MC_INT_SECURITY_VIOLATION,
+	       "non secure access to secure region",
+	       0, MC_ERR_STATUS, MC_ERR_ADR),
+	MC_ERR(MC_INT_SECERR_SEC,
+	       "MC request violated SEC carveout requirements",
+	       0, MC_ERR_SEC_STATUS, MC_ERR_SEC_ADR),
+
+	/*
+	 * SMMU related faults.
+	 */
+	MC_ERR(MC_INT_INVALID_SMMU_PAGE,
+	       "SMMU address translation fault",
+	       E_SMMU, MC_ERR_STATUS, MC_ERR_ADR),
+	MC_ERR(MC_INT_INVALID_SMMU_PAGE | MC_INT_DECERR_EMEM,
+	       "EMEM decode error on PDE or PTE entry",
+	       E_SMMU, MC_ERR_STATUS, MC_ERR_ADR),
+	MC_ERR(MC_INT_INVALID_SMMU_PAGE | MC_INT_SECERR_SEC,
+	       "secure SMMU address translation fault",
+	       E_SMMU, MC_ERR_SEC_STATUS, MC_ERR_SEC_ADR),
+	MC_ERR(MC_INT_INVALID_SMMU_PAGE | MC_INT_DECERR_VPR,
+	       "VPR SMMU address translation fault",
+	       E_VPR | E_SMMU, MC_ERR_VPR_STATUS, MC_ERR_VPR_ADR),
+	MC_ERR(MC_INT_INVALID_SMMU_PAGE | MC_INT_DECERR_VPR |
+	       MC_INT_DECERR_EMEM,
+	       "EMEM decode error on PDE or PTE entry on VPR context",
+	       E_VPR | E_SMMU, MC_ERR_VPR_STATUS, MC_ERR_VPR_ADR),
+
+	/*
+	 * Generalized carveouts.
+	 */
+	MC_ERR(MC_INT_DECERR_GENERALIZED_CARVEOUT,
+	       "GSC access violation", 0,
+	       MC_ERR_GENERALIZED_CARVEOUT_STATUS,
+	       MC_ERR_GENERALIZED_CARVEOUT_ADR),
+	MC_ERR(MC_INT_DECERR_GENERALIZED_CARVEOUT | MC_INT_DECERR_EMEM,
+	       "EMEM GSC access violation", 0,
+	       MC_ERR_GENERALIZED_CARVEOUT_STATUS,
+	       MC_ERR_GENERALIZED_CARVEOUT_ADR),
+
+	MC_ERR(MC_INT_DECERR_UNTRANSLATED_VIOLATION,
+	       "Untranslated memory access violation",
+	       0, MC_ERR_STATUS, MC_ERR_ADR),
+
+	/*
+	 * Miscellaneous errors.
+	 */
+	MC_ERR(MC_INT_INVALID_APB_ASID_UPDATE,
+	       "invalid APB ASID update", 0,
+	       MC_ERR_STATUS, MC_ERR_ADR),
+
+	/* NULL terminate. */
+	MC_ERR(0, NULL, 0, 0, 0),
+};
+
+static int arb_intr_mma_set(const char *arg, const struct kernel_param *kp);
+static int arb_intr_mma_get(char *buff, const struct kernel_param *kp);
+
+static struct arb_emem_intr_info arb_intr_info = {
+	.lock = __SPIN_LOCK_UNLOCKED(arb_intr_info.lock),
+};
+static int arb_intr_count;
+
+static struct kernel_param_ops arb_intr_mma_ops = {
+	.get = arb_intr_mma_get,
+	.set = arb_intr_mma_set,
+};
+
+module_param_cb(arb_intr_mma_in_ms, &arb_intr_mma_ops,
+		&arb_intr_info.arb_intr_mma, S_IRUGO | S_IWUSR);
+module_param(arb_intr_count, int, S_IRUGO | S_IWUSR);
+
+static int arb_intr_mma_set(const char *arg, const struct kernel_param *kp)
+{
+	int ret;
+	unsigned long flags;
+
+	spin_lock_irqsave(&arb_intr_info.lock, flags);
+	ret = param_set_int(arg, kp);
+	spin_unlock_irqrestore(&arb_intr_info.lock, flags);
+	return ret;
+}
+
+static int arb_intr_mma_get(char *buff, const struct kernel_param *kp)
+{
+	return param_get_int(buff, kp);
+}
+
+static const struct mc_error *mcerr_default_info(u32 intr)
+{
+	const struct mc_error *err;
+
+	for (err = mc_errors; err->sig && err->msg; err++) {
+		if (intr != err->sig)
+			continue;
+		return err;
+	}
+
+	return NULL;
+}
+
+void __weak smmu_dump_pagetable(int swgid, dma_addr_t addr)
+{
+}
+
+/*
+ * This will print at least 8 hex digits for address. If the address is bigger
+ * then more digits will be printed but the full 16 hex digits for a 64 bit
+ * address will not get printed by the current code.
+ */
+static void mcerr_default_print(const struct mc_error *err,
+				const struct mc_client *client,
+				u32 status, phys_addr_t addr,
+				int secure, int rw, const char *smmu_info)
+{
+	if (smmu_info)
+		smmu_dump_pagetable(client->swgid, addr);
+
+	if (err->flags & E_VPR)
+		mcerr_pr("vpr base=%x:%x, size=%x, ctrl=%x, override:(%x, %x, %x, %x)\n",
+			 mc_readl(MC_VIDEO_PROTECT_BOM_ADR_HI),
+			 mc_readl(MC_VIDEO_PROTECT_BOM),
+			 mc_readl(MC_VIDEO_PROTECT_SIZE_MB),
+			 mc_readl(MC_VIDEO_PROTECT_REG_CTRL),
+			 mc_readl(MC_VIDEO_PROTECT_VPR_OVERRIDE),
+			 mc_readl(MC_VIDEO_PROTECT_VPR_OVERRIDE1),
+			 mc_readl(MC_VIDEO_PROTECT_GPU_OVERRIDE_0),
+			 mc_readl(MC_VIDEO_PROTECT_GPU_OVERRIDE_1));
+
+	mcerr_pr("(%d) %s: %s\n", client->swgid, client->name, err->msg);
+	mcerr_pr("  status = 0x%08x; addr = 0x%08llx\n", status,
+		 (long long unsigned int)addr);
+	mcerr_pr("  secure: %s, access-type: %s, SMMU fault: %s\n",
+		secure ? "yes" : "no", rw ? "write" : "read",
+		smmu_info ? smmu_info : "none");
+}
+
+static void arb_intr(void)
+{
+	u64 time;
+	u32 time_diff_ms;
+	unsigned long flags;
+
+	spin_lock_irqsave(&arb_intr_info.lock, flags);
+	arb_intr_count++;
+	time = sched_clock();
+	time_diff_ms = (time - arb_intr_info.time) >> 20;
+	arb_intr_info.time = time;
+	arb_intr_info.arb_intr_mma =
+		((MMA_HISTORY_SAMPLES - 1) * time_diff_ms +
+		 arb_intr_info.arb_intr_mma) / MMA_HISTORY_SAMPLES;
+	spin_unlock_irqrestore(&arb_intr_info.lock, flags);
+}
+
+static void clear_interrupt(unsigned int irq)
+{
+	mc_writel(0x00033F40, MC_INTSTATUS);
+}
+
+static void mcerr_info_update(struct mc_client *c, u32 stat)
+{
+	int i;
+
+	for (i = 0; i < (sizeof(stat) * 8); i++) {
+		if (stat & (1 << i))
+			c->intr_counts[i]++;
+	}
+}
+
+static void log_mcerr_fault(unsigned int irq)
+{
+	struct mc_client *client;
+	const struct mc_error *fault;
+	const char *smmu_info;
+	phys_addr_t addr;
+	u32 status, write, secure, client_id;
+	int src_chan = MC_BROADCAST_CHANNEL;
+	u32 intstatus = mc_int_mask &
+			__mc_readl(src_chan, MC_INTSTATUS);
+
+
+	if (intstatus & MC_INT_ARBITRATION_EMEM) {
+		arb_intr();
+		if (intstatus == MC_INT_ARBITRATION_EMEM)
+			goto end;
+		intstatus &= ~MC_INT_ARBITRATION_EMEM;
+	}
+
+	fault = mcerr_default_info(intstatus & mc_int_mask);
+	if (WARN(!fault, "Unknown error! intr sig: 0x%08x\n",
+		 intstatus & mc_int_mask))
+		goto end;
+
+	if (fault->flags & E_NO_STATUS) {
+		mcerr_pr("MC fault - no status: %s\n", fault->msg);
+		goto end;
+	}
+
+	status = __mc_readl(src_chan, fault->stat_reg);
+	addr = __mc_readl(src_chan, fault->addr_reg);
+
+	if (fault->flags & E_TWO_STATUS) {
+		mcerr_pr("MC fault - %s\n", fault->msg);
+		mcerr_pr("status: 0x%08x status2: 0x%08llx\n",
+			status, addr);
+		goto end;
+	}
+
+	secure = !!(status & MC_ERR_STATUS_SECURE);
+	write = !!(status & MC_ERR_STATUS_WRITE);
+	client_id = status & 0xff;
+	client = &mc_clients[client_id <= mc_client_last
+				     ? client_id : mc_client_last];
+
+	mcerr_info_update(client, intstatus & mc_int_mask);
+
+	/*
+	 * LPAE: make sure we get the extra 2 physical address bits available
+	 * and pass them down to the printing function.
+	 */
+	addr |= (((phys_addr_t)(status & MC_ERR_STATUS_ADR_HI)) << 12);
+
+	if (fault->flags & E_SMMU)
+		smmu_info = smmu_page_attrib[MC_ERR_SMMU_BITS(status)];
+	else
+		smmu_info = NULL;
+
+	mcerr_default_print(fault, client, status, addr, secure, write,
+				  smmu_info);
+end:
+	mc_writel(intstatus, MC_INTSTATUS);
+}
+
+static struct mcerr_ops mcerr_ops = {
+	.clear_interrupt = clear_interrupt,
+	.log_mcerr_fault = log_mcerr_fault,
+	.nr_clients = ARRAY_SIZE(mc_clients),
+	.intr_descriptions = t210_intr_info,
+	.mc_clients = mc_clients,
+};
+
+static struct mcerr_ops *t21x_mcerr_of_setup(struct device_node *np)
+{
+	pr_info("mcerr ops are set to t21x\n");
+	return &mcerr_ops;
+}
+
+MCERR_OF_DECLARE(mcerr_of, "nvidia,tegra-mc", t21x_mcerr_of_setup);
diff --git a/drivers/platform/tegra/mc/mcerr.c b/drivers/platform/tegra/mc/mcerr.c
new file mode 100644
index 000000000000..c3a0d30b7625
--- /dev/null
+++ b/drivers/platform/tegra/mc/mcerr.c
@@ -0,0 +1,282 @@
+/*
+ * arch/arm/mach-tegra/mcerr.c
+ *
+ * MC error code common to T3x and T11x. T20 has been left alone.
+ *
+ * Copyright (c) 2010-2021, NVIDIA Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ */
+
+#define pr_fmt(fmt) "mc-err: " fmt
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/stat.h>
+#include <linux/sched.h>
+#include <linux/debugfs.h>
+#include <linux/seq_file.h>
+#include <linux/moduleparam.h>
+#include <linux/platform_device.h>
+#include <linux/of_irq.h>
+#include <linux/atomic.h>
+
+#include <linux/platform/tegra/mc.h>
+#include <linux/platform/tegra/mcerr.h>
+#include <linux/platform/tegra/tegra_emc_err.h>
+#include <linux/platform/tegra/mc-regs-t18x.h>
+
+static const struct of_device_id __mcerr_of_table_sentinel
+	__used __section("__mcerr_of_table_end");
+extern struct of_device_id __mcerr_of_table;
+
+static bool mcerr_throttle_enabled = true;
+u32  mcerr_silenced;
+static atomic_t error_count;
+
+static void unthrottle_prints(struct work_struct *work);
+static DECLARE_DELAYED_WORK(unthrottle_prints_work, unthrottle_prints);
+static struct dentry *mcerr_debugfs_dir;
+u32 mc_int_mask;
+static struct mcerr_ops *mcerr_ops;
+
+static void unthrottle_prints(struct work_struct *work)
+{
+	atomic_set(&error_count, 0);
+}
+
+static void disable_interrupt(unsigned int irq)
+{
+	mc_writel(0, MC_INTMASK);
+}
+
+static void enable_interrupt(unsigned int irq)
+{
+	mc_writel(mc_int_mask, MC_INTMASK);
+}
+
+static irqreturn_t tegra_mcerr_thread(int irq, void *data)
+{
+	unsigned long count;
+
+	cancel_delayed_work(&unthrottle_prints_work);
+	count = atomic_inc_return(&error_count);
+
+	if (mcerr_throttle_enabled && count >= MAX_PRINTS) {
+		schedule_delayed_work(&unthrottle_prints_work, HZ/2);
+		if (count == MAX_PRINTS)
+			mcerr_pr("Too many MC errors; throttling prints\n");
+		mcerr_ops->clear_interrupt(irq);
+		goto exit;
+	}
+
+	mcerr_ops->log_mcerr_fault(irq);
+exit:
+	mcerr_ops->enable_interrupt(irq);
+
+	return IRQ_HANDLED;
+}
+
+/*
+ * The actual error handling takes longer than is ideal so this must be
+ * threaded.
+ */
+static irqreturn_t tegra_mcerr_hard_irq(int irq, void *data)
+{
+#ifdef CONFIG_TEGRA_MC_TRACE_PRINTK
+	trace_printk("MCERR detected.\n");
+#endif
+	 /*
+	  * Disable MC Error interrupt till the MC Error info is logged.
+	  * MC Errors can be lost as MC HW holds one MC error at a time.
+	  * The first MC Error is good enough to point out potential memory
+	  * access issues in SW and allow debugging further.
+	  */
+	mcerr_ops->disable_interrupt(irq);
+	return IRQ_WAKE_THREAD;
+}
+
+/*
+ * Print the MC err stats for each client.
+ */
+static int mcerr_default_debugfs_show(struct seq_file *s, void *v)
+{
+	int i, j;
+	int do_print;
+
+	seq_printf(s, "%-18s %-18s", "swgroup", "client");
+	for (i = 0; i < (sizeof(u32) * 8); i++) {
+		if (mcerr_ops->intr_descriptions[i])
+			seq_printf(s, " %-12s",
+				   mcerr_ops->intr_descriptions[i]);
+	}
+	seq_puts(s, "\n");
+
+	for (i = 0; i < mcerr_ops->nr_clients; i++) {
+		do_print = 0;
+
+		/* Only print clients who actually have errors. */
+		for (j = 0; j < (sizeof(u32) * 8); j++) {
+			if (mcerr_ops->intr_descriptions[j] &&
+			    mcerr_ops->mc_clients[i].intr_counts[j]) {
+				do_print = 1;
+				break;
+			}
+		}
+
+		if (do_print) {
+			seq_printf(s, "%-18s %-18s",
+				   mcerr_ops->mc_clients[i].name,
+				   mcerr_ops->mc_clients[i].swgroup);
+			for (j = 0; j < (sizeof(u32) * 8); j++) {
+				if (!mcerr_ops->intr_descriptions[j])
+					continue;
+				seq_printf(s, " %-12u",
+					   mcerr_ops->mc_clients[i].intr_counts[j]);
+			}
+			seq_puts(s, "\n");
+		}
+	}
+
+	return 0;
+}
+
+static int mcerr_debugfs_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, mcerr_ops->mcerr_debugfs_show, NULL);
+}
+
+static const struct file_operations mcerr_debugfs_fops = {
+	.open           = mcerr_debugfs_open,
+	.read           = seq_read,
+	.llseek         = seq_lseek,
+	.release        = single_release,
+};
+
+static int __get_throttle(void *data, u64 *val)
+{
+	*val = mcerr_throttle_enabled;
+	return 0;
+}
+
+static int __set_throttle(void *data, u64 val)
+{
+	atomic_set(&error_count, 0);
+
+	mcerr_throttle_enabled = (bool) val;
+	return 0;
+}
+DEFINE_SIMPLE_ATTRIBUTE(mcerr_throttle_debugfs_fops, __get_throttle,
+			__set_throttle, "%llu\n");
+
+int tegra_mcerr_init(struct dentry *mc_parent, struct platform_device *pdev)
+{
+	int irq;
+	const void *prop;
+	bool match_found = false;
+	struct device_node *np = pdev->dev.of_node;
+	const struct of_device_id *matches = &__mcerr_of_table;
+
+	for (; matches; matches++) {
+		if (of_device_is_compatible(np, matches->compatible)) {
+			const of_mcerr_init_fn init_fn = matches->data;
+
+			mcerr_ops = init_fn(np);
+			match_found = true;
+			break;
+		}
+	}
+
+	if (WARN_ON(match_found == false)) {
+		pr_err("%s: no mcerr_ops found\n", __func__);
+		return -EINVAL;
+	}
+
+	if (!mcerr_ops || !mcerr_ops->clear_interrupt ||
+		!mcerr_ops->log_mcerr_fault) {
+		pr_err("invalid mcerr ops. disabling mcerr.\n");
+		goto fail;
+	}
+
+	mcerr_ops->mcerr_debugfs_show = mcerr_ops->mcerr_debugfs_show ?: mcerr_default_debugfs_show;
+	mcerr_ops->enable_interrupt = mcerr_ops->enable_interrupt ?: enable_interrupt;
+	mcerr_ops->disable_interrupt = mcerr_ops->disable_interrupt ?: disable_interrupt;
+
+	if (mcerr_ops->nr_clients == 0 ||
+	    mcerr_ops->intr_descriptions == NULL) {
+		pr_err("Missing necessary chip_specific functionality!\n");
+		return -ENODEV;
+	}
+
+	prop = of_get_property(pdev->dev.of_node, "int_mask", NULL);
+	if (!prop) {
+		pr_err("No int_mask prop for mcerr!\n");
+		return -EINVAL;
+	}
+
+	irq = irq_of_parse_and_map(pdev->dev.of_node, 0);
+	if (irq < 0) {
+		pr_err("Unable to parse/map MC error interrupt\n");
+		goto done;
+	}
+
+	if (request_threaded_irq(irq, tegra_mcerr_hard_irq,
+				 tegra_mcerr_thread, 0, "mc_status", NULL)) {
+		pr_err("Unable to register MC error interrupt\n");
+		goto done;
+	}
+
+	mc_int_mask = be32_to_cpup(prop);
+	/* clear any mc-err's that occured before. */
+	mcerr_ops->clear_interrupt(irq);
+	mc_writel(mc_int_mask, MC_INTMASK);
+	pr_debug("Set intmask: 0x%x\n", mc_readl(MC_INTMASK));
+
+	/* This need to be fixed to work for all SOC's. */
+	if (IS_ENABLED(CONFIG_ARCH_TEGRA_18x_SOC)) {
+		prop = of_get_property(pdev->dev.of_node,"compatible", NULL);
+		if (prop && strcmp(prop, "nvidia,tegra-t18x-mc") == 0)
+			tegra_emcerr_init(mc_parent, pdev);
+	}
+
+	if (!mc_parent)
+		goto done;
+
+	mcerr_debugfs_dir = debugfs_create_dir("err", mc_parent);
+	if (mcerr_debugfs_dir == NULL) {
+		pr_err("Failed to make debugfs node: %ld\n",
+		       PTR_ERR(mcerr_debugfs_dir));
+		goto done;
+	}
+	debugfs_create_file("mcerr", 0644, mcerr_debugfs_dir, NULL,
+			    &mcerr_debugfs_fops);
+	debugfs_create_file("mcerr_throttle", S_IRUGO | S_IWUSR,
+			    mcerr_debugfs_dir, NULL,
+			    &mcerr_throttle_debugfs_fops);
+	debugfs_create_u32("quiet", 0644, mcerr_debugfs_dir, &mcerr_silenced);
+done:
+	return 0;
+fail:
+	pr_err("init failied\n");
+	return -EINVAL;
+}
+
+void tegra_mcerr_resume(void)
+{
+	mc_writel(mc_int_mask, MC_INTMASK);
+}
diff --git a/drivers/platform/tegra/mc/mcerr_ecc_t18x.c b/drivers/platform/tegra/mc/mcerr_ecc_t18x.c
new file mode 100644
index 000000000000..9efec3efda1a
--- /dev/null
+++ b/drivers/platform/tegra/mc/mcerr_ecc_t18x.c
@@ -0,0 +1,757 @@
+/*
+ * Tegra 18x SoC-specific DRAM ECC Error handling code.
+ *
+ * Copyright (c) 2016-2018, NVIDIA Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ */
+
+#define pr_fmt(fmt) "dram-ecc: " fmt
+
+#include <linux/kernel.h>
+#include <linux/uaccess.h>
+#include <linux/debugfs.h>
+#include <linux/seq_file.h>
+#include <linux/of.h>
+#include <linux/of_reserved_mem.h>
+#include <linux/of_irq.h>
+#include <linux/seq_file.h>
+#include <linux/platform_device.h>
+#include <linux/platform/tegra/mc.h>
+#include <linux/platform/tegra/mcerr_ecc_t18x.h>
+#include <linux/platform/tegra/tegra18_emc.h>
+#include <linux/platform/tegra/tegra_emc_err.h>
+
+#include <soc/tegra/chip-id.h>
+
+static struct mc_ecc_err_log ecc_log;
+static u32 mc_emem_arb_misc1;
+static u32 mc_emem_arb_cfg;
+
+void __iomem *emc;
+void __iomem *emc_regs[MAX_CHANNELS];
+static u32 emc_int_status[MAX_CHANNELS];
+static u32 gbl_int_status;
+u32 ecc_int_mask;
+#ifdef CONFIG_TEGRA_MC_TRACE_PRINTK
+static u32 ecc_err_silenced;
+
+#define ecc_err_pr(fmt, ...)					\
+	do {							\
+		if (!ecc_err_silenced) {			\
+			trace_printk(fmt, ##__VA_ARGS__);	\
+			pr_err(fmt, ##__VA_ARGS__);		\
+		}						\
+	} while (0)
+#else
+#define ecc_err_pr(fmt, ...)
+#endif
+
+static int mc_check_ebe(struct mc_ecc_err_log *log)
+{
+	if ((log->ecc_eerr_par_sp0) || (log->ecc_eerr_par_sp1))
+		return 1;
+
+	return 0;
+}
+
+static int mc_check_sbe(struct mc_ecc_err_log *log)
+{
+	if ((log->ecc_derr_par_sp0 == 1) || (log->ecc_derr_par_sp1 == 1))
+		return 1;
+
+	return 0;
+}
+
+static int mc_check_dbe(struct mc_ecc_err_log *log)
+{
+	if ((log->ecc_derr_par_sp0 == 2) || (log->ecc_derr_par_sp1 == 2))
+		return 1;
+
+	return 0;
+}
+
+static int mc_check_poison(struct mc_ecc_err_log *log)
+{
+	if ((log->ecc_err_poison_sp0 == 1) || (log->ecc_err_poison_sp1 == 1))
+		return 1;
+
+	return 0;
+}
+
+static void mc_ecc_dump_regs(struct mc_ecc_err_log *log)
+{
+	ecc_err_pr("EMC_ECC_ERR_REQ = 0x%08x\n", log->emc_ecc_err_req);
+	ecc_err_pr("EMC_ECC_ERR_SP0 = 0x%08x\n", log->emc_ecc_err_sp0);
+	ecc_err_pr("EMC_ECC_ERR_SP1 = 0x%08x\n", log->emc_ecc_err_sp1);
+	ecc_err_pr("EMC_ECC_ERR_ADDR = 0x%08x\n", log->ecc_err_addr);
+
+	ecc_err_pr("D.X.R.B.C.S.L:%d.%d.0x%x.%d.0x%x.%d.0\n", log->ecc_err_dev,
+			log->ecc_err_ch, log->row, log->bank, log->col,
+			log->subp);
+}
+
+static void mc_ecc_dump_log(struct mc_ecc_err_log *log)
+{
+	pr_debug("emc_ecc_err_sp0 - reg value = 0x%08x\n",
+		log->emc_ecc_err_sp0);
+	pr_debug("emc_ecc_err_sp1 - reg value = 0x%08x\n",
+		log->emc_ecc_err_sp1);
+	pr_debug("ncol = 0x%08x, gob=0x%08x, col_sp0=0x%08x, err_seq=0x%08x\n",
+		log->col, log->gob, log->col_sp0, log->err_seq);
+	pr_debug("ecc_err_cgid = %d, ecc_err_ch = %d\n", log->ecc_err_cgid,
+		log->ecc_err_ch);
+	pr_debug("ecc_err_dev = %d, ecc_err_size = %d\n", log->ecc_err_dev,
+		log->ecc_err_size);
+	pr_debug("ecc_err_swap = %d\n", log->ecc_err_swap);
+	pr_debug("ecc_eerr_par_sp0 = %d, ecc_eerr_par_sp1 = %d\n",
+		log->ecc_eerr_par_sp0, log->ecc_eerr_par_sp1);
+	pr_debug("ecc_derr_par_sp0 = %d, ecc_derr_par_sp1 = %d\n",
+		log->ecc_derr_par_sp0, log->ecc_derr_par_sp1);
+	pr_debug("ecc_err_poison_sp0 = %d,ecc_err_poison_sp1 = %d\n",
+		log->ecc_err_poison_sp0, log->ecc_err_poison_sp1);
+	pr_debug("ecc_err_addr = 0x%08x\n", log->ecc_err_addr);
+	pr_debug("row = 0x%08x, bank = 0x%08x\n", log->row, log->bank);
+	pr_debug("D.X.R.B.C.S.L:%d.%d.0x%x.%d.0x%x.%d.0\n", log->ecc_err_dev,
+			log->ecc_err_ch, log->row, log->bank, log->col,
+			log->subp);
+}
+
+static int mc_check_subp1_err(struct mc_ecc_err_log *log)
+{
+	if (((log->ecc_derr_par_sp1 == 1)  ||  (log->ecc_derr_par_sp1 == 2)) &&
+		(!((log->ecc_derr_par_sp0 == 1) ||
+		(log->ecc_derr_par_sp0 == 2))))
+		return 1; /*Error only in subp1*/
+	else
+		return 0; /*Error on both Subpartitions or only Subp0*/
+}
+
+static u64 mc_ecc_read_log(struct mc_ecc_err_log *log, u32 ch)
+{
+	u64 addr;
+	u32 val;
+
+	memset((void *)log, 0, sizeof(struct mc_ecc_err_log));
+
+	val = __emc_readl(ch, EMC_ECC_CONTROL);
+	val |= (1 << ERR_BUFFER_LOAD_SHIFT);
+	__emc_writel(ch, val, EMC_ECC_CONTROL);
+
+	val = __emc_readl(ch, EMC_ECC_ERR_REQ);
+	log->emc_ecc_err_req = val;
+	log->ecc_err_cgid = ((val >> ECC_ERR_CGID_SHIFT) & ECC_ERR_CGID_MASK);
+	log->ecc_err_ch = ((val >> ECC_ERR_EMC_ID_SHIFT) & ECC_ERR_EMC_ID_MASK);
+
+	log->ecc_err_dev = ((val >> ECC_ERR_DEVICE_SHIFT) &
+						ECC_ERR_DEVICE_MASK);
+	log->ecc_err_size = ((val >> ECC_ERR_SIZE_SHIFT) & ECC_ERR_SIZE_MASK);
+	log->ecc_err_swap = ((val >> ECC_ERR_SWAP_SHIFT) &  ECC_ERR_SWAP_MASK);
+	log->col_sp0 = ((val >> ECC_ERR_COL_SP0_SHIFT) & ECC_ERR_COL_SP0_MASK);
+	log->col_sp1 = ((val >> ECC_ERR_COL_SP1_SHIFT) & ECC_ERR_COL_SP1_MASK);
+	log->err_seq = ((val >> ECC_ERR_SEQ_SHIFT) & ECC_ERR_SEQ_MASK);
+
+	val = __emc_readl(ch, EMC_ECC_ERR_SP0);
+	log->emc_ecc_err_sp0 = val;
+	log->ecc_eerr_par_sp0 = ((val >> ECC_EERR_PAR_SHIFT) &
+						ECC_EERR_PAR_MASK);
+	log->ecc_derr_par_sp0 = ((val >> ECC_DERR_PAR_SHIFT) &
+						ECC_DERR_PAR_MASK);
+	log->ecc_err_poison_sp0 = ((val >> ECC_ERR_POISON_SHIFT) &
+						ECC_ERR_POISON_MASK);
+	log->ecc_err_bit_sp0 = (((val >> ECC_DERR_SYNDROME_SHIFT) &
+					ECC_DERR_SYNDROME_MASK) & ~(0x200));
+
+
+	val = __emc_readl(ch, EMC_ECC_ERR_SP1);
+	log->emc_ecc_err_sp1 = val;
+	log->ecc_eerr_par_sp1 = ((val >> ECC_EERR_PAR_SHIFT) &
+						ECC_EERR_PAR_MASK);
+	log->ecc_derr_par_sp1 = ((val >> ECC_DERR_PAR_SHIFT) &
+						ECC_DERR_PAR_MASK);
+	log->ecc_err_poison_sp1 = ((val >> ECC_ERR_POISON_SHIFT) &
+						ECC_ERR_POISON_MASK);
+	log->ecc_err_bit_sp1 = (((val >> ECC_DERR_SYNDROME_SHIFT) &
+					ECC_DERR_SYNDROME_MASK) & ~(0x200));
+
+	val = __emc_readl(ch, EMC_ECC_ERR_ADDR);
+	log->ecc_err_addr = val;
+	log->row = ((val >> ECC_ERR_ROW_SHIFT) & ECC_ERR_ROW_MASK);
+	log->bank = ((val >> ECC_ERR_BANK_SHIFT) & ECC_ERR_BANK_MASK);
+	log->gob = ((val >> ECC_ERR_GOB_SHIFT) & ECC_ERR_GOB_MASK);
+	log->col = log->gob;
+
+	if ((log->ecc_err_size == 1) || (log->ecc_err_size == 2)) {
+		/* Read size is 32bytes or 16bytes */
+		log->subp = log->ecc_err_swap;
+	} else {
+		/* Read size is 64bytes */
+		if (mc_check_poison(log))
+			log->subp = 0;
+		else if (mc_check_subp1_err(log))
+			log->subp = 1;
+		else
+			log->subp = 0;
+	}
+
+	if (log->subp)
+		log->col = (log->col << 3) | log->col_sp1;
+	else
+		log->col = (log->col << 3) | log->col_sp0;
+
+	log->col = (log->col << 2) | log->err_seq;
+	log->col = (log->col << 2);
+
+	pr_debug("D.X.R.B.C.S.L:%d.%d.0x%x.%d.0x%x.%d.0\n", log->ecc_err_dev,
+			log->ecc_err_ch, log->row, log->bank, log->col,
+			log->subp);
+
+	addr = mc_addr_translate(log->ecc_err_dev, log->ecc_err_ch,
+			log->row, log->bank, log->col, log->subp, 0);
+
+	pr_debug("Linear addr = 0x%016llx\n", addr);
+	return addr;
+}
+
+static void mc_ecc_dump_intr_mask(void)
+{
+	pr_info("EMC_INTMASK = 0x%08x\n",
+			__emc_readl(0, EMC_INTMASK));
+	pr_info("EMC_NONCRITICAL_INTMASK = 0x%08x\n",
+			__emc_readl(0, EMC_NONCRITICAL_INTMASK));
+	pr_info("EMC_CRITICAL_INTMASK = 0x%08x\n",
+			__emc_readl(0, EMC_CRITICAL_INTMASK));
+}
+
+static void mc_config_ecc_log(uint32_t mode, uint32_t depth)
+{
+	uint32_t val;
+
+	val = __emc_readl(0, EMC_ECC_CONTROL);
+
+	val &= ~(ERR_BUFFER_MODE_MASK << ERR_BUFFER_MODE_SHIFT);
+	val |= (mode << ERR_BUFFER_MODE_SHIFT);
+
+	val &= ~(ERR_BUFFER_LIMIT_MASK << ERR_BUFFER_LIMIT_SHIFT);
+	val |= (depth << ERR_BUFFER_LIMIT_SHIFT);
+
+	emc_writel(val, EMC_ECC_CONTROL);
+}
+
+static void mc_ecc_clear_all_intr(void)
+{
+	emc_writel(0xFFFFFFFF, EMC_INTSTATUS);
+	emc_writel(0xF, EMC_MCH_GLOBAL_INTSTATUS);
+	emc_writel(0xF, EMC_MCH_GLOBAL_NONCRITICAL_INTSTATUS);
+	emc_writel(0xF, EMC_MCH_GLOBAL_CRITICAL_INTSTATUS);
+}
+
+static void mc_ecc_sec_scrub(u32 scrub_addr)
+{
+	u32 val;
+
+	mc_writel(scrub_addr, MC_MEM_SCRUBBER_ECC_ADDR);
+
+	pr_debug("MC_MEM_SCRUBBER_ECC_ADDR = 0x%08x\n",
+			mc_readl(MC_MEM_SCRUBBER_ECC_ADDR));
+
+	val = mc_readl(MC_MEM_SCRUBBER_ECC_REG_CTRL);
+	val |= (1 << SCRUB_ECC_TRIGGER_SHIFT);
+
+	mc_writel(val, MC_MEM_SCRUBBER_ECC_REG_CTRL);
+
+	do {
+		val = mc_readl(MC_MEM_SCRUBBER_ECC_REG_CTRL);
+		val = ((val >> SCRUB_ECC_PENDING_SHIFT) &
+					SCRUB_ECC_PENDING_MASK);
+		pr_debug("SCrubbing in progress : %d\n", val);
+	} while (val);
+
+	pr_debug("SCrubbing done\n");
+}
+
+static void mc_check_ecc_err(struct mc_ecc_err_log *pecclog, u32 ch)
+{
+	u32 err = false;
+	u64 addr;
+
+	addr = mc_ecc_read_log(pecclog, ch);
+	mc_ecc_dump_log(pecclog);
+
+	if (mc_check_poison(pecclog)) {
+		ecc_err_pr("-----POISON Bit ERR, addr:0x%016llx\n",
+								addr);
+		err = true;
+	}
+	if (mc_check_ebe(pecclog)) {
+		ecc_err_pr("-----ECC Bit ERR, addr:0x%016llx\n", addr);
+		err = true;
+	}
+	if (mc_check_sbe(pecclog)) {
+		ecc_err_pr("------SBE ERR, addr:0x%016llx\n", addr);
+		err = true;
+		/* Demand scrub in case of SBE */
+		if (pecclog->ecc_err_cgid != HW_SCRUBBER_CGID)
+			mc_ecc_sec_scrub((u32)(addr >> 6));
+	}
+	if (mc_check_dbe(pecclog)) {
+		ecc_err_pr("------DBE ERR, addr:0x%016llx\n", addr);
+		err = true;
+		mc_ecc_dump_regs(pecclog);
+	}
+
+	if (err)
+		mc_ecc_dump_regs(pecclog);
+}
+
+static void mc_ecc_dump_ch_logs(uint32_t ch)
+{
+	uint32_t val, err_buff_count;
+	struct mc_ecc_err_log *pecclog = &ecc_log;
+
+	val = __emc_readl(ch, EMC_ECC_STATUS);
+	err_buff_count = ((val >> ERR_BUFFER_CNT_SHIFT) &
+					ERR_BUFFER_CNT_MASK);
+
+	while (err_buff_count) {
+		pr_debug("----ch%d---Error log(%d)---<Start>-----\n", ch,
+				err_buff_count);
+		mc_check_ecc_err(pecclog, ch);
+		pr_debug("----ch%d---Error log(%d)---<End>-----\n", ch,
+				err_buff_count);
+		val = __emc_readl(ch, EMC_ECC_STATUS);
+		err_buff_count = ((val >> ERR_BUFFER_CNT_SHIFT) &
+					ERR_BUFFER_CNT_MASK);
+	}
+}
+
+static void mc_ecc_dump_status(void)
+{
+	u32 val;
+	u32 err_buff_count;
+	u32 buff_ovf_intr;
+	u32 corr_err_intr;
+	u32 uncorr_err_intr;
+	u32 ch = 0;
+
+	do {
+		val = __emc_readl(ch, EMC_ECC_STATUS);
+		err_buff_count = ((val >> ERR_BUFFER_CNT_SHIFT) &
+					ERR_BUFFER_CNT_MASK);
+
+		val = __emc_readl(ch, EMC_INTSTATUS);
+		buff_ovf_intr = ((val >> ECC_ERR_BUF_OVF_INT_SHIFT) &
+				ECC_ERR_BUF_OVF_INT_MASK);
+		corr_err_intr = ((val >>  ECC_CORR_ERR_INT_SHIFT) &
+				ECC_CORR_ERR_INT_MASK);
+		uncorr_err_intr = ((val >> ECC_UNCORR_ERR_INT_SHIFT) &
+				ECC_UNCORR_ERR_INT_MASK);
+
+		pr_debug("##### EMC Channel %d #####\n", ch);
+		pr_debug("err_buff_count = %d,buff_ovf_intr = %d\n",
+			err_buff_count, buff_ovf_intr);
+		pr_debug("corr_err_intr = %d,uncorr_err_intr = %d\n",
+			corr_err_intr, uncorr_err_intr);
+
+		mc_ecc_dump_ch_logs(ch);
+
+		ch++;
+
+	} while (ch < MAX_CHANNELS);
+
+	pr_debug("EMC_MCH_GLOBAL_INTSTATUS = 0x%08x\n",
+				emc_readl(EMC_MCH_GLOBAL_INTSTATUS));
+	pr_debug("EMC_MCH_GLOBAL_CRITICAL_INTSTATUS = 0x%08x\n",
+		emc_readl(EMC_MCH_GLOBAL_CRITICAL_INTSTATUS));
+	pr_debug("EMC_MCH_GLOBAL_NONCRITICAL_INTSTATUS = 0x%08x\n",
+		emc_readl(EMC_MCH_GLOBAL_NONCRITICAL_INTSTATUS));
+}
+
+static int mc_ecc_debugfs_dump_status(struct seq_file *s, void *v)
+{
+	mc_ecc_dump_status();
+
+	return 0;
+}
+static void mc_increase_ecc_errors(void)
+{
+	mc_writel(0x02, MC_TIMING_CONTROL_DBG);
+	mc_writel(0x40040001, MC_EMEM_ARB_CFG);
+	mc_writel(0x00400b39, MC_EMEM_ARB_MISC1);
+	mc_writel(0x0, MC_TIMING_CONTROL_DBG);
+}
+
+static void mc_normal_ecc_errors(void)
+{
+	mc_writel(0x02, MC_TIMING_CONTROL_DBG);
+	mc_writel(mc_emem_arb_cfg, MC_EMEM_ARB_CFG);
+	mc_writel(mc_emem_arb_misc1, MC_EMEM_ARB_MISC1);
+	mc_writel(0x0, MC_TIMING_CONTROL_DBG);
+}
+
+static int mc_dump_regs_emem_arb(struct seq_file *s, void *v)
+{
+	uint32_t val;
+
+	val = mc_readl(MC_EMEM_ARB_CFG);
+	seq_printf(s, "MC_EMEM_ARB_CFG = 0x%x\n", val);
+	val = mc_readl(MC_EMEM_ARB_MISC1);
+	seq_printf(s, "MC_EMEM_ARB_MISC1 = 0x%x\n", val);
+
+	return 0;
+}
+
+static int mc_handle_err_intr_ch(u32 ch)
+{
+	u32 val, err_buff_count;
+	struct mc_ecc_err_log *pecclog = &ecc_log;
+
+	if (ch >= MAX_CHANNELS) {
+		pr_err("!ERROR:Invalid channel number, ch :%d\n", ch);
+		return -EINVAL;
+	}
+	/* Process the new interrupts while at bottom half, at the same time
+		preserve the ch status which is read from top half
+	*/
+	emc_int_status[ch] |= __emc_readl(ch, EMC_INTSTATUS);
+	pr_debug("ch:%d, emc_int_status:0x%08x\n", ch, emc_int_status[ch]);
+
+	val = __emc_readl(ch, EMC_ECC_STATUS);
+	err_buff_count = ((val >> ERR_BUFFER_CNT_SHIFT) &
+					ERR_BUFFER_CNT_MASK);
+	while (err_buff_count) {
+
+		mc_check_ecc_err(pecclog, ch);
+
+		val = __emc_readl(ch, EMC_ECC_STATUS);
+		err_buff_count = ((val >> ERR_BUFFER_CNT_SHIFT) &
+					ERR_BUFFER_CNT_MASK);
+	}
+	if (emc_int_status[ch] & (1 << ECC_ERR_BUF_OVF_INT_SHIFT))
+			ecc_err_pr("BUFF OVER FLOW ERR\n");
+
+	/* clear the channel local interrupts */
+	__emc_writel(ch, emc_int_status[ch], EMC_INTSTATUS);
+
+	return 0;
+}
+static void mc_handle_err_intr(void)
+{
+	u32 ch = 0;
+	u32 ch_mask = 1;
+	u32 val;
+	u32 err_buff_count;
+
+	/* Process the new interrupts while at bottom half, at the same time
+		preserve the status which is read from top half
+	*/
+	gbl_int_status |= emc_readl(EMC_MCH_GLOBAL_INTSTATUS);
+
+	pr_debug("gbl_int_status = 0x%08x\n", gbl_int_status);
+
+	do {
+		if (gbl_int_status & ch_mask) {
+			mc_handle_err_intr_ch(ch);
+
+			/* Again check for new errors in the channel,
+				before clearing global bit */
+			val = __emc_readl(ch, EMC_ECC_STATUS);
+			err_buff_count = ((val >> ERR_BUFFER_CNT_SHIFT) &
+					ERR_BUFFER_CNT_MASK);
+
+			if (err_buff_count == 0) {
+				/*Clear the global interrupt bit
+					for that channel*/
+				emc_writel((1 << ch),
+					EMC_MCH_GLOBAL_INTSTATUS);
+				gbl_int_status &= ~(ch_mask);
+			}
+		}
+
+		gbl_int_status |= emc_readl(
+				EMC_MCH_GLOBAL_INTSTATUS);
+
+		if (!(gbl_int_status & ch_mask)) {
+			/* Current channel no errors, move to next
+				channel */
+			ch_mask = (ch_mask << 1);
+			ch++;
+		}
+
+	} while (gbl_int_status);
+}
+
+static irqreturn_t tegra_ecc_error_thread(int irq, void *data)
+{
+	mc_handle_err_intr();
+
+	/* Unmask the interrupt back */
+	emc_writel(ecc_int_mask, EMC_INTMASK);
+
+	return IRQ_HANDLED;
+}
+static irqreturn_t tegra_ecc_error_hard_irq(int irq, void *data)
+{
+	u32 ch = 0;
+
+	pr_debug("ECC ERR detected.\n");
+	gbl_int_status = emc_readl(EMC_MCH_GLOBAL_INTSTATUS);
+
+	if (!gbl_int_status) {
+		pr_err("ECC Err unknown source (global status = 0x%08x)\n",
+			     gbl_int_status);
+		return IRQ_NONE;
+	}
+
+	/* prevent new interrupts until we've handled this one */
+	emc_writel(0, EMC_INTMASK);
+
+	do {
+		emc_int_status[ch] = __emc_readl(ch, EMC_INTSTATUS);
+		__emc_writel(ch, emc_int_status[ch], EMC_INTSTATUS);
+		ch++;
+	} while (ch < MAX_CHANNELS);
+
+	emc_writel(gbl_int_status, EMC_MCH_GLOBAL_INTSTATUS);
+
+	return IRQ_WAKE_THREAD;
+}
+static struct dentry *ecc_err_debugfs_dir;
+
+static int ecc_err_rate_debugfs_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, mc_dump_regs_emem_arb, NULL);
+}
+
+static ssize_t ecc_err_rate_debugfs_write(struct file *file,
+		const char __user *user_buf, size_t size, loff_t *ppos)
+{
+	char buf[64];
+	int buf_size;
+	int ret;
+
+	buf_size = min(size, (sizeof(buf) - 1));
+	if (strncpy_from_user(buf, user_buf, buf_size) < 0)
+		return -EFAULT;
+	buf[buf_size] = 0;
+
+	if (strncmp(buf, "increase", 8) == 0)
+		mc_increase_ecc_errors();
+	 else if (strncmp(buf, "normal", 6) == 0)
+		mc_normal_ecc_errors();
+	else
+		ret = -EINVAL;
+
+	/* ignore the rest of the buffer, only one command at a time */
+	*ppos += size;
+	return size;
+}
+
+static const struct file_operations ecc_err_rate_debugfs_fops = {
+	.open           = ecc_err_rate_debugfs_open,
+	.read           = seq_read,
+	.write          = ecc_err_rate_debugfs_write,
+	.llseek         = seq_lseek,
+	.release        = single_release,
+};
+
+static int ecc_status_debugfs_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, mc_ecc_debugfs_dump_status, NULL);
+}
+
+static const struct file_operations ecc_status_debugfs_fops = {
+	.open           = ecc_status_debugfs_open,
+	.read           = seq_read,
+	.llseek         = seq_lseek,
+	.release        = single_release,
+};
+
+static int ecc_cfg_debugfs_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, mc_ecc_config_dump, NULL);
+}
+
+static const struct file_operations ecc_cfg_debugfs_fops = {
+	.open           = ecc_cfg_debugfs_open,
+	.read           = seq_read,
+	.llseek         = seq_lseek,
+	.release        = single_release,
+};
+
+static int mc_ecc_debugfs_init(struct dentry *mc_parent)
+{
+	if (!mc_parent)
+		return -EINVAL;
+
+	ecc_err_debugfs_dir = debugfs_create_dir("ecc", mc_parent);
+	if (ecc_err_debugfs_dir == NULL) {
+		pr_err("Failed to make debugfs node: %ld\n",
+		       PTR_ERR(ecc_err_debugfs_dir));
+		return -EINVAL;
+	}
+
+	debugfs_create_file("cfg", 0644, ecc_err_debugfs_dir, NULL,
+			    &ecc_cfg_debugfs_fops);
+
+	debugfs_create_file("status", 0644, ecc_err_debugfs_dir, NULL,
+			    &ecc_status_debugfs_fops);
+
+	debugfs_create_file("error_rate", 0644, ecc_err_debugfs_dir, NULL,
+			    &ecc_err_rate_debugfs_fops);
+
+#ifdef CONFIG_TEGRA_MC_TRACE_PRINTK
+	debugfs_create_u32("quiet", 0644, ecc_err_debugfs_dir,
+					&ecc_err_silenced);
+#endif
+
+	return 0;
+}
+
+static u32 mc_ecc_check_err_handling(struct platform_device *pdev)
+{
+	struct device_node *rtcpu_sce = of_find_node_by_path("/rtcpu@b000000");
+	u32 handle_ecc_err;
+
+	if (!rtcpu_sce) {
+		pr_err("Unable to get rtcpu_sce node, Handle DRAM ECC Errors in Kernel\n");
+		handle_ecc_err = 1;
+		goto exit;
+	}
+
+	if (of_device_is_available(rtcpu_sce)) {
+		/*
+		 * if rtcpu@b000000 is enabled, SCE is booted with Camera FW.
+		 *     if ecc_on_camera_fw, then handle ECC errors in Camera FW.
+		 *     else, we handle DRAM ECC errors @ CCPLEX from Kernel
+		 */
+		pr_info("SCE-R5 is booted with Camera FW\n");
+		if (of_property_read_bool(pdev->dev.of_node,
+					"ecc_on_camera_fw")) {
+			pr_info("DRAM ECC interrupts handled in Camera FW\n");
+			handle_ecc_err = 0;
+		} else {
+			pr_info("DRAM ECC interrupts handled in Kernel\n");
+			handle_ecc_err = 1;
+		}
+	} else {
+		/*
+		 * if rtcpu@b000000 is disabled SCE is booted with sample
+		 * safety FW, so we handle DRAM ECC errors @ SCE
+		*/
+		pr_info("DRAM ECC interrupts handled in SCE FW\n");
+		handle_ecc_err = 0;
+	}
+exit:
+	return handle_ecc_err;
+}
+
+static int mc_ecc_err_init(struct dentry *mc_parent,
+				struct platform_device *pdev)
+{
+	struct resource *res;
+	u32 reg_index = DT_REG_INDEX_EMC_BROADCAST;
+	u32 ch = 0;
+	const void *prop;
+	s32 ecc_err_irq;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, reg_index);
+	emc = devm_ioremap_resource(&pdev->dev, res);
+	if (!emc) {
+		dev_err(&pdev->dev, "emc map failed\n");
+		return -ENOMEM;
+	}
+	reg_index++;
+	do {
+		res = platform_get_resource(pdev, IORESOURCE_MEM, reg_index);
+		emc_regs[ch] = devm_ioremap_resource(&pdev->dev, res);
+		if (!emc_regs[ch]) {
+			dev_err(&pdev->dev, "emc_regs[%d] map failed\n",
+								reg_index);
+			return -ENOMEM;
+		}
+		reg_index++;
+		ch++;
+	} while (ch < MAX_CHANNELS);
+
+	ecc_err_irq = irq_of_parse_and_map(pdev->dev.of_node, 1);
+	pr_info("ecc_err_irq = %d\n", ecc_err_irq);
+	if (ecc_err_irq < 0) {
+		pr_err("Unable to parse/map ECC interrupt\n");
+		return -EINVAL;
+	}
+
+	if (request_threaded_irq(ecc_err_irq, tegra_ecc_error_hard_irq,
+					tegra_ecc_error_thread, 0,
+					"ecc_irq_status", NULL)) {
+		pr_err("Unable to register ecc err interrupt\n");
+		return -EINVAL;
+	}
+
+	prop = of_get_property(pdev->dev.of_node, "ecc_int_mask", NULL);
+	if (!prop) {
+		pr_err("No int_mask prop for mcerr!\n");
+		return -EINVAL;
+	}
+	ecc_int_mask = be32_to_cpup(prop);
+
+	mc_ecc_config_read();
+
+	/*
+		Read the default MC EMEM config, so that we can decrease
+		the rate of ecc errors later
+	*/
+
+	mc_emem_arb_misc1 = mc_readl(MC_EMEM_ARB_MISC1);
+	mc_emem_arb_cfg = mc_readl(MC_EMEM_ARB_CFG);
+
+	mc_ecc_dump_status();
+
+	mc_config_ecc_log(MC_ECC_LOG_RING_MODE, MC_ECC_LOG_BUFF_DEPTH);
+
+	mc_ecc_clear_all_intr();
+
+	mc_ecc_dump_status();
+
+	mc_ecc_debugfs_init(mc_parent);
+
+	emc_writel(ecc_int_mask, EMC_INTMASK);
+
+	mc_ecc_dump_intr_mask();
+
+	return 0;
+}
+
+void tegra_emcerr_init(struct dentry *mc_parent, struct platform_device *pdev)
+{
+	u32 mc_ecc_control = mc_readl(MC_ECC_CONTROL);
+
+	if (tegra_get_chip_id() != TEGRA186)
+		return;
+
+	if (mc_ecc_control & 1) {
+		pr_info("DRAM ECC enabled-MC_ECC_CONTROL:0x%08x\n",
+							mc_ecc_control);
+
+		if (mc_ecc_check_err_handling(pdev)) {
+			if (mc_ecc_err_init(mc_parent, pdev))
+				pr_err("ecc error init failed\n");
+		}
+
+	} else {
+		pr_info("DRAM ECC disabled-MC_ECC_CONTROL:0x%08x\n",
+							mc_ecc_control);
+	}
+}
diff --git a/drivers/platform/tegra/mc/nvrm_drf.h b/drivers/platform/tegra/mc/nvrm_drf.h
new file mode 100644
index 000000000000..f35ac3869214
--- /dev/null
+++ b/drivers/platform/tegra/mc/nvrm_drf.h
@@ -0,0 +1,201 @@
+/*
+ * Copyright (c) 2007-2018 NVIDIA Corporation.  All Rights Reserved.
+ *
+ * NVIDIA Corporation and its licensors retain all intellectual property and
+ * proprietary rights in and to this software and related documentation.  Any
+ * use, reproduction, disclosure or distribution of this software and related
+ * documentation without an express license agreement from NVIDIA Corporation
+ * is strictly prohibited.
+ */
+
+#ifndef INCLUDED_NVRM_DRF_H
+#define INCLUDED_NVRM_DRF_H
+
+/**
+ *  @defgroup nvrm_drf RM DRF Macros
+ *
+ *  @ingroup nvddk_rm
+ *
+ * The following suite of macros are used for generating values to write into
+ * hardware registers, or for extracting fields from read registers.  The
+ * hardware headers have a RANGE define for each field in the register in the
+ * form of x:y, 'x' being the high bit, 'y' the lower.  Through a clever use
+ * of the C ternary operator, x:y may be passed into the macros below to
+ * geneate masks, shift values, etc.
+ *
+ * There are two basic flavors of DRF macros, the first is used to define
+ * a new register value from 0, the other is modifiying a field given a
+ * register value.  An example of the first:
+ *
+ * reg = NV_DRF_DEF( HW, REGISTER0, FIELD0, VALUE0 )
+ *     | NV_DRF_DEF( HW, REGISTER0, FIELD3, VALUE2 );
+ *
+ * To modify 'reg' from the previous example:
+ *
+ * reg = NV_FLD_SET_DRF_DEF( HW, REGISTER0, FIELD2, VALUE1, reg );
+ *
+ * To pass in numeric values instead of defined values from the header:
+ *
+ * reg = NV_DRF_NUM( HW, REGISTER3, FIELD2, 1024 );
+ *
+ * To read a value from a register:
+ *
+ * val = NV_DRF_VAL( HW, REGISTER3, FIELD2, reg );
+ *
+ * Some registers have non-zero reset values which may be extracted from the
+ * hardware headers via NV_RESETVAL.
+ */
+
+/*
+ * The NV_FIELD_* macros are helper macros for the public NV_DRF_* macros.
+ */
+#define NV_FIELD_LOWBIT(x)      (0?x)
+#define NV_FIELD_HIGHBIT(x)     (1?x)
+#define NV_FIELD_SIZE(x)        (NV_FIELD_HIGHBIT(x)-NV_FIELD_LOWBIT(x)+1)
+#define NV_FIELD_SHIFT(x)       ((0?x)%32)
+#define NV_FIELD_MASK(x)        (0xFFFFFFFFUL>>(31-((1?x)%32)+((0?x)%32)))
+#define NV_FIELD_BITS(val, x)   (((val) & NV_FIELD_MASK(x))<<NV_FIELD_SHIFT(x))
+#define NV_FIELD_SHIFTMASK(x)   (NV_FIELD_MASK(x)<< (NV_FIELD_SHIFT(x)))
+
+/** NV_DRF_DEF - define a new register value.
+
+    @ingroup nvrm_drf
+
+    @param d register domain (hardware block)
+    @param r register name
+    @param f register field
+    @param c defined value for the field
+ */
+#define NV_DRF_DEF(d,r,f,c) \
+    ((d##_##r##_0_##f##_##c) << NV_FIELD_SHIFT(d##_##r##_0_##f##_RANGE))
+
+/** NV_DRF_NUM - define a new register value.
+
+    @ingroup nvrm_drf
+
+    @param d register domain (hardware block)
+    @param r register name
+    @param f register field
+    @param n numeric value for the field
+ */
+#define NV_DRF_NUM(d,r,f,n) \
+    (((n)& NV_FIELD_MASK(d##_##r##_0_##f##_RANGE)) << \
+        NV_FIELD_SHIFT(d##_##r##_0_##f##_RANGE))
+
+/** NV_DRF_VAL - read a field from a register.
+
+    @ingroup nvrm_drf
+
+    @param d register domain (hardware block)
+    @param r register name
+    @param f register field
+    @param v register value
+ */
+#define NV_DRF_VAL(d,r,f,v) \
+    (((v)>> NV_FIELD_SHIFT(d##_##r##_0_##f##_RANGE)) & \
+        NV_FIELD_MASK(d##_##r##_0_##f##_RANGE))
+
+/** NV_FLD_SET_DRF_NUM - modify a register field.
+
+    @ingroup nvrm_drf
+
+    @param d register domain (hardware block)
+    @param r register name
+    @param f register field
+    @param n numeric field value
+    @param v register value
+ */
+#define NV_FLD_SET_DRF_NUM(d,r,f,n,v) \
+    (((v) & ~NV_FIELD_SHIFTMASK(d##_##r##_0_##f##_RANGE)) | NV_DRF_NUM(d,r,f,n))
+
+/** NV_FLD_SET_DRF_DEF - modify a register field.
+
+    @ingroup nvrm_drf
+
+    @param d register domain (hardware block)
+    @param r register name
+    @param f register field
+    @param c defined field value
+    @param v register value
+ */
+#define NV_FLD_SET_DRF_DEF(d,r,f,c,v) \
+    (((v) & ~NV_FIELD_SHIFTMASK(d##_##r##_0_##f##_RANGE)) | \
+        NV_DRF_DEF(d,r,f,c))
+
+/** NV_RESETVAL - get the reset value for a register.
+
+    @ingroup nvrm_drf
+
+    @param d register domain (hardware block)
+    @param r register name
+ */
+#define NV_RESETVAL(d,r)    (d##_##r##_0_RESET_VAL)
+
+
+/*
+ * Packet variants.
+ * NOTE: these are limited to 32-bit or smaller packets
+ */
+
+/** NV_PF_DEF - define a new packet value.
+
+    @ingroup nvrm_drf
+
+    @param p packet name
+    @param f packet field
+    @param c defined value for the field
+ */
+#define NV_PF_DEF(p,f,c) \
+    ((p##_##f##_##c) << NV_FIELD_SHIFT(p##_##f##_RANGE))
+
+/** NV_PF_NUM - define a new packet value.
+
+    @ingroup nvrm_drf
+
+    @param p packet name
+    @param f packet field
+    @param n numeric value for the field
+ */
+#define NV_PF_NUM(p,f,n)                            \
+    (((n)& NV_FIELD_MASK(p##_##f##_RANGE)) <<       \
+     NV_FIELD_SHIFT(p##_##f##_RANGE))
+
+
+/** NV_PF_VAL - read a field from a packet
+
+    @ingroup nvrm_drf
+
+    @param p packet name
+    @param f packet field
+    @param v packet value
+ */
+#define NV_PF_VAL(p,f,v) \
+    (((v)>> NV_FIELD_SHIFT(p##_##f##_RANGE)) & \
+        NV_FIELD_MASK(p##_##f##_RANGE))
+
+/** NV_FLD_SET_PF_NUM - modify a packet field.
+
+    @ingroup nvrm_drf
+
+    @param p packet name
+    @param f packet field
+    @param n numeric field value
+    @param v packet value
+ */
+#define NV_FLD_SET_PF_NUM(p,f,n,v) \
+    (((v) & ~NV_FIELD_SHIFTMASK(p##_##f##_RANGE)) | NV_PF_NUM(p,f,n))
+
+/** NV_FLD_SET_PF_DEF - modify a packet field.
+
+    @ingroup nvrm_drf
+
+    @param p packet name
+    @param f packet field
+    @param c defined field value
+    @param v packet value
+ */
+#define NV_FLD_SET_PF_DEF(p,f,c,v) \
+    (((v) & ~NV_FIELD_SHIFTMASK(p##_##f##_RANGE)) | \
+        NV_PF_DEF(p,f,c))
+
+#endif // INCLUDED_NVRM_DRF_H
diff --git a/drivers/platform/tegra/mc/pmqos_bwmgr_client.c b/drivers/platform/tegra/mc/pmqos_bwmgr_client.c
new file mode 100644
index 000000000000..fae3df503754
--- /dev/null
+++ b/drivers/platform/tegra/mc/pmqos_bwmgr_client.c
@@ -0,0 +1,72 @@
+/**
+ * Copyright (c) 2015-2016, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ */
+
+#include <linux/platform/tegra/emc_bwmgr.h>
+#include <linux/err.h>
+#include <linux/pm_qos.h>
+
+
+#if defined(CONFIG_TEGRA_BWMGR)
+
+/* Static global handle for PMQoS client */
+static struct tegra_bwmgr_client *pmqos_bwmgr_handle;
+
+static int __init register_pmqos_bwmgr_client(void)
+{
+	int ret = 0;
+
+	pmqos_bwmgr_handle = tegra_bwmgr_register(TEGRA_BWMGR_CLIENT_PMQOS);
+	if (IS_ERR_OR_NULL(pmqos_bwmgr_handle)) {
+		pr_err("emc bwmgr registration failed for pmqos client\n");
+		ret = -ENODEV;
+	} else {
+		pr_debug("emc bwmgr registration successful for pmqos client\n");
+	}
+	return ret;
+}
+
+static int pmqos_emc_freq_min_notify(struct notifier_block *b,
+			unsigned long l, void *v)
+{
+	int ret = 0;
+	unsigned long floor_freq;
+
+	floor_freq = (unsigned long)pm_qos_request(PM_QOS_EMC_FREQ_MIN);
+	/* pm_qos_request() returns frequency in Khz */
+	floor_freq *= 1000;
+	ret = tegra_bwmgr_set_emc(pmqos_bwmgr_handle, floor_freq,
+						TEGRA_BWMGR_SET_EMC_FLOOR);
+	if (ret)
+		return ret;
+
+	return NOTIFY_OK;
+}
+
+static struct notifier_block pmqos_emc_freq_min_nb = {
+	.notifier_call = pmqos_emc_freq_min_notify,
+};
+
+int __init pmqos_bwmgr_init(void)
+{
+	int ret = 0;
+
+	ret = register_pmqos_bwmgr_client();
+	if (ret)
+		pr_err("pmqos init in bandwidth manager failed\n");
+	else
+		ret = pm_qos_add_notifier(PM_QOS_EMC_FREQ_MIN,
+						 &pmqos_emc_freq_min_nb);
+
+	return ret;
+}
+#endif /* CONFIG_TEGRA_BWMGR */
diff --git a/drivers/platform/tegra/mc/tegra-mc-sid.c b/drivers/platform/tegra/mc/tegra-mc-sid.c
new file mode 100644
index 000000000000..238593fff08a
--- /dev/null
+++ b/drivers/platform/tegra/mc/tegra-mc-sid.c
@@ -0,0 +1,272 @@
+/*
+ * MC StreamID configuration
+ *
+ * Copyright (c) 2015-2017, NVIDIA CORPORATION.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#define pr_fmt(fmt)	"%s(): " fmt, __func__
+
+#include <linux/err.h>
+#include <linux/module.h>
+#include <linux/debugfs.h>
+#include <soc/tegra/fuse.h>
+#include <linux/platform_device.h>
+#include <linux/io.h>
+#include <linux/of.h>
+
+#include <linux/platform/tegra/tegra-mc-sid.h>
+#include <dt-bindings/memory/tegra-swgroup.h>
+
+#define TO_MC_SID_STREAMID_SECURITY_CONFIG(addr)	(addr + sizeof(u32))
+
+#define SMMU_BYPASS_SID		0x7f
+
+struct tegra_mc_sid {
+	struct device *dev;
+	void __iomem *base;
+	void __iomem *sid_base;
+	const struct tegra_mc_sid_soc_data *soc_data;
+	u32 smmu_bypass_sid;
+	struct dentry *debugfs_root;
+};
+
+static struct tegra_mc_sid *mc_sid;
+
+/*
+ * Return the by-pass-smmu StreamID.
+ */
+u32 tegra_mc_get_smmu_bypass_sid(void)
+{
+	if (!mc_sid)
+		return SMMU_BYPASS_SID;
+
+	return mc_sid->smmu_bypass_sid;
+}
+EXPORT_SYMBOL(tegra_mc_get_smmu_bypass_sid);
+
+/*
+ * Return a string with the name associated with the passed StreamID.
+ */
+const char *tegra_mc_get_sid_name(int sid)
+{
+	int i;
+	struct sid_to_oids *entry;
+
+	if (!mc_sid) {
+		pr_err("mc-sid isn't populated yet\n");
+		goto end;
+	}
+
+	for (i = 0; i < mc_sid->soc_data->nsid_to_oids; i++) {
+		entry = &mc_sid->soc_data->sid_to_oids[i];
+
+		if (entry->sid == sid) {
+			if (!entry->name)
+				pr_err("Entry is missing name\n");
+			return entry->name;
+		}
+	}
+
+end:
+	if (sid > TEGRA_SID_PASSTHROUGH)
+		return "Invalid SID";
+	else
+		return "Unassigned SID";
+}
+
+static void __mc_override_sid(int sid, int oid, enum mc_overrides ord)
+{
+	volatile void __iomem *addr;
+	u32 val;
+	int offs = mc_sid->soc_data->sid_override_reg[oid].offs;
+
+	BUG_ON(oid >= mc_sid->soc_data->max_oids);
+
+	addr = TO_MC_SID_STREAMID_SECURITY_CONFIG(mc_sid->sid_base + offs);
+	val = readl_relaxed(addr);
+
+	if (!(val & SCEW_STREAMID_OVERRIDE)
+		&& (val & SCEW_STREAMID_WRITE_ACCESS_DISABLED))
+		return;
+
+	/*
+	 * Only valid when kernel runs in secure mode.
+	 * Otherwise, no effect on MC_SID_STREAMID_SECURITY_CONFIG_*.
+	 */
+	if ((ord == OVERRIDE) ||
+	    (tegra_platform_is_sim() && ord == SIM_OVERRIDE))
+		val = SCEW_STREAMID_OVERRIDE | SCEW_NS;
+	else
+		val = SCEW_NS;
+
+	writel_relaxed(val, addr);
+
+	addr = mc_sid->sid_base + offs;
+	writel_relaxed(sid, addr);
+
+	pr_debug("override sid=%d oid=%d ord=%d at offset=%x\n",
+		 sid, oid, ord, offs);
+}
+
+void platform_override_streamid(int sid)
+{
+	int i;
+
+	if (!mc_sid || !mc_sid->sid_base) {
+		pr_err("mc-sid isn't populated\n");
+		return;
+	}
+
+	for (i = 0; i < mc_sid->soc_data->nsid_to_oids; i++) {
+		struct sid_to_oids *conf;
+		int j;
+
+		conf = &mc_sid->soc_data->sid_to_oids[i];
+		BUG_ON(conf->noids > MAX_OIDS_IN_SID);
+
+		if (sid != conf->sid)
+			continue;
+
+		for (j = 0; j < conf->noids; j++)
+			__mc_override_sid(sid, conf->oid[j], conf->ord);
+	}
+}
+
+#if defined(CONFIG_DEBUG_FS)
+
+enum { ORD, SEC, TXN, MAX_REGS_TYPE};
+
+static const char * const mc_regs_type[] = { "ord", "sec", "txn", };
+
+static int mc_reg32_debugfs_set(void *data, u64 val)
+{
+	writel(val, data);
+	return 0;
+}
+
+static int mc_reg32_debugfs_get(void *data, u64 *val)
+{
+	*val = readl(data);
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(mc_reg32_debugfs_fops,
+			mc_reg32_debugfs_get,
+			mc_reg32_debugfs_set, "%08llx\n");
+
+static void tegra_mc_sid_create_debugfs(void)
+{
+	int i, j;
+
+	mc_sid->debugfs_root = debugfs_create_dir("tegra_mc_sid", NULL);
+	if (!mc_sid->debugfs_root)
+		return;
+
+	for (i = 0; i < MAX_REGS_TYPE; i++) {
+		void __iomem *base;
+		struct dentry *dent;
+
+		if (i == SEC)
+			base = mc_sid->sid_base + sizeof(u32);
+		else if (i == TXN)
+			base = mc_sid->base + 0x1000;
+		else
+			base = mc_sid->sid_base;
+
+		dent = debugfs_create_dir(mc_regs_type[i],
+						mc_sid->debugfs_root);
+		if (!dent)
+			continue;
+
+		for (j = 0; j < mc_sid->soc_data->nsid_override_reg; j++) {
+			void *addr;
+
+			addr = base +
+				mc_sid->soc_data->sid_override_reg[j].offs;
+			debugfs_create_file(
+				mc_sid->soc_data->sid_override_reg[j].name,
+				S_IRUGO | S_IWUSR, dent, addr,
+				&mc_reg32_debugfs_fops);
+		}
+	}
+}
+
+static void tegra_mc_sid_remove_debugfs(void)
+{
+	debugfs_remove_recursive(mc_sid->debugfs_root);
+}
+#else
+static inline void tegra_mc_sid_create_debugfs(void)
+{
+}
+static void tegra_mc_sid_remove_debugfs(void)
+{
+}
+#endif	/* CONFIG_DEBUG_FS */
+
+int tegra_mc_sid_probe(struct platform_device *pdev,
+			const struct tegra_mc_sid_soc_data *soc_data)
+{
+	struct resource *res;
+	static void __iomem *addr;
+
+	mc_sid = devm_kzalloc(&pdev->dev, sizeof(*mc_sid), GFP_KERNEL);
+	if (!mc_sid)
+		return -ENOMEM;
+
+	mc_sid->dev = &pdev->dev;
+	mc_sid->soc_data = soc_data;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	addr = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(addr))
+		return PTR_ERR(addr);
+
+	mc_sid->sid_base = addr;
+
+	/* Read the bypass streamid. If not found, assign default value. */
+	if (of_property_read_u32(pdev->dev.of_node,
+				"nvidia,by-pass-smmu-streamid",
+				&mc_sid->smmu_bypass_sid))
+		mc_sid->smmu_bypass_sid = SMMU_BYPASS_SID;
+
+	/* FIXME: wait for MC driver */
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 1);
+	addr = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(addr))
+		return PTR_ERR(addr);
+
+	mc_sid->base = addr;
+
+	writel_relaxed(TBU_BYPASS_SID,
+		mc_sid->base + MC_SMMU_BYPASS_CONFIG_0);
+
+	tegra_mc_sid_create_debugfs();
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(tegra_mc_sid_probe);
+
+int tegra_mc_sid_remove(struct platform_device *pdev)
+{
+	tegra_mc_sid_remove_debugfs();
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(tegra_mc_sid_remove);
+
+MODULE_DESCRIPTION("MC StreamID configuration");
+MODULE_AUTHOR("Hiroshi DOYU <hdoyu@nvidia.com>, Pritesh Raithatha <praithatha@nvidia.com>");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/platform/tegra/mc/tegra186-mc-sid.c b/drivers/platform/tegra/mc/tegra186-mc-sid.c
new file mode 100644
index 000000000000..5b939b639939
--- /dev/null
+++ b/drivers/platform/tegra/mc/tegra186-mc-sid.c
@@ -0,0 +1,539 @@
+/*
+ * Tegra186 MC StreamID configuration
+ *
+ * Copyright (c) 2016, NVIDIA CORPORATION.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#define pr_fmt(fmt)	"%s(): " fmt, __func__
+
+#include <linux/err.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+
+#include <linux/platform/tegra/tegra-mc-sid.h>
+#include <dt-bindings/memory/tegra-swgroup.h>
+
+enum override_id {
+	PTCR,
+	AFIR,
+	HDAR,
+	HOST1XDMAR,
+	NVENCSRD,
+	SATAR,
+	MPCORER,
+	NVENCSWR,
+	AFIW,
+	HDAW,
+	MPCOREW,
+	SATAW,
+	ISPRA,
+	ISPWA,
+	ISPWB,
+	XUSB_HOSTR,
+	XUSB_HOSTW,
+	XUSB_DEVR,
+	XUSB_DEVW,
+	TSECSRD,
+	TSECSWR,
+	GPUSRD,
+	GPUSWR,
+	SDMMCRA,
+	SDMMCRAA,
+	SDMMCR,
+	SDMMCRAB,
+	SDMMCWA,
+	SDMMCWAA,
+	SDMMCW,
+	SDMMCWAB,
+	VICSRD,
+	VICSWR,
+	VIW,
+	NVDECSRD,
+	NVDECSWR,
+	APER,
+	APEW,
+	NVJPGSRD,
+	NVJPGSWR,
+	SESRD,
+	SESWR,
+	ETRR,
+	ETRW,
+	TSECSRDB,
+	TSECSWRB,
+	GPUSRD2,
+	GPUSWR2,
+	AXISR,
+	AXISW,
+	EQOSR,
+	EQOSW,
+	UFSHCR,
+	UFSHCW,
+	NVDISPLAYR,
+	BPMPR,
+	BPMPW,
+	BPMPDMAR,
+	BPMPDMAW,
+	AONR,
+	AONW,
+	AONDMAR,
+	AONDMAW,
+	SCER,
+	SCEW,
+	SCEDMAR,
+	SCEDMAW,
+	APEDMAR,
+	APEDMAW,
+	NVDISPLAYR1,
+	VICSRD1,
+	NVDECSRD1,
+	MAX_OID,
+};
+
+static struct sid_override_reg sid_override_reg[] = {
+	DEFREG(PTCR,		0x000),
+	DEFREG(AFIR,		0x070),
+	DEFREG(HDAR,		0x0a8),
+	DEFREG(HOST1XDMAR,	0x0b0),
+	DEFREG(NVENCSRD,	0x0e0),
+	DEFREG(SATAR,		0x0f8),
+	DEFREG(MPCORER,		0x138),
+	DEFREG(NVENCSWR,	0x158),
+	DEFREG(AFIW,		0x188),
+	DEFREG(HDAW,		0x1a8),
+	DEFREG(MPCOREW,		0x1c8),
+	DEFREG(SATAW,		0x1e8),
+	DEFREG(ISPRA,		0x220),
+	DEFREG(ISPWA,		0x230),
+	DEFREG(ISPWB,		0x238),
+	DEFREG(XUSB_HOSTR,	0x250),
+	DEFREG(XUSB_HOSTW,	0x258),
+	DEFREG(XUSB_DEVR,	0x260),
+	DEFREG(XUSB_DEVW,	0x268),
+	DEFREG(TSECSRD,		0x2a0),
+	DEFREG(TSECSWR,		0x2a8),
+	DEFREG(GPUSRD,		0x2c0),
+	DEFREG(GPUSWR,		0x2c8),
+	DEFREG(SDMMCRA,		0x300),
+	DEFREG(SDMMCRAA,	0x308),
+	DEFREG(SDMMCR,		0x310),
+	DEFREG(SDMMCRAB,	0x318),
+	DEFREG(SDMMCWA,		0x320),
+	DEFREG(SDMMCWAA,	0x328),
+	DEFREG(SDMMCW,		0x330),
+	DEFREG(SDMMCWAB,	0x338),
+	DEFREG(VICSRD,		0x360),
+	DEFREG(VICSWR,		0x368),
+	DEFREG(VIW,		0x390),
+	DEFREG(NVDECSRD,	0x3c0),
+	DEFREG(NVDECSWR,	0x3c8),
+	DEFREG(APER,		0x3d0),
+	DEFREG(APEW,		0x3d8),
+	DEFREG(NVJPGSRD,	0x3f0),
+	DEFREG(NVJPGSWR,	0x3f8),
+	DEFREG(SESRD,		0x400),
+	DEFREG(SESWR,		0x408),
+	DEFREG(ETRR,		0x420),
+	DEFREG(ETRW,		0x428),
+	DEFREG(TSECSRDB,	0x430),
+	DEFREG(TSECSWRB,	0x438),
+	DEFREG(GPUSRD2,		0x440),
+	DEFREG(GPUSWR2,		0x448),
+	DEFREG(AXISR,		0x460),
+	DEFREG(AXISW,		0x468),
+	DEFREG(EQOSR,		0x470),
+	DEFREG(EQOSW,		0x478),
+	DEFREG(UFSHCR,		0x480),
+	DEFREG(UFSHCW,		0x488),
+	DEFREG(NVDISPLAYR,	0x490),
+	DEFREG(BPMPR,		0x498),
+	DEFREG(BPMPW,		0x4a0),
+	DEFREG(BPMPDMAR,	0x4a8),
+	DEFREG(BPMPDMAW,	0x4b0),
+	DEFREG(AONR,		0x4b8),
+	DEFREG(AONW,		0x4c0),
+	DEFREG(AONDMAR,		0x4c8),
+	DEFREG(AONDMAW,		0x4d0),
+	DEFREG(SCER,		0x4d8),
+	DEFREG(SCEW,		0x4e0),
+	DEFREG(SCEDMAR,		0x4e8),
+	DEFREG(SCEDMAW,		0x4f0),
+	DEFREG(APEDMAR,		0x4f8),
+	DEFREG(APEDMAW,		0x500),
+	DEFREG(NVDISPLAYR1,	0x508),
+	DEFREG(VICSRD1,		0x510),
+	DEFREG(NVDECSRD1,	0x518),
+};
+
+static struct sid_to_oids sid_to_oids[] = {
+	{
+		.sid	= TEGRA_SID_AFI,
+		.noids	= 2,
+		.oid	= {
+			AFIR,
+			AFIW,
+		},
+		.ord = OVERRIDE,
+		.name = "AFI",
+	},
+	{
+		.sid	= TEGRA_SID_HDA,
+		.noids	= 2,
+		.oid	= {
+			HDAR,
+			HDAW,
+		},
+		.ord = OVERRIDE,
+		.name = "HDA",
+	},
+	{
+		.sid	= TEGRA_SID_SATA2,
+		.noids	= 2,
+		.oid	= {
+			SATAR,
+			SATAW,
+		},
+		.ord = OVERRIDE,
+		.name = "SATA2",
+	},
+	{
+		.sid	= TEGRA_SID_XUSB_HOST,
+		.noids	= 2,
+		.oid	= {
+			XUSB_HOSTR,
+			XUSB_HOSTW,
+		},
+		.ord = OVERRIDE,
+		.name = "XUSB_HOST",
+	},
+	{
+		.sid	= TEGRA_SID_XUSB_DEV,
+		.noids	= 2,
+		.oid	= {
+			XUSB_DEVR,
+			XUSB_DEVW,
+		},
+		.ord = OVERRIDE,
+		.name = "XUSB_DEV",
+	},
+	{
+		.sid	= TEGRA_SID_TSEC,
+		.noids	= 2,
+		.oid	= {
+			TSECSRD,
+			TSECSWR,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "TSEC",
+	},
+	{
+		.sid	= TEGRA_SID_GPUB,
+		.noids	= 4,
+		.oid	= {
+			GPUSRD,
+			GPUSWR,
+			GPUSRD2,
+			GPUSWR2,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "GPU",
+	},
+	{
+		.sid	= TEGRA_SID_SDMMC1A,
+		.noids	= 2,
+		.oid	= {
+			SDMMCRA,
+			SDMMCWA,
+		},
+		.ord = OVERRIDE,
+		.name = "SDMMC1A",
+	},
+	{
+		.sid	= TEGRA_SID_SDMMC2A,
+		.noids	= 2,
+		.oid	= {
+			SDMMCRAA,
+			SDMMCWAA,
+		},
+		.ord = OVERRIDE,
+		.name = "SDMMC2A",
+	},
+	{
+		.sid	= TEGRA_SID_SDMMC3A,
+		.noids	= 2,
+		.oid	= {
+			SDMMCR,
+			SDMMCW,
+		},
+		.ord = OVERRIDE,
+		.name = "SDMMC3A",
+	},
+	{
+		.sid	= TEGRA_SID_SDMMC4A,
+		.noids	= 2,
+		.oid	= {
+			SDMMCRAB,
+			SDMMCWAB,
+		},
+		.ord = OVERRIDE,
+		.name = "SDMMC4A",
+	},
+	{
+		.sid	= TEGRA_SID_APE,
+		.noids	= 4,
+		.oid	= {
+			APER,
+			APEW,
+			APEDMAR,
+			APEDMAW,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "APE",
+	},
+	{
+		.sid	= TEGRA_SID_SE,
+		.noids	= 2,
+		.oid	= {
+			SESRD,
+			SESWR,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "SE",
+	},
+	{
+		.sid	= TEGRA_SID_ETR,
+		.noids	= 2,
+		.oid	= {
+			ETRR,
+			ETRW,
+		},
+		.ord = OVERRIDE,
+		.name = "ETR",
+	},
+	{
+		.sid	= TEGRA_SID_TSECB,
+		.noids	= 2,
+		.oid	= {
+			TSECSRDB,
+			TSECSWRB,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "TSECB",
+	},
+	{
+		.sid	= TEGRA_SID_GPCDMA_0, /* AXIS */
+		.noids	= 2,
+		.oid	= {
+			AXISR,
+			AXISW,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "GPCDMA",
+	},
+	{
+		.sid	= TEGRA_SID_EQOS,
+		.noids	= 2,
+		.oid	= {
+			EQOSR,
+			EQOSW,
+		},
+		.ord = OVERRIDE,
+		.name = "EQOS",
+	},
+	{
+		.sid	= TEGRA_SID_UFSHC,
+		.noids	= 2,
+		.oid	= {
+			UFSHCR,
+			UFSHCW,
+		},
+		.ord = OVERRIDE,
+		.name = "UFSHC",
+	},
+	{
+		.sid	= TEGRA_SID_NVDISPLAY,
+		.noids	= 2,
+		.oid	= {
+			NVDISPLAYR,
+			NVDISPLAYR1,
+		},
+		.ord = OVERRIDE,
+		.name = "NVDISPLAY",
+	},
+	{
+		.sid	= TEGRA_SID_BPMP,
+		.noids	= 4,
+		.oid	= {
+			BPMPR,
+			BPMPW,
+			BPMPDMAR,
+			BPMPDMAW,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "BPMP",
+	},
+	{
+		.sid	= TEGRA_SID_AON,
+		.noids	= 4,
+		.oid	= {
+			AONR,
+			AONW,
+			AONDMAR,
+			AONDMAW,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "AON",
+	},
+	{
+		.sid	= TEGRA_SID_SCE,
+		.noids	= 4,
+		.oid	= {
+			SCER,
+			SCEW,
+			SCEDMAR,
+			SCEDMAW,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "SCE",
+	},
+	{
+		.sid	= TEGRA_SID_HC,
+		.noids	= 1,
+		.oid	= {
+			HOST1XDMAR,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "HC",
+	},
+	{
+		.sid	= TEGRA_SID_VIC,
+		.noids	= 3,
+		.oid = {
+			VICSRD1,
+			VICSRD,
+			VICSWR,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "VIC",
+	},
+	{
+		.sid	= TEGRA_SID_VI,
+		.noids	= 1,
+		.oid	= {
+			VIW,
+		},
+		.ord = OVERRIDE,
+		.name = "VI",
+	},
+	{
+		.sid	= TEGRA_SID_ISP,
+		.noids	= 3,
+		.oid	= {
+			ISPRA,
+			ISPWA,
+			ISPWB,
+		},
+		.ord = OVERRIDE,
+		.name = "ISP",
+	},
+	{
+		.sid	= TEGRA_SID_NVDEC,
+		.noids	= 3,
+		.oid	= {
+			NVDECSRD1,
+			NVDECSRD,
+			NVDECSWR,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "NVDEC",
+	},
+	{
+		.sid	= TEGRA_SID_NVENC,
+		.noids	= 2,
+		.oid	= {
+			NVENCSRD,
+			NVENCSWR,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "NVENC",
+	},
+	{
+		.sid	= TEGRA_SID_NVJPG,
+		.noids	= 2,
+		.oid	= {
+			NVJPGSRD,
+			NVJPGSWR,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "NVJPG",
+	},
+};
+
+static const struct tegra_mc_sid_soc_data tegra186_mc_soc_data = {
+	.sid_override_reg = sid_override_reg,
+	.nsid_override_reg = ARRAY_SIZE(sid_override_reg),
+	.sid_to_oids = sid_to_oids,
+	.nsid_to_oids = ARRAY_SIZE(sid_to_oids),
+	.max_oids = MAX_OID,
+};
+
+static int tegra186_mc_sid_probe(struct platform_device *pdev)
+{
+	return tegra_mc_sid_probe(pdev, &tegra186_mc_soc_data);
+}
+
+static const struct of_device_id tegra186_mc_sid_of_match[] = {
+	{ .compatible = "nvidia,tegra-mc-sid", },
+	{ .compatible = "nvidia,tegra186-mc-sid", },
+	{},
+};
+MODULE_DEVICE_TABLE(of, tegra186_mc_sid_of_match);
+
+static struct platform_driver tegra186_mc_sid_driver = {
+	.probe	= tegra186_mc_sid_probe,
+	.remove = tegra_mc_sid_remove,
+	.driver	= {
+		.owner	= THIS_MODULE,
+		.name	= "tegra186-mc-sid",
+		.of_match_table	= of_match_ptr(tegra186_mc_sid_of_match),
+	},
+};
+
+static int __init tegra186_mc_sid_init(void)
+{
+	struct device_node *np;
+	struct platform_device *pdev = NULL;
+
+	np = of_find_compatible_node(NULL, NULL, "nvidia,tegra186-mc-sid");
+	if (!np)
+		np = of_find_compatible_node(NULL, NULL, "nvidia,tegra-mc-sid");
+
+	if (np) {
+		pdev = of_platform_device_create(np, NULL,
+						 platform_bus_type.dev_root);
+		of_node_put(np);
+	}
+
+	if (IS_ERR_OR_NULL(pdev))
+		return -ENODEV;
+
+	return platform_driver_register(&tegra186_mc_sid_driver);
+}
+arch_initcall(tegra186_mc_sid_init);
+
+MODULE_DESCRIPTION("MC StreamID configuration");
+MODULE_AUTHOR("Hiroshi DOYU <hdoyu@nvidia.com>, Pritesh Raithatha <praithatha@nvidia.com>");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/platform/tegra/mc/tegra18_emc.c b/drivers/platform/tegra/mc/tegra18_emc.c
new file mode 100644
index 000000000000..2cdb05c80347
--- /dev/null
+++ b/drivers/platform/tegra/mc/tegra18_emc.c
@@ -0,0 +1,38 @@
+/*
+ * Copyright (c) 2015, NVIDIA CORPORATION.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ */
+
+#include <linux/kernel.h>
+
+#include <linux/platform/tegra/tegra_emc.h>
+#include <linux/platform/tegra/mc.h>
+
+/*
+ * Currently just some stubs to get things building.
+ */
+u8 tegra_emc_bw_efficiency = 50;
+
+int tegra_emc_get_dram_type(void)
+{
+	return DRAM_TYPE_LPDDR4;
+}
+
+int tegra_emc_set_over_temp_state(unsigned long state)
+{
+	return 0;
+}
+
+int tegra_emc_get_dram_temperature(void)
+{
+	return 0;
+}
+
diff --git a/drivers/platform/tegra/mc/tegra18x_la.c b/drivers/platform/tegra/mc/tegra18x_la.c
new file mode 100644
index 000000000000..e92adb26e4d5
--- /dev/null
+++ b/drivers/platform/tegra/mc/tegra18x_la.c
@@ -0,0 +1,708 @@
+/*
+ * Copyright (C) 2015-2018, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+
+#include <linux/types.h>
+#include <linux/clk.h>
+#include <linux/of.h>
+#include <linux/resource.h>
+#include <linux/of_address.h>
+#include <linux/version.h>
+#include <asm/io.h>
+
+#include <linux/platform/tegra/mc-regs-t18x.h>
+#include <linux/platform/tegra/tegra_emc.h>
+#include <linux/platform/tegra/mc.h>
+#include <linux/platform/tegra/latency_allowance.h>
+#include <linux/platform/tegra/emc_bwmgr.h>
+
+#include "la_priv.h"
+
+#define T18X_LA_EMEM_CHANNEL_ENABLE_MASK		0xf
+#define T18X_LA_ECC_ENABLE_MASK				0x1
+#define T18X_LA_2_STAGE_ECC_ISO_DDA_FACTOR_FP		1400U
+#define T18X_LA_DISP_CATCHUP_FACTOR_FP			1100U
+#define T18X_LA_MCCIF_BUF_SZ_BYTES_FP			30976000U
+#define T18X_LA_ST_LA_SNAP_ARB_TO_ROW_SRT_EMCCLKS	54U
+#define T18X_LA_ST_LA_MINUS_SNAP_ARB_TO_ROW_SRT_EMCCLKS	130U
+#define T18X_LA_EXPIRATION_TIME_EMCCLKS			210U
+#define T18X_LA_MAX_DRAIN_TIME_USEC			10U
+#define T18X_LA_CONS_MEM_EFF_DIV_FACTOR			2U
+
+/*
+ * For T18X we need varying fixed point accuracies. "fp2" variables provide an
+ * accuracy of 1/100. And "fp5" variables provide an accuracy of 1/100000.
+ */
+#define T18X_LA_FP2_FACTOR			100U
+#define T18X_LA_REAL_TO_FP2(val)		((val) * T18X_LA_FP2_FACTOR)
+#define T18X_LA_FP_TO_FP2(val)			((val) / 10U)
+#define T18X_LA_FP5_TO_FPA(val)			((val) / 10U)
+
+#define T18X_LA(a, r, i, ct, sr, la, clk)		\
+{							\
+	.reg_addr = MC_LATENCY_ALLOWANCE_ ## a,		\
+	.mask = MASK(r),				\
+	.shift = SHIFT(r),				\
+	.id = ID(i),					\
+	.name = __stringify(i),				\
+	.client_type = TEGRA_LA_ ## ct ## _CLIENT,	\
+	.min_scaling_ratio = sr,			\
+	.init_la = la,					\
+	.la_ref_clk_mhz = clk				\
+}
+
+#define T18X_MC_SET_INIT_PTSA_MIN_MAX(p, client, tt, min, max)		\
+	do {								\
+		(p)->client ## _traffic_type = TEGRA_LA_ ## tt;		\
+		(p)->client ## _ptsa_min = (unsigned int)(min) &	\
+			MC_PTSA_MIN_DEFAULT_MASK;			\
+		(p)->client ## _ptsa_max = (unsigned int)(max) &	\
+			MC_PTSA_MAX_DEFAULT_MASK;			\
+	} while (0)
+
+#define T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, client, tt, min, max, rate) \
+	do {								\
+		(p)->client ## _traffic_type = TEGRA_LA_ ## tt;		\
+		(p)->client ## _ptsa_min = (unsigned int)(min) &	\
+			MC_PTSA_MIN_DEFAULT_MASK;			\
+		(p)->client ## _ptsa_max = (unsigned int)(max) &	\
+			MC_PTSA_MAX_DEFAULT_MASK;			\
+		(p)->client ## _ptsa_rate = (unsigned int)(rate) &	\
+			MC_PTSA_RATE_DEFAULT_MASK;			\
+	} while (0)
+
+#define T18X_CALC_AND_UPDATE_ISO_PTSA(p, field, reg, bw_mbps)		\
+	do {								\
+		(p)->field ##_ptsa_rate =				\
+			__t18x_fraction2dda_fp(				\
+				t18x_bwfp_to_fractionfpa(		\
+					bw_mbps * iso_dda_factor_fp),	\
+				hub_dda_div,				\
+				MC_PTSA_RATE_DEFAULT_MASK,		\
+				(p)->field ##_traffic_type);		\
+		mc_writel((p)->field ##_ptsa_rate,			\
+			MC_ ## reg ## _PTSA_RATE);			\
+	} while (0)
+
+
+static struct la_chip_specific *cs;
+static unsigned int num_channels;
+static unsigned int row_srt_sz_bytes;
+static unsigned int dram_emc_freq_factor;
+static unsigned int hi_freq_fp;
+static unsigned int lo_freq_fp;
+static unsigned int hub_dda_div;
+static unsigned int r0_dda_div;
+static unsigned int dram_width_bytes;
+static unsigned int hi_gd_fpa;
+static unsigned int hi_gd_fp5;
+static unsigned int lo_gd_fpa;
+static unsigned int lo_gd_fp5;
+static unsigned int iso_dda_factor_fp;
+
+static struct la_client_info t18x_la_info_array[] = {
+	T18X_LA(AFI_0, 7 : 0,  AFIR, DYNAMIC_READ, 0, 105, 250),
+	T18X_LA(AFI_0, 23 : 16, AFIW, WRITE, 0, 128, 0),
+	T18X_LA(AON_0, 7 : 0, AONR, CONSTANT_READ, 0, 10, 0),
+	T18X_LA(AON_0, 23 : 16, AONW, WRITE, 0, 128, 0),
+	T18X_LA(AONDMA_0, 7 : 0, AONDMAR, DYNAMIC_READ, 1, 189, 102),
+	T18X_LA(AONDMA_0, 23 : 16, AONDMAW, WRITE, 0, 128, 0),
+	T18X_LA(APEDMA_0, 7 : 0, APEDMAR, DYNAMIC_READ, 1, 188, 102),
+	T18X_LA(APEDMA_0, 23 : 16, APEDMAW, WRITE, 0, 128, 0),
+	T18X_LA(APE_0, 7 : 0, APER, CONSTANT_READ, 0, 10, 0),
+	T18X_LA(APE_0, 23 : 16, APEW, WRITE, 0, 128, 0),
+	T18X_LA(AXIS_0, 7 : 0, AXISR, DYNAMIC_READ, 1, 124, 204),
+	T18X_LA(AXIS_0, 23 : 16, AXISW, WRITE, 0, 128, 0),
+	T18X_LA(BPMP_0, 7 : 0, BPMPR, CONSTANT_READ, 0, 10, 0),
+	T18X_LA(BPMP_0, 23 : 16, BPMPW, WRITE, 0, 128, 0),
+	T18X_LA(BPMPDMA_0, 7 : 0, BPMPDMAR, DYNAMIC_READ, 1, 189, 102),
+	T18X_LA(BPMPDMA_0, 23 : 16, BPMPDMAW, WRITE, 0, 128, 0),
+	T18X_LA(EQOS_0, 7 : 0, EQOSR, DYNAMIC_READ, 0, 42, 600),
+	T18X_LA(EQOS_0, 23 : 16, EQOSW, WRITE, 0, 128, 0),
+	T18X_LA(ETR_0, 7 : 0, ETRR, CONSTANT_READ, 0, 80, 0),
+	T18X_LA(ETR_0, 23 : 16, ETRW, WRITE, 0, 128, 0),
+	T18X_LA(GPU_0, 7 : 0, GPUSRD, DYNAMIC_READ, 0, 32, 800),
+	T18X_LA(GPU_0, 23 : 16, GPUSWR, WRITE, 0, 128, 0),
+	T18X_LA(GPU2_0, 7 : 0, GPUSRD2, DYNAMIC_READ, 0, 32, 800),
+	T18X_LA(GPU2_0, 23 : 16, GPUSWR2, WRITE, 0, 128, 0),
+	T18X_LA(HDA_0, 7 : 0, HDAR, CONSTANT_READ, 0, 36, 0),
+	T18X_LA(HDA_0, 23 : 16, HDAW, WRITE, 0, 128, 0),
+	T18X_LA(HC_0, 7 : 0, HOST1X_DMAR, DYNAMIC_READ, 1, 189, 102),
+	T18X_LA(ISP2_0, 7 : 0, ISP_RA, DYNAMIC_READ, 0, 83, 307),
+	T18X_LA(ISP2_1, 7 : 0, ISP_WA, WRITE, 0, 128, 0),
+	T18X_LA(ISP2_1, 23 : 16, ISP_WB, WRITE, 0, 128, 0),
+	T18X_LA(MPCORE_0, 7 : 0, MPCORER, CONSTANT_READ, 0, 4, 0),
+	T18X_LA(MPCORE_0, 23 : 16, MPCOREW, WRITE, 0, 128, 0),
+	T18X_LA(NVDEC_0, 7 : 0, NVDECR, DYNAMIC_READ, 0, 58, 203),
+	T18X_LA(NVDEC_0, 23 : 16, NVDECW, WRITE, 0, 128, 0),
+	T18X_LA(NVDISPLAY_0, 7 : 0, NVDISPLAYR, DISPLAY_READ, 0, 0, 0),
+	T18X_LA(NVENC_0, 7 : 0, NVENCSRD, DYNAMIC_READ, 0, 34, 535),
+	T18X_LA(NVENC_0, 23 : 16, NVENCSWR, WRITE, 0, 128, 0),
+	T18X_LA(NVJPG_0, 7 : 0, NVJPGSRD, DYNAMIC_READ, 0, 127, 197),
+	T18X_LA(NVJPG_0, 23 : 16, NVJPGSWR, WRITE, 0, 128, 0),
+	T18X_LA(PTC_0, 7 : 0, PTCR, CONSTANT_READ, 0, 0, 0),
+	T18X_LA(SATA_0, 7 : 0, SATAR, DYNAMIC_READ, 1, 57, 450),
+	T18X_LA(SATA_0, 23 : 16, SATAW, WRITE, 0, 128, 0),
+	T18X_LA(SCE_0, 7 : 0, SCER, CONSTANT_READ, 0, 10, 0),
+	T18X_LA(SCE_0, 23 : 16, SCEW, WRITE, 0, 128, 0),
+	T18X_LA(SCEDMA_0, 7 : 0, SCEDMAR, DYNAMIC_READ, 1, 189, 102),
+	T18X_LA(SCEDMA_0, 23 : 16, SCEDMAW, WRITE, 0, 128, 0),
+	T18X_LA(SDMMC_0, 7 : 0, SDMMCR, DYNAMIC_READ, 1, 271, 30),
+	T18X_LA(SDMMC_0, 23 : 16, SDMMCW, WRITE, 0, 128, 0),
+	T18X_LA(SDMMCA_0, 7 : 0, SDMMCRA, DYNAMIC_READ, 1, 269, 30),
+	T18X_LA(SDMMCA_0, 23 : 16, SDMMCWA, WRITE, 0, 128, 0),
+	T18X_LA(SDMMCAA_0, 7 : 0, SDMMCRAA, DYNAMIC_READ, 1, 271, 30),
+	T18X_LA(SDMMCAA_0, 23 : 16, SDMMCWAA, WRITE, 0, 128, 0),
+	T18X_LA(SDMMCAB_0, 7 : 0, SDMMCRAB, DYNAMIC_READ, 1, 241, 67),
+	T18X_LA(SDMMCAB_0, 23 : 16, SDMMCWAB, WRITE, 0, 128, 0),
+	T18X_LA(SE_0, 7 : 0, SESRD, DYNAMIC_READ, 0, 122, 208),
+	T18X_LA(SE_0, 23 : 16, SESWR, WRITE, 0, 128, 0),
+	T18X_LA(TSEC_0, 7 : 0, TSECSRD, DYNAMIC_READ, 1, 189, 102),
+	T18X_LA(TSEC_0, 23 : 16, TSECSWR, WRITE, 0, 128, 0),
+	T18X_LA(TSECB_0, 7 : 0, TSECBSRD, DYNAMIC_READ, 1, 189, 102),
+	T18X_LA(TSECB_0, 23 : 16, TSECBSWR, WRITE, 0, 128, 0),
+	T18X_LA(UFSHC_0, 7 : 0, UFSHCR, DYNAMIC_READ, 0, 135, 187),
+	T18X_LA(UFSHC_0, 23 : 16, UFSHCW, WRITE, 0, 128, 0),
+	T18X_LA(VI2_0, 7 : 0, VI_W, WRITE, 0, 128, 0),
+	T18X_LA(VIC_0, 7 : 0, VICSRD, DYNAMIC_READ, 0, 32, 800),
+	T18X_LA(VIC_0, 23 : 16, VICSWR, WRITE, 0, 128, 0),
+	T18X_LA(XUSB_1, 7 : 0, XUSB_DEVR, DYNAMIC_READ, 1, 123, 204),
+	T18X_LA(XUSB_1, 23 : 16, XUSB_DEVW, WRITE, 0, 128, 0),
+	T18X_LA(XUSB_0, 7 : 0, XUSB_HOSTR, DYNAMIC_READ, 1, 123, 204),
+	T18X_LA(XUSB_0, 23 : 16, XUSB_HOSTW, WRITE, 0, 128, 0),
+
+	/* end of list */
+	T18X_LA(ROC_DMA_R_0, 0 : 0, MAX_ID, CONSTANT_READ, 0, 0, 0)
+};
+
+
+static inline unsigned int __t18x_fraction2dda_fp(unsigned int fraction_fpa,
+					unsigned int div,
+					unsigned int mask,
+					enum la_traffic_type traffic_type)
+{
+	unsigned int dda = 0;
+	int i = 0;
+	unsigned int r = 0;
+
+	fraction_fpa /= div;
+
+	for (i = 0; i < EMEM_PTSA_RATE_WIDTH; i++) {
+		fraction_fpa *= 2;
+		r = LA_FPA_TO_REAL(fraction_fpa);
+		dda = (dda << 1) | (unsigned int)(r);
+		fraction_fpa -= LA_REAL_TO_FPA(r);
+	}
+	if (fraction_fpa > 0) {
+		/* Do not round up if the calculated dda is at the mask value
+		   already, it will overflow */
+		if (dda != mask) {
+			if (traffic_type != TEGRA_LA_NISO ||
+				fraction_fpa >= 5000 ||
+				dda == 0) {
+				/* to round up dda value */
+				dda++;
+			}
+		}
+	}
+
+	return min(dda, (unsigned int)MAX_DDA_RATE);
+}
+
+static inline unsigned int t18x_bw_to_fractionfpa(unsigned int bw_mbps)
+{
+	unsigned int ret_val =
+			(lo_gd_fpa * T18X_LA_REAL_TO_FP2(bw_mbps)) /
+			(T18X_LA_FP_TO_FP2(lo_freq_fp) * dram_width_bytes);
+
+	if (bw_mbps == 0)
+		return 0;
+	else
+		return max((unsigned int)1, ret_val);
+}
+
+static inline unsigned int t18x_bwfp_to_fractionfpa(unsigned int bw_mbps_fp)
+{
+	unsigned int ret_val =
+			(lo_gd_fpa * T18X_LA_FP_TO_FP2(bw_mbps_fp)) /
+			(T18X_LA_FP_TO_FP2(lo_freq_fp) * dram_width_bytes);
+
+	if (bw_mbps_fp == 0)
+		return 0;
+	else
+		return max((unsigned int)1, ret_val);
+}
+
+static void program_ptsa(void)
+{
+	struct ptsa_info *p = &cs->ptsa_info;
+
+	WRITE_PTSA_MIN_MAX_RATE(p, dis, DIS);
+	WRITE_PTSA_MIN_MAX_RATE(p, ve, VE);
+	WRITE_PTSA_MIN_MAX_RATE(p, isp, ISP);
+	WRITE_PTSA_MIN_MAX_RATE(p, apedmapc, APEDMAPC);
+	WRITE_PTSA_MIN_MAX_RATE(p, eqospc, EQOSPC);
+	WRITE_PTSA_MIN_MAX(p, ring1_rd_nb, RING1_RD_NB);
+	WRITE_PTSA_MIN_MAX(p, ring1_wr_nb, RING1_WR_NB);
+	WRITE_PTSA_MIN_MAX_RATE(p, ring1_rd_b, RING1_RD_B);
+	WRITE_PTSA_MIN_MAX_RATE(p, ring1_wr_b, RING1_WR_B);
+	WRITE_PTSA_MIN_MAX_RATE(p, ring2, RING2);
+	WRITE_PTSA_MIN_MAX(p, mll_mpcorer, MLL_MPCORER);
+	WRITE_PTSA_MIN_MAX_RATE(p, smmu, SMMU_SMMU);
+	WRITE_PTSA_MIN_MAX_RATE(p, bpmpdmapc, BPMPDMAPC);
+
+	WRITE_PTSA_MIN_MAX_RATE(p, aondmapc, AONDMAPC);
+	WRITE_PTSA_MIN_MAX_RATE(p, aonpc, AONPC);
+	WRITE_PTSA_MIN_MAX_RATE(p, apb, APB);
+	WRITE_PTSA_MIN_MAX_RATE(p, aud, AUD);
+	WRITE_PTSA_MIN_MAX_RATE(p, bpmppc, BPMPPC);
+	WRITE_PTSA_MIN_MAX_RATE(p, dfd, DFD);
+	WRITE_PTSA_MIN_MAX_RATE(p, ftop, FTOP);
+	WRITE_PTSA_MIN_MAX_RATE(p, gk, GK);
+	WRITE_PTSA_MIN_MAX_RATE(p, gk2, GK2);
+	WRITE_PTSA_MIN_MAX_RATE(p, hdapc, HDAPC);
+	WRITE_PTSA_MIN_MAX_RATE(p, host, HOST);
+	WRITE_PTSA_MIN_MAX_RATE(p, jpg, JPG);
+	WRITE_PTSA_MIN_MAX_RATE(p, mse, MSE);
+	WRITE_PTSA_MIN_MAX_RATE(p, mse2, MSE2);
+	WRITE_PTSA_MIN_MAX_RATE(p, nic, NIC);
+	WRITE_PTSA_MIN_MAX_RATE(p, nvd, NVD);
+	WRITE_PTSA_MIN_MAX_RATE(p, nvd3, NVD3);
+	WRITE_PTSA_MIN_MAX_RATE(p, pcx, PCX);
+	WRITE_PTSA_MIN_MAX_RATE(p, roc_dma_r, ROC_DMA_R);
+	WRITE_PTSA_MIN_MAX_RATE(p, sax, SAX);
+	WRITE_PTSA_MIN_MAX_RATE(p, scedmapc, SCEDMAPC);
+	WRITE_PTSA_MIN_MAX_RATE(p, scepc, SCEPC);
+	WRITE_PTSA_MIN_MAX_RATE(p, sd, SD);
+	WRITE_PTSA_MIN_MAX_RATE(p, sdm, SDM);
+	WRITE_PTSA_MIN_MAX_RATE(p, sdm1, SDM1);
+	WRITE_PTSA_MIN_MAX_RATE(p, ufshcpc, UFSHCPC);
+	WRITE_PTSA_MIN_MAX_RATE(p, usbd, USBD);
+	WRITE_PTSA_MIN_MAX_RATE(p, usbx, USBX);
+	WRITE_PTSA_MIN_MAX_RATE(p, vicpc, VICPC);
+	WRITE_PTSA_MIN_MAX_RATE(p, vicpc3, VICPC3);
+
+	/* update shadowed registers */
+	mc_writel(1, MC_TIMING_CONTROL);
+}
+
+static void save_ptsa(void)
+{
+	struct ptsa_info *p = &cs->ptsa_info;
+
+	READ_PTSA_MIN_MAX_RATE(p, dis, DIS);
+	READ_PTSA_MIN_MAX_RATE(p, ve, VE);
+	READ_PTSA_MIN_MAX_RATE(p, isp, ISP);
+	READ_PTSA_MIN_MAX_RATE(p, apedmapc, APEDMAPC);
+	READ_PTSA_MIN_MAX_RATE(p, eqospc, EQOSPC);
+	READ_PTSA_MIN_MAX(p, ring1_rd_nb, RING1_RD_NB);
+	READ_PTSA_MIN_MAX(p, ring1_wr_nb, RING1_WR_NB);
+	READ_PTSA_MIN_MAX_RATE(p, ring1_rd_b, RING1_RD_B);
+	READ_PTSA_MIN_MAX_RATE(p, ring1_wr_b, RING1_WR_B);
+	READ_PTSA_MIN_MAX_RATE(p, ring2, RING2);
+	READ_PTSA_MIN_MAX(p, mll_mpcorer, MLL_MPCORER);
+	READ_PTSA_MIN_MAX_RATE(p, smmu, SMMU_SMMU);
+	READ_PTSA_MIN_MAX_RATE(p, bpmpdmapc, BPMPDMAPC);
+
+	READ_PTSA_MIN_MAX_RATE(p, aondmapc, AONDMAPC);
+	READ_PTSA_MIN_MAX_RATE(p, aonpc, AONPC);
+	READ_PTSA_MIN_MAX_RATE(p, apb, APB);
+	READ_PTSA_MIN_MAX_RATE(p, aud, AUD);
+	READ_PTSA_MIN_MAX_RATE(p, bpmppc, BPMPPC);
+	READ_PTSA_MIN_MAX_RATE(p, dfd, DFD);
+	READ_PTSA_MIN_MAX_RATE(p, ftop, FTOP);
+	READ_PTSA_MIN_MAX_RATE(p, gk, GK);
+	READ_PTSA_MIN_MAX_RATE(p, gk2, GK2);
+	READ_PTSA_MIN_MAX_RATE(p, hdapc, HDAPC);
+	READ_PTSA_MIN_MAX_RATE(p, host, HOST);
+	READ_PTSA_MIN_MAX_RATE(p, jpg, JPG);
+	READ_PTSA_MIN_MAX_RATE(p, mse, MSE);
+	READ_PTSA_MIN_MAX_RATE(p, mse2, MSE2);
+	READ_PTSA_MIN_MAX_RATE(p, nic, NIC);
+	READ_PTSA_MIN_MAX_RATE(p, nvd, NVD);
+	READ_PTSA_MIN_MAX_RATE(p, nvd3, NVD3);
+	READ_PTSA_MIN_MAX_RATE(p, pcx, PCX);
+	READ_PTSA_MIN_MAX_RATE(p, roc_dma_r, ROC_DMA_R);
+	READ_PTSA_MIN_MAX_RATE(p, sax, SAX);
+	READ_PTSA_MIN_MAX_RATE(p, scedmapc, SCEDMAPC);
+	READ_PTSA_MIN_MAX_RATE(p, scepc, SCEPC);
+	READ_PTSA_MIN_MAX_RATE(p, sd, SD);
+	READ_PTSA_MIN_MAX_RATE(p, sdm, SDM);
+	READ_PTSA_MIN_MAX_RATE(p, sdm1, SDM1);
+	READ_PTSA_MIN_MAX_RATE(p, ufshcpc, UFSHCPC);
+	READ_PTSA_MIN_MAX_RATE(p, usbd, USBD);
+	READ_PTSA_MIN_MAX_RATE(p, usbx, USBX);
+	READ_PTSA_MIN_MAX_RATE(p, vicpc, VICPC);
+	READ_PTSA_MIN_MAX_RATE(p, vicpc3, VICPC3);
+}
+
+static void t18x_init_ptsa(void)
+{
+	struct ptsa_info *p = &cs->ptsa_info;
+	unsigned int eqos_bw;
+
+	/* initialize PTSA min/max values */
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, aondmapc, SISO, 1, 1, 0);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, aonpc, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, apb, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX(p, apedmapc, HISO, -5, 31);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, aud, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, bpmpdmapc, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, bpmppc, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, dfd, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX(p, dis, HISO, -5, 31);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX(p, eqospc, HISO, -5, 31);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX(p, ftop, NISO, -2, 0);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, gk, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, gk2, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, hdapc, SISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, host, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, isp, SISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, jpg, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX(p, mll_mpcorer, NISO, -4, 4);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, mse, SISO, 1, 1, 0);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, mse2, SISO, 1, 1, 0);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, nic, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, nvd, SISO, 1, 1, 0);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, nvd3, SISO, 1, 1, 0);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, pcx, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, roc_dma_r, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, ring1_rd_b, NISO, 62, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX(p, ring1_rd_nb, HISO, -5, 31);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, ring1_wr_b, NISO, 62, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX(p, ring1_wr_nb, HISO, -5, 31);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, ring2, NISO, -2, 0, 12);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, sax, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, scedmapc, SISO, 1, 1, 0);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, scepc, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, sd, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, sdm, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, sdm1, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, smmu, NISO, 1, 1, 0);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, ufshcpc, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, usbd, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, usbx, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX(p, ve, HISO, 1, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, vicpc, NISO, -2, 0, 1);
+	T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, vicpc3, NISO, -2, 0, 1);
+
+
+	p->ring1_rd_b_ptsa_rate = (unsigned int)(1) & MC_PTSA_RATE_DEFAULT_MASK;
+	p->ring1_wr_b_ptsa_rate = (unsigned int)(1) & MC_PTSA_RATE_DEFAULT_MASK;
+
+	p->ring2_ptsa_rate = (unsigned int)(12) & MC_PTSA_RATE_DEFAULT_MASK;
+
+	p->bpmpdmapc_ptsa_rate = (unsigned int)(1) & MC_PTSA_RATE_DEFAULT_MASK;
+
+	eqos_bw = LA_FP_TO_REAL(250 * T18X_LA_2_STAGE_ECC_ISO_DDA_FACTOR_FP);
+	p->eqospc_ptsa_rate =
+		__t18x_fraction2dda_fp(t18x_bw_to_fractionfpa(eqos_bw),
+					hub_dda_div,
+					MC_PTSA_RATE_DEFAULT_MASK,
+					p->eqospc_traffic_type);
+
+	program_ptsa();
+}
+
+static int t18x_update_camera_ptsa_rate(enum tegra_la_id id,
+					unsigned int bw_mbps,
+					int is_hiso)
+{
+	struct ptsa_info *p = &cs->ptsa_info;
+
+	if ((id == ID(ISP_RA)) ||
+		(id == ID(ISP_WA)) ||
+		(id == ID(ISP_WB))) {
+		unsigned int client_traffic_type_config_2 =
+				mc_readl(MC_CLIENT_TRAFFIC_TYPE_CONFIG_2);
+
+		if (is_hiso) {
+			T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, isp, HISO,
+								1, 1, 0);
+			WRITE_PTSA_MIN_MAX_RATE(p, isp, ISP);
+
+			/* Make ISPWA and ISPWB non-blocking clients */
+			mc_writel(client_traffic_type_config_2 & ~0xc0,
+					MC_CLIENT_TRAFFIC_TYPE_CONFIG_2);
+
+			/* Make ISP_RA an ISO client */
+			mc_writel(0x10, MC_EMEM_ARB_ISOCHRONOUS_2);
+		} else {
+			T18X_MC_SET_INIT_PTSA_MIN_MAX_RATE(p, isp, SISO,
+								-2, 0, 1);
+			WRITE_PTSA_MIN_MAX_RATE(p, isp, ISP);
+
+			/* Make ISPWA and ISPWB blocking clients */
+			mc_writel(client_traffic_type_config_2 | 0xc0,
+					MC_CLIENT_TRAFFIC_TYPE_CONFIG_2);
+
+			/* Make ISP_RA a non-ISO client */
+			mc_writel(0x0, MC_EMEM_ARB_ISOCHRONOUS_2);
+		}
+	} else if (id == ID(VI_W)) {
+		if (!is_hiso)
+			pr_err("%s: Someone is trying to set VI\\VE into SISO "
+				"mode. Ignoring request because VI\\VE is "
+				"always HISO.\n",
+				__func__);
+
+		T18X_CALC_AND_UPDATE_ISO_PTSA(p, ve, VE, bw_mbps);
+	} else {
+		int idx = cs->id_to_index[id];
+		char *name = cs->la_info_array[idx].name;
+
+		pr_err("%s: Ignoring PTSA update request from %s because "
+			"its not a camera client.\n",
+			__func__, name);
+		return -1;
+	}
+
+	/* update shadowed registers */
+	mc_writel(1, MC_TIMING_CONTROL);
+	return 0;
+}
+
+static int t18x_set_init_la(enum tegra_la_id id,
+			unsigned int bw_mbps)
+{
+	int idx = cs->id_to_index[id];
+	struct la_client_info *ci = &cs->la_info_array[idx];
+	unsigned int la_to_set = 0;
+
+	/* We only have to program init LA values for constant read
+	   clients. All other clients will either be handled by BPMP or
+	   t18x_handle_disp_la(). */
+	if (ci->client_type == TEGRA_LA_CONSTANT_READ_CLIENT) {
+		la_to_set = ci->init_la;
+	} else {
+		pr_debug(
+		"%s is not constant read client, don't program init LA value\n",
+		ci->name);
+		return 0;
+	}
+
+	program_la(ci, la_to_set);
+	return 0;
+}
+
+static int t18x_set_dynamic_la(enum tegra_la_id id,
+			unsigned int bw_mbps)
+{
+	struct ptsa_info *p = &cs->ptsa_info;
+
+	if ((id == ID(APEDMAR)) ||
+		(id == ID(APEDMAW))) {
+		T18X_CALC_AND_UPDATE_ISO_PTSA(p, apedmapc, APEDMAPC, bw_mbps);
+	} else if ((id == ID(ISP_RA)) ||
+			(id == ID(ISP_WA)) ||
+			(id == ID(ISP_WB)) ||
+			(id == ID(VI_W))) {
+		int idx = cs->id_to_index[id];
+		char *name = cs->la_info_array[idx].name;
+
+		pr_warn("%s: Ignoring LA update request from %s because its "
+			"LA programming is part of the EMC DVFS table.\n",
+			__func__, name);
+		return 0;
+	} else if ((id == ID(EQOSR)) ||
+			(id == ID(EQOSW))) {
+		pr_err("%s: Ignoring LA\\PTSA update request from EQOS "
+			"because its PTSA rate is static.\n",
+			__func__);
+		return -1;
+	} else if (id == ID(NVDISPLAYR)) {
+		pr_err("%s: Ignoring LA\\PTSA update request from display. "
+			"Display should be handled by t18x_handle_disp_la(...).\n",
+			__func__);
+		return -1;
+	} else {
+		int idx = cs->id_to_index[id];
+		char *name = cs->la_info_array[idx].name;
+
+		pr_err("%s: Ignoring LA\\PTSA update request from %s because "
+			"its not a HISO\\SISO client.\n",
+			__func__, name);
+		return -1;
+	}
+
+	/* update shadowed registers */
+	mc_writel(1, MC_TIMING_CONTROL);
+	return 0;
+}
+
+static int t18x_handle_disp_la(enum tegra_la_id id,
+			       unsigned long emc_freq_hz,
+			       unsigned int bw_mbps,
+			       struct dc_to_la_params disp_params,
+			       int write_la)
+{
+	int idx = cs->id_to_index[id];
+	struct la_client_info *ci = &cs->la_info_array[idx];
+	struct ptsa_info *p = &cs->ptsa_info;
+	unsigned long emc_freq_mhz = 0;
+	unsigned int bw_mbps_disp_catchup_factor_fp =
+						bw_mbps *
+						T18X_LA_DISP_CATCHUP_FACTOR_FP;
+	unsigned int eff_row_srt_sz_bytes = 0;
+	unsigned int drain_time_usec_fp = 0;
+	int la_bw_upper_bound_usec_fp = 0;
+	int la_to_set_fp = 0;
+	unsigned int la_to_set = 0;
+
+	if (id != ID(NVDISPLAYR)) {
+		char *name = ci->name;
+
+		pr_err("%s: Ignoring LA\\PTSA update request from %s because "
+			"its not a display client.\n",
+			__func__, name);
+		return -1;
+	}
+
+	emc_freq_mhz = emc_freq_hz / LA_HZ_TO_MHZ_FACTOR;
+	la_bw_upper_bound_usec_fp =
+		(unsigned long)T18X_LA_MCCIF_BUF_SZ_BYTES_FP *
+			(unsigned long)LA_FP_FACTOR /
+			(unsigned long)bw_mbps_disp_catchup_factor_fp -
+		LA_REAL_TO_FP(T18X_LA_ST_LA_MINUS_SNAP_ARB_TO_ROW_SRT_EMCCLKS +
+				T18X_LA_EXPIRATION_TIME_EMCCLKS) /
+			emc_freq_mhz;
+	eff_row_srt_sz_bytes = min(row_srt_sz_bytes,
+					(unsigned int)(2 * dram_width_bytes *
+							(emc_freq_mhz + 50)));
+	eff_row_srt_sz_bytes =
+		min(eff_row_srt_sz_bytes,
+			(unsigned int)((T18X_LA_MAX_DRAIN_TIME_USEC *
+				emc_freq_mhz -
+				T18X_LA_ST_LA_SNAP_ARB_TO_ROW_SRT_EMCCLKS) *
+				2 *
+				dram_width_bytes /
+				T18X_LA_CONS_MEM_EFF_DIV_FACTOR));
+	drain_time_usec_fp = LA_REAL_TO_FP(eff_row_srt_sz_bytes) /
+				(emc_freq_mhz *
+				dram_width_bytes *
+				2 /
+				T18X_LA_CONS_MEM_EFF_DIV_FACTOR);
+	drain_time_usec_fp +=
+		LA_REAL_TO_FP(T18X_LA_ST_LA_SNAP_ARB_TO_ROW_SRT_EMCCLKS) /
+		emc_freq_mhz;
+	if ((int)drain_time_usec_fp > (int)la_bw_upper_bound_usec_fp)
+		return -1;
+
+	la_to_set_fp = la_bw_upper_bound_usec_fp *
+			(int)1000 /
+			(int)cs->ns_per_tick;
+	if (la_to_set_fp < 0)
+		return -1;
+	/* rounding */
+	la_to_set_fp += 500;
+	la_to_set = LA_FP_TO_REAL(la_to_set_fp);
+	la_to_set = min(la_to_set, MC_LA_MAX_VALUE);
+	if (write_la) {
+		program_la(ci, la_to_set);
+		T18X_CALC_AND_UPDATE_ISO_PTSA(p, dis, DIS, bw_mbps);
+	}
+	return 0;
+}
+
+static int t18x_set_disp_la(enum tegra_la_id id,
+			    unsigned long emc_freq_hz,
+			    unsigned int bw_mbps,
+			    struct dc_to_la_params disp_params)
+{
+	return t18x_handle_disp_la(id, emc_freq_hz, bw_mbps, disp_params, 1);
+}
+
+static int t18x_check_disp_la(enum tegra_la_id id,
+			      unsigned long emc_freq_hz,
+			      unsigned int bw_mbps,
+			      struct dc_to_la_params disp_params)
+{
+	return t18x_handle_disp_la(id, emc_freq_hz, bw_mbps, disp_params, 0);
+}
+
+void tegra_la_get_t18x_specific(struct la_chip_specific *cs_la)
+{
+	int i;
+	unsigned int channel_enable;
+	unsigned int adj_lo_freq_fp;
+	int dram_ecc_enabled;
+	unsigned int client_traffic_type_config_2;
+
+	cs_la->ns_per_tick = 30;
+	cs_la->la_max_value = MC_LA_MAX_VALUE;
+
+	cs_la->la_info_array = t18x_la_info_array;
+	cs_la->la_info_array_size = ARRAY_SIZE(t18x_la_info_array);
+
+	cs_la->init_ptsa = t18x_init_ptsa;
+	cs_la->update_camera_ptsa_rate = t18x_update_camera_ptsa_rate;
+	cs_la->set_init_la = t18x_set_init_la;
+	cs_la->set_dynamic_la = t18x_set_dynamic_la;
+	cs_la->set_disp_la = t18x_set_disp_la;
+	cs_la->check_disp_la = t18x_check_disp_la;
+	cs_la->save_ptsa = save_ptsa;
+	cs_la->program_ptsa = program_ptsa;
+	cs_la->suspend = la_suspend;
+	cs_la->resume = la_resume;
+	cs = cs_la;
+
+	channel_enable = mc_readl(MC_EMEM_ADR_CFG_CHANNEL_ENABLE) &
+					T18X_LA_EMEM_CHANNEL_ENABLE_MASK;
+	num_channels = 0;
+	for (i = 0; i < 4; i++) {
+		if (channel_enable & 0x1)
+			num_channels++;
+		channel_enable >>= 1;
+	}
+	row_srt_sz_bytes = 64 * 64 * num_channels;
+
+	dram_emc_freq_factor = 1;
+	hi_gd_fpa = 14998;
+	hi_gd_fp5 = 149976;
+
+	dram_emc_freq_factor = 2;
+	hi_freq_fp = LA_REAL_TO_FP(2132);
+	lo_freq_fp = LA_REAL_TO_FP(25);
+	hub_dda_div = 1;
+	r0_dda_div = 2;
+
+	if (num_channels == 2)
+		dram_width_bytes = 16;
+	else if (num_channels == 4)
+		dram_width_bytes = 32;
+
+	adj_lo_freq_fp = lo_freq_fp / 2;
+	lo_gd_fpa = (hi_gd_fpa * adj_lo_freq_fp) / (hi_freq_fp / 2);
+	lo_gd_fp5 = (hi_gd_fp5 * adj_lo_freq_fp) / (hi_freq_fp / 2);
+
+	dram_ecc_enabled = mc_readl(MC_ECC_CONTROL) & T18X_LA_ECC_ENABLE_MASK;
+	if (dram_ecc_enabled)
+		iso_dda_factor_fp = 1400;
+	else
+		iso_dda_factor_fp = 1200;
+
+	/* Make ISPWA and ISPWB blocking clients */
+	client_traffic_type_config_2 =
+				mc_readl(MC_CLIENT_TRAFFIC_TYPE_CONFIG_2);
+	mc_writel(client_traffic_type_config_2 | 0xc0,
+			MC_CLIENT_TRAFFIC_TYPE_CONFIG_2);
+
+	/* Set arbiter iso client types */
+	mc_writel(0x1, MC_EMEM_ARB_ISOCHRONOUS_0);
+	mc_writel(0x0, MC_EMEM_ARB_ISOCHRONOUS_1);
+	mc_writel(0x0, MC_EMEM_ARB_ISOCHRONOUS_2);
+	mc_writel(0x0, MC_EMEM_ARB_ISOCHRONOUS_3);
+	mc_writel(0x80044000, MC_EMEM_ARB_ISOCHRONOUS_4);
+	mc_writel(0x2, MC_EMEM_ARB_ISOCHRONOUS_5);
+}
diff --git a/drivers/platform/tegra/mc/tegra194-mc-sid.c b/drivers/platform/tegra/mc/tegra194-mc-sid.c
new file mode 100644
index 000000000000..ebd8ca456f12
--- /dev/null
+++ b/drivers/platform/tegra/mc/tegra194-mc-sid.c
@@ -0,0 +1,804 @@
+/*
+ * Tegra194 MC StreamID configuration
+ *
+ * Copyright (c) 2016-2017, NVIDIA CORPORATION.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#define pr_fmt(fmt)	"%s(): " fmt, __func__
+
+#include <linux/err.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+
+#include <linux/platform/tegra/tegra-mc-sid.h>
+#include <dt-bindings/memory/tegra-swgroup.h>
+#include <dt-bindings/memory/tegra194-swgroup.h>
+
+enum override_id {
+	PTCR,
+	HDAR,
+	HOST1XDMAR,
+	NVENCSRD,
+	SATAR,
+	MPCORER,
+	NVENCSWR,
+	HDAW,
+	MPCOREW,
+	SATAW,
+	ISPRA,
+	ISPFALR,
+	ISPWA,
+	ISPWB,
+	XUSB_HOSTR,
+	XUSB_HOSTW,
+	XUSB_DEVR,
+	XUSB_DEVW,
+	TSECSRD,
+	TSECSWR,
+	SDMMCRA,
+	SDMMCR,
+	SDMMCRAB,
+	SDMMCWA,
+	SDMMCW,
+	SDMMCWAB,
+	VICSRD,
+	VICSWR,
+	VIW,
+	NVDECSRD,
+	NVDECSWR,
+	APER,
+	APEW,
+	NVJPGSRD,
+	NVJPGSWR,
+	SESRD,
+	SESWR,
+	AXIAPR,
+	AXIAPW,
+	ETRR,
+	ETRW,
+	TSECSRDB,
+	TSECSWRB,
+	AXISR,
+	AXISW,
+	EQOSR,
+	EQOSW,
+	UFSHCR,
+	UFSHCW,
+	NVDISPLAYR,
+	BPMPR,
+	BPMPW,
+	BPMPDMAR,
+	BPMPDMAW,
+	AONR,
+	AONW,
+	AONDMAR,
+	AONDMAW,
+	SCER,
+	SCEW,
+	SCEDMAR,
+	SCEDMAW,
+	APEDMAR,
+	APEDMAW,
+	NVDISPLAYR1,
+	VICSRD1,
+	NVDECSRD1,
+	MIU0R,
+	MIU0W,
+	MIU1R,
+	MIU1W,
+	MIU2R,
+	MIU2W,
+	MIU3R,
+	MIU3W,
+	VIFALR,
+	VIFALW,
+	DLA0RDA,
+	DLA0FALRDB,
+	DLA0WRA,
+	DLA0FALWRB,
+	DLA1RDA,
+	DLA1FALRDB,
+	DLA1WRA,
+	DLA1FALWRB,
+	PVA0RDA,
+	PVA0RDB,
+	PVA0RDC,
+	PVA0WRA,
+	PVA0WRB,
+	PVA0WRC,
+	PVA1RDA,
+	PVA1RDB,
+	PVA1RDC,
+	PVA1WRA,
+	PVA1WRB,
+	PVA1WRC,
+	RCER,
+	RCEW,
+	RCEDMAR,
+	RCEDMAW,
+	NVENC1SRD,
+	NVENC1SWR,
+	PCIE0R,
+	PCIE0W,
+	PCIE1R,
+	PCIE1W,
+	PCIE2AR,
+	PCIE2AW,
+	PCIE3R,
+	PCIE3W,
+	PCIE4R,
+	PCIE4W,
+	PCIE5R,
+	PCIE5W,
+	ISPFALW,
+	DLA0RDA1,
+	DLA1RDA1,
+	PVA0RDA1,
+	PVA0RDB1,
+	PVA1RDA1,
+	PVA1RDB1,
+	PCIE5R1,
+	NVENCSRD1,
+	NVENC1SRD1,
+	ISPRA1,
+	PCIE0R1,
+	NVDEC1SRD,
+	NVDEC1SRD1,
+	NVDEC1SWR,
+	MAX_OID,
+};
+
+static struct sid_override_reg sid_override_reg[] = {
+	DEFREG(PTCR,		0x000),
+	DEFREG(HDAR,		0x0A8),
+	DEFREG(HOST1XDMAR,	0x0B0),
+	DEFREG(NVENCSRD,	0x0E0),
+	DEFREG(SATAR,		0x0F8),
+	DEFREG(MPCORER,		0x138),
+	DEFREG(NVENCSWR,	0x158),
+	DEFREG(HDAW,		0x1A8),
+	DEFREG(MPCOREW,		0x1C8),
+	DEFREG(SATAW,		0x1E8),
+	DEFREG(ISPRA,		0x220),
+	DEFREG(ISPFALR,		0x228),
+	DEFREG(ISPWA,		0x230),
+	DEFREG(ISPWB,		0x238),
+	DEFREG(XUSB_HOSTR,	0x250),
+	DEFREG(XUSB_HOSTW,	0x258),
+	DEFREG(XUSB_DEVR,	0x260),
+	DEFREG(XUSB_DEVW,	0x268),
+	DEFREG(TSECSRD,		0x2A0),
+	DEFREG(TSECSWR,		0x2A8),
+	DEFREG(SDMMCRA,		0x300),
+	DEFREG(SDMMCR,		0x310),
+	DEFREG(SDMMCRAB,	0x318),
+	DEFREG(SDMMCWA,		0x320),
+	DEFREG(SDMMCW,		0x330),
+	DEFREG(SDMMCWAB,	0x338),
+	DEFREG(VICSRD,		0x360),
+	DEFREG(VICSWR,		0x368),
+	DEFREG(VIW,		0x390),
+	DEFREG(NVDECSRD,	0x3C0),
+	DEFREG(NVDECSWR,	0x3C8),
+	DEFREG(APER,		0x3D0),
+	DEFREG(APEW,		0x3D8),
+	DEFREG(NVJPGSRD,	0x3F0),
+	DEFREG(NVJPGSWR,	0x3F8),
+	DEFREG(SESRD,		0x400),
+	DEFREG(SESWR,		0x408),
+	DEFREG(AXIAPR,		0x410),
+	DEFREG(AXIAPW,		0x418),
+	DEFREG(ETRR,		0x420),
+	DEFREG(ETRW,		0x428),
+	DEFREG(TSECSRDB,	0x430),
+	DEFREG(TSECSWRB,	0x438),
+	DEFREG(AXISR,		0x460),
+	DEFREG(AXISW,		0x468),
+	DEFREG(EQOSR,		0x470),
+	DEFREG(EQOSW,		0x478),
+	DEFREG(UFSHCR,		0x480),
+	DEFREG(UFSHCW,		0x488),
+	DEFREG(NVDISPLAYR,	0x490),
+	DEFREG(BPMPR,		0x498),
+	DEFREG(BPMPW,		0x4A0),
+	DEFREG(BPMPDMAR,	0x4A8),
+	DEFREG(BPMPDMAW,	0x4B0),
+	DEFREG(AONR,		0x4B8),
+	DEFREG(AONW,		0x4C0),
+	DEFREG(AONDMAR,		0x4C8),
+	DEFREG(AONDMAW,		0x4D0),
+	DEFREG(SCER,		0x4D8),
+	DEFREG(SCEW,		0x4E0),
+	DEFREG(SCEDMAR,		0x4E8),
+	DEFREG(SCEDMAW,		0x4F0),
+	DEFREG(APEDMAR,		0x4F8),
+	DEFREG(APEDMAW,		0x500),
+	DEFREG(NVDISPLAYR1,	0x508),
+	DEFREG(VICSRD1,		0x510),
+	DEFREG(NVDECSRD1,	0x518),
+	DEFREG(MIU0R,		0x530),
+	DEFREG(MIU0W,		0x538),
+	DEFREG(MIU1R,		0x540),
+	DEFREG(MIU1W,		0x548),
+	DEFREG(MIU2R,		0x570),
+	DEFREG(MIU2W,		0x578),
+	DEFREG(MIU3R,		0x580),
+	DEFREG(MIU3W,		0x588),
+	DEFREG(VIFALR,		0x5E0),
+	DEFREG(VIFALW,		0x5E8),
+	DEFREG(DLA0RDA,		0x5F0),
+	DEFREG(DLA0FALRDB,	0x5F8),
+	DEFREG(DLA0WRA,		0x600),
+	DEFREG(DLA0FALWRB,	0x608),
+	DEFREG(DLA1RDA,		0x610),
+	DEFREG(DLA1FALRDB,	0x618),
+	DEFREG(DLA1WRA,		0x620),
+	DEFREG(DLA1FALWRB,	0x628),
+	DEFREG(PVA0RDA,		0x630),
+	DEFREG(PVA0RDB,		0x638),
+	DEFREG(PVA0RDC,		0x640),
+	DEFREG(PVA0WRA,		0x648),
+	DEFREG(PVA0WRB,		0x650),
+	DEFREG(PVA0WRC,		0x658),
+	DEFREG(PVA1RDA,		0x660),
+	DEFREG(PVA1RDB,		0x668),
+	DEFREG(PVA1RDC,		0x670),
+	DEFREG(PVA1WRA,		0x678),
+	DEFREG(PVA1WRB,		0x680),
+	DEFREG(PVA1WRC,		0x688),
+	DEFREG(RCER,		0x690),
+	DEFREG(RCEW,		0x698),
+	DEFREG(RCEDMAR,		0x6A0),
+	DEFREG(RCEDMAW,		0x6A8),
+	DEFREG(NVENC1SRD,	0x6B0),
+	DEFREG(NVENC1SWR,	0x6B8),
+	DEFREG(PCIE0R,		0x6C0),
+	DEFREG(PCIE0W,		0x6C8),
+	DEFREG(PCIE1R,		0x6D0),
+	DEFREG(PCIE1W,		0x6D8),
+	DEFREG(PCIE2AR,		0x6E0),
+	DEFREG(PCIE2AW,		0x6E8),
+	DEFREG(PCIE3R,		0x6F0),
+	DEFREG(PCIE3W,		0x6F8),
+	DEFREG(PCIE4R,		0x700),
+	DEFREG(PCIE4W,		0x708),
+	DEFREG(PCIE5R,		0x710),
+	DEFREG(PCIE5W,		0x718),
+	DEFREG(ISPFALW,		0x720),
+	DEFREG(DLA0RDA1,	0x748),
+	DEFREG(DLA1RDA1,	0x750),
+	DEFREG(PVA0RDA1,	0x758),
+	DEFREG(PVA0RDB1,	0x760),
+	DEFREG(PVA1RDA1,	0x768),
+	DEFREG(PVA1RDB1,	0x770),
+	DEFREG(PCIE5R1,		0x778),
+	DEFREG(NVENCSRD1,	0x780),
+	DEFREG(NVENC1SRD1,	0x788),
+	DEFREG(ISPRA1,		0x790),
+	DEFREG(PCIE0R1,		0x798),
+	DEFREG(NVDEC1SRD,	0x7C8),
+	DEFREG(NVDEC1SRD1,	0x7D0),
+	DEFREG(NVDEC1SWR,	0x7D8),
+};
+
+static struct sid_to_oids sid_to_oids[] = {
+	{
+		.sid	= TEGRA_SID_HDA,
+		.noids	= 2,
+		.oid	= {
+			HDAR,
+			HDAW,
+		},
+		.ord = OVERRIDE,
+		.name = "HDA",
+	},
+	{
+		.sid	= TEGRA_SID_SATA2,
+		.noids	= 2,
+		.oid	= {
+			SATAR,
+			SATAW,
+		},
+		.ord = OVERRIDE,
+		.name = "SATA2",
+	},
+	{
+		.sid	= TEGRA_SID_XUSB_HOST,
+		.noids	= 2,
+		.oid	= {
+			XUSB_HOSTR,
+			XUSB_HOSTW,
+		},
+		.ord = OVERRIDE,
+		.name = "XUSB_HOST",
+	},
+	{
+		.sid	= TEGRA_SID_XUSB_DEV,
+		.noids	= 2,
+		.oid	= {
+			XUSB_DEVR,
+			XUSB_DEVW,
+		},
+		.ord = OVERRIDE,
+		.name = "XUSB_DEV",
+	},
+	{
+		.sid	= TEGRA_SID_TSEC,
+		.noids	= 2,
+		.oid	= {
+			TSECSRD,
+			TSECSWR,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "TSEC",
+	},
+	{
+		.sid	= TEGRA_SID_SDMMC1A,
+		.noids	= 2,
+		.oid	= {
+			SDMMCRA,
+			SDMMCWA,
+		},
+		.ord = OVERRIDE,
+		.name = "SDMMC1A",
+	},
+	{
+		.sid	= TEGRA_SID_SDMMC3A,
+		.noids	= 2,
+		.oid	= {
+			SDMMCR,
+			SDMMCW,
+		},
+		.ord = OVERRIDE,
+		.name = "SDMMC3A",
+	},
+	{
+		.sid	= TEGRA_SID_SDMMC4A,
+		.noids	= 2,
+		.oid	= {
+			SDMMCRAB,
+			SDMMCWAB,
+		},
+		.ord = OVERRIDE,
+		.name = "SDMMC4A",
+	},
+	{
+		.sid	= TEGRA_SID_APE,
+		.noids	= 4,
+		.oid	= {
+			APER,
+			APEW,
+			APEDMAR,
+			APEDMAW,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "APE",
+	},
+	{
+		.sid	= TEGRA_SID_SE,
+		.noids	= 2,
+		.oid	= {
+			SESRD,
+			SESWR,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "SE",
+	},
+	{
+		.sid	= TEGRA_SID_ETR,
+		.noids	= 2,
+		.oid	= {
+			ETRR,
+			ETRW,
+		},
+		.ord = OVERRIDE,
+		.name = "ETR",
+	},
+	{
+		.sid	= TEGRA_SID_TSECB,
+		.noids	= 2,
+		.oid	= {
+			TSECSRDB,
+			TSECSWRB,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "TSECB",
+	},
+	{
+		.sid	= TEGRA_SID_GPCDMA_0, /* AXIS */
+		.noids	= 2,
+		.oid	= {
+			AXISR,
+			AXISW,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "GPCDMA",
+	},
+	{
+		.sid	= TEGRA_SID_EQOS,
+		.noids	= 2,
+		.oid	= {
+			EQOSR,
+			EQOSW,
+		},
+		.ord = OVERRIDE,
+		.name = "EQOS",
+	},
+	{
+		.sid	= TEGRA_SID_UFSHC,
+		.noids	= 2,
+		.oid	= {
+			UFSHCR,
+			UFSHCW,
+		},
+		.ord = OVERRIDE,
+		.name = "UFSHC",
+	},
+	{
+		.sid	= TEGRA_SID_NVDISPLAY,
+		.noids	= 2,
+		.oid	= {
+			NVDISPLAYR,
+			NVDISPLAYR1,
+		},
+		.ord = OVERRIDE,
+		.name = "NVDISPLAY",
+	},
+	{
+		.sid	= TEGRA_SID_BPMP,
+		.noids	= 4,
+		.oid	= {
+			BPMPR,
+			BPMPW,
+			BPMPDMAR,
+			BPMPDMAW,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "BPMP",
+	},
+	{
+		.sid	= TEGRA_SID_AON,
+		.noids	= 4,
+		.oid	= {
+			AONR,
+			AONW,
+			AONDMAR,
+			AONDMAW,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "AON",
+	},
+	{
+		.sid	= TEGRA_SID_SCE,
+		.noids	= 4,
+		.oid	= {
+			SCER,
+			SCEW,
+			SCEDMAR,
+			SCEDMAW,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "SCE",
+	},
+	{
+		.sid	= TEGRA_SID_HC,
+		.noids	= 1,
+		.oid	= {
+			HOST1XDMAR,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "HC",
+	},
+	{
+		.sid	= TEGRA_SID_VIC,
+		.noids	= 3,
+		.oid = {
+			VICSRD1,
+			VICSRD,
+			VICSWR,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "VIC",
+	},
+	{
+		.sid	= TEGRA_SID_VI,
+		.noids	= 1,
+		.oid	= {
+			VIW,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "VI",
+	},
+	{
+		.sid	= TEGRA_SID_VIFALC,
+		.noids	= 2,
+		.oid	= {
+			VIFALR,
+			VIFALW,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "VIFALC",
+	},
+	{
+		.sid	= TEGRA_SID_ISP,
+		.noids	= 6,
+		.oid	= {
+			ISPRA,
+			ISPWA,
+			ISPWB,
+			ISPFALR,
+			ISPFALW,
+			ISPRA1,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "ISP",
+	},
+	{
+		.sid	= TEGRA_SID_NVDEC,
+		.noids	= 3,
+		.oid	= {
+			NVDECSRD1,
+			NVDECSRD,
+			NVDECSWR,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "NVDEC",
+	},
+	{
+		.sid	= TEGRA_SID_NVENC,
+		.noids	= 3,
+		.oid	= {
+			NVENCSRD,
+			NVENCSWR,
+			NVENCSRD1,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "NVENC",
+	},
+	{
+		.sid	= TEGRA_SID_NVJPG,
+		.noids	= 2,
+		.oid	= {
+			NVJPGSRD,
+			NVJPGSWR,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "NVJPG",
+	},
+	{
+		.sid	= TEGRA_SID_MIU,
+		.noids	= 8,
+		.oid	= {
+			MIU0R,
+			MIU0W,
+			MIU1R,
+			MIU1W,
+			MIU2R,
+			MIU2W,
+			MIU3R,
+			MIU3W,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "MIU",
+	},
+	{
+		.sid	= TEGRA_SID_NVDLA0,
+		.noids	= 5,
+		.oid	= {
+			DLA0RDA,
+			DLA0FALRDB,
+			DLA0WRA,
+			DLA0FALWRB,
+			DLA0RDA1,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "NVDLA0",
+	},
+	{
+		.sid	= TEGRA_SID_NVDLA1,
+		.noids	= 5,
+		.oid	= {
+			DLA1RDA,
+			DLA1FALRDB,
+			DLA1WRA,
+			DLA1FALWRB,
+			DLA1RDA1,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "NVDLA1",
+	},
+	{
+		.sid	= TEGRA_SID_PVA0,
+		.noids	= 8,
+		.oid	= {
+			PVA0RDA,
+			PVA0RDB,
+			PVA0RDC,
+			PVA0WRA,
+			PVA0WRB,
+			PVA0WRC,
+			PVA0RDA1,
+			PVA0RDB1,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "PVA0",
+	},
+	{
+		.sid	= TEGRA_SID_PVA1,
+		.noids	= 8,
+		.oid	= {
+			PVA1RDA,
+			PVA1RDB,
+			PVA1RDC,
+			PVA1WRA,
+			PVA1WRB,
+			PVA1WRC,
+			PVA1RDA1,
+			PVA1RDB1,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "PVA1",
+	},
+	{
+		.sid	= TEGRA_SID_RCE,
+		.noids	= 4,
+		.oid	= {
+			RCER,
+			RCEW,
+			RCEDMAR,
+			RCEDMAW,
+		},
+		.ord = NO_OVERRIDE,
+		.name = "RCE",
+	},
+	{
+		.sid	= TEGRA_SID_NVENC1,
+		.noids	= 3,
+		.oid	= {
+			NVENC1SRD,
+			NVENC1SWR,
+			NVENC1SRD1,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "NVENC1",
+	},
+	{
+		.sid	= TEGRA_SID_PCIE0,
+		.noids	= 3,
+		.oid	= {
+			PCIE0R,
+			PCIE0W,
+			PCIE0R1,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "PCIE0",
+	},
+	{
+		.sid	= TEGRA_SID_PCIE1,
+		.noids	= 2,
+		.oid	= {
+			PCIE1R,
+			PCIE1W,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "PCIE1",
+	},
+	{
+		.sid	= TEGRA_SID_PCIE2,
+		.noids	= 2,
+		.oid	= {
+			PCIE2AR,
+			PCIE2AW,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "PCIE2",
+	},
+	{
+		.sid	= TEGRA_SID_PCIE3,
+		.noids	= 2,
+		.oid	= {
+			PCIE3R,
+			PCIE3W,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "PCIE3",
+	},
+	{
+		.sid	= TEGRA_SID_PCIE4,
+		.noids	= 2,
+		.oid	= {
+			PCIE4R,
+			PCIE4W,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "PCIE4",
+	},
+	{
+		.sid	= TEGRA_SID_PCIE5,
+		.noids	= 3,
+		.oid	= {
+			PCIE5R,
+			PCIE5W,
+			PCIE5R1,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "PCIE5",
+	},
+	{
+		.sid	= TEGRA_SID_NVDEC1,
+		.noids	= 3,
+		.oid	= {
+			NVDEC1SRD,
+			NVDEC1SRD1,
+			NVDEC1SWR,
+		},
+		.ord = SIM_OVERRIDE,
+		.name = "NVDEC1",
+	},
+};
+
+static const struct tegra_mc_sid_soc_data tegra194_mc_soc_data = {
+	.sid_override_reg = sid_override_reg,
+	.nsid_override_reg = ARRAY_SIZE(sid_override_reg),
+	.sid_to_oids = sid_to_oids,
+	.nsid_to_oids = ARRAY_SIZE(sid_to_oids),
+	.max_oids = MAX_OID,
+};
+
+static int tegra194_mc_sid_probe(struct platform_device *pdev)
+{
+	return tegra_mc_sid_probe(pdev, &tegra194_mc_soc_data);
+}
+
+static const struct of_device_id tegra194_mc_sid_of_match[] = {
+	{ .compatible = "nvidia,tegra194-mc-sid", },
+	{},
+};
+MODULE_DEVICE_TABLE(of, tegra194_mc_sid_of_match);
+
+static struct platform_driver tegra194_mc_sid_driver = {
+	.probe	= tegra194_mc_sid_probe,
+	.remove = tegra_mc_sid_remove,
+	.driver	= {
+		.owner	= THIS_MODULE,
+		.name	= "tegra194-mc-sid",
+		.of_match_table	= of_match_ptr(tegra194_mc_sid_of_match),
+	},
+};
+
+static int __init tegra194_mc_sid_init(void)
+{
+	struct device_node *np;
+	struct platform_device *pdev = NULL;
+
+	np = of_find_compatible_node(NULL, NULL, "nvidia,tegra194-mc-sid");
+	if (np) {
+		pdev = of_platform_device_create(np, NULL,
+						 platform_bus_type.dev_root);
+		of_node_put(np);
+	}
+
+	if (IS_ERR_OR_NULL(pdev))
+		return -ENODEV;
+
+	return platform_driver_register(&tegra194_mc_sid_driver);
+}
+arch_initcall(tegra194_mc_sid_init);
+
+MODULE_DESCRIPTION("MC StreamID configuration");
+MODULE_AUTHOR("Hiroshi DOYU <hdoyu@nvidia.com>, Pritesh Raithatha <praithatha@nvidia.com>");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/platform/tegra/mc/tegra19x_la_ptsa.c b/drivers/platform/tegra/mc/tegra19x_la_ptsa.c
new file mode 100644
index 000000000000..cf8fabf148f7
--- /dev/null
+++ b/drivers/platform/tegra/mc/tegra19x_la_ptsa.c
@@ -0,0 +1,976 @@
+/*
+ * Copyright (C) 2018, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#include <asm/io.h>
+#include <linux/printk.h>
+#include <linux/io.h>
+#include <linux/slab.h>
+#include <linux/tegra-mce.h>
+#include "tegra19x_la_ptsa.h"
+#include <linux/platform/tegra/mc.h>
+
+#define FIX_PT(x, y, err) fixed_point_init(x, y, 32, 32, err)
+
+/* TODO: Get the base address from dtb */
+/* Reuse API from other drivers */
+#define NV_ADDRESS_MAP_EMCB_BASE                    0x02C60000
+
+/* Non LA/PTSA mmio apertures */
+static void __iomem *t19x_pipe2uphy_xbar_base;
+
+/* TODO: Enable MSSNVLINK aperture access */
+
+#define mssnvl1_writel(x, y)	mssnvlink_writel(0, x, y)
+#define mssnvl2_writel(x, y)	mssnvlink_writel(1, x, y)
+#define mssnvl3_writel(x, y)	mssnvlink_writel(2, x, y)
+#define mssnvl4_writel(x, y)	mssnvlink_writel(3, x, y)
+
+#define mssnvl1_readl(x)	mssnvlink_readl(0, x)
+#define mssnvl2_readl(x)	mssnvlink_readl(1, x)
+#define mssnvl3_readl(x)	mssnvlink_readl(2, x)
+#define mssnvl4_readl(x)	mssnvlink_readl(3, x)
+
+/* TODO: Use pcie driver interface */
+static inline unsigned int pipe2uphy_xbar_readl(unsigned int offset)
+{
+	return readl(t19x_pipe2uphy_xbar_base + offset);
+}
+
+static struct la_ptsa_core lp;
+static int tegra_gen_to_t19x_la_id[TEGRA_LA_MAX_ID];
+static int tegra_t19x_to_gen_la_id[TEGRA_T19X_LA_MAX_ID];
+static int t19x_la_kern_init[TEGRA_T19X_LA_MAX_ID];
+static struct la_client_info t19x_la_info_array[TEGRA_T19X_LA_MAX_ID];
+static struct dda_info dda_info_array[TEGRA_DDA_MAX_ID];
+static struct mc_settings_info mc_settings;
+static struct reg_info mc_reg_info_array[TEGRA_KERN_INIT_MC_MAX_ID];
+static struct reg_info
+mssnvlink1_reg_info_array[TEGRA_KERN_INIT_MSSNVLINK_MAX_ID];
+static struct reg_info
+mssnvlink2_reg_info_array[TEGRA_KERN_INIT_MSSNVLINK_MAX_ID];
+static struct reg_info
+mssnvlink3_reg_info_array[TEGRA_KERN_INIT_MSSNVLINK_MAX_ID];
+static struct reg_info
+mssnvlink4_reg_info_array[TEGRA_KERN_INIT_MSSNVLINK_MAX_ID];
+static struct reg_info mcpcie_reg_info_array[TEGRA_KERN_INIT_MCPCIE_MAX_ID];
+
+static void la_init(unsigned int *error)
+{
+	lp.la_info_array_init(
+		t19x_la_info_array,
+		tegra_gen_to_t19x_la_id,
+		tegra_t19x_to_gen_la_id,
+		t19x_la_kern_init,
+		&mc_settings,
+		error);
+}
+
+static int t19x_set_init_la(enum tegra_la_id id, unsigned int bw_mbps)
+{
+	enum tegra_t19x_la_id t19x_id = tegra_gen_to_t19x_la_id[id];
+	unsigned int error = 0;
+	unsigned int lat_all;
+
+	lat_all =
+		lp.get_init_la(
+			t19x_la_info_array[t19x_id].client_type,
+			&mc_settings,
+			&error);
+	if (error) {
+		pr_err("%s: ", __func__);
+		pr_err("error. Skipping la programming\n");
+		WARN_ON(1);
+		return -1;
+	}
+
+	if (t19x_la_kern_init[t19x_id])
+		program_la(&t19x_la_info_array[t19x_id], lat_all);
+
+	return 0;
+}
+
+static void dda_init(unsigned int *error)
+{
+	lp.dda_info_array_init(
+		dda_info_array,
+		TEGRA_DDA_MAX_ID,
+		&mc_settings,
+		error);
+}
+
+#define T19X_WRITE_PTSA_MIN_MAX_RATE(NAME) \
+	do { \
+		mc_writel(dda_info_array[TEGRA_DDA_##NAME##_ID].min & \
+			MC_##NAME##_PTSA_MIN_0_PTSA_MIN_##NAME##_DEFAULT_MASK, \
+			MC_##NAME##_PTSA_MIN_0); \
+		mc_writel(dda_info_array[TEGRA_DDA_##NAME##_ID].max & \
+			MC_##NAME##_PTSA_MAX_0_PTSA_MAX_##NAME##_DEFAULT_MASK, \
+			MC_##NAME##_PTSA_MAX_0); \
+		mc_writel(dda_info_array[TEGRA_DDA_##NAME##_ID].rate & \
+			MC_##NAME##_PTSA_RATE_0_PTSA_RATE_## \
+				NAME##_DEFAULT_MASK, \
+			MC_##NAME##_PTSA_RATE_0); \
+	} while (0)
+
+#define T19X_WRITE_PTSA_MIN_MAX(NAME) \
+	do { \
+		mc_writel(dda_info_array[TEGRA_DDA_##NAME##_ID].min & \
+			MC_##NAME##_PTSA_MIN_0_PTSA_MIN_##NAME##_DEFAULT_MASK, \
+			MC_##NAME##_PTSA_MIN_0); \
+		mc_writel(dda_info_array[TEGRA_DDA_##NAME##_ID].max & \
+			MC_##NAME##_PTSA_MAX_0_PTSA_MAX_##NAME##_DEFAULT_MASK, \
+			MC_##NAME##_PTSA_MAX_0); \
+	} while (0)
+
+#define T19X_WRITE_PTSA_RATE(NAME) \
+	mc_writel(dda_info_array[TEGRA_DDA_##NAME##_ID].rate & \
+		MC_##NAME##_PTSA_RATE_0_PTSA_RATE_## \
+			NAME##_DEFAULT_MASK, \
+		MC_##NAME##_PTSA_RATE_0)
+
+#define T19X_WRITE_PTSA_MIN(NAME) \
+	mc_writel(dda_info_array[TEGRA_DDA_##NAME##_ID].min & \
+		MC_##NAME##_PTSA_MIN_0_PTSA_MIN_##NAME##_DEFAULT_MASK, \
+		MC_##NAME##_PTSA_MIN_0)
+
+#define T19X_WRITE_PTSA_MAX(NAME) \
+	mc_writel(dda_info_array[TEGRA_DDA_##NAME##_ID].max & \
+		MC_##NAME##_PTSA_MAX_0_PTSA_MAX_##NAME##_DEFAULT_MASK, \
+		MC_##NAME##_PTSA_MAX_0)
+
+static void program_kern_init_ptsa(void)
+{
+	T19X_WRITE_PTSA_MIN_MAX_RATE(AONPC);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(APB);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(AUD);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(BPMPPC);
+	T19X_WRITE_PTSA_MIN_MAX(CIFLL_ISO);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(CIFLL_SISO);
+	T19X_WRITE_PTSA_MAX(CIFLL_NISO);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(CIFLL_RING0X);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(DIS);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(DLA0FALPC);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(DLA0XA);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(DLA0XA2);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(DLA0XA3);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(DLA1FALPC);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(DLA1XA);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(DLA1XA2);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(DLA1XA3);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(EQOSPC);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(HDAPC);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(HOST);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(ISP);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(ISP2PC);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(ISPPC);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(JPG);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(MIU0);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(MIU1);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(MIU2);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(MIU3);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(MIU4);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(MIU5);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(MIU6);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(MIU7);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(MSE);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(MSE2);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(MSE3);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(MSEA);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(MSEB);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(MSEB1);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(NIC);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(NVD);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(NVD2);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(NVD3);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(NVD4);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(NVD5);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(NVD6);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PCIE0X);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PCIE0X2);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PCIE0XA);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PCIE1X);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PCIE1XA);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PCIE4X);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PCIE4XA);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PCIE5X);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PCIE5X2);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PCIE5XA);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PVA0XA);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PVA0XA2);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PVA0XA3);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PVA0XB);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PVA0XB2);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PVA0XB3);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PVA0XC);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PVA1XA);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PVA1XA2);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PVA1XA3);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PVA1XB);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PVA1XB2);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PVA1XB3);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(PVA1XC);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(RCEPC);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(RING2);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(SAX);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(SCEPC);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(SD);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(SDM);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(SMMU_SMMU);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(UFSHCPC);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(UFSHCPC2);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(USBD);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(USBD2);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(USBX);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(USBX2);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(VE);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(VICPC);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(VICPC2);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(VICPC3);
+}
+
+
+static void program_non_kern_init_ptsa(void)
+{
+	T19X_WRITE_PTSA_RATE(CIFLL_ISO);
+	T19X_WRITE_PTSA_MIN(CIFLL_NISO);
+	T19X_WRITE_PTSA_RATE(CIFLL_NISO);
+	T19X_WRITE_PTSA_MIN_MAX_RATE(MLL_MPCORER);
+}
+
+#undef T19X_WRITE_PTSA_MIN_MAX_RATE
+
+static void program_ptsa(void)
+{
+	program_kern_init_ptsa();
+	program_non_kern_init_ptsa();
+}
+
+#define T19X_SAVE_PTSA_MIN_MAX_RATE(NAME) \
+	do { \
+		dda_info_array[TEGRA_DDA_##NAME##_ID].min = \
+		mc_readl(MC_##NAME##_PTSA_MIN_0); \
+		dda_info_array[TEGRA_DDA_##NAME##_ID].max = \
+		mc_readl(MC_##NAME##_PTSA_MAX_0); \
+		dda_info_array[TEGRA_DDA_##NAME##_ID].rate = \
+		mc_readl(MC_##NAME##_PTSA_RATE_0); \
+	} while (0)
+
+static void save_ptsa(void)
+{
+	T19X_SAVE_PTSA_MIN_MAX_RATE(AONPC);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(APB);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(AUD);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(BPMPPC);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(CIFLL_ISO);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(CIFLL_SISO);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(CIFLL_NISO);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(CIFLL_RING0X);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(DIS);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(DLA0FALPC);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(DLA0XA);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(DLA0XA2);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(DLA0XA3);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(DLA1FALPC);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(DLA1XA);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(DLA1XA2);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(DLA1XA3);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(EQOSPC);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(HDAPC);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(HOST);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(ISP);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(ISP2PC);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(ISPPC);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(JPG);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(MIU0);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(MIU1);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(MIU2);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(MIU3);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(MIU4);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(MIU5);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(MIU6);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(MIU7);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(MLL_MPCORER);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(MSE);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(MSE2);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(MSE3);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(MSEA);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(MSEB);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(MSEB1);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(NIC);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(NVD);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(NVD2);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(NVD3);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(NVD4);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(NVD5);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(NVD6);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PCIE0X);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PCIE0X2);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PCIE0XA);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PCIE1X);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PCIE1XA);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PCIE4X);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PCIE4XA);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PCIE5X);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PCIE5X2);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PCIE5XA);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PVA0XA);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PVA0XA2);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PVA0XA3);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PVA0XB);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PVA0XB2);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PVA0XB3);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PVA0XC);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PVA1XA);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PVA1XA2);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PVA1XA3);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PVA1XB);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PVA1XB2);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PVA1XB3);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(PVA1XC);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(RCEPC);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(RING2);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(SAX);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(SCEPC);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(SD);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(SDM);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(SMMU_SMMU);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(UFSHCPC);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(UFSHCPC2);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(USBD);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(USBD2);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(USBX);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(USBX2);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(VE);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(VICPC);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(VICPC2);
+	T19X_SAVE_PTSA_MIN_MAX_RATE(VICPC3);
+}
+#undef T19X_SAVE_PTSA_MIN_MAX_RATE
+
+static void t19x_init_ptsa(void)
+{
+	unsigned int error = 0;
+
+	dda_init(&error);
+
+	lp.update_new_dda_minmax_kern_init(
+		dda_info_array, &mc_settings, &error);
+	if (error) {
+		pr_err("%s: ", __func__);
+		pr_err("error. Skipping kernel init programming\n");
+		WARN_ON(1);
+		return;
+	}
+
+	lp.update_new_dda_rate_frac_kern_init(
+		dda_info_array,
+		&mc_settings,
+		&error);
+	if (error) {
+		pr_err("%s: ", __func__);
+		pr_err("error. Skipping kernel init programming\n");
+		WARN_ON(1);
+		return;
+	}
+	dda_info_array[TEGRA_DDA_MLL_MPCORER_ID].min = -6;
+	dda_info_array[TEGRA_DDA_MLL_MPCORER_ID].max = 6;
+
+	program_kern_init_ptsa();
+}
+
+static void t19x_set_dynamic_ptsa(
+	enum tegra_dda_id id,
+	unsigned int bw_mbps,
+	unsigned int *error)
+{
+	struct fixed_point iso_adj_bw;
+
+	if (dda_info_array[id].iso_type == TEGRA_HISO) {
+		if (id == TEGRA_DDA_EQOSPC_ID) {
+			iso_adj_bw = fixed_point_mult(
+				FIX_PT(250, 0, error),
+				mc_settings.two_stge_ecc_iso_dda_bw_margin,
+				error);
+		} else {
+			iso_adj_bw = fixed_point_mult(
+				FIX_PT(bw_mbps, 0, error),
+				mc_settings.dda_bw_margin,
+				error);
+		}
+	} else {
+		iso_adj_bw = FIX_PT(bw_mbps, 0, error);
+	}
+
+	lp.update_new_dda_rate_frac_use_case(
+		dda_info_array,
+		&mc_settings,
+		id,
+		iso_adj_bw,
+		error);
+
+	if ((*error)) {
+		pr_err("%s: ", __func__);
+		pr_err("error. Skipping PTSA write for MC reg offset 0x%08x\n",
+			dda_info_array[id].rate_reg_addr);
+		WARN_ON(1);
+		return;
+	}
+
+	mc_writel(dda_info_array[id].rate &
+		dda_info_array[id].mask,
+		dda_info_array[id].rate_reg_addr);
+}
+
+static int t19x_handle_display_la_ptsa(
+	enum tegra_la_id id,
+	unsigned long emc_freq_hz,
+	unsigned int bw_mbps,
+	int write_la)
+{
+	int disp_la = 0;
+	struct fixed_point drain_time_usec;
+	struct fixed_point la_bw_up_bnd_usec;
+	int clientid;
+	enum tegra_t19x_la_id t19x_id = tegra_gen_to_t19x_la_id[id];
+	int ret_val = 0;
+	unsigned int error = 0;
+
+	clientid = lp.convert_la2dda_id_for_dyn_ptsa(id, &error);
+	drain_time_usec = FIX_PT(0, 0, &error);
+	la_bw_up_bnd_usec = FIX_PT(0, 0, &error);
+	lp.get_disp_rd_lat_allow_given_disp_bw(
+		&mc_settings,
+		fixed_point_div(FIX_PT(emc_freq_hz, 0, &error),
+			FIX_PT(1000000, 0, &error), &error),
+		fixed_point_mult(FIX_PT(bw_mbps, 0, &error),
+			mc_settings.disp_catchup_factor, &error),
+		&disp_la,
+		&drain_time_usec,
+		&la_bw_up_bnd_usec, &error);
+
+	if (disp_la < 0)
+		return -1;
+
+	if (fixed_point_gt(drain_time_usec, la_bw_up_bnd_usec, &error))
+		return -1;
+
+	if (error) {
+		if (write_la) {
+			pr_err("error. ");
+			pr_err("Skipping la and dynamic ptsa programming\n");
+		} else {
+			pr_err("%s: error.\n", __func__);
+		}
+		WARN_ON(1);
+		return -1;
+	}
+
+	if (write_la) {
+		program_la(&t19x_la_info_array[t19x_id], disp_la);
+		t19x_set_dynamic_ptsa(clientid, bw_mbps, &error);
+
+		if (error)
+			return -1;
+	}
+
+	return ret_val;
+}
+
+static int t19x_set_display_la_ptsa(
+		enum tegra_la_id id,
+		unsigned long emc_freq_hz,
+		unsigned int bw_mbps,
+		struct dc_to_la_params disp_params)
+{
+	return t19x_handle_display_la_ptsa(id, emc_freq_hz, bw_mbps, 1);
+}
+
+static int t19x_check_display_la_ptsa(
+		enum tegra_la_id id,
+		unsigned long emc_freq_hz,
+		unsigned int bw_mbps,
+		struct dc_to_la_params disp_params)
+{
+	return t19x_handle_display_la_ptsa(id, emc_freq_hz, bw_mbps, 0);
+}
+
+static int t19x_set_camera_la_ptsa(
+		enum tegra_la_id id,
+		unsigned int bw_mbps,
+		int is_hiso)
+{
+	/* Nothing needs to be changed from kernel init values, so do nothing*/
+	return 0;
+}
+
+static int t19x_set_dynamic_la_ptsa(enum tegra_la_id id, unsigned int bw_mbps)
+{
+	unsigned int error = 0;
+	int ret_val = 0;
+	int clientid;
+
+	clientid = lp.convert_la2dda_id_for_dyn_ptsa(id, &error);
+
+	t19x_set_dynamic_ptsa(clientid, bw_mbps, &error);
+
+	if (error)
+		return -1;
+
+	return ret_val;
+}
+
+static void program_non_la_ptsa(void)
+{
+	int i;
+
+	for (i = 0; i < TEGRA_KERN_INIT_MC_MAX_ID; i++) {
+		mc_writel(mc_reg_info_array[i].val,
+				mc_reg_info_array[i].offset);
+	}
+
+	for (i = 0; i < TEGRA_KERN_INIT_MSSNVLINK_MAX_ID; i++) {
+		mssnvl1_writel(mssnvlink1_reg_info_array[i].val,
+				mssnvlink1_reg_info_array[i].offset);
+	}
+
+	for (i = 0; i < TEGRA_KERN_INIT_MSSNVLINK_MAX_ID; i++) {
+		mssnvl2_writel(mssnvlink2_reg_info_array[i].val,
+				mssnvlink2_reg_info_array[i].offset);
+	}
+
+	for (i = 0; i < TEGRA_KERN_INIT_MSSNVLINK_MAX_ID; i++) {
+		mssnvl3_writel(mssnvlink3_reg_info_array[i].val,
+				mssnvlink3_reg_info_array[i].offset);
+	}
+
+	for (i = 0; i < TEGRA_KERN_INIT_MSSNVLINK_MAX_ID; i++) {
+		mssnvl4_writel(mssnvlink4_reg_info_array[i].val,
+				mssnvlink4_reg_info_array[i].offset);
+	}
+}
+
+static void save_non_la_ptsa(void)
+{
+	int i;
+
+	for (i = 0; i < TEGRA_KERN_INIT_MC_MAX_ID; i++) {
+		mc_reg_info_array[i].val =
+			mc_readl(mc_reg_info_array[i].offset);
+	}
+
+	for (i = 0; i < TEGRA_KERN_INIT_MSSNVLINK_MAX_ID; i++) {
+		mssnvlink1_reg_info_array[i].val =
+			mssnvl1_readl(mssnvlink1_reg_info_array[i].offset);
+	}
+
+	for (i = 0; i < TEGRA_KERN_INIT_MSSNVLINK_MAX_ID; i++) {
+		mssnvlink2_reg_info_array[i].val =
+			mssnvl2_readl(mssnvlink2_reg_info_array[i].offset);
+	}
+
+	for (i = 0; i < TEGRA_KERN_INIT_MSSNVLINK_MAX_ID; i++) {
+		mssnvlink3_reg_info_array[i].val =
+			mssnvl3_readl(mssnvlink3_reg_info_array[i].offset);
+	}
+
+	for (i = 0; i < TEGRA_KERN_INIT_MSSNVLINK_MAX_ID; i++) {
+		mssnvlink4_reg_info_array[i].val =
+			mssnvl4_readl(mssnvlink4_reg_info_array[i].offset);
+	}
+}
+
+#define SET_FIELD_IN_64BIT_REG(fn_name, var, start, width, field) \
+	do { \
+		if (((field) & ~((1ull<<(width))-1)) != 0) { \
+			pr_err("%s: ", __func__); \
+			pr_err("error. ((field) & ~((1ull<<(width))-1)) "); \
+			pr_err("!= 0, field=%d, width=%d\n", \
+				field, width); \
+			(*error) |= 1; \
+			WARN_ON(1); \
+		} \
+		var = (var & ~((((1ull<<(width))-1)<<(start)))) | \
+				(((field) & ((1ull<<(width))-1))<<(start)); \
+	} while (0)
+
+static void set_nvg_scf_dda(
+	unsigned int nvg_ch,
+	uint32_t rate,
+	uint32_t min,
+	uint32_t max,
+	unsigned int *error)
+{
+	int ret = 0;
+	uint64_t nvg_reg = 0;
+
+	SET_FIELD_IN_64BIT_REG("set_nvg_scf_dda", nvg_reg, 0, 12, rate);
+	SET_FIELD_IN_64BIT_REG("set_nvg_scf_dda", nvg_reg, 12, 11, min);
+	SET_FIELD_IN_64BIT_REG("set_nvg_scf_dda", nvg_reg, 23, 11, max);
+
+	ret = tegra_mce_write_dda_ctrl(nvg_ch, nvg_reg);
+	if (ret != 0) {
+		pr_err("%s: tegra_mce_write_dda_ctrl failed, %d\n",
+			__func__, ret);
+		(*error) |= 1;
+		WARN_ON(1);
+	}
+}
+
+static void set_nvg_scf_gd(
+	unsigned int nvg_ch,
+	uint32_t int_part,
+	uint32_t frac_part,
+	unsigned int *error)
+{
+	int ret = 0;
+	uint64_t nvg_reg = 0;
+
+	ret = tegra_mce_read_dda_ctrl(nvg_ch, &nvg_reg);
+	if (ret != 0) {
+		pr_err("%s: tegra_mce_read_dda_ctrl failed, %d\n",
+			__func__, ret);
+		(*error) |= 1;
+		WARN_ON(1);
+	}
+
+	SET_FIELD_IN_64BIT_REG("set_nvg_scf_gd", nvg_reg, 0, 12, frac_part);
+	SET_FIELD_IN_64BIT_REG("set_nvg_scf_gd", nvg_reg, 12, 1, int_part);
+
+	ret = tegra_mce_write_dda_ctrl(nvg_ch, nvg_reg);
+	if (ret != 0) {
+		pr_err("%s: tegra_mce_write_dda_ctrl failed, %d\n",
+			__func__, ret);
+		(*error) |= 1;
+		WARN_ON(1);
+	}
+}
+#undef SET_FIELD_IN_64BIT_REG
+
+static void scf_dda_init(
+	struct mc_settings_info *mc_settings_ptr,
+	unsigned int *error)
+{
+	uint32_t gd_int, gd_frac;
+	uint32_t eps = 1;
+	uint32_t bw100percent;
+	unsigned int division_factor;
+	struct fixed_point tmp;
+	unsigned disable_dvfs_conflicts = 1;
+
+	switch (mc_settings_ptr->num_channels) {
+	case 16:
+		division_factor = 2; break;
+	case 8:
+		division_factor = 4; break;
+	case 4:
+		division_factor = 8; break;
+	default:
+		division_factor = 1;
+		pr_err("%s: num_channels %d not handled\n",
+			__func__,
+			mc_settings_ptr->num_channels);
+		(*error) |= 1;
+		WARN_ON(1);
+	}
+	tmp = fixed_point_div(
+		mc_settings_ptr->max_gd,
+		FIX_PT(division_factor, 0, error),
+		error);
+
+	/* Rate only has fractional part, so 100% rate < 1 */
+	if (tmp.int_part != 0) {
+		pr_err("%s: int_part is non-zero, expecting only frac part\n",
+			__func__);
+		(*error) |= 1;
+		WARN_ON(1);
+	}
+
+	/* Lower precision to 12 bits of fraction part. */
+	if (tmp.frac_prec < 12) {
+		pr_err("%s: frac_prec < 12, frac_prec = %d\n",
+			__func__,
+			tmp.frac_prec);
+		(*error) |= 1;
+		WARN_ON(1);
+	}
+	bw100percent = (tmp.frac_part & tmp.frac_mask) >> (tmp.frac_prec - 12);
+
+	/* Implement 11bit two's compliment for negative min/max. */
+#define NEG(val) ((~(val) + 1) & 0x7ff)
+
+	/* Simplified int math with just fraction part.
+	 * Multiply first to not lose precision by division. */
+#define PERC(val) ((bw100percent * (val)) / 100)
+
+	/* Initialize grant decrements to max value at init.
+	 * These will be updated by DVFS later. */
+	tmp = mc_settings_ptr->max_gd;
+	if (tmp.int_part > 1) {
+		pr_err("%s: int_part > 1, int_part = %d\n",
+			__func__,
+			tmp.int_part);
+		(*error) |= 1;
+		WARN_ON(1);
+	}
+	gd_int = tmp.int_part;
+	gd_frac = (tmp.frac_part & tmp.frac_mask) >> (tmp.frac_prec - 12);
+
+	if (!disable_dvfs_conflicts) {
+		set_nvg_scf_gd(TEGRA_NVG_CHANNEL_DDA_SNOC_GLOBAL_CTRL,
+					   gd_int, gd_frac, error);
+		set_nvg_scf_gd(TEGRA_NVG_CHANNEL_DDA_L3CTRL_GLOBAL,
+					   gd_int, gd_frac, error);
+		set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_SNOC_CLIENT_REQ_CTRL,
+						PERC(10), NEG(16), 16, error);
+		set_nvg_scf_dda(
+			TEGRA_NVG_CHANNEL_DDA_SNOC_CLIENT_REPLENTISH_CTRL,
+			PERC(10), NEG(16), 16, error);
+		set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_L3CTRL_LL,
+						PERC(10), NEG(16), 16, error);
+		set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_L3CTRL_L3D,
+						PERC(10), NEG(4), 4, error);
+		set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_L3CTRL_NISO,
+						eps, NEG(3), 0, error);
+	}
+
+	set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_SNOC_MCF,
+					eps, NEG(3), 0, error);
+
+	set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_MCF_SISO,
+					0, 1, 1, error);
+	set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_MCF_ORD1,
+					PERC(13), NEG(4), 31, error);
+	set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_MCF_ORD2,
+					PERC(13), NEG(4), 31, error);
+	set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_MCF_ORD3,
+					PERC(7), NEG(4), 31, error);
+	set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_MCF_NISO,
+					eps, NEG(3), 0, error);
+	set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_MCF_NISO_REMOTE,
+					eps, NEG(3), 0, error);
+	set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_MCF_ISO,
+					eps, NEG(3), 0, error);
+
+	set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_L3CTRL_SISO,
+					0, 1, 1, error);
+	set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_L3CTRL_NISO_REMOTE,
+					eps, NEG(3), 0, error);
+	set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_L3CTRL_ISO,
+					eps, NEG(3), 0, error);
+
+	set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_L3CTRL_L3FILL,
+					0x133, NEG(31), 31, error);
+	set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_L3CTRL_L3WR,
+					0, NEG(3), 0, error);
+
+	set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_L3CTRL_RSP_L3RD_DMA,
+					0xE66, NEG(31), 31, error);
+	set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_L3CTRL_RSP_MCFRD_DMA,
+					0, NEG(3), 0, error);
+
+	set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_L3CTRL_FCM_RD,
+					0x555, NEG(1024), 72, error);
+	set_nvg_scf_dda(TEGRA_NVG_CHANNEL_DDA_L3CTRL_FCM_WR,
+					0x555, NEG(1024), 72, error);
+
+#undef NEG
+#undef PERC
+}
+
+static void program_mcpcie(void)
+{
+	int i;
+
+	for (i = 0; i < TEGRA_KERN_INIT_MCPCIE_MAX_ID; i++) {
+		mc_writel(mcpcie_reg_info_array[i].val,
+				mcpcie_reg_info_array[i].offset);
+	}
+}
+
+static void save_mcpcie(void)
+{
+	int i;
+
+	for (i = 0; i < TEGRA_KERN_INIT_MCPCIE_MAX_ID; i++) {
+		mcpcie_reg_info_array[i].val =
+			mc_readl(mcpcie_reg_info_array[i].offset);
+	}
+}
+
+// TODO: Use pcie driver interface
+// TODO: Read base address from dtb
+#define NV_ADDRESS_MAP_PIPE2UPHY_XBAR_BASE          0x03e00000
+static void t19x_mc_pcie_init(void)
+{
+	unsigned int data;
+	unsigned int xbar_cfg;
+	unsigned int error = 0;
+
+	t19x_pipe2uphy_xbar_base = ioremap(NV_ADDRESS_MAP_PIPE2UPHY_XBAR_BASE, 0x00010000);
+	data = pipe2uphy_xbar_readl(PCIE_COMMON_APPL_COMMON_CONTROL_0);
+	iounmap(t19x_pipe2uphy_xbar_base);
+
+	xbar_cfg = NV_DRF_VAL(PCIE_COMMON, APPL_COMMON_CONTROL,
+							XBAR_CONFIG, data);
+
+	lp.mcpcie_reg_info_array_init(mcpcie_reg_info_array);
+	save_mcpcie();
+
+	lp.update_ord_ids(
+		mcpcie_reg_info_array,
+		&mc_settings,
+		xbar_cfg,
+		&error);
+
+	if (error) {
+		pr_err("%s: ", __func__);
+		pr_err("error. Skipping mcpcie programming\n");
+		WARN_ON(1);
+		return;
+	}
+
+	program_mcpcie();
+}
+
+static void t19x_la_cleanup(void)
+{
+	int i;
+
+	for (i = 0; i < TEGRA_T19X_LA_MAX_ID; i++) {
+		if (t19x_la_info_array[i].name) {
+			kfree(t19x_la_info_array[i].name);
+			t19x_la_info_array[i].name = NULL;
+		}
+	}
+}
+
+/*
+ * Get dram type and channels configuration.
+ * TODO: Make use of api from emc driver
+ */
+static enum tegra_dram_t t19x_emc_get_dram_type(void)
+{
+	unsigned int dram, ch, mem_type;
+	enum tegra_dram_t dram_type;
+	void __iomem *t19x_emc_base;
+
+	t19x_emc_base = ioremap(NV_ADDRESS_MAP_EMCB_BASE, 0x00010000);
+	dram = readl(t19x_emc_base + EMC_FBIO_CFG5_0) & DRAM_TYPE_MASK;
+	mem_type = readl(t19x_emc_base + EMC_PMACRO_PAD_CFG_CTRL_0);
+	iounmap(t19x_emc_base);
+
+	ch = mc_readl(MC_EMEM_ADR_CFG_CHANNEL_ENABLE_0) & DRAM_CH_MASK;
+	mem_type = (mem_type >> MEM_MODE_SHIFT) & MEM_MODE_MASK;
+	la_debug("mem_type: 0x%x, dram reg: 0x%x, channels reg: 0x%x\n", mem_type, dram, ch);
+
+	if (dram != DRAM_LPDDR4) {
+		pr_err("dram is not LPDDR4\n");
+		WARN_ON(1);
+		return -1;
+	}
+
+	switch (ch) {
+	case(0xf):
+		dram_type = TEGRA_LP4_4CH;
+		break;
+	case(0xff):
+		dram_type = mem_type ? TEGRA_LP4_8CH : TEGRA_LP4X_8CH;
+		break;
+	case(0xffff):
+		dram_type = mem_type ? TEGRA_LP4_16CH : TEGRA_LP4X_16CH;
+		break;
+	default:
+		pr_err("la/ptsa: 0x%x: Unknown memory channel configuration\n", ch);
+		WARN_ON(1);
+		return -1;
+	}
+	return dram_type;
+}
+
+static void tegra_la_init(void)
+{
+	unsigned int error = 0;
+	enum tegra_dram_t tegra_dram_type = t19x_emc_get_dram_type();
+
+	la_debug("DRAM Type: %d\n", tegra_dram_type);
+	if (tegra_dram_type < 0)
+		return;
+
+	init_la_ptsa_core(&lp);
+	lp.mc_settings_init(tegra_dram_type, &mc_settings, &error);
+	lp.setup_freq_ranges(&mc_settings, &error);
+	la_init(&error);
+	if (error) {
+		pr_err("%s: ", __func__);
+		pr_err("error. Skipping kern init programming\n");
+		WARN_ON(1);
+		return;
+	}
+
+	lp.all_reg_info_array_init(
+		mc_reg_info_array,
+		mssnvlink1_reg_info_array,
+		mssnvlink2_reg_info_array,
+		mssnvlink3_reg_info_array,
+		mssnvlink4_reg_info_array);
+	save_non_la_ptsa();
+
+	lp.write_perf_regs_kern_init(
+		&mc_settings,
+		mc_reg_info_array,
+		mssnvlink1_reg_info_array,
+		mssnvlink2_reg_info_array,
+		mssnvlink3_reg_info_array,
+		mssnvlink4_reg_info_array);
+	program_non_la_ptsa();
+
+	scf_dda_init(&mc_settings, &error);
+	if (error) {
+		pr_err("%s: ", __func__);
+		pr_err("error. Skipping MC_TIMING_CONTROL programming\n");
+		WARN_ON(1);
+		return;
+	}
+
+	/* update shadowed registers */
+	mc_writel(1, MC_TIMING_CONTROL_0);
+}
+
+
+void tegra_la_get_t19x_specific(struct la_chip_specific *cs_la)
+{
+
+	cs_la->ns_per_tick = 30;
+	cs_la->la_max_value = T19X_MC_LA_MAX_VALUE;
+
+	cs_la->la_info_array = t19x_la_info_array;
+	cs_la->la_info_array_size = TEGRA_T19X_LA_MAX_ID;
+
+	cs_la->init_ptsa = t19x_init_ptsa;
+	cs_la->update_camera_ptsa_rate = t19x_set_camera_la_ptsa;
+	cs_la->set_init_la = t19x_set_init_la;
+	cs_la->set_dynamic_la = t19x_set_dynamic_la_ptsa;
+	cs_la->set_disp_la = t19x_set_display_la_ptsa;
+	cs_la->check_disp_la = t19x_check_display_la_ptsa;
+	cs_la->save_ptsa = save_ptsa;
+	cs_la->program_ptsa = program_ptsa;
+	cs_la->save_non_la_ptsa = save_non_la_ptsa;
+	cs_la->program_non_la_ptsa = program_non_la_ptsa;
+	cs_la->suspend = la_suspend;
+	cs_la->resume = la_resume;
+	cs_la->mc_pcie_init = t19x_mc_pcie_init;
+	cs_la->la_cleanup = t19x_la_cleanup;
+
+	tegra_la_init();
+}
diff --git a/drivers/platform/tegra/mc/tegra19x_la_ptsa.h b/drivers/platform/tegra/mc/tegra19x_la_ptsa.h
new file mode 100644
index 000000000000..c55e9ddc3ceb
--- /dev/null
+++ b/drivers/platform/tegra/mc/tegra19x_la_ptsa.h
@@ -0,0 +1,594 @@
+/*
+ * Copyright (C) 2018, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#ifndef _MACH_TEGRA_19X_LA_PTSA_H
+#define _MACH_TEGRA_19X_LA_PTSA_H
+
+#include <asm/io.h>
+#include <linux/types.h>
+#include <linux/platform/tegra/tegra_emc.h>
+#include <linux/platform/tegra/mc.h>
+#include <linux/platform/tegra/latency_allowance.h>
+#include <linux/t194_nvg.h>
+#include "mc-regs-t19x.h"
+#include "la_priv.h"
+#include "fixed_point.h"
+#include "nvrm_drf.h"
+
+
+#define T19X_MC_LA_MAX_VALUE                    2047U
+#define DRAM_TYPE_MASK                          0x3
+#define DRAM_LPDDR4                             1
+#define DRAM_CH_MASK                            0xffff
+#define MEM_MODE_SHIFT                          16
+#define MEM_MODE_MASK                           0x3
+
+#define MAX_TEGRA_DDA_NAME_SIZE 128
+#define MAX_TEGRA_LA_CLIENT_NAME_SIZE 128
+#define MAX_TEGRA_MC_REG_NAME_SIZE 128
+
+enum tegra_t19x_la_id {
+	TEGRA_T19X_LA_AONDMAR_ID,
+	TEGRA_T19X_LA_AONDMAW_ID,
+	TEGRA_T19X_LA_AONR_ID,
+	TEGRA_T19X_LA_AONW_ID,
+	TEGRA_T19X_LA_APEDMAR_ID,
+	TEGRA_T19X_LA_APEDMAW_ID,
+	TEGRA_T19X_LA_APER_ID,
+	TEGRA_T19X_LA_APEW_ID,
+	TEGRA_T19X_LA_AXIAPR_ID,
+	TEGRA_T19X_LA_AXIAPW_ID,
+	TEGRA_T19X_LA_AXISR_ID,
+	TEGRA_T19X_LA_AXISW_ID,
+	TEGRA_T19X_LA_BPMPDMAR_ID,
+	TEGRA_T19X_LA_BPMPDMAW_ID,
+	TEGRA_T19X_LA_BPMPR_ID,
+	TEGRA_T19X_LA_BPMPW_ID,
+	TEGRA_T19X_LA_CIFLL_WR_ID,
+	TEGRA_T19X_LA_DLA0FALRDB_ID,
+	TEGRA_T19X_LA_DLA0RDA_ID,
+	TEGRA_T19X_LA_DLA0FALWRB_ID,
+	TEGRA_T19X_LA_DLA0WRA_ID,
+	TEGRA_T19X_LA_DLA0RDA1_ID,
+	TEGRA_T19X_LA_DLA1RDA1_ID,
+	TEGRA_T19X_LA_DLA1FALRDB_ID,
+	TEGRA_T19X_LA_DLA1RDA_ID,
+	TEGRA_T19X_LA_DLA1FALWRB_ID,
+	TEGRA_T19X_LA_DLA1WRA_ID,
+	TEGRA_T19X_LA_EQOSR_ID,
+	TEGRA_T19X_LA_EQOSW_ID,
+	TEGRA_T19X_LA_ETRR_ID,
+	TEGRA_T19X_LA_ETRW_ID,
+	TEGRA_T19X_LA_HOST1XDMAR_ID,
+	TEGRA_T19X_LA_HDAR_ID,
+	TEGRA_T19X_LA_HDAW_ID,
+	TEGRA_T19X_LA_ISPFALR_ID,
+	TEGRA_T19X_LA_ISPRA_ID,
+	TEGRA_T19X_LA_ISPWA_ID,
+	TEGRA_T19X_LA_ISPWB_ID,
+	TEGRA_T19X_LA_ISPFALW_ID,
+	TEGRA_T19X_LA_ISPRA1_ID,
+	TEGRA_T19X_LA_MIU0R_ID,
+	TEGRA_T19X_LA_MIU0W_ID,
+	TEGRA_T19X_LA_MIU1R_ID,
+	TEGRA_T19X_LA_MIU1W_ID,
+	TEGRA_T19X_LA_MIU2R_ID,
+	TEGRA_T19X_LA_MIU2W_ID,
+	TEGRA_T19X_LA_MIU3R_ID,
+	TEGRA_T19X_LA_MIU3W_ID,
+	TEGRA_T19X_LA_MIU4R_ID,
+	TEGRA_T19X_LA_MIU4W_ID,
+	TEGRA_T19X_LA_MIU5R_ID,
+	TEGRA_T19X_LA_MIU5W_ID,
+	TEGRA_T19X_LA_MIU6R_ID,
+	TEGRA_T19X_LA_MIU6W_ID,
+	TEGRA_T19X_LA_MIU7R_ID,
+	TEGRA_T19X_LA_MIU7W_ID,
+	TEGRA_T19X_LA_MPCORER_ID,
+	TEGRA_T19X_LA_MPCOREW_ID,
+	TEGRA_T19X_LA_NVDECSRD_ID,
+	TEGRA_T19X_LA_NVDECSWR_ID,
+	TEGRA_T19X_LA_NVDEC1SRD_ID,
+	TEGRA_T19X_LA_NVDECSRD1_ID,
+	TEGRA_T19X_LA_NVDEC1SRD1_ID,
+	TEGRA_T19X_LA_NVDEC1SWR_ID,
+	TEGRA_T19X_LA_NVDISPLAYR_ID,
+	TEGRA_T19X_LA_NVENCSRD_ID,
+	TEGRA_T19X_LA_NVENCSWR_ID,
+	TEGRA_T19X_LA_NVENC1SRD_ID,
+	TEGRA_T19X_LA_NVENC1SWR_ID,
+	TEGRA_T19X_LA_NVENC1SRD1_ID,
+	TEGRA_T19X_LA_NVENCSRD1_ID,
+	TEGRA_T19X_LA_NVJPGSRD_ID,
+	TEGRA_T19X_LA_NVJPGSWR_ID,
+	TEGRA_T19X_LA_PCIE0R_ID,
+	TEGRA_T19X_LA_PCIE0W_ID,
+	TEGRA_T19X_LA_PCIE1R_ID,
+	TEGRA_T19X_LA_PCIE1W_ID,
+	TEGRA_T19X_LA_PCIE2AR_ID,
+	TEGRA_T19X_LA_PCIE2AW_ID,
+	TEGRA_T19X_LA_PCIE3R_ID,
+	TEGRA_T19X_LA_PCIE3W_ID,
+	TEGRA_T19X_LA_PCIE4R_ID,
+	TEGRA_T19X_LA_PCIE4W_ID,
+	TEGRA_T19X_LA_PCIE5R_ID,
+	TEGRA_T19X_LA_PCIE5W_ID,
+	TEGRA_T19X_LA_PCIE0R1_ID,
+	TEGRA_T19X_LA_PCIE5R1_ID,
+	TEGRA_T19X_LA_PVA0RDA_ID,
+	TEGRA_T19X_LA_PVA0RDB_ID,
+	TEGRA_T19X_LA_PVA0RDC_ID,
+	TEGRA_T19X_LA_PVA0WRA_ID,
+	TEGRA_T19X_LA_PVA0WRB_ID,
+	TEGRA_T19X_LA_PVA0WRC_ID,
+	TEGRA_T19X_LA_PVA0RDA1_ID,
+	TEGRA_T19X_LA_PVA0RDB1_ID,
+	TEGRA_T19X_LA_PVA1RDA_ID,
+	TEGRA_T19X_LA_PVA1RDB_ID,
+	TEGRA_T19X_LA_PVA1RDC_ID,
+	TEGRA_T19X_LA_PVA1WRA_ID,
+	TEGRA_T19X_LA_PVA1WRB_ID,
+	TEGRA_T19X_LA_PVA1WRC_ID,
+	TEGRA_T19X_LA_PVA1RDA1_ID,
+	TEGRA_T19X_LA_PVA1RDB1_ID,
+	TEGRA_T19X_LA_RCEDMAR_ID,
+	TEGRA_T19X_LA_RCEDMAW_ID,
+	TEGRA_T19X_LA_RCER_ID,
+	TEGRA_T19X_LA_RCEW_ID,
+	TEGRA_T19X_LA_SATAR_ID,
+	TEGRA_T19X_LA_SATAW_ID,
+	TEGRA_T19X_LA_SCEDMAR_ID,
+	TEGRA_T19X_LA_SCEDMAW_ID,
+	TEGRA_T19X_LA_SCER_ID,
+	TEGRA_T19X_LA_SCEW_ID,
+	TEGRA_T19X_LA_SDMMCRAB_ID,
+	TEGRA_T19X_LA_SDMMCWAB_ID,
+	TEGRA_T19X_LA_SDMMCRA_ID,
+	TEGRA_T19X_LA_SDMMCWA_ID,
+	TEGRA_T19X_LA_SDMMCR_ID,
+	TEGRA_T19X_LA_SDMMCW_ID,
+	TEGRA_T19X_LA_SESRD_ID,
+	TEGRA_T19X_LA_SESWR_ID,
+	TEGRA_T19X_LA_TSECSRDB_ID,
+	TEGRA_T19X_LA_TSECSWRB_ID,
+	TEGRA_T19X_LA_TSECSRD_ID,
+	TEGRA_T19X_LA_TSECSWR_ID,
+	TEGRA_T19X_LA_UFSHCR_ID,
+	TEGRA_T19X_LA_UFSHCW_ID,
+	TEGRA_T19X_LA_VIW_ID,
+	TEGRA_T19X_LA_VICSRD_ID,
+	TEGRA_T19X_LA_VICSWR_ID,
+	TEGRA_T19X_LA_VICSRD1_ID,
+	TEGRA_T19X_LA_VIFALR_ID,
+	TEGRA_T19X_LA_VIFALW_ID,
+	TEGRA_T19X_LA_WCAM_ID,
+	TEGRA_T19X_LA_XUSB_HOSTR_ID,
+	TEGRA_T19X_LA_XUSB_HOSTW_ID,
+	TEGRA_T19X_LA_XUSB_DEVR_ID,
+	TEGRA_T19X_LA_XUSB_DEVW_ID,
+	TEGRA_T19X_LA_NVLRHP_ID,
+	TEGRA_T19X_LA_DGPU_ID,
+	TEGRA_T19X_LA_IGPU_ID,
+	TEGRA_T19X_LA_MAX_ID
+};
+
+/*
+ * T19X only supports LP4 and LP4X with 8 and 16 channels.
+ * TODO: Check and remove others if not needed.
+ */
+enum tegra_dram_t {
+	TEGRA_DDR3,
+	TEGRA_LP3,
+	TEGRA_LP4,
+	TEGRA_DDR3_1CH,
+	TEGRA_DDR3_2CH,
+	TEGRA_LP3_1CH,
+	TEGRA_LP3_2CH,
+	TEGRA_LP4_2CH,
+	TEGRA_LP4_4CH,
+	TEGRA_LP4_8CH,
+	TEGRA_LP4X_8CH,
+	TEGRA_LP4_16CH,
+	TEGRA_LP4X_16CH
+};
+
+#define MAX_TEGRA_LA_CLIENT_NAME_SIZE 128
+
+/* Frequency range used to determine different DDA parameters */
+struct dda_freq_range {
+	struct fixed_point lo_freq;
+	struct fixed_point hi_freq;
+	struct fixed_point lo_gd; /* Grantdec at lowest freq in this range */
+	struct fixed_point hi_gd; /* Grantdec at highest freq in this range */
+	unsigned int emc_mc_ratio;
+	unsigned int valid;
+};
+
+struct mc_settings_info {
+	enum tegra_dram_t dram_type;
+	int num_channels;
+	int mccif_buf_sz_bytes;
+	int stat_lat_minus_snaparb2rs;
+	int exp_time;
+	int dram_width_bits;
+	struct fixed_point cons_mem_eff;
+	int stat_lat_snaparb_rs;
+	int row_sorter_sz_bytes;
+	struct fixed_point max_drain_time_usec;
+	struct fixed_point ns_per_tick;
+	struct fixed_point max_lat_all_usec;
+	int ring2_dda_rate;
+	int ring2_dda_en;
+	int siso_hp_en;
+	int vi_always_hp;
+	int bytes_per_dram_clk;
+	struct fixed_point hub_dda_div;
+	struct fixed_point ring0_dda_div;
+	int dram_to_emc_freq_ratio;
+	struct fixed_point disp_catchup_factor;
+	struct fixed_point dda_bw_margin;
+	struct fixed_point two_stge_ecc_iso_dda_bw_margin;
+	struct fixed_point mc_emc_same_freq_thr;
+	struct fixed_point lowest_dram_freq;
+	struct fixed_point highest_dram_freq;
+	int ptsa_reg_length_bits;
+	struct fixed_point grant_dec_multiplier;
+	struct fixed_point max_gd;
+	int set_perf_regs;
+	int hub2mcf_dda;
+	int igpu_mcf_dda;
+	int tsa_arb_fix;
+	int iso_holdoff_override;
+	int pcfifo_interlock;
+	int en_ordering;
+	int set_order_id;
+	int hp_cpu_throttle_en;
+	int override_isoptc_hub_mapping;
+	int override_hub_vcarb_type;
+	int override_hub_vcarb_wt;
+	int override_iso_tbu_cchk_en_ctrl;
+	int hub2mcf_dda_rate;
+	int hub2mcf_dda_max;
+	int mssnvlink_mcf_igpu_dda_rate;
+	int mssnvlink_mcf_igpu_dda_max;
+	int isoptc_hub_num;
+	int hub_vcarb_type;
+	int hub_vcarb_niso_wt;
+	int hub_vcarb_siso_wt;
+	int hub_vcarb_iso_wt;
+	int iso_tbu_cchk_en_ctrl;
+	struct dda_freq_range freq_range;
+};
+
+enum tegra_dda_id {
+	TEGRA_DDA_AONPC_ID,
+	TEGRA_DDA_APB_ID,
+	TEGRA_DDA_AUD_ID,
+	TEGRA_DDA_BPMPPC_ID,
+	TEGRA_DDA_CIFLL_ISO_ID,
+	TEGRA_DDA_CIFLL_SISO_ID,
+	TEGRA_DDA_CIFLL_NISO_ID,
+	TEGRA_DDA_CIFLL_RING0X_ID,
+	TEGRA_DDA_DIS_ID,
+	TEGRA_DDA_DLA0FALPC_ID,
+	TEGRA_DDA_DLA0XA_ID,
+	TEGRA_DDA_DLA0XA2_ID,
+	TEGRA_DDA_DLA0XA3_ID,
+	TEGRA_DDA_DLA1FALPC_ID,
+	TEGRA_DDA_DLA1XA_ID,
+	TEGRA_DDA_DLA1XA2_ID,
+	TEGRA_DDA_DLA1XA3_ID,
+	TEGRA_DDA_EQOSPC_ID,
+	TEGRA_DDA_HDAPC_ID,
+	TEGRA_DDA_HOST_ID,
+	TEGRA_DDA_ISP_ID,
+	TEGRA_DDA_ISP2PC_ID,
+	TEGRA_DDA_ISPPC_ID,
+	TEGRA_DDA_JPG_ID,
+	TEGRA_DDA_MIU0_ID,
+	TEGRA_DDA_MIU1_ID,
+	TEGRA_DDA_MIU2_ID,
+	TEGRA_DDA_MIU3_ID,
+	TEGRA_DDA_MIU4_ID,
+	TEGRA_DDA_MIU5_ID,
+	TEGRA_DDA_MIU6_ID,
+	TEGRA_DDA_MIU7_ID,
+	TEGRA_DDA_MLL_MPCORER_ID,
+	TEGRA_DDA_MSE_ID,
+	TEGRA_DDA_MSE2_ID,
+	TEGRA_DDA_MSE3_ID,
+	TEGRA_DDA_MSEA_ID,
+	TEGRA_DDA_MSEB_ID,
+	TEGRA_DDA_MSEB1_ID,
+	TEGRA_DDA_NIC_ID,
+	TEGRA_DDA_NVD_ID,
+	TEGRA_DDA_NVD2_ID,
+	TEGRA_DDA_NVD3_ID,
+	TEGRA_DDA_NVD4_ID,
+	TEGRA_DDA_NVD5_ID,
+	TEGRA_DDA_NVD6_ID,
+	TEGRA_DDA_PCIE0X_ID,
+	TEGRA_DDA_PCIE0X2_ID,
+	TEGRA_DDA_PCIE0XA_ID,
+	TEGRA_DDA_PCIE1X_ID,
+	TEGRA_DDA_PCIE1XA_ID,
+	TEGRA_DDA_PCIE4X_ID,
+	TEGRA_DDA_PCIE4XA_ID,
+	TEGRA_DDA_PCIE5X_ID,
+	TEGRA_DDA_PCIE5X2_ID,
+	TEGRA_DDA_PCIE5XA_ID,
+	TEGRA_DDA_PVA0XA_ID,
+	TEGRA_DDA_PVA0XA2_ID,
+	TEGRA_DDA_PVA0XA3_ID,
+	TEGRA_DDA_PVA0XB_ID,
+	TEGRA_DDA_PVA0XB2_ID,
+	TEGRA_DDA_PVA0XB3_ID,
+	TEGRA_DDA_PVA0XC_ID,
+	TEGRA_DDA_PVA1XA_ID,
+	TEGRA_DDA_PVA1XA2_ID,
+	TEGRA_DDA_PVA1XA3_ID,
+	TEGRA_DDA_PVA1XB_ID,
+	TEGRA_DDA_PVA1XB2_ID,
+	TEGRA_DDA_PVA1XB3_ID,
+	TEGRA_DDA_PVA1XC_ID,
+	TEGRA_DDA_RCEPC_ID,
+	TEGRA_DDA_RING2_ID,
+	TEGRA_DDA_SAX_ID,
+	TEGRA_DDA_SCEPC_ID,
+	TEGRA_DDA_SD_ID,
+	TEGRA_DDA_SDM_ID,
+	TEGRA_DDA_SMMU_SMMU_ID,
+	TEGRA_DDA_UFSHCPC_ID,
+	TEGRA_DDA_UFSHCPC2_ID,
+	TEGRA_DDA_USBD_ID,
+	TEGRA_DDA_USBD2_ID,
+	TEGRA_DDA_USBX_ID,
+	TEGRA_DDA_USBX2_ID,
+	TEGRA_DDA_VE_ID,
+	TEGRA_DDA_VICPC_ID,
+	TEGRA_DDA_VICPC2_ID,
+	TEGRA_DDA_VICPC3_ID,
+	TEGRA_DDA_MAX_ID
+};
+
+enum tegra_iso_t {
+	TEGRA_HISO,
+	TEGRA_SISO,
+	TEGRA_NISO
+};
+
+#define MAX_TEGRA_DDA_NAME_SIZE 128
+
+struct dda_info {
+	char name[MAX_TEGRA_DDA_NAME_SIZE];
+	unsigned int rate; /* BW rate expressed as 0.rate */
+	struct fixed_point frac; /* fixed point fraction for the BW rate */
+	int frac_valid; /* frac is valid. */
+	int max; /* Maximum value of accum allowed. Expressed as max.0 */
+	int min; /* Minimum value of accum allowed. Expressed as min.0 */
+	struct fixed_point bw; /* actual BW requested */
+	unsigned int ring; /* what ring this client feeds into. */
+	enum tegra_iso_t iso_type; /* HISO, SISO, or NISO*/
+	unsigned int rate_reg_addr;
+	unsigned long mask;
+	struct fixed_point dda_div;
+};
+
+enum tegra_kern_init_mc_id {
+	TEGRA_MC_HUB2MCF_REQ_DDA_ENABLE_ID,
+	TEGRA_MC_HUB_HUB2MCF_REQ_DDA_RATE_ID,
+	TEGRA_MC_HUBORD_HUB2MCF_REQ_DDA_RATE_ID,
+	TEGRA_MC_HUBINT_HUB2MCF_REQ_DDA_RATE_ID,
+	TEGRA_MC_HUB_HUB2MCF_REQ_DDA_MAX_ID,
+	TEGRA_MC_HUBORD_HUB2MCF_REQ_DDA_MAX_ID,
+	TEGRA_MC_HUBINT_HUB2MCF_REQ_DDA_MAX_ID,
+	TEGRA_MC_CIFLL_NVLRHP_LATENCY_ALLOWANCE_ID,
+	TEGRA_MC_TXN_OVERRIDE_CONFIG_APER_ID,
+	TEGRA_MC_TXN_OVERRIDE_CONFIG_APEW_ID,
+	TEGRA_MC_TXN_OVERRIDE_CONFIG_APEDMAR_ID,
+	TEGRA_MC_TXN_OVERRIDE_CONFIG_APEDMAW_ID,
+	TEGRA_MC_TXN_OVERRIDE_CONFIG_EQOSR_ID,
+	TEGRA_MC_TXN_OVERRIDE_CONFIG_EQOSW_ID,
+	TEGRA_MC_TXN_OVERRIDE_CONFIG_HDAR_ID,
+	TEGRA_MC_TXN_OVERRIDE_CONFIG_HDAW_ID,
+	TEGRA_MC_TXN_OVERRIDE_CONFIG_NVDISPLAYR_ID,
+	TEGRA_MC_TXN_OVERRIDE_CONFIG_NVDISPLAYR1_ID,
+	TEGRA_MC_TXN_OVERRIDE_CONFIG_PTCR_ID,
+	TEGRA_MC_TXN_OVERRIDE_CONFIG_VIFALR_ID,
+	TEGRA_MC_TXN_OVERRIDE_CONFIG_VIFALW_ID,
+	TEGRA_MC_TXN_OVERRIDE_CONFIG_VIW_ID,
+	TEGRA_MC_CONFIG_TSA_SINGLE_ARB_ENABLE_ID,
+	TEGRA_MC_EMEM_ARB_OVERRIDE_ID,
+	TEGRA_MC_PCFIFO_CLIENT_CONFIG0_ID,
+	TEGRA_MC_PCFIFO_CLIENT_CONFIG1_ID,
+	TEGRA_MC_PCFIFO_CLIENT_CONFIG2_ID,
+	TEGRA_MC_PCFIFO_CLIENT_CONFIG3_ID,
+	TEGRA_MC_PCFIFO_CLIENT_CONFIG4_ID,
+	TEGRA_MC_PCFIFO_CLIENT_CONFIG5_ID,
+	TEGRA_MC_PCFIFO_CLIENT_CONFIG7_ID,
+	TEGRA_MC_TBU_CLIENT_STEERING_CONFIG_PCIE5W_ID,
+	TEGRA_MC_TBU_CLIENT_STEERING_CONFIG_PCIE0W_ID,
+	TEGRA_MC_TBU_CLIENT_STEERING_CONFIG_PCIE4W_ID,
+	TEGRA_MC_TBU_CLIENT_STEERING_CONFIG_XUSB_HOSTW_ID,
+	TEGRA_MC_TBU_CLIENT_STEERING_CONFIG_XUSB_DEVW_ID,
+	TEGRA_MC_TBU_CLIENT_STEERING_CONFIG_SATAW_ID,
+	TEGRA_MC_CLIENT_ORDER_ID_9_ID,
+	TEGRA_MC_CLIENT_ORDER_ID_28_ID,
+	TEGRA_MC_FREE_BANK_QUEUES_ID,
+	TEGRA_MC_MC_SMMU_PTC2H_REQ_MAPPING_OVERRIDE_ID,
+	TEGRA_MC_MC_SMMU_PTC2H_REQ_MAPPING_ID,
+	TEGRA_MC_HUB_VC_ARB_SEL_ID,
+	TEGRA_MC_MC_SMMU_ISO_TBU_CCHK_REQ_PRI_CTRL_ID,
+	TEGRA_KERN_INIT_MC_MAX_ID
+};
+
+enum tegra_kern_init_mssnvlink_id {
+	TEGRA_MSSNVLINK_MASTER_MCF_DDA_ID,
+	TEGRA_KERN_INIT_MSSNVLINK_MAX_ID
+};
+
+enum tegra_kern_init_mcpcie_id {
+	TEGRA_MC_PCFIFO_CLIENT_CONFIG6_ID,
+	TEGRA_MC_TBU_CLIENT_STEERING_CONFIG_PCIE1W_ID,
+	TEGRA_MC_TBU_CLIENT_STEERING_CONFIG_PCIE2AW_ID,
+	TEGRA_MC_TBU_CLIENT_STEERING_CONFIG_PCIE3W_ID,
+	TEGRA_MC_CLIENT_ORDER_ID_27_ID,
+	TEGRA_KERN_INIT_MCPCIE_MAX_ID
+};
+
+#define MAX_TEGRA_MC_REG_NAME_SIZE 128
+
+struct reg_info {
+	char name[MAX_TEGRA_MC_REG_NAME_SIZE];
+	unsigned int val;
+	unsigned int offset;
+	int dirty;
+};
+
+struct la_ptsa_core {
+	/* Gets the initial la value given client type and mc settings */
+	unsigned int (*get_init_la)(
+		enum la_client_type client_type,
+		struct mc_settings_info *mc_settings_ptr,
+		unsigned int *error);
+
+	/* Init la_client_info_array for all clients */
+	void (*la_info_array_init)(
+		struct la_client_info *info_array,
+		int *gen_to_t19x_la_id,
+		int *t19x_to_gen_la_id,
+		int *t19x_la_kern_init,
+		struct mc_settings_info *mc_set,
+		unsigned int *error);
+
+	/* Updates mc parameters given dram type */
+	void (*mc_settings_init)(
+		enum tegra_dram_t dram_type,
+		struct mc_settings_info *mc_settings_ptr,
+		unsigned int *error);
+
+	/* Overrides a mc_settings_info type */
+	void (*mc_settings_override)(
+		struct mc_settings_info info,
+		struct mc_settings_info *mc_settings_ptr);
+
+	/* Calculates the display read latency allowance given the bw */
+	void (*get_disp_rd_lat_allow_given_disp_bw)(
+		struct mc_settings_info *mc_settings_ptr,
+		struct fixed_point emc_freq_mhz,
+		struct fixed_point dis_bw, /* MBps */
+		int *disp_la,
+		struct fixed_point *drain_time_usec,
+		struct fixed_point *la_bw_up_bnd_usec,
+		unsigned int *error);
+
+	/* Init dda_info_array for all clients */
+	void (*dda_info_array_init)(
+		struct dda_info *inf_arr,
+		int info_array_size,
+		struct mc_settings_info *mc_set,
+		unsigned int *error);
+
+	/* Updates DDA MIN/MAX values for kernel init */
+	void (*update_new_dda_minmax_kern_init)(
+		struct dda_info *dda_info_array,
+		struct mc_settings_info *mc_settings_ptr,
+		unsigned int *error);
+
+	/* Updates DDA RATE values for kernel init */
+	void (*update_new_dda_rate_frac_kern_init)(
+		struct dda_info *dda_info_array,
+		struct mc_settings_info *mc_settings_ptr,
+		unsigned int *error);
+
+	/* Maps ISO LA to DDA */
+	enum tegra_dda_id (*convert_la2dda_id_for_dyn_ptsa)(
+		enum tegra_la_id la_id,
+		unsigned int *error);
+
+	/* Init max grant decrement */
+	void (*init_max_gd)(
+		struct mc_settings_info *mc_settings_ptr,
+		unsigned int *error);
+
+	/* Init mc/emc same freq threshold */
+	void (*init_mcemc_same_freq_thr)(
+		struct mc_settings_info *mc_settings_ptr,
+		unsigned int *error);
+
+	/* Sets up frequency ranges for grant decrement */
+	void (*setup_freq_ranges)(
+		struct mc_settings_info *mc_settings_ptr,
+		unsigned int *error);
+
+	/* Gets bytes per DRAM clock */
+	int (*get_bytes_per_dram_clk)(
+		enum tegra_dram_t dram_type,
+		unsigned int *error);
+
+	/* Converts bw to fraction of DRAM bw */
+	struct fixed_point (*bw2fraction)(
+		struct mc_settings_info *mc_settings_ptr,
+		struct fixed_point bw_mbps,
+		unsigned int *error);
+
+	/* Converts fraction of DRAM bw to bw */
+	unsigned int (*fraction2dda)(
+		struct fixed_point fraction,
+		struct fixed_point div,
+		unsigned int mask,
+		int round_up_or_to_nearest,
+		unsigned int *error);
+
+	/* Update DDA rate based on use case */
+	void (*update_new_dda_rate_frac_use_case)(
+		struct dda_info *dda_info_array,
+		struct mc_settings_info *mc_settings_ptr,
+		int clientid,
+		struct fixed_point bw_mbps,
+		unsigned int *error);
+
+	/* Init non freq dep kernel init registers */
+	void (*all_reg_info_array_init)(
+		struct reg_info *mc_inf_arr,
+		struct reg_info *mssnvl1_inf_arr,
+		struct reg_info *mssnvl2_inf_arr,
+		struct reg_info *mssnvl3_inf_arr,
+		struct reg_info *mssnvl4_inf_arr);
+
+	/* Write non freq dep kernel init registers */
+	void (*write_perf_regs_kern_init)(
+		struct mc_settings_info *mc_settings_ptr,
+		struct reg_info *mc_inf_arr,
+		struct reg_info *mssnvl1_inf_arr,
+		struct reg_info *mssnvl2_inf_arr,
+		struct reg_info *mssnvl3_inf_arr,
+		struct reg_info *mssnvl4_inf_arr);
+
+	/* Init non freq dep kernel init registers */
+	void (*mcpcie_reg_info_array_init)(
+		struct reg_info *inf_arr);
+
+	void (*update_ord_ids)(
+		struct reg_info *mcpcie_inf_arr,
+		struct mc_settings_info *mc_settings_ptr,
+		unsigned int pcie_xbar_cfg,
+		unsigned int *error);
+};
+
+void init_la_ptsa_core(struct la_ptsa_core *lp);
+
+void tegra_la_get_t19x_specific(struct la_chip_specific *cs_la);
+
+#endif /* _MACH_TEGRA_19X_LA_PTSA_H */
diff --git a/drivers/platform/tegra/mc/tegra19x_la_ptsa_core.c b/drivers/platform/tegra/mc/tegra19x_la_ptsa_core.c
new file mode 100644
index 000000000000..2e82bbb1e14d
--- /dev/null
+++ b/drivers/platform/tegra/mc/tegra19x_la_ptsa_core.c
@@ -0,0 +1,2072 @@
+/*
+ * Copyright (C) 2018, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#include <linux/string.h>
+#include <linux/slab.h>
+#include <linux/err.h>
+#include "tegra19x_la_ptsa.h"
+
+#define __stringify_1(x...) #x
+#define __stringify(x...) __stringify_1(x)
+#define FIX_PT(x, y, err) fixed_point_init(x, y, 32, 32, err)
+#define MASK(x) \
+	((0xFFFFFFFFUL >> (31 - (1 ? x) + (0 ? x))) << (0 ? x))
+#define SHIFT(x) \
+	(0 ? x)
+#define GEN_ID(id) \
+	TEGRA_LA_##id
+#define T19X_ID(id) \
+	TEGRA_T19X_LA_##id##_ID
+
+#define LA_T19X(a, r, i, ct, k)			\
+	do { \
+		gen_to_t19x_la_id[GEN_ID(i)] = T19X_ID(i); \
+		t19x_to_gen_la_id[T19X_ID(i)] = GEN_ID(i); \
+		t19x_la_kern_init[T19X_ID(i)] = k; \
+		la_client_info_init( \
+			&info_array[T19X_ID(i)], \
+			mc_set, \
+			MC_LATENCY_ALLOWANCE_ ## a ## _0, \
+			MASK(r), \
+			SHIFT(r), \
+			GEN_ID(i), \
+			__stringify(i), \
+			TEGRA_LA_ ## ct ## _CLIENT, \
+			error);   \
+	} while (0)
+
+#define GPU_LA_T19X(a, r, i, ct, k)		\
+	do { \
+		gen_to_t19x_la_id[GEN_ID(i)] = T19X_ID(i); \
+		t19x_to_gen_la_id[T19X_ID(i)] = GEN_ID(i); \
+		t19x_la_kern_init[T19X_ID(i)] = k; \
+		la_client_info_init( \
+			&info_array[T19X_ID(i)], \
+			mc_set, \
+			MC_ ## a ## _LATENCY_ALLOWANCE ## _0, \
+			MASK(r), \
+			SHIFT(r), \
+			GEN_ID(i), \
+			__stringify(i), \
+			TEGRA_LA_ ## ct ## _CLIENT, \
+			error);   \
+	} while (0)
+
+static struct fixed_point bw2fraction(
+	struct mc_settings_info *mc_settings_ptr,
+	struct fixed_point bw_mbps,
+	unsigned int *error);
+
+static unsigned int fraction2dda(
+	struct fixed_point fraction,
+	struct fixed_point div,
+	unsigned int mask,
+	int round_up_or_to_nearest,
+	unsigned int *error);
+
+static unsigned int calc_eff_rowsorter_sz(
+	struct fixed_point emc_clk_mhz,
+	struct mc_settings_info *mc_settings_ptr,
+	unsigned int *error)
+{
+	struct fixed_point term1;
+	struct fixed_point term2;
+	struct fixed_point term3;
+	unsigned int eff_rs_size_bytes;
+
+	term1 = FIX_PT(mc_settings_ptr->row_sorter_sz_bytes, 0, error);
+	term2 = fixed_point_mult(
+		fixed_point_div(
+			fixed_point_mult(
+				FIX_PT(2, 0, error),
+				FIX_PT(mc_settings_ptr->dram_width_bits,
+					0,
+					error),
+				error),
+			FIX_PT(8, 0, error),
+			error),
+		fixed_point_add(
+			emc_clk_mhz,
+			FIX_PT(50, 0, error),
+			error),
+		error);
+	term3 = fixed_point_mult(
+		fixed_point_mult(
+			fixed_point_sub(
+				fixed_point_mult(
+					mc_settings_ptr->max_drain_time_usec,
+					emc_clk_mhz,
+					error),
+				FIX_PT(mc_settings_ptr->stat_lat_snaparb_rs,
+					0,
+					error),
+				error),
+			FIX_PT(2, 0, error),
+			error),
+		fixed_point_mult(
+			fixed_point_div(
+				FIX_PT(mc_settings_ptr->dram_width_bits,
+					0,
+					error),
+				FIX_PT(8, 0, error),
+				error),
+			mc_settings_ptr->cons_mem_eff,
+			error),
+		error);
+	eff_rs_size_bytes = (unsigned int)
+		fixed_point_to_int(
+			fixed_point_min(
+				fixed_point_min(term1, term2, error),
+				term3,
+				error),
+			error);
+
+	return eff_rs_size_bytes;
+}
+
+static struct fixed_point calc_drain_time(
+	struct fixed_point emc_clk_mhz,
+	struct mc_settings_info *mc_settings_ptr,
+	unsigned int *error)
+{
+	unsigned int eff_rs_size_bytes;
+	struct fixed_point term1;
+	struct fixed_point drain_time_usec;
+
+	eff_rs_size_bytes =
+		calc_eff_rowsorter_sz(emc_clk_mhz, mc_settings_ptr, error);
+
+	term1 = fixed_point_div(
+		FIX_PT(mc_settings_ptr->dram_width_bits, 0, error),
+		FIX_PT(4, 0, error),
+		error);
+	drain_time_usec =
+		fixed_point_add(
+			fixed_point_div(
+				FIX_PT(eff_rs_size_bytes, 0, error),
+				fixed_point_mult(
+					fixed_point_mult(
+						emc_clk_mhz,
+						term1,
+						error
+					),
+					mc_settings_ptr->cons_mem_eff,
+					error
+				),
+			error
+			),
+			fixed_point_div(
+				FIX_PT(mc_settings_ptr->stat_lat_snaparb_rs,
+					0,
+					error),
+				emc_clk_mhz,
+				error),
+			error
+		);
+
+	return drain_time_usec;
+}
+
+static unsigned int get_init_la(
+	enum la_client_type client_type,
+	struct mc_settings_info *mc_settings_ptr,
+	unsigned int *error)
+{
+	unsigned int ret_la = 0;
+
+	switch (client_type) {
+	case TEGRA_LA_HUB_READ_CLIENT:
+		ret_la = 33; /*(min((1000/1066.5) * 1059, 7650) / 30)*/
+		break;
+	case TEGRA_LA_HUB_WRITE_CLIENT:
+		ret_la = 255;
+		break;
+	case TEGRA_LA_WCAM_WRITE_CLIENT:
+		ret_la = 40;
+		break;
+	case TEGRA_LA_CPU_READ_CLIENT:
+		ret_la = 4;
+		break;
+	case TEGRA_LA_CIFLL_WRITE_CLIENT:
+		ret_la = 1023;
+		break;
+	case TEGRA_LA_DISPLAY_READ_CLIENT:
+	{
+		struct fixed_point term1;
+		struct fixed_point term2;
+		struct fixed_point max_drain_time_usec;
+
+		max_drain_time_usec =
+			calc_drain_time(
+				FIX_PT(1066, 0x80000000, error) /* 1066.5 */,
+				mc_settings_ptr,
+				error);
+		term1 = fixed_point_min(
+			mc_settings_ptr->max_lat_all_usec,
+			max_drain_time_usec,
+			error);
+		term2 = fixed_point_div(
+			mc_settings_ptr->ns_per_tick,
+			FIX_PT(1000, 0, error),
+			error);
+		ret_la = (unsigned int)
+			fixed_point_ceil(
+				fixed_point_div(
+					term1,
+					term2,
+					error),
+				error); /* 18 */
+		break;
+	}
+	case TEGRA_LA_NVLRHP_READ_CLIENT:
+		ret_la = 4;
+		break;
+	case TEGRA_LA_GPU_READ_CLIENT:
+		ret_la = 31; /*(min((1000/1066.5) * 1019, 7650) / 30)*/
+		break;
+	case TEGRA_LA_NUM_CLIENT_TYPES:
+		ret_la = 0;
+		break;
+	default:
+		pr_err("%s: la_client_type %d not handled\n",
+			__func__, client_type);
+		(*error) |= 1;
+		WARN_ON(1);
+	}
+
+	return ret_la;
+}
+
+static void la_client_info_init(
+	struct la_client_info *entry,
+	struct mc_settings_info *mc_settings_ptr,
+	unsigned int reg_addr,
+	unsigned long mask,
+	unsigned long shift,
+	enum tegra_la_id id,
+	const char *name,
+	enum la_client_type client_type,
+	unsigned int *error)
+{
+	entry->reg_addr = reg_addr;
+	entry->mask = mask;
+	entry->shift = shift;
+	entry->id = id;
+	if (name != NULL) {
+		entry->name = (char *) kmalloc(strlen(name) + 1, GFP_KERNEL);
+		strcpy(entry->name, name);
+	}
+	entry->client_type = client_type;
+	entry->min_scaling_ratio = 0;
+	entry->la_ref_clk_mhz = 0;
+}
+
+static void la_info_array_init(
+	struct la_client_info *info_array,
+	int *gen_to_t19x_la_id,
+	int *t19x_to_gen_la_id,
+	int *t19x_la_kern_init,
+	struct mc_settings_info *mc_set,
+	unsigned int *error)
+{
+	int i;
+
+	for (i = 0; i < TEGRA_LA_MAX_ID; i++)
+		gen_to_t19x_la_id[i] = TEGRA_T19X_LA_MAX_ID;
+
+	for (i = 0; i < TEGRA_T19X_LA_MAX_ID; i++) {
+		t19x_to_gen_la_id[i] = TEGRA_LA_MAX_ID;
+		la_client_info_init(
+			&info_array[i],
+			mc_set,
+			0,
+			0,
+			0,
+			TEGRA_LA_MAX_ID,
+			NULL,
+			TEGRA_LA_NUM_CLIENT_TYPES,
+			error);
+	}
+
+	LA_T19X(AONDMA_0, 10 : 0, AONDMAR, HUB_READ, 0);
+	LA_T19X(AONDMA_0, 26 : 16, AONDMAW, HUB_WRITE, 0);
+	LA_T19X(AON_0, 10 : 0, AONR, HUB_READ, 0);
+	LA_T19X(AON_0, 26 : 16, AONW, HUB_WRITE, 0);
+	LA_T19X(APEDMA_0, 10 : 0, APEDMAR, HUB_READ, 0);
+	LA_T19X(APEDMA_0, 26 : 16, APEDMAW, HUB_WRITE, 0);
+	LA_T19X(APE_0, 10 : 0, APER, HUB_READ, 0);
+	LA_T19X(APE_0, 26 : 16, APEW, HUB_WRITE, 0);
+	LA_T19X(AXIAP_0, 10 : 0, AXIAPR, HUB_READ, 0);
+	LA_T19X(AXIAP_0, 26 : 16, AXIAPW, HUB_WRITE, 0);
+	LA_T19X(AXIS_0, 10 : 0, AXISR, HUB_READ, 0);
+	LA_T19X(AXIS_0, 26 : 16, AXISW, HUB_WRITE, 0);
+	LA_T19X(BPMPDMA_0, 10 : 0, BPMPDMAR, HUB_READ, 0);
+	LA_T19X(BPMPDMA_0, 26 : 16, BPMPDMAW, HUB_WRITE, 0);
+	LA_T19X(BPMP_0, 10 : 0, BPMPR, HUB_READ, 0);
+	LA_T19X(BPMP_0, 26 : 16, BPMPW, HUB_WRITE, 0);
+	LA_T19X(CIFLL_WR_0, 10 : 0, CIFLL_WR, CIFLL_WRITE, 1);
+	LA_T19X(DLA0_0, 26 : 16, DLA0FALRDB, HUB_READ, 0);
+	LA_T19X(DLA0_0, 10 : 0, DLA0RDA, HUB_READ, 0);
+	LA_T19X(DLA0_1, 26 : 16, DLA0FALWRB, HUB_WRITE, 0);
+	LA_T19X(DLA0_1, 10 : 0, DLA0WRA, HUB_WRITE, 0);
+	LA_T19X(DLA0_2, 10 : 0, DLA0RDA1, HUB_READ, 0);
+	LA_T19X(DLA0_2, 26 : 16, DLA1RDA1, HUB_READ, 0);
+	LA_T19X(DLA1_0, 26 : 16, DLA1FALRDB, HUB_READ, 0);
+	LA_T19X(DLA1_0, 10 : 0, DLA1RDA, HUB_READ, 0);
+	LA_T19X(DLA1_1, 26 : 16, DLA1FALWRB, HUB_WRITE, 0);
+	LA_T19X(DLA1_1, 10 : 0, DLA1WRA, HUB_WRITE, 0);
+	LA_T19X(EQOS_0, 10 : 0, EQOSR, HUB_READ, 0);
+	LA_T19X(EQOS_0, 26 : 16, EQOSW, HUB_WRITE, 0);
+	LA_T19X(ETR_0, 10 : 0, ETRR, HUB_READ, 0);
+	LA_T19X(ETR_0, 26 : 16, ETRW, HUB_WRITE, 0);
+	LA_T19X(HC_0, 10 : 0, HOST1XDMAR, HUB_READ, 0);
+	LA_T19X(HDA_0, 10 : 0, HDAR, HUB_READ, 0);
+	LA_T19X(HDA_0, 26 : 16, HDAW, HUB_WRITE, 0);
+	LA_T19X(ISP2_0, 26 : 16, ISPFALR, HUB_READ, 0);
+	LA_T19X(ISP2_0, 10 : 0, ISPRA, HUB_READ, 0);
+	LA_T19X(ISP2_1, 10 : 0, ISPWA, HUB_WRITE, 0);
+	LA_T19X(ISP2_1, 26 : 16, ISPWB, HUB_WRITE, 0);
+	LA_T19X(ISP3_0, 10 : 0, ISPFALW, HUB_WRITE, 0);
+	LA_T19X(ISP3_0, 26 : 16, ISPRA1, HUB_READ, 0);
+	LA_T19X(MIU0_0, 10 : 0, MIU0R, HUB_READ, 0);
+	LA_T19X(MIU0_0, 26 : 16, MIU0W, HUB_WRITE, 0);
+	LA_T19X(MIU1_0, 10 : 0, MIU1R, HUB_READ, 0);
+	LA_T19X(MIU1_0, 26 : 16, MIU1W, HUB_WRITE, 0);
+	LA_T19X(MIU2_0, 10 : 0, MIU2R, HUB_READ, 0);
+	LA_T19X(MIU2_0, 26 : 16, MIU2W, HUB_WRITE, 0);
+	LA_T19X(MIU3_0, 10 : 0, MIU3R, HUB_READ, 0);
+	LA_T19X(MIU3_0, 26 : 16, MIU3W, HUB_WRITE, 0);
+	LA_T19X(MIU4_0, 10 : 0, MIU4R, HUB_READ, 0);
+	LA_T19X(MIU4_0, 26 : 16, MIU4W, HUB_WRITE, 0);
+	LA_T19X(MIU5_0, 10 : 0, MIU5R, HUB_READ, 0);
+	LA_T19X(MIU5_0, 26 : 16, MIU5W, HUB_WRITE, 0);
+	LA_T19X(MIU6_0, 10 : 0, MIU6R, HUB_READ, 0);
+	LA_T19X(MIU6_0, 26 : 16, MIU6W, HUB_WRITE, 0);
+	LA_T19X(MIU7_0, 10 : 0, MIU7R, HUB_READ, 0);
+	LA_T19X(MIU7_0, 26 : 16, MIU7W, HUB_WRITE, 0);
+	LA_T19X(MPCORE_0, 10 : 0, MPCORER, CPU_READ, 0);
+	LA_T19X(MPCORE_0, 26 : 16, MPCOREW, HUB_WRITE, 0);
+	LA_T19X(NVDEC_0, 10 : 0, NVDECSRD, HUB_READ, 0);
+	LA_T19X(NVDEC_0, 26 : 16, NVDECSWR, HUB_WRITE, 0);
+	LA_T19X(NVDEC_1, 26 : 16, NVDEC1SRD, HUB_READ, 0);
+	LA_T19X(NVDEC_1, 10 : 0, NVDECSRD1, HUB_READ, 0);
+	LA_T19X(NVDEC_2, 10 : 0, NVDEC1SRD1, HUB_READ, 0);
+	LA_T19X(NVDEC_2, 26 : 16, NVDEC1SWR, HUB_WRITE, 0);
+	LA_T19X(NVDISPLAY_0, 10 : 0, NVDISPLAYR, DISPLAY_READ, 1);
+	LA_T19X(NVENC_0, 10 : 0, NVENCSRD, HUB_READ, 0);
+	LA_T19X(NVENC_0, 26 : 16, NVENCSWR, HUB_WRITE, 0);
+	LA_T19X(NVENC_1, 10 : 0, NVENC1SRD, HUB_READ, 0);
+	LA_T19X(NVENC_1, 26 : 16, NVENC1SWR, HUB_WRITE, 0);
+	LA_T19X(NVENC_2, 26 : 16, NVENC1SRD1, HUB_READ, 0);
+	LA_T19X(NVENC_2, 10 : 0, NVENCSRD1, HUB_READ, 0);
+	LA_T19X(NVJPG_0, 10 : 0, NVJPGSRD, HUB_READ, 0);
+	LA_T19X(NVJPG_0, 26 : 16, NVJPGSWR, HUB_WRITE, 0);
+	LA_T19X(PCIE0_0, 10 : 0, PCIE0R, HUB_READ, 0);
+	LA_T19X(PCIE0_0, 26 : 16, PCIE0W, HUB_WRITE, 0);
+	LA_T19X(PCIE1_0, 10 : 0, PCIE1R, HUB_READ, 0);
+	LA_T19X(PCIE1_0, 26 : 16, PCIE1W, HUB_WRITE, 0);
+	LA_T19X(PCIE2_0, 10 : 0, PCIE2AR, HUB_READ, 0);
+	LA_T19X(PCIE2_0, 26 : 16, PCIE2AW, HUB_WRITE, 0);
+	LA_T19X(PCIE3_0, 10 : 0, PCIE3R, HUB_READ, 0);
+	LA_T19X(PCIE3_0, 26 : 16, PCIE3W, HUB_WRITE, 0);
+	LA_T19X(PCIE4_0, 10 : 0, PCIE4R, HUB_READ, 0);
+	LA_T19X(PCIE4_0, 26 : 16, PCIE4W, HUB_WRITE, 0);
+	LA_T19X(PCIE5_0, 10 : 0, PCIE5R, HUB_READ, 0);
+	LA_T19X(PCIE5_0, 26 : 16, PCIE5W, HUB_WRITE, 0);
+	LA_T19X(PCIE5_1, 26 : 16, PCIE0R1, HUB_READ, 0);
+	LA_T19X(PCIE5_1, 10 : 0, PCIE5R1, HUB_READ, 0);
+	LA_T19X(PVA0_0, 10 : 0, PVA0RDA, HUB_READ, 0);
+	LA_T19X(PVA0_0, 26 : 16, PVA0RDB, HUB_READ, 0);
+	LA_T19X(PVA0_1, 10 : 0, PVA0RDC, HUB_READ, 0);
+	LA_T19X(PVA0_1, 26 : 16, PVA0WRA, HUB_WRITE, 0);
+	LA_T19X(PVA0_2, 10 : 0, PVA0WRB, HUB_WRITE, 0);
+	LA_T19X(PVA0_2, 26 : 16, PVA0WRC, HUB_WRITE, 0);
+	LA_T19X(PVA0_3, 10 : 0, PVA0RDA1, HUB_READ, 0);
+	LA_T19X(PVA0_3, 26 : 16, PVA0RDB1, HUB_READ, 0);
+	LA_T19X(PVA1_0, 10 : 0, PVA1RDA, HUB_READ, 0);
+	LA_T19X(PVA1_0, 26 : 16, PVA1RDB, HUB_READ, 0);
+	LA_T19X(PVA1_1, 10 : 0, PVA1RDC, HUB_READ, 0);
+	LA_T19X(PVA1_1, 26 : 16, PVA1WRA, HUB_WRITE, 0);
+	LA_T19X(PVA1_2, 10 : 0, PVA1WRB, HUB_WRITE, 0);
+	LA_T19X(PVA1_2, 26 : 16, PVA1WRC, HUB_WRITE, 0);
+	LA_T19X(PVA1_3, 10 : 0, PVA1RDA1, HUB_READ, 0);
+	LA_T19X(PVA1_3, 26 : 16, PVA1RDB1, HUB_READ, 0);
+	LA_T19X(RCEDMA_0, 10 : 0, RCEDMAR, HUB_READ, 0);
+	LA_T19X(RCEDMA_0, 26 : 16, RCEDMAW, HUB_WRITE, 0);
+	LA_T19X(RCE_0, 10 : 0, RCER, HUB_READ, 0);
+	LA_T19X(RCE_0, 26 : 16, RCEW, HUB_WRITE, 0);
+	LA_T19X(SATA_0, 10 : 0, SATAR, HUB_READ, 0);
+	LA_T19X(SATA_0, 26 : 16, SATAW, HUB_WRITE, 0);
+	LA_T19X(SCEDMA_0, 10 : 0, SCEDMAR, HUB_READ, 0);
+	LA_T19X(SCEDMA_0, 26 : 16, SCEDMAW, HUB_WRITE, 0);
+	LA_T19X(SCE_0, 10 : 0, SCER, HUB_READ, 0);
+	LA_T19X(SCE_0, 26 : 16, SCEW, HUB_WRITE, 0);
+	LA_T19X(SDMMCAB_0, 10 : 0, SDMMCRAB, HUB_READ, 0);
+	LA_T19X(SDMMCAB_0, 26 : 16, SDMMCWAB, HUB_WRITE, 0);
+	LA_T19X(SDMMCA_0, 10 : 0, SDMMCRA, HUB_READ, 0);
+	LA_T19X(SDMMCA_0, 26 : 16, SDMMCWA, HUB_WRITE, 0);
+	LA_T19X(SDMMC_0, 10 : 0, SDMMCR, HUB_READ, 0);
+	LA_T19X(SDMMC_0, 26 : 16, SDMMCW, HUB_WRITE, 0);
+	LA_T19X(SE_0, 10 : 0, SESRD, HUB_READ, 0);
+	LA_T19X(SE_0, 26 : 16, SESWR, HUB_WRITE, 0);
+	LA_T19X(TSECB_0, 10 : 0, TSECSRDB, HUB_READ, 0);
+	LA_T19X(TSECB_0, 26 : 16, TSECSWRB, HUB_WRITE, 0);
+	LA_T19X(TSEC_0, 10 : 0, TSECSRD, HUB_READ, 0);
+	LA_T19X(TSEC_0, 26 : 16, TSECSWR, HUB_WRITE, 0);
+	LA_T19X(UFSHC_0, 10 : 0, UFSHCR, HUB_READ, 0);
+	LA_T19X(UFSHC_0, 26 : 16, UFSHCW, HUB_WRITE, 0);
+	LA_T19X(VI2_0, 10 : 0, VIW, HUB_WRITE, 0);
+	LA_T19X(VIC_0, 10 : 0, VICSRD, HUB_READ, 0);
+	LA_T19X(VIC_0, 26 : 16, VICSWR, HUB_WRITE, 0);
+	LA_T19X(VIC_1, 10 : 0, VICSRD1, HUB_READ, 0);
+	LA_T19X(VIFAL_0, 10 : 0, VIFALR, HUB_READ, 0);
+	LA_T19X(VIFAL_0, 26 : 16, VIFALW, HUB_WRITE, 0);
+	LA_T19X(WCAM, 10 : 0, WCAM, WCAM_WRITE, 0);
+	LA_T19X(XUSB_0, 10 : 0, XUSB_HOSTR, HUB_READ, 0);
+	LA_T19X(XUSB_0, 26 : 16, XUSB_HOSTW, HUB_WRITE, 0);
+	LA_T19X(XUSB_1, 10 : 0, XUSB_DEVR, HUB_READ, 0);
+	LA_T19X(XUSB_1, 26 : 16, XUSB_DEVW, HUB_WRITE, 0);
+	GPU_LA_T19X(CIFLL_NVLRHP, 10 : 0, NVLRHP, NVLRHP_READ, 1);
+	GPU_LA_T19X(MSSNVLINK_DGPU, 10 : 0, DGPU, GPU_READ, 0);
+	GPU_LA_T19X(MSSNVLINK_IGPU, 10 : 0, IGPU, GPU_READ, 0);
+}
+
+static void init_max_gd(
+	struct mc_settings_info *mc_settings_ptr,
+	unsigned int *error
+)
+{
+	struct fixed_point max_gd = FIX_PT(0, 0, error);
+
+	if (mc_settings_ptr->dram_to_emc_freq_ratio == 2) {
+		/* 1.5 - pow(2.0, -1.0 * PTSA_reg_length_bits) */
+		switch (mc_settings_ptr->ptsa_reg_length_bits) {
+		case 8:
+			max_gd = fixed_point_sub(
+				FIX_PT(1, 0x80000000, error),
+				FIX_PT(0, 0x01000000, error),
+				error); /* 1.49609375 */
+			break;
+		case 12:
+			max_gd = fixed_point_sub(
+				FIX_PT(1, 0x80000000, error),
+				FIX_PT(0, 0x00100000, error),
+				error); /* 1.499755859*/
+			break;
+		default:
+			pr_err("%s: ptsa_reg_length_bits %d not handled\n",
+				__func__,
+				mc_settings_ptr->ptsa_reg_length_bits);
+			(*error) |= 1;
+			WARN_ON(1);
+		}
+	} else {
+		/* 2 - pow(2.0, -1.0 * PTSA_reg_length_bits) */
+		switch (mc_settings_ptr->ptsa_reg_length_bits) {
+		case 8:
+			max_gd = fixed_point_sub(
+				FIX_PT(2, 0, error),
+				FIX_PT(0, 0x01000000, error),
+				error); /* 1.99609375 */
+			break;
+		case 12:
+			max_gd = fixed_point_sub(
+				FIX_PT(2, 0, error),
+				FIX_PT(0, 0x00100000, error),
+				error); /* 1.999755859 */
+			break;
+		default:
+			pr_err("%s: ptsa_reg_length_bits %d not handled\n",
+				__func__,
+				mc_settings_ptr->ptsa_reg_length_bits);
+			(*error) |= 1;
+			WARN_ON(1);
+		}
+	}
+
+	mc_settings_ptr->max_gd =
+		fixed_point_mult(
+			mc_settings_ptr->grant_dec_multiplier,
+			max_gd,
+			error);
+}
+
+static void init_mcemc_same_freq_thr(
+	struct mc_settings_info *mc_settings_ptr,
+	unsigned int *error
+)
+{
+	struct fixed_point lowest_emc_freq;
+	lowest_emc_freq = fixed_point_div(
+		mc_settings_ptr->lowest_dram_freq,
+		FIX_PT(mc_settings_ptr->dram_to_emc_freq_ratio, 0, error),
+		error);
+
+	/* Want 2:1 all throughout, so set mc_emc_same_freq_thr to something */
+	/* below lowest_emc_freq, but don't make it zero. */
+	mc_settings_ptr->mc_emc_same_freq_thr =
+		fixed_point_max(
+			fixed_point_sub(
+				lowest_emc_freq,
+				FIX_PT(1, 0, error),
+				error
+				),
+			FIX_PT(0, 0x1999999A, error), /* 0.1 */
+			error
+			);
+}
+
+static void mc_settings_init(
+	enum tegra_dram_t dram_type,
+	struct mc_settings_info *mc_settings_ptr,
+	unsigned int *error)
+{
+	switch (dram_type) {
+	case TEGRA_LP4_4CH:
+		mc_settings_ptr->num_channels = 4;
+		mc_settings_ptr->bytes_per_dram_clk = 16;
+		mc_settings_ptr->hub_dda_div = FIX_PT(1, 0, error);
+		mc_settings_ptr->ring0_dda_div = FIX_PT(4, 0, error);
+		mc_settings_ptr->dram_to_emc_freq_ratio = 2;
+		mc_settings_ptr->highest_dram_freq = FIX_PT(2132, 0, error);
+		mc_settings_ptr->lowest_dram_freq = FIX_PT(25, 0, error);
+		break;
+	case TEGRA_LP4_8CH:
+	case TEGRA_LP4X_8CH:
+		mc_settings_ptr->num_channels = 8;
+		mc_settings_ptr->bytes_per_dram_clk = 32;
+		mc_settings_ptr->hub_dda_div = FIX_PT(1, 0, error);
+		mc_settings_ptr->ring0_dda_div = FIX_PT(4, 0, error);
+		mc_settings_ptr->dram_to_emc_freq_ratio = 2;
+		mc_settings_ptr->highest_dram_freq = FIX_PT(2132, 0, error);
+		mc_settings_ptr->lowest_dram_freq = FIX_PT(25, 0, error);
+		break;
+	case TEGRA_LP4_16CH:
+	case TEGRA_LP4X_16CH:
+		mc_settings_ptr->num_channels = 16;
+		mc_settings_ptr->bytes_per_dram_clk = 64;
+		mc_settings_ptr->hub_dda_div = FIX_PT(1, 0, error);
+		mc_settings_ptr->ring0_dda_div = FIX_PT(4, 0, error);
+		mc_settings_ptr->dram_to_emc_freq_ratio = 2;
+		mc_settings_ptr->highest_dram_freq = FIX_PT(2132, 0, error);
+		mc_settings_ptr->lowest_dram_freq = FIX_PT(25, 0, error);
+		break;
+	default:
+		pr_err("%s: tegra_dram_t %d not handled\n",
+			__func__, dram_type);
+		(*error) |= 1;
+		WARN_ON(1);
+	}
+
+	mc_settings_ptr->dram_type = dram_type;
+	mc_settings_ptr->mccif_buf_sz_bytes = 64 * 484;
+	mc_settings_ptr->stat_lat_minus_snaparb2rs = 230;
+	mc_settings_ptr->exp_time = 206;
+	mc_settings_ptr->dram_width_bits = EMC_FBIO_DATA_WIDTH *
+		mc_settings_ptr->num_channels;
+	mc_settings_ptr->cons_mem_eff = FIX_PT(0, 0x80000000, error); /* 0.5 */
+	mc_settings_ptr->stat_lat_snaparb_rs = 54;
+	mc_settings_ptr->row_sorter_sz_bytes =
+		mc_settings_ptr->num_channels *
+		64 * (NV_MC_EMEM_NUM_SLOTS + 1);
+	mc_settings_ptr->max_drain_time_usec = FIX_PT(10, 0, error);
+	mc_settings_ptr->ns_per_tick = FIX_PT(30, 0, error);
+	mc_settings_ptr->max_lat_all_usec =
+		FIX_PT(7, 0xA6666666, error); /* 7.65 */
+	mc_settings_ptr->ring2_dda_rate = 1;
+	mc_settings_ptr->ring2_dda_en = 1;
+	mc_settings_ptr->siso_hp_en = 1;
+	mc_settings_ptr->vi_always_hp = 1;
+	mc_settings_ptr->disp_catchup_factor =
+		FIX_PT(1, 0x1999999A, error); /* 1.1 */
+	mc_settings_ptr->dda_bw_margin = FIX_PT(1, 0x33333333, error); /* 1.2 */
+	mc_settings_ptr->two_stge_ecc_iso_dda_bw_margin =
+		FIX_PT(1, 0x66666666, error); /* 1.4 */
+	mc_settings_ptr->ptsa_reg_length_bits = NV_MC_EMEM_PTSA_RATE_WIDTH;
+	mc_settings_ptr->grant_dec_multiplier = FIX_PT(1, 0, error);
+	mc_settings_ptr->set_perf_regs = 1;
+	mc_settings_ptr->hub2mcf_dda = 2; /* AUTO */
+	mc_settings_ptr->igpu_mcf_dda = 2; /* AUTO */
+	mc_settings_ptr->tsa_arb_fix = 1;
+	mc_settings_ptr->iso_holdoff_override = 1;
+	mc_settings_ptr->pcfifo_interlock = 1;
+	mc_settings_ptr->en_ordering = 1;
+	mc_settings_ptr->set_order_id = 1;
+	mc_settings_ptr->hp_cpu_throttle_en = 0;
+	mc_settings_ptr->override_isoptc_hub_mapping = 1;
+	mc_settings_ptr->override_hub_vcarb_type = 1;
+	mc_settings_ptr->override_hub_vcarb_wt = 1;
+	mc_settings_ptr->override_iso_tbu_cchk_en_ctrl = 1;
+	mc_settings_ptr->hub2mcf_dda_rate = 1638; /* 80% */
+	mc_settings_ptr->hub2mcf_dda_max = 32;
+	mc_settings_ptr->mssnvlink_mcf_igpu_dda_rate = 1740; /* 85% */
+	mc_settings_ptr->mssnvlink_mcf_igpu_dda_max = 32;
+	mc_settings_ptr->isoptc_hub_num = 0;
+	mc_settings_ptr->hub_vcarb_type = 3;
+	mc_settings_ptr->hub_vcarb_niso_wt = 1;
+	mc_settings_ptr->hub_vcarb_siso_wt = 4;
+	mc_settings_ptr->hub_vcarb_iso_wt = 31;
+	mc_settings_ptr->iso_tbu_cchk_en_ctrl = 1; /* disable hp iso tbu chk */
+	mc_settings_ptr->freq_range.lo_freq = FIX_PT(0, 0, error);
+	mc_settings_ptr->freq_range.hi_freq = FIX_PT(0, 0, error);
+	mc_settings_ptr->freq_range.lo_gd = FIX_PT(0, 0, error);
+	mc_settings_ptr->freq_range.hi_gd = FIX_PT(0, 0, error);
+	mc_settings_ptr->freq_range.emc_mc_ratio = 0;
+	mc_settings_ptr->freq_range.valid = 0;
+	init_max_gd(mc_settings_ptr, error);
+	init_mcemc_same_freq_thr(mc_settings_ptr, error);
+}
+
+static void mc_settings_override(
+	struct mc_settings_info info,
+	struct mc_settings_info *mc_settings_ptr)
+{
+	(*mc_settings_ptr) = info;
+}
+
+static void get_disp_rd_lat_allow_given_disp_bw(
+	struct mc_settings_info *mc_settings_ptr,
+	struct fixed_point emc_freq_mhz,
+	struct fixed_point dis_bw, /* MBps */
+	int *disp_la,
+	struct fixed_point *drain_time_usec,
+	struct fixed_point *la_bw_up_bnd_usec,
+	unsigned int *error)
+{
+	struct fixed_point mccif_buf_sz_bytes;
+	struct fixed_point lat_allow_usec;
+	struct fixed_point lat_allow_ticks;
+
+	struct fixed_point term1;
+
+	mccif_buf_sz_bytes =
+		FIX_PT(mc_settings_ptr->mccif_buf_sz_bytes, 0, error);
+	term1 = fixed_point_add(
+		FIX_PT(mc_settings_ptr->stat_lat_minus_snaparb2rs, 0, error),
+		FIX_PT(mc_settings_ptr->exp_time, 0, error),
+		error);
+	(*la_bw_up_bnd_usec) =
+		fixed_point_sub(
+			fixed_point_div(
+				mccif_buf_sz_bytes,
+				dis_bw,
+				error
+			),
+			fixed_point_div(
+				term1,
+				emc_freq_mhz,
+				error
+			),
+			error
+		);
+	lat_allow_usec = fixed_point_min((*la_bw_up_bnd_usec),
+		mc_settings_ptr->max_lat_all_usec,
+		error);
+
+	lat_allow_ticks =
+		fixed_point_div(lat_allow_usec,
+			fixed_point_div(
+				mc_settings_ptr->ns_per_tick,
+				FIX_PT(1000, 0, error),
+				error),
+			error
+		);
+
+	if (fixed_point_gt(lat_allow_ticks, FIX_PT(255, 0, error), error))
+		lat_allow_ticks = FIX_PT(255, 0, error);
+
+	(*disp_la) = fixed_point_ceil(lat_allow_ticks, error);
+	(*drain_time_usec) =
+		calc_drain_time(emc_freq_mhz, mc_settings_ptr, error);
+}
+
+static void dda_info_init(
+	struct dda_info *entry,
+	const char *name,
+	int ring,
+	enum tegra_iso_t iso_type,
+	unsigned int rate_reg_addr,
+	unsigned long mask,
+	struct fixed_point dda_div,
+	unsigned int *error
+)
+{
+	strcpy(entry->name, name);
+	entry->iso_type = iso_type;
+	entry->ring = ring;
+	entry->rate_reg_addr = rate_reg_addr;
+	entry->mask = mask;
+	entry->dda_div = dda_div;
+
+	entry->min = -1;
+	entry->max = -1;
+	entry->rate = 0;
+	entry->frac = FIX_PT(0, 0, error);
+	entry->frac_valid = 0;
+	entry->bw = FIX_PT(0, 0, error);
+}
+
+#define INIT_DDA(info_array, NAME, RING, ISO_TYPE, DDA_DIV) \
+	dda_info_init( \
+		&info_array[TEGRA_DDA_##NAME##_ID], \
+		__stringify(TEGRA_DDA_##NAME##_ID), \
+		RING, \
+		ISO_TYPE, \
+		MC_##NAME##_PTSA_RATE_0, \
+		MC_##NAME##_PTSA_RATE_0_PTSA_RATE_##NAME##_DEFAULT_MASK, \
+		DDA_DIV, error)
+
+
+static void dda_info_array_init(
+	struct dda_info *inf_arr,
+	int info_array_size,
+	struct mc_settings_info *mc_set,
+	unsigned int *error
+)
+{
+	int i;
+
+	for (i = 0; i < info_array_size; i++) {
+		dda_info_init(
+			&inf_arr[i],
+			"",
+			-1,
+			TEGRA_NISO,
+			0,
+			0xffff,
+			FIX_PT(0, 0, error),
+			error);
+	}
+
+	INIT_DDA(inf_arr, AONPC,        1, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, APB,          2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, AUD,          1, TEGRA_HISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, BPMPPC,       1, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, CIFLL_ISO,    0, TEGRA_HISO, mc_set->ring0_dda_div);
+	INIT_DDA(inf_arr, CIFLL_SISO,   0, TEGRA_SISO, mc_set->ring0_dda_div);
+	INIT_DDA(inf_arr, CIFLL_NISO,   0, TEGRA_NISO, mc_set->ring0_dda_div);
+	INIT_DDA(inf_arr, CIFLL_RING0X, 0, TEGRA_NISO, mc_set->ring0_dda_div);
+	INIT_DDA(inf_arr, DIS,          1, TEGRA_HISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, DLA0FALPC,    2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, DLA0XA,       2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, DLA0XA2,      2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, DLA0XA3,      2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, DLA1FALPC,    2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, DLA1XA,       2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, DLA1XA2,      2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, DLA1XA3,      2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, EQOSPC,       1, TEGRA_HISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, HDAPC,        1, TEGRA_HISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, HOST,         2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, ISP,          2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, ISP2PC,       2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, ISPPC,        2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, JPG,          2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, MIU0,         2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, MIU1,         2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, MIU2,         2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, MIU3,         2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, MIU4,         2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, MIU5,         2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, MIU6,         2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, MIU7,         2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, MLL_MPCORER,  0, TEGRA_NISO, mc_set->ring0_dda_div);
+	INIT_DDA(inf_arr, MSE,          2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, MSE2,         2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, MSE3,         2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, MSEA,         2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, MSEB,         2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, MSEB1,        2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, NIC,          2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, NVD,          2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, NVD2,         2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, NVD3,         2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, NVD4,         2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, NVD5,         2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, NVD6,         2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PCIE0X,       2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PCIE0X2,      2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PCIE0XA,      2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PCIE1X,       2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PCIE1XA,      2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PCIE4X,       2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PCIE4XA,      2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PCIE5X,       2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PCIE5X2,      2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PCIE5XA,      2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PVA0XA,       2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PVA0XA2,      2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PVA0XA3,      2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PVA0XB,       2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PVA0XB2,      2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PVA0XB3,      2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PVA0XC,       2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PVA1XA,       2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PVA1XA2,      2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PVA1XA3,      2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PVA1XB,       2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PVA1XB2,      2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PVA1XB3,      2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, PVA1XC,       2, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, RCEPC,        1, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, RING2,        1, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, SAX,          2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, SCEPC,        1, TEGRA_SISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, SD,           2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, SDM,          2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, SMMU_SMMU,    0, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, UFSHCPC,      2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, UFSHCPC2,     2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, USBD,         2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, USBD2,        2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, USBX,         2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, USBX2,        2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, VE,           1, TEGRA_HISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, VICPC,        2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, VICPC2,       2, TEGRA_NISO, mc_set->hub_dda_div);
+	INIT_DDA(inf_arr, VICPC3,       2, TEGRA_NISO, mc_set->hub_dda_div);
+}
+
+#undef INIT_DDA
+
+static void update_new_dda_minmax_kern_init(
+	struct dda_info *dda_info_array,
+	struct mc_settings_info *mc_settings_ptr,
+	unsigned int *error
+) {
+	int clientid;
+
+	for (clientid = 0; clientid < TEGRA_DDA_MAX_ID; clientid++) {
+		if (!mc_settings_ptr->ring2_dda_en &&
+			dda_info_array[clientid].ring == 2) {
+			dda_info_array[clientid].min =
+				dda_info_array[clientid].max = -1;
+		} else if (((mc_settings_ptr->vi_always_hp) &&
+					(clientid == TEGRA_DDA_VE_ID)) ||
+				 (clientid == TEGRA_DDA_CIFLL_SISO_ID) ||
+				 (clientid == TEGRA_DDA_SMMU_SMMU_ID)
+			) { /* VI always high priority since self limiting */
+			dda_info_array[clientid].min = 1;
+			dda_info_array[clientid].max = 1;
+		} else if (dda_info_array[clientid].iso_type == TEGRA_HISO ||
+			(dda_info_array[clientid].iso_type == TEGRA_SISO &&
+				!mc_settings_ptr->siso_hp_en &&
+				dda_info_array[clientid].ring == 2) ||
+			(clientid == TEGRA_DDA_CIFLL_ISO_ID)
+			){
+			int max_max = (1 << NV_MC_EMEM_PTSA_MINMAX_WIDTH) - 1;
+			dda_info_array[clientid].min = -5;
+			dda_info_array[clientid].max = max_max;
+		} else if (dda_info_array[clientid].iso_type == TEGRA_SISO &&
+			mc_settings_ptr->siso_hp_en &&
+			dda_info_array[clientid].ring == 2) {
+			dda_info_array[clientid].min =
+				dda_info_array[clientid].max = 1;
+		} else if ((
+			(dda_info_array[clientid].iso_type == TEGRA_NISO) ||
+			(dda_info_array[clientid].iso_type == TEGRA_SISO &&
+			dda_info_array[clientid].ring == 1) ||
+			(clientid == TEGRA_DDA_RING2_ID) ||
+			(clientid == TEGRA_DDA_CIFLL_NISO_ID) ||
+			(clientid == TEGRA_DDA_CIFLL_RING0X_ID)
+			)
+			&& (clientid != TEGRA_DDA_MLL_MPCORER_ID)) {
+			dda_info_array[clientid].min = -2;
+			dda_info_array[clientid].max = 0;
+		} else if (clientid != TEGRA_DDA_MLL_MPCORER_ID) {
+			pr_err("%s: ", __func__);
+			pr_err("clientid != TEGRA_DDA_MLL_MPCORER_ID\n");
+			(*error) |= 1;
+			WARN_ON(1);
+		}
+	}
+}
+
+static void update_new_dda_rate_frac_kern_init(
+	struct dda_info *dda_info_array,
+	struct mc_settings_info *mc_settings_ptr,
+	unsigned int *error
+)
+{
+	int clientid;
+
+	for (clientid = 0; clientid < TEGRA_DDA_MAX_ID; clientid++) {
+		enum tegra_iso_t iso_type = dda_info_array[clientid].iso_type;
+		unsigned int ring = dda_info_array[clientid].ring;
+		int iso_or_ring2_siso;
+		int ring2_hp_siso;
+
+		iso_or_ring2_siso = ((iso_type == TEGRA_HISO) ||
+			((iso_type == TEGRA_SISO) &&
+			!mc_settings_ptr->siso_hp_en &&
+			(ring == 2))) ? 1 : 0;
+		ring2_hp_siso = ((iso_type == TEGRA_SISO) &&
+			mc_settings_ptr->siso_hp_en &&
+			(ring == 2)) ? 1 : 0;
+
+		if (!mc_settings_ptr->ring2_dda_en && (ring == 2)) {
+			dda_info_array[clientid].rate = 0;
+			dda_info_array[clientid].frac_valid = 0;
+		} else if (!iso_or_ring2_siso) {
+			if (ring2_hp_siso) {
+				/*ring2 SISO client and always hp SISO */
+				dda_info_array[clientid].rate = 0;
+				dda_info_array[clientid].frac_valid = 0;
+			} else if (clientid != TEGRA_DDA_MLL_MPCORER_ID) {
+				if (clientid != TEGRA_DDA_SMMU_SMMU_ID) {
+					/* all other DDAs */
+					dda_info_array[clientid].rate = 1;
+					dda_info_array[clientid].frac_valid = 0;
+				}
+			}
+		} else if (clientid == TEGRA_DDA_EQOSPC_ID) {
+			struct fixed_point iso_adj_bw;
+
+			iso_adj_bw = fixed_point_mult(
+				FIX_PT(250, 0, error),
+				mc_settings_ptr->two_stge_ecc_iso_dda_bw_margin,
+				error);
+			dda_info_array[clientid].frac =
+				bw2fraction(mc_settings_ptr, iso_adj_bw, error);
+			dda_info_array[clientid].frac_valid = 1;
+			dda_info_array[clientid].rate =
+			fraction2dda(
+				dda_info_array[clientid].frac,
+				dda_info_array[clientid].dda_div,
+				dda_info_array[clientid].mask,
+				(dda_info_array[clientid].iso_type !=
+					TEGRA_NISO),
+				error);
+		}
+	}
+
+	/* Set the DDA value of ring2 to epsilon*/
+	dda_info_array[TEGRA_DDA_RING2_ID].rate =
+		mc_settings_ptr->ring2_dda_rate;
+
+	/* Ring1 DDA */
+	dda_info_array[TEGRA_DDA_CIFLL_SISO_ID].rate = 0;
+	dda_info_array[TEGRA_DDA_CIFLL_NISO_ID].rate = 1;
+	dda_info_array[TEGRA_DDA_CIFLL_RING0X_ID].rate = 1;
+}
+
+static enum tegra_dda_id convert_la2dda_id_for_dyn_ptsa(
+	enum tegra_la_id la_id,
+	unsigned int *error)
+{
+	enum tegra_dda_id ret_dda_id = TEGRA_DDA_MAX_ID;
+
+	switch (la_id) {
+	case TEGRA_LA_APEDMAR:
+	case TEGRA_LA_APEDMAW:
+	case TEGRA_LA_APER:
+	case TEGRA_LA_APEW:
+		ret_dda_id = TEGRA_DDA_AUD_ID;
+		break;
+	case TEGRA_LA_EQOSR:
+	case TEGRA_LA_EQOSW:
+		ret_dda_id = TEGRA_DDA_EQOSPC_ID;
+		break;
+	case TEGRA_LA_HDAR:
+	case TEGRA_LA_HDAW:
+		ret_dda_id = TEGRA_DDA_HDAPC_ID;
+		break;
+	case TEGRA_LA_NVDISPLAYR:
+		ret_dda_id = TEGRA_DDA_DIS_ID;
+		break;
+	case TEGRA_LA_VIW:
+	case TEGRA_LA_VIFALR:
+	case TEGRA_LA_VIFALW:
+		ret_dda_id = TEGRA_DDA_VE_ID;
+		break;
+	default:
+	{
+		pr_err("%s: tegra_la_id %d not handled\n",
+			__func__, la_id);
+		(*error) |= 1;
+		WARN_ON(1);
+	}
+	}
+
+	return ret_dda_id;
+}
+
+/*
+  setupFreqRanges()
+  ====================================================================
+  This function is used to initialize the frequency ranges based on which DDA
+  programming is done.
+  ====================================================================
+*/
+static void setup_freq_ranges(
+	struct mc_settings_info *mc_settings_ptr,
+	unsigned int *error
+)
+{
+	struct fixed_point comparison_freq_thr_to_use;
+	struct fixed_point lo_freq;
+
+	/*if we are in LP4, then DRAM:EMC is 2:1 so to make the comparison */
+	/* below we need to use double MCEMCsameFreqThr */
+	comparison_freq_thr_to_use =
+		fixed_point_mult(
+			mc_settings_ptr->mc_emc_same_freq_thr,
+			FIX_PT(mc_settings_ptr->dram_to_emc_freq_ratio,
+				0,
+				error),
+			error
+			);
+
+	mc_settings_ptr->freq_range.lo_freq =
+		mc_settings_ptr->lowest_dram_freq;
+	mc_settings_ptr->freq_range.hi_freq =
+		mc_settings_ptr->highest_dram_freq;
+	mc_settings_ptr->freq_range.hi_gd = mc_settings_ptr->max_gd;
+	lo_freq = fixed_point_lt(
+		comparison_freq_thr_to_use,
+		mc_settings_ptr->lowest_dram_freq,
+		error
+		) ? fixed_point_div(
+			mc_settings_ptr->lowest_dram_freq,
+			FIX_PT(2, 0, error),
+			error
+			) : mc_settings_ptr->lowest_dram_freq;
+	mc_settings_ptr->freq_range.lo_gd =
+		fixed_point_mult(
+			mc_settings_ptr->max_gd,
+			fixed_point_div(
+				lo_freq,
+				fixed_point_div(
+					mc_settings_ptr->highest_dram_freq,
+					FIX_PT(2, 0, error),
+					error
+					),
+				error
+				),
+			error
+			);
+	mc_settings_ptr->freq_range.valid = 1;
+}
+
+static int get_bytes_per_dram_clk(
+	enum tegra_dram_t dram_type,
+	unsigned int *error)
+{
+	int bytes_per_dram_clk = 0;
+
+	switch (dram_type) {
+	case TEGRA_DDR3_1CH:
+	case TEGRA_LP3_1CH:
+	case TEGRA_LP4_2CH:
+		bytes_per_dram_clk = 16;
+		break;
+	case TEGRA_DDR3_2CH:
+	case TEGRA_LP3_2CH:
+	case TEGRA_LP4_4CH:
+		bytes_per_dram_clk = 16;
+		break;
+	case TEGRA_LP4_8CH:
+	case TEGRA_LP4X_8CH:
+		bytes_per_dram_clk = 32;
+		break;
+	case TEGRA_LP4_16CH:
+	case TEGRA_LP4X_16CH:
+		bytes_per_dram_clk = 64;
+		break;
+	default:
+	{
+		pr_err("%s: tegra_dram_t %d not handled\n",
+			__func__, dram_type);
+		(*error) |= 1;
+		WARN_ON(1);
+	}
+	}
+
+	return bytes_per_dram_clk;
+}
+
+static struct fixed_point bw2fraction(
+	struct mc_settings_info *mc_settings_ptr,
+	struct fixed_point bw_mbps,
+	unsigned int *error
+)
+{
+	struct fixed_point bw_at_lo_freq_mbps;
+	if (mc_settings_ptr->freq_range.valid != 1) {
+		pr_err("%s: freq_range.valid not 1, but %d\n",
+			__func__, mc_settings_ptr->freq_range.valid);
+		(*error) |= 1;
+		WARN_ON(1);
+	}
+
+	bw_at_lo_freq_mbps =
+		fixed_point_mult(
+			mc_settings_ptr->freq_range.lo_freq,
+			FIX_PT(
+				get_bytes_per_dram_clk(
+					mc_settings_ptr->dram_type,
+					error),
+			0,
+			error),
+			error
+			);
+	return fixed_point_mult(
+		fixed_point_div(
+			bw_mbps,
+			bw_at_lo_freq_mbps,
+			error),
+		mc_settings_ptr->freq_range.lo_gd,
+		error
+		);
+}
+
+/*
+  Method fraction2dda()
+  =================================================================
+  Convert a floating point fraction into a DDA value
+  =================================================================
+*/
+static unsigned int fraction2dda(
+	struct fixed_point fraction,
+	struct fixed_point div,
+	unsigned int mask,
+	int round_up_or_to_nearest,
+	unsigned int *error)
+{
+	/* round_up_or_to_nearest determines whether the final calculated
+	 * DDA rate is to be rounded up or to nearest. Using this input
+	 * to the function we can enable rounding to nearest for NISO client
+	 * DDA rates. Rounding up for all other cases to be conservative.
+	 */
+	int i;
+	unsigned int dda = 0;
+	struct fixed_point f = fixed_point_div(fraction, div, error);
+
+	for (i = 0; i < NV_MC_EMEM_PTSA_RATE_WIDTH; i++) {
+		struct fixed_point r;
+		f = fixed_point_mult(f, FIX_PT(2, 0, error), error);
+		r = FIX_PT(fixed_point_to_int(f, error), 0, error);
+		dda = (dda << 1) | ((unsigned int)fixed_point_to_int(r, error));
+		f = fixed_point_sub(f, r, error);
+	}
+	if (fixed_point_gt(f, FIX_PT(0, 0, error), error)) {
+		/* Do not round up if the calculated dda is at the mask
+		 * value already, it will overflow
+		 */
+		if (dda != mask) {
+			if (round_up_or_to_nearest == 1 ||
+				fixed_point_goet(f,
+					FIX_PT(0, 0x80000000, error) /* 0.5 */,
+					error)
+				|| dda == 0) {
+				dda++; /* to round up dda value */
+			}
+		}
+	}
+
+	return dda;
+}
+
+static void update_new_dda_rate_frac_use_case(
+	struct dda_info *dda_info_array,
+	struct mc_settings_info *mc_settings_ptr,
+	int clientid,
+	struct fixed_point bw_mbps,
+	unsigned int *error
+)
+{
+	dda_info_array[clientid].frac =
+		bw2fraction(mc_settings_ptr, bw_mbps, error);
+	dda_info_array[clientid].frac_valid = 1;
+	dda_info_array[clientid].rate =
+		fraction2dda(
+			dda_info_array[clientid].frac,
+			dda_info_array[clientid].dda_div,
+			dda_info_array[clientid].mask,
+			(dda_info_array[clientid].iso_type != TEGRA_NISO),
+			error);
+}
+
+static void reg_info_init(
+	struct reg_info *entry,
+	const char *name,
+	unsigned int offset,
+	int dirty
+)
+{
+	strcpy(entry->name, name);
+	entry->offset = offset;
+	entry->dirty = dirty;
+
+	entry->val = 0;
+}
+
+#define INIT_REG_INFO(info_array, NAME) \
+	reg_info_init( \
+		&info_array[TEGRA_##NAME##_ID], \
+		__stringify(NAME), \
+		NAME##_0, \
+		0)
+
+static void mc_reg_info_array_init(
+	struct reg_info *inf_arr
+)
+{
+	int i;
+
+	for (i = 0; i < TEGRA_KERN_INIT_MC_MAX_ID; i++) {
+		reg_info_init(
+			&inf_arr[i],
+			"",
+			0,
+			0);
+	}
+
+	INIT_REG_INFO(inf_arr, MC_HUB2MCF_REQ_DDA_ENABLE);
+	INIT_REG_INFO(inf_arr, MC_HUB_HUB2MCF_REQ_DDA_RATE);
+	INIT_REG_INFO(inf_arr, MC_HUBORD_HUB2MCF_REQ_DDA_RATE);
+	INIT_REG_INFO(inf_arr, MC_HUBINT_HUB2MCF_REQ_DDA_RATE);
+	INIT_REG_INFO(inf_arr, MC_HUB_HUB2MCF_REQ_DDA_MAX);
+	INIT_REG_INFO(inf_arr, MC_HUBORD_HUB2MCF_REQ_DDA_MAX);
+	INIT_REG_INFO(inf_arr, MC_HUBINT_HUB2MCF_REQ_DDA_MAX);
+	INIT_REG_INFO(inf_arr, MC_CIFLL_NVLRHP_LATENCY_ALLOWANCE);
+	INIT_REG_INFO(inf_arr, MC_CONFIG_TSA_SINGLE_ARB_ENABLE);
+	INIT_REG_INFO(inf_arr, MC_EMEM_ARB_OVERRIDE);
+	INIT_REG_INFO(inf_arr, MC_PCFIFO_CLIENT_CONFIG0);
+	INIT_REG_INFO(inf_arr, MC_PCFIFO_CLIENT_CONFIG1);
+	INIT_REG_INFO(inf_arr, MC_PCFIFO_CLIENT_CONFIG2);
+	INIT_REG_INFO(inf_arr, MC_PCFIFO_CLIENT_CONFIG3);
+	INIT_REG_INFO(inf_arr, MC_PCFIFO_CLIENT_CONFIG4);
+	INIT_REG_INFO(inf_arr, MC_PCFIFO_CLIENT_CONFIG5);
+	INIT_REG_INFO(inf_arr, MC_PCFIFO_CLIENT_CONFIG7);
+	INIT_REG_INFO(inf_arr, MC_PCFIFO_CLIENT_CONFIG2);
+	INIT_REG_INFO(inf_arr, MC_PCFIFO_CLIENT_CONFIG1);
+	INIT_REG_INFO(inf_arr, MC_TBU_CLIENT_STEERING_CONFIG_PCIE5W);
+	INIT_REG_INFO(inf_arr, MC_TBU_CLIENT_STEERING_CONFIG_PCIE0W);
+	INIT_REG_INFO(inf_arr, MC_TBU_CLIENT_STEERING_CONFIG_PCIE4W);
+	INIT_REG_INFO(inf_arr, MC_TBU_CLIENT_STEERING_CONFIG_XUSB_HOSTW);
+	INIT_REG_INFO(inf_arr, MC_TBU_CLIENT_STEERING_CONFIG_XUSB_DEVW);
+	INIT_REG_INFO(inf_arr, MC_TBU_CLIENT_STEERING_CONFIG_SATAW);
+	INIT_REG_INFO(inf_arr, MC_CLIENT_ORDER_ID_9);
+	INIT_REG_INFO(inf_arr, MC_CLIENT_ORDER_ID_28);
+	INIT_REG_INFO(inf_arr, MC_FREE_BANK_QUEUES);
+	INIT_REG_INFO(inf_arr, MC_MC_SMMU_PTC2H_REQ_MAPPING_OVERRIDE);
+	INIT_REG_INFO(inf_arr, MC_MC_SMMU_PTC2H_REQ_MAPPING);
+	INIT_REG_INFO(inf_arr, MC_HUB_VC_ARB_SEL);
+	INIT_REG_INFO(inf_arr, MC_MC_SMMU_ISO_TBU_CCHK_REQ_PRI_CTRL);
+}
+
+#define INIT_MSSNVLINK_REG_INFO(info_array, NAME) \
+	do { \
+		strcpy(reg_name, apert_name); \
+		strcat(reg_name, __stringify(_##NAME)); \
+		reg_info_init( \
+			&info_array[TEGRA_##NAME##_ID], \
+			reg_name, \
+			NAME##_0, \
+			0); \
+	} while (0)
+
+static void mssnvlink_reg_info_array_init(
+	struct reg_info *inf_arr,
+	const char *apert_name
+)
+{
+	int i;
+	char reg_name[MAX_TEGRA_MC_REG_NAME_SIZE];
+
+	for (i = 0; i < TEGRA_KERN_INIT_MSSNVLINK_MAX_ID; i++) {
+		reg_info_init(
+			&inf_arr[i],
+			"",
+			0,
+			0);
+	}
+
+	INIT_MSSNVLINK_REG_INFO(inf_arr, MSSNVLINK_MASTER_MCF_DDA);
+}
+
+static void all_reg_info_array_init(
+	struct reg_info *mc_inf_arr,
+	struct reg_info *mssnvl1_inf_arr,
+	struct reg_info *mssnvl2_inf_arr,
+	struct reg_info *mssnvl3_inf_arr,
+	struct reg_info *mssnvl4_inf_arr
+)
+{
+	mc_reg_info_array_init(
+	mc_inf_arr);
+	mssnvlink_reg_info_array_init(
+	mssnvl1_inf_arr,
+		"NV_ADDRESS_MAP_MSS_NVLINK_1_BASE");
+	mssnvlink_reg_info_array_init(
+	mssnvl2_inf_arr,
+		"NV_ADDRESS_MAP_MSS_NVLINK_2_BASE");
+	mssnvlink_reg_info_array_init(
+	mssnvl3_inf_arr,
+		"NV_ADDRESS_MAP_MSS_NVLINK_3_BASE");
+	mssnvlink_reg_info_array_init(
+	mssnvl4_inf_arr,
+		"NV_ADDRESS_MAP_MSS_NVLINK_4_BASE");
+}
+
+static void mcpcie_reg_info_array_init(
+	struct reg_info *inf_arr
+)
+{
+	int i;
+
+	for (i = 0; i < TEGRA_KERN_INIT_MCPCIE_MAX_ID; i++) {
+		reg_info_init(
+			&inf_arr[i],
+			"",
+			0,
+			0);
+	}
+
+	INIT_REG_INFO(inf_arr, MC_PCFIFO_CLIENT_CONFIG6);
+	INIT_REG_INFO(inf_arr, MC_TBU_CLIENT_STEERING_CONFIG_PCIE1W);
+	INIT_REG_INFO(inf_arr, MC_TBU_CLIENT_STEERING_CONFIG_PCIE2AW);
+	INIT_REG_INFO(inf_arr, MC_TBU_CLIENT_STEERING_CONFIG_PCIE3W);
+	INIT_REG_INFO(inf_arr, MC_CLIENT_ORDER_ID_27);
+}
+#undef INIT_REG_INFO
+
+static unsigned int reg_info_reg_rd(
+	struct reg_info *inf_arr,
+	unsigned int addr
+)
+{
+	return inf_arr[addr].val;
+}
+
+static void reg_info_reg_wr(
+	struct reg_info *inf_arr,
+	unsigned int addr,
+	unsigned int data
+)
+{
+	inf_arr[addr].val = data;
+	inf_arr[addr].dirty = 1;
+}
+
+static void write_mcf_dda_perf_regs_kern_init(
+	struct mc_settings_info *mc_settings_ptr,
+	struct reg_info *mc_inf_arr,
+	struct reg_info *mssnvl1_inf_arr,
+	struct reg_info *mssnvl2_inf_arr,
+	struct reg_info *mssnvl3_inf_arr,
+	struct reg_info *mssnvl4_inf_arr
+)
+{
+	unsigned int data;
+
+	if ((mc_settings_ptr->hub2mcf_dda == 1) ||
+	   ((mc_settings_ptr->hub2mcf_dda == 2) &&
+		((mc_settings_ptr->dram_type == TEGRA_LP4_16CH) ||
+		(mc_settings_ptr->dram_type == TEGRA_LP4X_16CH)))) {
+		data = reg_info_reg_rd(mc_inf_arr,
+			TEGRA_MC_HUB2MCF_REQ_DDA_ENABLE_ID);
+		data = NV_FLD_SET_DRF_DEF(MC,
+			HUB2MCF_REQ_DDA_ENABLE,
+			HUB_DDA_ENABLE,
+			ENABLED,
+			data);
+		data = NV_FLD_SET_DRF_DEF(MC,
+			HUB2MCF_REQ_DDA_ENABLE,
+			HUBORD_DDA_ENABLE,
+			ENABLED,
+			data);
+		data = NV_FLD_SET_DRF_DEF(MC,
+			HUB2MCF_REQ_DDA_ENABLE,
+			HUBINT_DDA_ENABLE,
+			ENABLED,
+			data);
+		reg_info_reg_wr(mc_inf_arr,
+			TEGRA_MC_HUB2MCF_REQ_DDA_ENABLE_ID,
+			data);
+
+#define WRITE_HUB2MCF_DDA(VAR_NAME, REG_NAME) \
+	do { \
+		reg_info_reg_wr(mc_inf_arr, \
+			TEGRA_MC_##REG_NAME##_HUB2MCF_REQ_DDA_RATE_ID, \
+			mc_settings_ptr->hub2mcf_dda_rate & \
+			MC_##REG_NAME##_HUB2MCF_REQ_DDA_RATE_0_## \
+			REG_NAME##_DDA_RATE_DEFAULT_MASK); \
+		reg_info_reg_wr(mc_inf_arr, \
+			TEGRA_MC_##REG_NAME##_HUB2MCF_REQ_DDA_MAX_ID, \
+			mc_settings_ptr->hub2mcf_dda_max & \
+			MC_##REG_NAME##_HUB2MCF_REQ_DDA_MAX_0_## \
+			REG_NAME##_DDA_MAX_DEFAULT_MASK); \
+	} while (0)
+
+		WRITE_HUB2MCF_DDA(hub, HUB);
+		WRITE_HUB2MCF_DDA(hubord, HUBORD);
+		WRITE_HUB2MCF_DDA(hubint, HUBINT);
+
+#undef WRITE_HUB2MCF_DDA
+	} else {
+		data = reg_info_reg_rd(
+			mc_inf_arr,
+			TEGRA_MC_HUB2MCF_REQ_DDA_ENABLE_ID);
+		data = NV_FLD_SET_DRF_DEF(
+			MC,
+			HUB2MCF_REQ_DDA_ENABLE,
+			HUB_DDA_ENABLE,
+			DISABLED,
+			data);
+		data = NV_FLD_SET_DRF_DEF(
+			MC,
+			HUB2MCF_REQ_DDA_ENABLE,
+			HUBORD_DDA_ENABLE,
+			DISABLED,
+			data);
+		data = NV_FLD_SET_DRF_DEF(
+			MC,
+			HUB2MCF_REQ_DDA_ENABLE,
+			HUBINT_DDA_ENABLE,
+			DISABLED,
+			data);
+		reg_info_reg_wr(
+			mc_inf_arr,
+			TEGRA_MC_HUB2MCF_REQ_DDA_ENABLE_ID,
+			data);
+	}
+
+	if ((mc_settings_ptr->igpu_mcf_dda == 1) ||
+	   ((mc_settings_ptr->igpu_mcf_dda == 2) &&
+		((mc_settings_ptr->dram_type == TEGRA_LP4_16CH) ||
+		(mc_settings_ptr->dram_type == TEGRA_LP4X_16CH)))) {
+#define WRITE_MSSNVLINK_MCF_DDA(NVL_NUM) \
+	do { \
+		data = reg_info_reg_rd( \
+			mssnvl##NVL_NUM##_inf_arr, \
+			TEGRA_MSSNVLINK_MASTER_MCF_DDA_ID); \
+		data = NV_FLD_SET_DRF_DEF( \
+			MSSNVLINK, \
+			MASTER_MCF_DDA, \
+			ENBL, \
+			ENABLE, \
+			data); \
+		data = NV_FLD_SET_DRF_NUM( \
+			MSSNVLINK, \
+			MASTER_MCF_DDA, \
+			RATE, \
+			mc_settings_ptr->mssnvlink_mcf_igpu_dda_rate, \
+			data); \
+		data = NV_FLD_SET_DRF_NUM( \
+			MSSNVLINK, \
+			MASTER_MCF_DDA, \
+			MAX, \
+			mc_settings_ptr->mssnvlink_mcf_igpu_dda_max, \
+			data); \
+		reg_info_reg_wr( \
+			mssnvl##NVL_NUM##_inf_arr, \
+			TEGRA_MSSNVLINK_MASTER_MCF_DDA_ID, \
+			data); \
+	} while (0)
+
+		WRITE_MSSNVLINK_MCF_DDA(1);
+		WRITE_MSSNVLINK_MCF_DDA(2);
+		WRITE_MSSNVLINK_MCF_DDA(3);
+		WRITE_MSSNVLINK_MCF_DDA(4);
+#undef WRITE_MSSNVLINK_MCF_DDA
+	} else {
+#define DISABLE_MSSNVLINK_MCF_DDA(NVL_NUM) \
+	do { \
+		data = reg_info_reg_rd( \
+			mssnvl##NVL_NUM##_inf_arr, \
+			TEGRA_MSSNVLINK_MASTER_MCF_DDA_ID); \
+		data = NV_FLD_SET_DRF_DEF( \
+			MSSNVLINK, \
+			MASTER_MCF_DDA, \
+			ENBL, \
+			DISABLE, \
+			data); \
+		reg_info_reg_wr( \
+			mssnvl##NVL_NUM##_inf_arr, \
+			TEGRA_MSSNVLINK_MASTER_MCF_DDA_ID, \
+			data); \
+	} while (0)
+
+		DISABLE_MSSNVLINK_MCF_DDA(1);
+		DISABLE_MSSNVLINK_MCF_DDA(2);
+		DISABLE_MSSNVLINK_MCF_DDA(3);
+		DISABLE_MSSNVLINK_MCF_DDA(4);
+#undef DISABLE_MSSNVLINK_MCF_DDA
+	}
+}
+
+static void disable_pcfifo_interlock(
+	struct reg_info *mc_inf_arr
+)
+{
+	unsigned int data = 0x0;
+#define DIS_PCFIFO_INT(cfg_num) \
+	reg_info_reg_wr(mc_inf_arr, \
+		TEGRA_MC_PCFIFO_CLIENT_CONFIG##cfg_num##_ID, \
+		data);
+
+	DIS_PCFIFO_INT(0);
+	DIS_PCFIFO_INT(1);
+	DIS_PCFIFO_INT(2);
+	DIS_PCFIFO_INT(3);
+	DIS_PCFIFO_INT(4);
+	DIS_PCFIFO_INT(5);
+	DIS_PCFIFO_INT(7);
+#undef DIS_PCFIFO_INT
+}
+
+static void wr_pcfifo_interlock_perf_regs(
+	struct reg_info *mc_inf_arr
+)
+{
+	unsigned int data;
+
+	data = 0;
+	data = NV_FLD_SET_DRF_DEF(
+		MC,
+		PCFIFO_CLIENT_CONFIG2,
+		PCFIFO_XUSB_DEVW_ORDERED_CLIENT,
+		ORDERED,
+		data);
+	reg_info_reg_wr(
+		mc_inf_arr,
+		TEGRA_MC_PCFIFO_CLIENT_CONFIG2_ID,
+		data);
+
+	data = 0;
+	data = NV_FLD_SET_DRF_DEF(
+		MC,
+		PCFIFO_CLIENT_CONFIG1,
+		PCFIFO_HDAW_ORDERED_CLIENT,
+		ORDERED,
+		data);
+	data = NV_FLD_SET_DRF_DEF(
+		MC,
+		PCFIFO_CLIENT_CONFIG1,
+		PCFIFO_SATAW_ORDERED_CLIENT,
+		ORDERED,
+		data);
+	reg_info_reg_wr(
+		mc_inf_arr,
+		TEGRA_MC_PCFIFO_CLIENT_CONFIG1_ID,
+		data);
+}
+
+static void wr_ord_perf_regs(
+	struct reg_info *mc_inf_arr
+)
+{
+	unsigned int data = 0;
+
+	/* Mapping ordered clients to different TBUs */
+
+	#define WRITE_TBU_CLNT_STEER(client_name, tbu_num) \
+	do { \
+		data = reg_info_reg_rd( \
+			mc_inf_arr, \
+			TEGRA_MC_TBU_CLIENT_STEERING_CONFIG_## \
+			client_name##_ID); \
+		data = NV_FLD_SET_DRF_NUM( \
+			MC, \
+			TBU_CLIENT_STEERING_CONFIG_##client_name, \
+			client_name##_SO_DEV_TBUID, \
+			tbu_num, \
+			data); \
+		reg_info_reg_wr( \
+			mc_inf_arr, \
+			TEGRA_MC_TBU_CLIENT_STEERING_CONFIG_## \
+				client_name##_ID, \
+			data); \
+	} while (0)
+
+	WRITE_TBU_CLNT_STEER(PCIE5W, 0x1);
+	WRITE_TBU_CLNT_STEER(PCIE0W, 0x2);
+	WRITE_TBU_CLNT_STEER(PCIE4W, 0x3);
+	WRITE_TBU_CLNT_STEER(XUSB_HOSTW, 0x3);
+	WRITE_TBU_CLNT_STEER(XUSB_DEVW, 0x0);
+	WRITE_TBU_CLNT_STEER(SATAW, 0x0);
+#undef WRITE_TBU_CLNT_STEER
+}
+
+static void wr_ord_id_perf_regs(
+	struct reg_info *mc_inf_arr
+)
+{
+	unsigned int data;
+
+	data = reg_info_reg_rd(mc_inf_arr,
+		TEGRA_MC_CLIENT_ORDER_ID_9_ID);
+	data = NV_FLD_SET_DRF_DEF(MC, CLIENT_ORDER_ID_9,
+		XUSB_HOSTW_ORDER_ID, ORDER_ID3, data);
+	reg_info_reg_wr(mc_inf_arr,
+		TEGRA_MC_CLIENT_ORDER_ID_9_ID, data);
+
+	data = reg_info_reg_rd(mc_inf_arr,
+		TEGRA_MC_CLIENT_ORDER_ID_28_ID);
+	data = NV_FLD_SET_DRF_DEF(MC, CLIENT_ORDER_ID_28,
+		PCIE4W_ORDER_ID, ORDER_ID3, data);
+	data = NV_FLD_SET_DRF_DEF(MC, CLIENT_ORDER_ID_28,
+		PCIE5W_ORDER_ID, ORDER_ID1, data);
+	reg_info_reg_wr(mc_inf_arr,
+		TEGRA_MC_CLIENT_ORDER_ID_28_ID, data);
+}
+
+static void write_perf_regs_kern_init(
+	struct mc_settings_info *mc_settings_ptr,
+	struct reg_info *mc_inf_arr,
+	struct reg_info *mssnvl1_inf_arr,
+	struct reg_info *mssnvl2_inf_arr,
+	struct reg_info *mssnvl3_inf_arr,
+	struct reg_info *mssnvl4_inf_arr
+)
+{
+	unsigned int data;
+
+	if (!mc_settings_ptr->set_perf_regs)
+		return;
+
+	write_mcf_dda_perf_regs_kern_init(
+		mc_settings_ptr,
+	mc_inf_arr,
+	mssnvl1_inf_arr,
+	mssnvl2_inf_arr,
+	mssnvl3_inf_arr,
+	mssnvl4_inf_arr
+		);
+
+	/* Setting GMMU misses to high priority [Bug#200288764] */
+	data = 0x4;
+	reg_info_reg_wr(mc_inf_arr,
+		TEGRA_MC_CIFLL_NVLRHP_LATENCY_ALLOWANCE_ID, data);
+
+	if (mc_settings_ptr->tsa_arb_fix) {
+		data = 0;
+		data = NV_FLD_SET_DRF_DEF(MC,
+			CONFIG_TSA_SINGLE_ARB_ENABLE,
+			SINGLE_ARB_ENABLE, ENABLE, data);
+		reg_info_reg_wr(mc_inf_arr,
+			TEGRA_MC_CONFIG_TSA_SINGLE_ARB_ENABLE_ID, data);
+	}
+
+	/* Setup ISO holdoff clients.
+	 * By default, ISO holdoff for DISPLAY is always "on".
+	 * ISO holdoff can be turned off completely by setting
+	 * the "override" bit.
+	 */
+	data = reg_info_reg_rd(mc_inf_arr, TEGRA_MC_EMEM_ARB_OVERRIDE_ID);
+	if (mc_settings_ptr->iso_holdoff_override) {
+		data = NV_FLD_SET_DRF_DEF(MC, EMEM_ARB_OVERRIDE,
+			TS2AA_HOLDOFF_OVERRIDE, ENABLE, data);
+	} else {
+		data = NV_FLD_SET_DRF_DEF(MC, EMEM_ARB_OVERRIDE,
+			TS2AA_HOLDOFF_OVERRIDE, DISABLE, data);
+	}
+	reg_info_reg_wr(mc_inf_arr, TEGRA_MC_EMEM_ARB_OVERRIDE_ID, data);
+
+	disable_pcfifo_interlock(mc_inf_arr);
+	if (mc_settings_ptr->pcfifo_interlock)
+		wr_pcfifo_interlock_perf_regs(mc_inf_arr);
+
+	if (mc_settings_ptr->en_ordering)
+		wr_ord_perf_regs(mc_inf_arr);
+
+	if (mc_settings_ptr->set_order_id)
+		wr_ord_id_perf_regs(mc_inf_arr);
+
+	data = reg_info_reg_rd(mc_inf_arr, TEGRA_MC_FREE_BANK_QUEUES_ID);
+	if (mc_settings_ptr->hp_cpu_throttle_en) {
+		data = NV_FLD_SET_DRF_DEF(MC, FREE_BANK_QUEUES,
+			HP_CPU_THROTTLE_EN, ENABLE, data);
+	} else {
+		data = NV_FLD_SET_DRF_DEF(MC, FREE_BANK_QUEUES,
+			HP_CPU_THROTTLE_EN, DISABLE, data);
+	}
+	reg_info_reg_wr(mc_inf_arr, TEGRA_MC_FREE_BANK_QUEUES_ID, data);
+
+	if (mc_settings_ptr->override_isoptc_hub_mapping) {
+		data = reg_info_reg_rd(mc_inf_arr,
+			TEGRA_MC_MC_SMMU_PTC2H_REQ_MAPPING_OVERRIDE_ID);
+		data = NV_FLD_SET_DRF_DEF(MC,
+			MC_SMMU_PTC2H_REQ_MAPPING_OVERRIDE,
+			PTC22H_REQ_MAPPING_OVERRIDE, ENABLE, data);
+		reg_info_reg_wr(mc_inf_arr,
+			TEGRA_MC_MC_SMMU_PTC2H_REQ_MAPPING_OVERRIDE_ID, data);
+
+		data = reg_info_reg_rd(mc_inf_arr,
+			TEGRA_MC_MC_SMMU_PTC2H_REQ_MAPPING_ID);
+		data = NV_FLD_SET_DRF_NUM(MC, MC_SMMU_PTC2H_REQ_MAPPING,
+			PTC22H_REQ_MAPPING,
+			mc_settings_ptr->isoptc_hub_num, data);
+		reg_info_reg_wr(mc_inf_arr,
+			TEGRA_MC_MC_SMMU_PTC2H_REQ_MAPPING_ID, data);
+	}
+
+	if (mc_settings_ptr->override_hub_vcarb_type) {
+		data = reg_info_reg_rd(mc_inf_arr, TEGRA_MC_HUB_VC_ARB_SEL_ID);
+		data = NV_FLD_SET_DRF_NUM(MC, HUB_VC_ARB_SEL, VC_ARB_TYPE,
+			mc_settings_ptr->hub_vcarb_type, data);
+		reg_info_reg_wr(mc_inf_arr, TEGRA_MC_HUB_VC_ARB_SEL_ID, data);
+	}
+
+	if (mc_settings_ptr->override_hub_vcarb_wt) {
+		data = reg_info_reg_rd(mc_inf_arr, TEGRA_MC_HUB_VC_ARB_SEL_ID);
+		data = NV_FLD_SET_DRF_NUM(MC, HUB_VC_ARB_SEL, NISO_WT,
+			mc_settings_ptr->hub_vcarb_niso_wt, data);
+		data = NV_FLD_SET_DRF_NUM(MC, HUB_VC_ARB_SEL, SISO_WT,
+			mc_settings_ptr->hub_vcarb_siso_wt, data);
+		data = NV_FLD_SET_DRF_NUM(MC, HUB_VC_ARB_SEL, ISO_WT,
+			mc_settings_ptr->hub_vcarb_iso_wt, data);
+		reg_info_reg_wr(mc_inf_arr, TEGRA_MC_HUB_VC_ARB_SEL_ID, data);
+	}
+
+	if (mc_settings_ptr->override_iso_tbu_cchk_en_ctrl) {
+		data = reg_info_reg_rd(mc_inf_arr,
+			TEGRA_MC_MC_SMMU_ISO_TBU_CCHK_REQ_PRI_CTRL_ID);
+		data = NV_FLD_SET_DRF_NUM(MC,
+			MC_SMMU_ISO_TBU_CCHK_REQ_PRI_CTRL,
+			ISO_TBU_CCHK_EN_CTRL,
+			mc_settings_ptr->iso_tbu_cchk_en_ctrl, data);
+		reg_info_reg_wr(mc_inf_arr,
+			TEGRA_MC_MC_SMMU_ISO_TBU_CCHK_REQ_PRI_CTRL_ID, data);
+	}
+
+}
+
+#undef INIT_MSSNVLINK_REG_INFO
+
+static void set_pcie1_ord_id(
+	struct reg_info *mcpcie_inf_arr,
+	struct mc_settings_info *mc_settings_ptr,
+	int ordered,
+	int id)
+{
+	unsigned int data;
+
+	if (mc_settings_ptr->pcfifo_interlock) {
+		data = reg_info_reg_rd(mcpcie_inf_arr,
+			TEGRA_MC_PCFIFO_CLIENT_CONFIG6_ID);
+		if (ordered) {
+			data = NV_FLD_SET_DRF_DEF(MC, PCFIFO_CLIENT_CONFIG6,
+				PCFIFO_PCIE1W_ORDERED_CLIENT,
+				ORDERED, data);
+		} else {
+			data = NV_FLD_SET_DRF_DEF(MC, PCFIFO_CLIENT_CONFIG6,
+				PCFIFO_PCIE1W_ORDERED_CLIENT,
+				UNORDERED, data);
+		}
+		reg_info_reg_wr(mcpcie_inf_arr,
+			TEGRA_MC_PCFIFO_CLIENT_CONFIG6_ID, data);
+	}
+
+	if (mc_settings_ptr->set_order_id) {
+		data = reg_info_reg_rd(mcpcie_inf_arr,
+			TEGRA_MC_CLIENT_ORDER_ID_27_ID);
+		data = NV_FLD_SET_DRF_NUM(MC, CLIENT_ORDER_ID_27,
+			PCIE1W_ORDER_ID,
+			id, data);
+		reg_info_reg_wr(mcpcie_inf_arr,
+			TEGRA_MC_CLIENT_ORDER_ID_27_ID, data);
+	}
+
+	if (mc_settings_ptr->en_ordering) {
+		data = reg_info_reg_rd(
+			mcpcie_inf_arr,
+			TEGRA_MC_TBU_CLIENT_STEERING_CONFIG_PCIE1W_ID);
+		data = NV_FLD_SET_DRF_NUM(MC, TBU_CLIENT_STEERING_CONFIG_PCIE1W,
+			PCIE1W_SO_DEV_TBUID,
+			id, data);
+		reg_info_reg_wr(mcpcie_inf_arr,
+			TEGRA_MC_TBU_CLIENT_STEERING_CONFIG_PCIE1W_ID, data);
+	}
+}
+
+static void set_pcie2_ord_id(
+	struct reg_info *mcpcie_inf_arr,
+	struct mc_settings_info *mc_settings_ptr,
+	int ordered,
+	int id)
+{
+	unsigned int data;
+
+	if (mc_settings_ptr->pcfifo_interlock) {
+		data = reg_info_reg_rd(mcpcie_inf_arr,
+			TEGRA_MC_PCFIFO_CLIENT_CONFIG6_ID);
+		if (ordered) {
+			data = NV_FLD_SET_DRF_DEF(MC, PCFIFO_CLIENT_CONFIG6,
+				PCFIFO_PCIE2AW_ORDERED_CLIENT,
+				ORDERED, data);
+		} else {
+			data = NV_FLD_SET_DRF_DEF(MC, PCFIFO_CLIENT_CONFIG6,
+				PCFIFO_PCIE2AW_ORDERED_CLIENT,
+				UNORDERED, data);
+		}
+		reg_info_reg_wr(mcpcie_inf_arr,
+			TEGRA_MC_PCFIFO_CLIENT_CONFIG6_ID, data);
+	}
+
+	if (mc_settings_ptr->set_order_id) {
+		data = reg_info_reg_rd(mcpcie_inf_arr,
+			TEGRA_MC_CLIENT_ORDER_ID_27_ID);
+		data = NV_FLD_SET_DRF_NUM(MC, CLIENT_ORDER_ID_27,
+			PCIE2AW_ORDER_ID,
+			id, data);
+		reg_info_reg_wr(mcpcie_inf_arr,
+			TEGRA_MC_CLIENT_ORDER_ID_27_ID, data);
+	}
+
+	if (mc_settings_ptr->en_ordering) {
+		data = reg_info_reg_rd(
+			mcpcie_inf_arr,
+			TEGRA_MC_TBU_CLIENT_STEERING_CONFIG_PCIE2AW_ID);
+		data = NV_FLD_SET_DRF_NUM(MC,
+			TBU_CLIENT_STEERING_CONFIG_PCIE2AW,
+			PCIE2AW_SO_DEV_TBUID,
+			id, data);
+		reg_info_reg_wr(mcpcie_inf_arr,
+			TEGRA_MC_TBU_CLIENT_STEERING_CONFIG_PCIE2AW_ID, data);
+	}
+}
+
+static void set_pcie3_ord_id(
+	struct reg_info *mcpcie_inf_arr,
+	struct mc_settings_info *mc_settings_ptr,
+	int ordered,
+	int id)
+{
+	unsigned int data;
+
+	if (mc_settings_ptr->pcfifo_interlock) {
+		data = reg_info_reg_rd(mcpcie_inf_arr,
+			TEGRA_MC_PCFIFO_CLIENT_CONFIG6_ID);
+		if (ordered) {
+			data = NV_FLD_SET_DRF_DEF(MC, PCFIFO_CLIENT_CONFIG6,
+				PCFIFO_PCIE3W_ORDERED_CLIENT,
+				ORDERED, data);
+		} else {
+			data = NV_FLD_SET_DRF_DEF(MC, PCFIFO_CLIENT_CONFIG6,
+				PCFIFO_PCIE3W_ORDERED_CLIENT,
+				UNORDERED, data);
+		}
+		reg_info_reg_wr(mcpcie_inf_arr,
+			TEGRA_MC_PCFIFO_CLIENT_CONFIG6_ID, data);
+	}
+
+	if (mc_settings_ptr->set_order_id) {
+		data = reg_info_reg_rd(mcpcie_inf_arr,
+			TEGRA_MC_CLIENT_ORDER_ID_27_ID);
+		data = NV_FLD_SET_DRF_NUM(MC, CLIENT_ORDER_ID_27,
+			PCIE3W_ORDER_ID,
+			id, data);
+		reg_info_reg_wr(mcpcie_inf_arr,
+			TEGRA_MC_CLIENT_ORDER_ID_27_ID, data);
+	}
+
+	if (mc_settings_ptr->en_ordering) {
+		data = reg_info_reg_rd(
+			mcpcie_inf_arr,
+			TEGRA_MC_TBU_CLIENT_STEERING_CONFIG_PCIE3W_ID);
+		data = NV_FLD_SET_DRF_NUM(MC, TBU_CLIENT_STEERING_CONFIG_PCIE3W,
+			PCIE3W_SO_DEV_TBUID,
+			id, data);
+		reg_info_reg_wr(mcpcie_inf_arr,
+			TEGRA_MC_TBU_CLIENT_STEERING_CONFIG_PCIE3W_ID, data);
+	}
+}
+
+static void update_ord_ids(
+	struct reg_info *mcpcie_inf_arr,
+	struct mc_settings_info *mc_settings_ptr,
+	unsigned int pcie_xbar_cfg,
+	unsigned int *error)
+{
+	unsigned int data;
+
+	data = 0;
+	reg_info_reg_wr(mcpcie_inf_arr,
+		TEGRA_MC_PCFIFO_CLIENT_CONFIG6_ID,
+		data);
+
+	if (mc_settings_ptr->set_order_id) {
+		data = reg_info_reg_rd(mcpcie_inf_arr,
+			TEGRA_MC_CLIENT_ORDER_ID_27_ID);
+		data = NV_FLD_SET_DRF_DEF(MC, CLIENT_ORDER_ID_27,
+			PCIE0W_ORDER_ID, ORDER_ID2, data);
+		reg_info_reg_wr(mcpcie_inf_arr,
+			TEGRA_MC_CLIENT_ORDER_ID_27_ID, data);
+	}
+
+	switch (pcie_xbar_cfg) { /* PCIE_COMMON_APPL_COMMON_CONTROL_0 */
+	case 0:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 2);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 3);
+		break;
+	case 1:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 2);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		break;
+	case 2:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 2);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 3);
+		break;
+	case 3:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		break;
+	case 4:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 2);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		break;
+	case 5:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 2);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		break;
+	case 6:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 2);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 3);
+		break;
+	case 7:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 2);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		break;
+	case 8:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 2);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 2);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		break;
+	case 9:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		break;
+	case 10:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 2);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		break;
+	case 11:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 3);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		break;
+	case 12:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 2);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 3);
+		break;
+	case 13:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		break;
+	case 14:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 3);
+		break;
+	case 15:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		break;
+	case 16:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		break;
+	case 17:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 3);
+		break;
+	case 18:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 3);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		break;
+	case 19:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 3);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 3);
+		break;
+	case 20:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		break;
+	case 21:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 3);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		break;
+	case 22:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 3);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 3);
+		break;
+	case 23:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		break;
+	case 24:
+		set_pcie1_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie2_ord_id(mcpcie_inf_arr, mc_settings_ptr, 1, 0);
+		set_pcie3_ord_id(mcpcie_inf_arr, mc_settings_ptr, 0, 3);
+		break;
+	default:
+	{
+		pr_err("%s: pcie_xbar_cfg %d not handled\n",
+			__func__, pcie_xbar_cfg);
+		(*error) |= 1;
+		WARN_ON(1);
+	}
+	}
+}
+
+void init_la_ptsa_core(struct la_ptsa_core *lp)
+{
+	lp->get_init_la = get_init_la;
+	lp->la_info_array_init = la_info_array_init;
+	lp->mc_settings_init = mc_settings_init;
+	lp->mc_settings_override = mc_settings_override;
+	lp->get_disp_rd_lat_allow_given_disp_bw =
+		get_disp_rd_lat_allow_given_disp_bw;
+	lp->dda_info_array_init = dda_info_array_init;
+	lp->update_new_dda_minmax_kern_init = update_new_dda_minmax_kern_init;
+	lp->update_new_dda_rate_frac_kern_init =
+		update_new_dda_rate_frac_kern_init;
+	lp->convert_la2dda_id_for_dyn_ptsa = convert_la2dda_id_for_dyn_ptsa;
+	lp->init_max_gd = init_max_gd;
+	lp->init_mcemc_same_freq_thr = init_mcemc_same_freq_thr;
+	lp->setup_freq_ranges = setup_freq_ranges;
+	lp->get_bytes_per_dram_clk = get_bytes_per_dram_clk;
+	lp->bw2fraction = bw2fraction;
+	lp->fraction2dda = fraction2dda;
+	lp->update_new_dda_rate_frac_use_case =
+		update_new_dda_rate_frac_use_case;
+	lp->all_reg_info_array_init = all_reg_info_array_init;
+	lp->write_perf_regs_kern_init = write_perf_regs_kern_init;
+	lp->mcpcie_reg_info_array_init = mcpcie_reg_info_array_init;
+	lp->update_ord_ids = update_ord_ids;
+}
diff --git a/drivers/platform/tegra/mc/tegra21x_la.c b/drivers/platform/tegra/mc/tegra21x_la.c
new file mode 100644
index 000000000000..831567b37fc3
--- /dev/null
+++ b/drivers/platform/tegra/mc/tegra21x_la.c
@@ -0,0 +1,934 @@
+/*
+ * Copyright (C) 2014-2018, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#include <linux/types.h>
+#include <linux/clk.h>
+
+#include <asm/io.h>
+
+#include <linux/platform/tegra/latency_allowance.h>
+#include <linux/platform/tegra/mc-regs-t21x.h>
+#include <linux/platform/tegra/mc.h>
+#include <soc/tegra/fuse.h>
+
+#include "la_priv.h"
+
+#define ON_LPDDR4() (tegra_emc_get_dram_type() == DRAM_TYPE_LPDDR4)
+
+#define LA_ST_LA_MINUS_SNAP_ARB_TO_ROW_SRT_EMCCLKS_FP	70000
+#define LA_DRAM_WIDTH_BITS				64
+#define LA_DISP_CATCHUP_FACTOR_FP			1100
+#define MC_MAX_FREQ_MHZ					533
+#define MAX_GRANT_DEC					511
+
+#define EXP_TIME_EMCCLKS_FP				88000
+#define MAX_LA_NSEC					7650
+#define DDA_BW_MARGIN_FP				1100
+#define ONE_DDA_FRAC_FP					10
+#define CPU_RD_BW_PERC					9
+#define CPU_WR_BW_PERC					1
+#define MIN_CYCLES_PER_GRANT				2
+#define EMEM_PTSA_MINMAX_WIDTH				5
+#define RING1_FEEDER_SISO_ALLOC_DIV			2
+
+static struct la_client_info t21x_la_info_array[] = {
+	LA(0, 0, AFI_0,		23 : 16, AFIW,		false, 128, 800),
+	LA(0, 0, AFI_0,		7  : 0,  AFIR,		false, 59,  400),
+	LA(0, 0, AVPC_0,	7  : 0,  AVPC_ARM7R,	false, 4,   0),
+	LA(0, 0, AVPC_0,	23 : 16, AVPC_ARM7W,	false, 128, 800),
+	LA(0, 0, DC_0,		7  : 0,  DISPLAY_0A,	true,  80,  0),
+	LA(0, 0, DCB_0,		7  : 0,  DISPLAY_0AB,	true,  80,  0),
+	LA(0, 0, DC_0,		23 : 16, DISPLAY_0B,	true,  80,  0),
+	LA(0, 0, DCB_0,		23 : 16, DISPLAY_0BB,	true,  80,  0),
+	LA(0, 0, DC_1,		7  : 0,  DISPLAY_0C,	true,  80,  0),
+	LA(0, 0, DCB_1,		7  : 0,  DISPLAY_0CB,	true,  80,  0),
+	LA(0, 0, DC_3,		7  : 0,  DISPLAYD,	false, 80,  0),
+	LA(0, 0, DC_2,		7  : 0,  DISPLAY_HC,	false, 80,  0),
+	LA(0, 0, DCB_2,		7  : 0,  DISPLAY_HCB,	false, 80,  0),
+	LA(0, 0, DC_2,		23 : 16, DISPLAY_T,	false, 80,  0),
+	LA(0, 0, GPU_0,		7  : 0,  GPUSRD,	false, 25,  800),
+	LA(0, 0, GPU_0,		23 : 16, GPUSWR,	false, 128, 800),
+	LA(0, 0, HDA_0,		7  : 0,  HDAR,		false, 36,  0),
+	LA(0, 0, HDA_0,		23 : 16, HDAW,		false, 128, 800),
+	LA(0, 0, TSEC_0,	7  : 0,  TSECSRD,	false, 157, 200),
+	LA(0, 0, TSEC_0,	23 : 16, TSECSWR,	false, 128, 800),
+	LA(0, 0, TSECB_0,	7  : 0,  TSECBSRD,	false, 157, 200),
+	LA(0, 0, TSECB_0,	23 : 16, TSECBSWR,	false, 128, 800),
+	LA(0, 0, HC_0,		7  : 0,  HOST1X_DMAR,	false, 28,  800),
+	LA(0, 0, HC_0,		23 : 16, HOST1XR,	false, 80,  0),
+	LA(0, 0, HC_1,		7  : 0,  HOST1XW,	false, 128, 800),
+	LA(0, 0, ISP2_0,	7  : 0,  ISP_RA,	false, 51,  300),
+	LA(0, 0, ISP2_1,	7  : 0,  ISP_WA,	false, 128, 800),
+	LA(0, 0, ISP2_1,	23 : 16, ISP_WB,	false, 128, 800),
+	LA(0, 0, ISP2B_0,	7  : 0,  ISP_RAB,	false, 54,  300),
+	LA(0, 0, ISP2B_1,	7  : 0,  ISP_WAB,	false, 128, 800),
+	LA(0, 0, ISP2B_1,	23 : 16, ISP_WBB,	false, 128, 800),
+	LA(0, 0, MPCORE_0,	7  : 0,  MPCORER,	false, 4,   0),
+	LA(0, 0, MPCORE_0,	23 : 16, MPCOREW,	false, 128, 800),
+	LA(0, 0, NVDEC_0,	7  : 0,  NVDECR,	false, 4,   0),
+	LA(0, 0, NVDEC_0,	23 : 16, NVDECW,	false, 128, 800),
+	/* No entries for nvenc and nvjpg ?? */
+	/* LA(0, 0, PPCS_1,	7  : 0,  PPCS_AHBDMAW,	true,  128, 800), */
+	LA(0, 0, PPCS_0,	23 : 16, PPCS_AHBSLVR,	false, 89,  408),
+	LA(0, 0, PPCS_1,	23 : 16, PPCS_AHBSLVW,	false, 128, 800),
+	LA(0, 0, PTC_0,		7  : 0,  PTCR,		false, 0,   0),
+	LA(0, 0, SATA_0,	7  : 0,  SATAR,		false, 104, 400),
+	LA(0, 0, SATA_0,	23 : 16, SATAW,		false, 128, 800),
+	LA(0, 0, SDMMC_0,	7  : 0,  SDMMCR,	false, 150, 248),
+	LA(0, 0, SDMMCA_0,	7  : 0,  SDMMCRA,	false, 150, 248),
+	LA(0, 0, SDMMCAA_0,	7  : 0,  SDMMCRAA,	false, 88,  248),
+	LA(0, 0, SDMMCAB_0,	7  : 0,  SDMMCRAB,	false, 88,  248),
+	LA(0, 0, SDMMC_0,	23 : 16, SDMMCW,	false, 128, 800),
+	LA(0, 0, SDMMCA_0,	23 : 16, SDMMCWA,	false, 128, 800),
+	LA(0, 0, SDMMCAA_0,	23 : 16, SDMMCWAA,	false, 128, 800),
+	LA(0, 0, SDMMCAB_0,	23 : 16, SDMMCWAB,	false, 128, 800),
+	LA(0, 0, VIC_0,		7  : 0,  VICSRD,	false, 29,  800),
+	LA(0, 0, VIC_0,		23 : 16, VICSWR,	false, 128, 800),
+	LA(0, 0, VI2_0,		7  : 0,  VI_W,		false, 128, 800),
+	LA(0, 0, XUSB_1,	7  : 0,  XUSB_DEVR,	false, 59,  400),
+	LA(0, 0, XUSB_1,	23 : 16, XUSB_DEVW,	false, 128, 800),
+	LA(0, 0, XUSB_0,	7  : 0,  XUSB_HOSTR,	false, 66,  400),
+	LA(0, 0, XUSB_0,	23 : 16, XUSB_HOSTW,	false, 128, 800),
+
+	/* end of list */
+	LA(0, 0, DC_3,		0 : 0, MAX_ID, false, 0, 0)
+};
+
+static unsigned int emc_min_freq_mhz_fp;
+static unsigned int emc_min_freq_mhz;
+static unsigned int emc_max_freq_mhz;
+static unsigned int hi_gd_fp;
+static unsigned int lo_gd_fp;
+static unsigned int hi_gd_fpa;
+static unsigned int lo_gd_fpa;
+static unsigned int low_freq_bw;
+static unsigned int dda_div;
+
+static struct la_chip_specific *cs;
+const struct disp_client *tegra_la_disp_clients_info;
+static unsigned int total_dc0_bw;
+static unsigned int total_dc1_bw;
+static DEFINE_MUTEX(disp_and_camera_ptsa_lock);
+
+static void program_ptsa(void)
+{
+	struct ptsa_info *p = &cs->ptsa_info;
+
+	mc_writel(p->ptsa_grant_dec, MC_PTSA_GRANT_DECREMENT);
+	mc_writel(1, MC_TIMING_CONTROL);
+	mc_writel(p->dis_extra_snap_level, MC_DIS_EXTRA_SNAP_LEVELS);
+
+	WRITE_PTSA_MIN_MAX_RATE(p, dis, DIS);
+	WRITE_PTSA_MIN_MAX_RATE(p, disb, DISB);
+	WRITE_PTSA_MIN_MAX_RATE(p, ve, VE);
+	WRITE_PTSA_MIN_MAX_RATE(p, ve2, VE2);
+	WRITE_PTSA_MIN_MAX_RATE(p, ring2, RING2);
+	WRITE_PTSA_MIN_MAX_RATE(p, mpcorer, MLL_MPCORER);
+	WRITE_PTSA_MIN_MAX_RATE(p, smmu, SMMU_SMMU);
+	WRITE_PTSA_MIN_MAX_RATE(p, ring1, RING1);
+	WRITE_PTSA_MIN_MAX_RATE(p, isp, ISP);
+
+	WRITE_PTSA_MIN_MAX(p, a9avppc, A9AVPPC);
+	WRITE_PTSA_MIN_MAX(p, avp, AVP);
+	WRITE_PTSA_MIN_MAX(p, mse, MSE);
+	WRITE_PTSA_MIN_MAX(p, gk, GK);
+	WRITE_PTSA_MIN_MAX(p, vicpc, VICPC);
+	WRITE_PTSA_MIN_MAX(p, apb, APB);
+	WRITE_PTSA_MIN_MAX(p, pcx, PCX);
+	WRITE_PTSA_MIN_MAX(p, host, HOST);
+	WRITE_PTSA_MIN_MAX(p, ahb, AHB);
+	WRITE_PTSA_MIN_MAX(p, sax, SAX);
+	WRITE_PTSA_MIN_MAX(p, aud, AUD);
+	WRITE_PTSA_MIN_MAX(p, sd, SD);
+	WRITE_PTSA_MIN_MAX(p, usbx, USBX);
+	WRITE_PTSA_MIN_MAX(p, usbd, USBD);
+	WRITE_PTSA_MIN_MAX(p, ftop, FTOP);
+}
+
+static void save_ptsa(void)
+{
+	struct ptsa_info *p = &cs->ptsa_info;
+
+	p->ptsa_grant_dec = mc_readl(MC_PTSA_GRANT_DECREMENT);
+	p->dis_extra_snap_level = mc_readl(MC_DIS_EXTRA_SNAP_LEVELS);
+
+	READ_PTSA_MIN_MAX_RATE(p, dis, DIS);
+	READ_PTSA_MIN_MAX_RATE(p, disb, DISB);
+	READ_PTSA_MIN_MAX_RATE(p, ve, VE);
+	READ_PTSA_MIN_MAX_RATE(p, ve2, VE2);
+	READ_PTSA_MIN_MAX_RATE(p, ring2, RING2);
+	READ_PTSA_MIN_MAX_RATE(p, mpcorer, MLL_MPCORER);
+	READ_PTSA_MIN_MAX_RATE(p, smmu, SMMU_SMMU);
+	READ_PTSA_MIN_MAX_RATE(p, ring1, RING1);
+	READ_PTSA_MIN_MAX_RATE(p, isp, ISP);
+
+	READ_PTSA_MIN_MAX(p, a9avppc, A9AVPPC);
+	READ_PTSA_MIN_MAX(p, avp, AVP);
+	READ_PTSA_MIN_MAX(p, mse, MSE);
+	READ_PTSA_MIN_MAX(p, gk, GK);
+	READ_PTSA_MIN_MAX(p, vicpc, VICPC);
+	READ_PTSA_MIN_MAX(p, apb, APB);
+	READ_PTSA_MIN_MAX(p, apb, APB);
+	READ_PTSA_MIN_MAX(p, host, HOST);
+	READ_PTSA_MIN_MAX(p, ahb, AHB);
+	READ_PTSA_MIN_MAX(p, sax, SAX);
+	READ_PTSA_MIN_MAX(p, aud, AUD);
+	READ_PTSA_MIN_MAX(p, sd, SD);
+	READ_PTSA_MIN_MAX(p, usbx, USBX);
+	READ_PTSA_MIN_MAX(p, usbd, USBD);
+	READ_PTSA_MIN_MAX(p, ftop, FTOP);
+}
+
+/*
+ * Gets the memory BW in MBps. @emc_freq should be in MHz.
+ */
+static u32 get_mem_bw_mbps(u32 dram_freq)
+{
+	return dram_freq * 16;
+}
+
+static bool is_t210b01_soc(void)
+{
+	u32 chipid, major;
+
+	chipid = tegra_hidrev_get_chipid(tegra_read_chipid());
+	major = tegra_hidrev_get_majorrev(tegra_read_chipid());
+
+	if (chipid == TEGRA210B01 && major >= 2)
+		return true;
+
+	return false;
+}
+
+/*
+ * EMC frequency is actually DRAM frequency. Normally they are one in the same;
+ * however, with LPDDR4 DRAM, the DRAM clock goes to 1600MHz which the EMC clock
+ * cannot. Thus the EMC is actually running at DRAM clk / 2.
+ */
+static void t21x_init_ptsa(void)
+{
+	struct clk *emc_clk;
+	unsigned int emc_freq_mhz;
+	unsigned int mc_freq_mhz;
+	unsigned int same_freq;
+	struct ptsa_info *p = &cs->ptsa_info;
+	unsigned int cpu_rd_bw, cpu_wr_bw;
+	unsigned int gd_int, gd_frac_fp;
+	int gd_fpa;
+
+	/* get emc frequency */
+	emc_clk = clk_get_sys("tegra_emc", "emc");
+	if (IS_ERR(emc_clk))
+		return;
+
+	emc_freq_mhz = clk_get_rate(emc_clk) /
+			LA_HZ_TO_MHZ_FACTOR;
+	la_debug("emc clk_rate = %u MHz", emc_freq_mhz);
+
+	/* get mc frequency */
+	same_freq = mc_readl(MC_EMEM_ARB_MISC0) &
+		MC_EMEM_ARB_MISC0_MC_EMC_SAME_FREQ_BIT;
+	mc_freq_mhz = same_freq ? emc_freq_mhz : emc_freq_mhz / 2;
+	la_debug("mc clk_rate = %u MHz", mc_freq_mhz);
+
+	/* compute initial value for grant dec */
+	gd_fpa = (LA_FP_TO_FPA(lo_gd_fp) * emc_freq_mhz) / emc_min_freq_mhz;
+	if (gd_fpa >= LA_REAL_TO_FPA(1)) {
+		gd_int = 1;
+		gd_fpa -= LA_REAL_TO_FPA(1);
+	} else {
+		gd_int = 0;
+	}
+
+	gd_frac_fp = __fraction2dda_fp(gd_fpa, 1,
+				       MC_PTSA_RATE_DEFAULT_MASK);
+	p->ptsa_grant_dec = (gd_int << 12) | gd_frac_fp;
+
+	/* initialize PTSA reg values */
+	MC_SET_INIT_PTSA(p, ve,      -5, 31);
+	MC_SET_INIT_PTSA(p, isp,     -5, 31); /* Same for T210 and T210b01 */
+	if (is_t210b01_soc())
+		MC_SET_INIT_PTSA(p, ve2,     -2, 0);
+	else
+		MC_SET_INIT_PTSA(p, ve2,     -5, 31);
+	MC_SET_INIT_PTSA(p, a9avppc, -5, 16);
+	MC_SET_INIT_PTSA(p, ring2,   -2, 0);
+	MC_SET_INIT_PTSA(p, dis,     -5, 31);
+	MC_SET_INIT_PTSA(p, disb,    -5, 31);
+	MC_SET_INIT_PTSA(p, ring1,   -5, 31);
+	MC_SET_INIT_PTSA(p, mpcorer, -4, 4);
+	MC_SET_INIT_PTSA(p, smmu,     1, 1);
+	MC_SET_INIT_PTSA(p, mse,     -2, 0);
+	MC_SET_INIT_PTSA(p, gk,      -2, 0);
+	MC_SET_INIT_PTSA(p, vicpc,   -2, 0);
+	MC_SET_INIT_PTSA(p, apb,     -2, 0);
+	MC_SET_INIT_PTSA(p, pcx,     -2, 0);
+	MC_SET_INIT_PTSA(p, host,    -2, 0);
+	MC_SET_INIT_PTSA(p, ahb,     -2, 0);
+	MC_SET_INIT_PTSA(p, sax,     -2, 0);
+	MC_SET_INIT_PTSA(p, sd,      -2, 0);
+	MC_SET_INIT_PTSA(p, usbx,    -2, 0);
+	MC_SET_INIT_PTSA(p, usbd,    -2, 0);
+	MC_SET_INIT_PTSA(p, ftop,    -2, 0);
+	MC_SET_INIT_PTSA(p, avp,     -2, 0);
+	MC_SET_INIT_PTSA(p, aud,     -5, 31);
+	MC_SET_INIT_PTSA(p, jpg,     -2, 0);
+	MC_SET_INIT_PTSA(p, gk2,     -2, 0);
+
+	p->ring2_ptsa_rate = (unsigned int)(12) & MC_PTSA_RATE_DEFAULT_MASK;
+
+	/* mpcorer */
+	cpu_rd_bw = (get_mem_bw_mbps(emc_freq_mhz) * CPU_RD_BW_PERC) / 100;
+	if (ON_LPDDR4())
+		cpu_rd_bw /= 2;
+
+	p->mpcorer_ptsa_rate = __fraction2dda_fp(lo_gd_fpa * cpu_rd_bw /
+						 low_freq_bw,
+						 dda_div,
+						 MC_PTSA_RATE_DEFAULT_MASK);
+
+	/* FTOP (mpcorew it seems)*/
+	cpu_wr_bw = (get_mem_bw_mbps(emc_freq_mhz) * CPU_WR_BW_PERC) / 100;
+	if (ON_LPDDR4())
+		cpu_rd_bw /= 2;
+
+	p->ftop_ptsa_rate = __fraction2dda_fp(lo_gd_fpa * cpu_wr_bw /
+					      low_freq_bw,
+					      dda_div,
+					      MC_PTSA_RATE_DEFAULT_MASK);
+
+	/* Ring1 */
+	p->ring1_ptsa_rate =  p->mpcorer_ptsa_rate + p->ftop_ptsa_rate;
+	p->ring1_ptsa_rate += p->dis_ptsa_rate + p->disb_ptsa_rate;
+	p->ring1_ptsa_rate += p->ve_ptsa_rate + p->ring2_ptsa_rate;
+
+	program_ptsa();
+}
+
+/*
+ * This now also includes ring1 since that needs to have its PTSA updated
+ * based on freq and usecase.
+ */
+static void t21x_calc_disp_and_camera_ptsa(void)
+{
+	struct ptsa_info *p = &cs->ptsa_info;
+	unsigned int ve_bw_fp = cs->camera_bw_array[CAMERA_IDX(VI_W)] *
+				DDA_BW_MARGIN_FP;
+	unsigned int ve2_bw_fp = 0;
+	unsigned int isp_bw_fp = 0;
+	unsigned int total_dc0_bw_fp = total_dc0_bw * DDA_BW_MARGIN_FP;
+	unsigned int total_dc1_bw_fp = total_dc1_bw * DDA_BW_MARGIN_FP;
+	unsigned int low_freq_bw_fp = la_real_to_fp(low_freq_bw);
+	unsigned int dis_frac_fp = LA_FPA_TO_FP(lo_gd_fpa * total_dc0_bw_fp /
+						low_freq_bw_fp);
+	unsigned int disb_frac_fp = LA_FPA_TO_FP(lo_gd_fpa * total_dc1_bw_fp /
+						 low_freq_bw_fp);
+	unsigned int total_iso_bw_fp = total_dc0_bw_fp + total_dc1_bw_fp;
+	int max_max = (1 << EMEM_PTSA_MINMAX_WIDTH) - 1;
+	int i = 0;
+
+	if (cs->agg_camera_array[AGG_CAMERA_ID(VE2)].is_hiso) {
+		ve2_bw_fp = (cs->camera_bw_array[CAMERA_IDX(ISP_RAB)] +
+				cs->camera_bw_array[CAMERA_IDX(ISP_WAB)] +
+				cs->camera_bw_array[CAMERA_IDX(ISP_WBB)]) *
+				DDA_BW_MARGIN_FP;
+	} else {
+		ve2_bw_fp = LA_REAL_TO_FP(
+				cs->camera_bw_array[CAMERA_IDX(ISP_RAB)] +
+				cs->camera_bw_array[CAMERA_IDX(ISP_WAB)] +
+				cs->camera_bw_array[CAMERA_IDX(ISP_WBB)]);
+	}
+
+	if (cs->agg_camera_array[AGG_CAMERA_ID(ISP)].is_hiso) {
+		isp_bw_fp = (cs->camera_bw_array[CAMERA_IDX(ISP_RA)] +
+				cs->camera_bw_array[CAMERA_IDX(ISP_WA)] +
+				cs->camera_bw_array[CAMERA_IDX(ISP_WB)]) *
+				DDA_BW_MARGIN_FP;
+	} else {
+		isp_bw_fp = LA_REAL_TO_FP(
+				cs->camera_bw_array[CAMERA_IDX(ISP_RA)] +
+				cs->camera_bw_array[CAMERA_IDX(ISP_WA)] +
+				cs->camera_bw_array[CAMERA_IDX(ISP_WB)]);
+	}
+
+	cs->agg_camera_array[AGG_CAMERA_ID(VE)].bw_fp = ve_bw_fp;
+	cs->agg_camera_array[AGG_CAMERA_ID(VE2)].bw_fp = ve2_bw_fp;
+	cs->agg_camera_array[AGG_CAMERA_ID(ISP)].bw_fp = isp_bw_fp;
+
+	for (i = 0; i < TEGRA_LA_AGG_CAMERA_NUM_CLIENTS; i++) {
+		struct agg_camera_client_info *agg_client =
+						&cs->agg_camera_array[i];
+
+		if (agg_client->is_hiso) {
+			agg_client->frac_fp = LA_FPA_TO_FP(
+						lo_gd_fpa * agg_client->bw_fp /
+						low_freq_bw_fp);
+			agg_client->ptsa_min = (unsigned int)(-5) &
+						MC_PTSA_MIN_DEFAULT_MASK;
+			agg_client->ptsa_max = (unsigned int)(max_max) &
+						MC_PTSA_MAX_DEFAULT_MASK;
+
+			total_iso_bw_fp += agg_client->bw_fp;
+		} else {
+			agg_client->frac_fp = ONE_DDA_FRAC_FP;
+			agg_client->ptsa_min = (unsigned int)(-2) &
+						MC_PTSA_MIN_DEFAULT_MASK;
+			agg_client->ptsa_max = (unsigned int)(0) &
+						MC_PTSA_MAX_DEFAULT_MASK;
+		}
+	}
+
+	MC_SET_INIT_PTSA(p, dis, -5, max_max);
+	p->dis_ptsa_rate = fraction2dda_fp(
+				dis_frac_fp,
+				4,
+				MC_PTSA_RATE_DEFAULT_MASK) &
+		MC_PTSA_RATE_DEFAULT_MASK;
+
+	MC_SET_INIT_PTSA(p, disb, -5, max_max);
+	p->disb_ptsa_rate = fraction2dda_fp(
+				disb_frac_fp,
+				4,
+				MC_PTSA_RATE_DEFAULT_MASK) &
+		MC_PTSA_RATE_DEFAULT_MASK;
+
+	p->ve_ptsa_min = cs->agg_camera_array[AGG_CAMERA_ID(VE)].ptsa_min &
+					MC_PTSA_MIN_DEFAULT_MASK;
+	p->ve_ptsa_max = cs->agg_camera_array[AGG_CAMERA_ID(VE)].ptsa_max &
+					MC_PTSA_MAX_DEFAULT_MASK;
+	p->ve_ptsa_rate = fraction2dda_fp(
+				cs->agg_camera_array[AGG_CAMERA_ID(VE)].frac_fp,
+				4,
+				MC_PTSA_RATE_DEFAULT_MASK) &
+		MC_PTSA_RATE_DEFAULT_MASK;
+
+	p->ve2_ptsa_min = cs->agg_camera_array[AGG_CAMERA_ID(VE2)].ptsa_min &
+					MC_PTSA_MIN_DEFAULT_MASK;
+	p->ve2_ptsa_max = cs->agg_camera_array[AGG_CAMERA_ID(VE2)].ptsa_max &
+					MC_PTSA_MAX_DEFAULT_MASK;
+	if (is_t210b01_soc())
+		p->ve2_ptsa_rate = 1;
+	else
+		p->ve2_ptsa_rate = fraction2dda_fp(
+			cs->agg_camera_array[AGG_CAMERA_ID(VE2)].frac_fp,
+			4,
+			MC_PTSA_RATE_DEFAULT_MASK) &
+			MC_PTSA_RATE_DEFAULT_MASK;
+
+	p->isp_ptsa_min = cs->agg_camera_array[AGG_CAMERA_ID(ISP)].ptsa_min &
+					MC_PTSA_MIN_DEFAULT_MASK;
+	p->isp_ptsa_max = cs->agg_camera_array[AGG_CAMERA_ID(ISP)].ptsa_max &
+					MC_PTSA_MAX_DEFAULT_MASK;
+	if (is_t210b01_soc())
+		p->isp_ptsa_rate = 50;
+	else
+		p->isp_ptsa_rate = fraction2dda_fp(
+			cs->agg_camera_array[AGG_CAMERA_ID(ISP)].frac_fp,
+			4,
+			MC_PTSA_RATE_DEFAULT_MASK) &
+			MC_PTSA_RATE_DEFAULT_MASK;
+
+	MC_SET_INIT_PTSA(p, ring1, -5, max_max);
+
+
+	p->ring1_ptsa_rate = p->dis_ptsa_rate + p->disb_ptsa_rate +
+		p->ve_ptsa_rate;
+	p->ring1_ptsa_rate += cs->agg_camera_array[AGG_CAMERA_ID(VE2)].is_hiso ?
+		p->ve2_ptsa_rate : 0;
+	p->ring1_ptsa_rate += cs->agg_camera_array[AGG_CAMERA_ID(ISP)].is_hiso ?
+		p->isp_ptsa_rate : 0;
+
+	if (ON_LPDDR4())
+		p->ring1_ptsa_rate /= 2;
+
+	/* These need to be read from the registers since the MC/EMC clock may
+	   be different than last time these were read into *p. */
+	p->ring1_ptsa_rate += mc_readl(MC_MLL_MPCORER_PTSA_RATE) +
+		mc_readl(MC_FTOP_PTSA_RATE);
+
+	if (p->ring1_ptsa_rate == 0)
+		p->ring1_ptsa_rate = 0x1;
+}
+
+static void t21x_update_display_ptsa_rate(unsigned int *disp_bw_array)
+{
+	struct ptsa_info *p = &cs->ptsa_info;
+
+	t21x_calc_disp_and_camera_ptsa();
+
+	mc_writel(p->ring1_ptsa_min, MC_RING1_PTSA_MIN);
+	mc_writel(p->ring1_ptsa_max, MC_RING1_PTSA_MAX);
+	mc_writel(p->ring1_ptsa_rate, MC_RING1_PTSA_RATE);
+
+	mc_writel(p->dis_ptsa_min, MC_DIS_PTSA_MIN);
+	mc_writel(p->dis_ptsa_max, MC_DIS_PTSA_MAX);
+	mc_writel(p->dis_ptsa_rate, MC_DIS_PTSA_RATE);
+
+	mc_writel(p->disb_ptsa_min, MC_DISB_PTSA_MIN);
+	mc_writel(p->disb_ptsa_max, MC_DISB_PTSA_MAX);
+	mc_writel(p->disb_ptsa_rate, MC_DISB_PTSA_RATE);
+}
+
+static int t21x_update_camera_ptsa_rate(enum tegra_la_id id,
+					unsigned int bw_mbps,
+					int is_hiso)
+{
+	struct ptsa_info *p = NULL;
+	int ret_code = 0;
+
+	mutex_lock(&disp_and_camera_ptsa_lock);
+
+	if (!is_camera_client(id)) {
+		/* Non-camera clients should be handled by t21x_set_la(...) or
+		   t21x_set_disp_la(...). */
+		pr_err("%s: Ignoring request from a non-camera client.\n",
+			__func__);
+		pr_err("%s: Non-camera clients should be handled by "
+			"t21x_set_la(...) or t21x_set_disp_la(...).\n",
+			__func__);
+		ret_code = -1;
+		goto exit;
+	}
+
+	if ((id == ID(VI_W)) &&
+		(!is_hiso)) {
+		pr_err("%s: VI is stating that its not HISO.\n", __func__);
+		pr_err("%s: Ignoring and assuming that VI is HISO because VI "
+			"is always supposed to be HISO.\n",
+			__func__);
+		is_hiso = 1;
+	}
+
+
+	p = &cs->ptsa_info;
+
+	if (id == ID(VI_W)) {
+		cs->agg_camera_array[AGG_CAMERA_ID(VE)].is_hiso = is_hiso;
+	} else if ((id == ID(ISP_RAB)) ||
+			(id == ID(ISP_WAB)) ||
+			(id == ID(ISP_WBB))) {
+		cs->agg_camera_array[AGG_CAMERA_ID(VE2)].is_hiso = is_hiso;
+	} else {
+		cs->agg_camera_array[AGG_CAMERA_ID(ISP)].is_hiso = is_hiso;
+	}
+
+	cs->camera_bw_array[CAMERA_LA_IDX(id)] = bw_mbps;
+
+	t21x_calc_disp_and_camera_ptsa();
+
+	mc_writel(p->ring1_ptsa_min, MC_RING1_PTSA_MIN);
+	mc_writel(p->ring1_ptsa_max, MC_RING1_PTSA_MAX);
+	mc_writel(p->ring1_ptsa_rate, MC_RING1_PTSA_RATE);
+
+	mc_writel(p->ve_ptsa_min, MC_VE_PTSA_MIN);
+	mc_writel(p->ve_ptsa_max, MC_VE_PTSA_MAX);
+	mc_writel(p->ve_ptsa_rate, MC_VE_PTSA_RATE);
+
+	mc_writel(p->ve2_ptsa_min, MC_VE2_PTSA_MIN);
+	mc_writel(p->ve2_ptsa_max, MC_VE2_PTSA_MAX);
+	mc_writel(p->ve2_ptsa_rate, MC_VE2_PTSA_RATE);
+
+	mc_writel(p->isp_ptsa_min, MC_ISP_PTSA_MIN);
+	mc_writel(p->isp_ptsa_max, MC_ISP_PTSA_MAX);
+	mc_writel(p->isp_ptsa_rate, MC_ISP_PTSA_RATE);
+
+exit:
+	mutex_unlock(&disp_and_camera_ptsa_lock);
+
+	return ret_code;
+}
+
+static int t21x_set_la(enum tegra_la_id id,
+			unsigned int bw_mbps)
+{
+	int idx = cs->id_to_index[id];
+	struct la_client_info *ci = &cs->la_info_array[idx];
+	unsigned int la_to_set = 0;
+
+	if (is_display_client(id)) {
+		/* Display clients should be handled by
+		   t21x_set_disp_la(...). */
+		return -1;
+	} else if (id == ID(MSENCSRD)) {
+		/* This is a special case. */
+		struct clk *emc_clk = clk_get_sys("tegra_emc", "emc");
+		unsigned int emc_freq_mhz;
+		unsigned int val_1 = 53;
+		unsigned int val_2 = 24;
+
+		if (IS_ERR(emc_clk))
+			return 0;
+
+		emc_freq_mhz = clk_get_rate(emc_clk) /
+				LA_HZ_TO_MHZ_FACTOR;
+		if (!emc_freq_mhz)
+			return 0;
+
+		if (210 > emc_freq_mhz)
+			val_1 = val_1 * 210 / emc_freq_mhz;
+
+		if (574 > emc_freq_mhz)
+			val_2 = val_2 * 574 / emc_freq_mhz;
+
+		la_to_set = min3((unsigned int)MC_LA_MAX_VALUE,
+				val_1,
+				val_2);
+	} else if (ci->la_ref_clk_mhz != 0) {
+		/* In this case we need to scale LA with emc frequency. */
+		struct clk *emc_clk = clk_get_sys("tegra_emc", "emc");
+		unsigned long emc_freq_mhz;
+
+		if (IS_ERR(emc_clk))
+			return 0;
+
+		emc_freq_mhz = clk_get_rate(emc_clk) /
+				(unsigned long)LA_HZ_TO_MHZ_FACTOR;
+		if (!emc_freq_mhz) {
+			pr_err("emc_freq_mhz is zero!!\n");
+			return 0;
+		}
+
+		if (ci->la_ref_clk_mhz <= emc_freq_mhz) {
+			la_to_set = min(ci->init_la,
+				(unsigned int)MC_LA_MAX_VALUE);
+		} else {
+			la_to_set = min((unsigned int)(ci->init_la *
+					 ci->la_ref_clk_mhz / emc_freq_mhz),
+				(unsigned int)MC_LA_MAX_VALUE);
+		}
+	} else {
+		/* In this case we have a client with a static LA value. */
+		la_to_set = ci->init_la;
+	}
+
+	program_la(ci, la_to_set);
+	return 0;
+}
+
+static unsigned int t21x_min_la(struct dc_to_la_params *disp_params)
+{
+	unsigned int min_la_fp = disp_params->drain_time_usec_fp *
+				1000 /
+				cs->ns_per_tick;
+
+	/* round up */
+	if (min_la_fp % LA_FP_FACTOR != 0)
+		min_la_fp += LA_FP_FACTOR;
+
+	return LA_FP_TO_REAL(min_la_fp);
+}
+
+static int t21x_handle_disp_la(enum tegra_la_id id,
+			       unsigned long emc_freq_hz,
+			       unsigned int bw_mbps,
+			       struct dc_to_la_params disp_params,
+			       int write_la)
+{
+	int idx = 0;
+	struct la_client_info *ci = NULL;
+	long long la_to_set = 0;
+	unsigned int dvfs_time_nsec = 0;
+	unsigned int dvfs_buffering_reqd_bytes = 0;
+	unsigned int thresh_dvfs_bytes = 0;
+	unsigned int total_buf_sz_bytes = 0;
+	int effective_mccif_buf_sz = 0;
+	long long la_bw_upper_bound_nsec_fp = 0;
+	long long la_bw_upper_bound_nsec = 0;
+	long long la_nsec = 0;
+
+	if (!is_display_client(id)) {
+		/* Non-display clients should be handled by t21x_set_la(...). */
+		return -1;
+	}
+
+	mutex_lock(&disp_and_camera_ptsa_lock);
+	total_dc0_bw = disp_params.total_dc0_bw;
+	total_dc1_bw = disp_params.total_dc1_bw;
+	cs->update_display_ptsa_rate(cs->disp_bw_array);
+	mutex_unlock(&disp_and_camera_ptsa_lock);
+
+	idx = cs->id_to_index[id];
+	ci = &cs->la_info_array[idx];
+	la_to_set = 0;
+	dvfs_time_nsec =
+		tegra_get_dvfs_clk_change_latency_nsec(emc_freq_hz / 1000);
+	dvfs_buffering_reqd_bytes = bw_mbps *
+					dvfs_time_nsec /
+					LA_USEC_TO_NSEC_FACTOR;
+
+	thresh_dvfs_bytes =
+			disp_params.thresh_lwm_bytes +
+			dvfs_buffering_reqd_bytes +
+			disp_params.spool_up_buffering_adj_bytes;
+	total_buf_sz_bytes =
+		cs->disp_clients[DISP_CLIENT_LA_ID(id)].line_buf_sz_bytes +
+		cs->disp_clients[DISP_CLIENT_LA_ID(id)].mccif_size_bytes;
+	effective_mccif_buf_sz =
+		(cs->disp_clients[DISP_CLIENT_LA_ID(id)].line_buf_sz_bytes >
+		thresh_dvfs_bytes) ?
+		cs->disp_clients[DISP_CLIENT_LA_ID(id)].mccif_size_bytes :
+		total_buf_sz_bytes - thresh_dvfs_bytes;
+
+	if (effective_mccif_buf_sz < 0)
+		return -1;
+
+	la_bw_upper_bound_nsec_fp = (long long)effective_mccif_buf_sz *
+					LA_FP_FACTOR /
+					bw_mbps;
+	la_bw_upper_bound_nsec_fp = la_bw_upper_bound_nsec_fp *
+					LA_FP_FACTOR /
+					LA_DISP_CATCHUP_FACTOR_FP;
+	la_bw_upper_bound_nsec_fp =
+		la_bw_upper_bound_nsec_fp -
+		(LA_ST_LA_MINUS_SNAP_ARB_TO_ROW_SRT_EMCCLKS_FP +
+		 EXP_TIME_EMCCLKS_FP) /
+		(emc_freq_hz / LA_HZ_TO_MHZ_FACTOR);
+	la_bw_upper_bound_nsec_fp *= LA_USEC_TO_NSEC_FACTOR;
+	la_bw_upper_bound_nsec = LA_FP_TO_REAL(la_bw_upper_bound_nsec_fp);
+
+
+	la_nsec = min(la_bw_upper_bound_nsec,
+			(long long)MAX_LA_NSEC);
+
+	la_to_set = min((long long)(la_nsec/cs->ns_per_tick),
+			(long long)MC_LA_MAX_VALUE);
+
+	if ((la_to_set < t21x_min_la(&disp_params))
+		|| (la_to_set > MC_LA_MAX_VALUE))
+		return -1;
+
+	if (write_la)
+		program_la(ci, la_to_set);
+
+	return 0;
+}
+
+static int t21x_set_disp_la(enum tegra_la_id id,
+			    unsigned long emc_freq_hz,
+			    unsigned int bw_mbps,
+			    struct dc_to_la_params disp_params)
+{
+	return t21x_handle_disp_la(id, emc_freq_hz, bw_mbps, disp_params, 1);
+}
+
+static int t21x_check_disp_la(enum tegra_la_id id,
+			      unsigned long emc_freq_hz,
+			      unsigned int bw_mbps,
+			      struct dc_to_la_params disp_params)
+{
+	return t21x_handle_disp_la(id, emc_freq_hz, bw_mbps, disp_params, 0);
+}
+
+void program_scaled_la_t21x(struct la_client_info *ci, int la)
+{
+	unsigned long reg_write;
+
+	if (ci->id == ID(DISPLAY_0A)) {
+		reg_write =
+		     ((la << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0A_LOW_SHIFT) &
+		      MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0A_LOW_MASK) |
+		     ((la << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0A_HIGH_SHIFT) &
+		      MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0A_HIGH_MASK);
+		mc_writel(reg_write, MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0A);
+		la_debug("reg_addr=0x%x, write=0x%x",
+			 (u32)(uintptr_t)MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0A,
+			 (u32)reg_write);
+	} else if (ci->id == ID(DISPLAY_0AB)) {
+		reg_write =
+		    ((la << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0AB_LOW_SHIFT) &
+		     MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0AB_LOW_MASK) |
+		    ((la << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0AB_HIGH_SHIFT) &
+		     MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0AB_HIGH_MASK);
+		mc_writel(reg_write, MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0AB);
+		la_debug("reg_addr=0x%x, write=0x%x",
+			 (u32)(uintptr_t)MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0AB,
+			 (u32)reg_write);
+	} else if (ci->id == ID(DISPLAY_0B)) {
+		reg_write =
+		    ((la << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0B_LOW_SHIFT) &
+		     MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0B_LOW_MASK) |
+		    ((la << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0B_HIGH_SHIFT) &
+		     MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0B_HIGH_MASK);
+		mc_writel(reg_write, MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0B);
+		la_debug("reg_addr=0x%x, write=0x%x",
+			 (u32)(uintptr_t)MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0B,
+			 (u32)reg_write);
+	} else if (ci->id == ID(DISPLAY_0BB)) {
+		reg_write =
+		    ((la << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0BB_LOW_SHIFT) &
+		     MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0BB_LOW_MASK) |
+		    ((la << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0BB_HIGH_SHIFT) &
+		     MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0BB_HIGH_MASK);
+		mc_writel(reg_write, MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0BB);
+		la_debug("reg_addr=0x%x, write=0x%x",
+			 (u32)(uintptr_t)MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0BB,
+			 (u32)reg_write);
+	} else if (ci->id == ID(DISPLAY_0C)) {
+		reg_write =
+		    ((la << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0C_LOW_SHIFT) &
+		     MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0C_LOW_MASK) |
+		    ((la << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0C_HIGH_SHIFT) &
+		     MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0C_HIGH_MASK);
+		mc_writel(reg_write, MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0C);
+		la_debug("reg_addr=0x%x, write=0x%x",
+			 (u32)(uintptr_t)MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0C,
+			 (u32)reg_write);
+	} else if (ci->id == ID(DISPLAY_0CB)) {
+		reg_write =
+		    ((la << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0CB_LOW_SHIFT) &
+		     MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0CB_LOW_MASK) |
+		    ((la << MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0CB_HIGH_SHIFT) &
+		     MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0CB_HIGH_MASK);
+		mc_writel(reg_write, MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0CB);
+		la_debug("reg_addr=0x%x, write=0x%x",
+			 (u32)(uintptr_t)MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0CB,
+			 (u32)reg_write);
+	}
+}
+
+void tegra_la_get_t21x_specific(struct la_chip_specific *cs_la)
+{
+	int i = 0;
+
+	if (is_t210b01_soc()) {
+		/* Fixup t21x_la_info_array for t210b01 */
+		for (i = 0; i < ARRAY_SIZE(t21x_la_info_array); i++) {
+			if (t21x_la_info_array[i].id == ID(ISP_RA))
+				t21x_la_info_array[i].la_ref_clk_mhz = 600;
+			else if (t21x_la_info_array[i].id == ID(ISP_RAB))
+				t21x_la_info_array[i].la_ref_clk_mhz = 248;
+		}
+	}
+
+	cs_la->ns_per_tick = 30;
+	cs_la->atom_size = 64;
+	cs_la->la_max_value = MC_LA_MAX_VALUE;
+	cs_la->la_info_array = t21x_la_info_array;
+	cs_la->la_info_array_size = ARRAY_SIZE(t21x_la_info_array);
+
+	cs_la->la_params.fp_factor = LA_FP_FACTOR;
+	cs_la->la_params.la_real_to_fp = la_real_to_fp;
+	cs_la->la_params.la_fp_to_real = la_fp_to_real;
+	cs_la->la_params.static_la_minus_snap_arb_to_row_srt_emcclks_fp =
+			LA_ST_LA_MINUS_SNAP_ARB_TO_ROW_SRT_EMCCLKS_FP;
+	cs_la->la_params.dram_width_bits = LA_DRAM_WIDTH_BITS;
+	cs_la->la_params.disp_catchup_factor_fp = LA_DISP_CATCHUP_FACTOR_FP;
+
+	cs_la->init_ptsa = t21x_init_ptsa;
+	cs_la->update_display_ptsa_rate = t21x_update_display_ptsa_rate;
+	cs_la->update_camera_ptsa_rate = t21x_update_camera_ptsa_rate;
+	cs_la->set_init_la = t21x_set_la;
+	cs_la->set_dynamic_la = t21x_set_la;
+	cs_la->set_disp_la = t21x_set_disp_la;
+	cs_la->check_disp_la = t21x_check_disp_la;
+	cs_la->save_ptsa = save_ptsa;
+	cs_la->program_ptsa = program_ptsa;
+	cs_la->suspend = la_suspend;
+	cs_la->resume = la_resume;
+	cs = cs_la;
+
+	if (ON_LPDDR4()) {
+		emc_min_freq_mhz_fp = 25000;
+		emc_min_freq_mhz = 25;
+		emc_max_freq_mhz = 2132;
+		hi_gd_fp = 1500;
+		lo_gd_fp = 18;
+		hi_gd_fpa = 14998;
+		lo_gd_fpa = 176;
+		dda_div = 1;
+	} else {
+		emc_min_freq_mhz_fp = 12500;
+		emc_min_freq_mhz = 12;
+		emc_max_freq_mhz = 1200;
+		hi_gd_fp = 2000;
+		lo_gd_fp = 21;
+		hi_gd_fpa = 19998;
+		lo_gd_fpa = 208;
+		dda_div = 2;
+	}
+
+	low_freq_bw = emc_min_freq_mhz_fp * 2 * LA_DRAM_WIDTH_BITS / 8;
+	low_freq_bw /= 1000;
+	tegra_la_disp_clients_info = cs_la->disp_clients;
+
+	/* set some entries to zero */
+	for (i = 0; i < NUM_CAMERA_CLIENTS; i++)
+		cs_la->camera_bw_array[i] = 0;
+	for (i = 0; i < TEGRA_LA_AGG_CAMERA_NUM_CLIENTS; i++) {
+		cs_la->agg_camera_array[i].bw_fp = 0;
+		cs_la->agg_camera_array[i].frac_fp = 0;
+		cs_la->agg_camera_array[i].ptsa_min = 0;
+		cs_la->agg_camera_array[i].ptsa_max = 0;
+		cs_la->agg_camera_array[i].is_hiso = false;
+	}
+
+	/* set mccif_size_bytes values */
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_0A)].mccif_size_bytes = 6144;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_0B)].mccif_size_bytes = 6144;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_0C)].mccif_size_bytes =
+									11520;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAYD)].mccif_size_bytes = 4672;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_T)].mccif_size_bytes = 4672;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_HC)].mccif_size_bytes = 4992;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_0AB)].mccif_size_bytes =
+									11520;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_0BB)].mccif_size_bytes =
+									6144;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_0CB)].mccif_size_bytes =
+									6144;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_HCB)].mccif_size_bytes =
+									4992;
+
+	/* set line_buf_sz_bytes values */
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_0A)].line_buf_sz_bytes =
+									151552;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_0B)].line_buf_sz_bytes =
+									112640;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_0C)].line_buf_sz_bytes =
+									112640;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAYD)].line_buf_sz_bytes = 18432;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_T)].line_buf_sz_bytes =
+									18432;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_HC)].line_buf_sz_bytes = 320;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_0AB)].line_buf_sz_bytes =
+									112640;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_0BB)].line_buf_sz_bytes =
+									112640;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_0CB)].line_buf_sz_bytes =
+									112640;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_HCB)].line_buf_sz_bytes =
+									320;
+
+	/* set win_type values */
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_0A)].win_type =
+						TEGRA_LA_DISP_WIN_TYPE_FULL;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_0B)].win_type =
+						TEGRA_LA_DISP_WIN_TYPE_FULLA;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_0C)].win_type =
+						TEGRA_LA_DISP_WIN_TYPE_FULLA;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAYD)].win_type =
+						TEGRA_LA_DISP_WIN_TYPE_SIMPLE;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_HC)].win_type =
+						TEGRA_LA_DISP_WIN_TYPE_CURSOR;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_T)].win_type =
+						TEGRA_LA_DISP_WIN_TYPE_SIMPLE;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_0AB)].win_type =
+						TEGRA_LA_DISP_WIN_TYPE_FULLB;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_0BB)].win_type =
+						TEGRA_LA_DISP_WIN_TYPE_FULLB;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_0CB)].win_type =
+						TEGRA_LA_DISP_WIN_TYPE_FULLB;
+	cs_la->disp_clients[DISP_CLIENT_ID(DISPLAY_HCB)].win_type =
+						TEGRA_LA_DISP_WIN_TYPE_CURSOR;
+}
diff --git a/drivers/platform/tegra/mc/tegra_emc_dt_parse.h b/drivers/platform/tegra/mc/tegra_emc_dt_parse.h
new file mode 100644
index 000000000000..3cbef4ae625f
--- /dev/null
+++ b/drivers/platform/tegra/mc/tegra_emc_dt_parse.h
@@ -0,0 +1,27 @@
+/*
+ * drivers/platform/tegra/mc/tegra_emc_dt_parse.h
+ *
+ * Copyright (c) 2013, NVIDIA CORPORATION.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+ */
+
+#ifndef __TEGRA_EMC_DT_PARSE_H__
+#define __TEGRA_EMC_DT_PARSE_H__
+
+void *tegra_emc_dt_parse_pdata(struct platform_device *pdev);
+
+#endif /* __TEGRA_EMC_DT_PARSE_H__ */
+
diff --git a/drivers/platform/tegra/mc/tegra_fd.c b/drivers/platform/tegra/mc/tegra_fd.c
new file mode 100644
index 000000000000..fbc019f9284b
--- /dev/null
+++ b/drivers/platform/tegra/mc/tegra_fd.c
@@ -0,0 +1,25 @@
+/*
+ * Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ */
+
+#include <linux/fdtable.h>
+#include <linux/fs.h>
+
+#include <linux/platform/tegra/tegra_fd.h>
+
+/* allocates a free fd within [start, sysctl_nr_open) range */
+int tegra_alloc_fd(struct files_struct *files, unsigned int start,
+		   unsigned int flags)
+{
+	return __alloc_fd(files, start, sysctl_nr_open, flags);
+}
+EXPORT_SYMBOL_GPL(tegra_alloc_fd);
diff --git a/drivers/platform/tegra/tegra-mce.c b/drivers/platform/tegra/tegra-mce.c
new file mode 100644
index 000000000000..edc1000cbdfb
--- /dev/null
+++ b/drivers/platform/tegra/tegra-mce.c
@@ -0,0 +1,855 @@
+/*
+ * Copyright (c) 2014-2019, NVIDIA CORPORATION.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ */
+
+#include <linux/debugfs.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/tegra-mce.h>
+
+#include <asm/cacheflush.h>
+#include <asm/smp_plat.h>
+#include <soc/tegra/fuse.h>
+
+#include "tegra18x-mce.h"
+#include "tegra19x-mce.h"
+
+#define SMC_SIP_INVOKE_MCE	0xC2FFFF00
+
+#define NR_SMC_REGS		6
+
+enum {
+	TEGRA_MCE_ID_186,
+	TEGRA_MCE_ID_194,
+	TEGRA_MCE_ID_MAX,
+};
+
+static int tegra_mce_id = TEGRA_MCE_ID_MAX;
+
+static int (*_tegra_mce_enter_cstate)(u32, u32);
+static int (*_tegra_mce_update_cstate_info)(u32, u32, u32, u8, u32, bool);
+static int (*_tegra_mce_update_crossover_time)(u32, u32);
+static int (*_tegra_mce_read_cstate_stats)(u32, u64 *);
+static int (*_tegra_mce_write_cstate_stats)(u32, u32);
+static int (*_tegra_mce_is_sc7_allowed)(u32, u32, u32 *);
+static int (*_tegra_mce_online_core)(int);
+static int (*_tegra_mce_cc3_ctrl)(u32, u32, u8);
+static int (*_tegra_mce_echo_data)(u32, int *);
+static int (*_tegra_mce_read_versions)(u32 *, u32 *);
+static int (*_tegra_mce_enum_features)(u64 *);
+static int (*_tegra_mce_read_uncore_mca)(mca_cmd_t, u64 *, u32 *);
+static int (*_tegra_mce_write_uncore_mca)(mca_cmd_t, u64, u32 *);
+static int (*_tegra_mce_read_uncore_perfmon)(u32, u32 *);
+static int (*_tegra_mce_write_uncore_perfmon)(u32, u32);
+static int (*_tegra_mce_enable_latic)(void);
+static int (*_tegra_mce_write_dda_ctrl)(u32 index, u64 value);
+static int (*_tegra_mce_read_dda_ctrl)(u32 index, u64 *value);
+static int (*_tegra_mce_read_l3_cache_ways)(u64 *value);
+static int (*_tegra_mce_write_l3_cache_ways)(u64 data, u64 *value);
+static int (*_tegra_mce_read_rt_safe_mask)(u64 *);
+static int (*_tegra_mce_write_rt_safe_mask)(u64);
+static int (*_tegra_mce_read_rt_window_us)(u64 *);
+static int (*_tegra_mce_write_rt_window_us)(u64);
+static int (*_tegra_mce_read_rt_fwd_progress_us)(u64 *);
+static int (*_tegra_mce_write_rt_fwd_progress_us)(u64);
+/**
+ * Specify power state and wake time for entering upon STANDBYWFI
+ *
+ * @state:		requested core power state
+ * @wake_time:	wake time in TSC ticks
+ *
+ * Returns 0 if success.
+ */
+int tegra_mce_enter_cstate(u32 state, u32 wake_time)
+{
+	if (!_tegra_mce_enter_cstate)
+		return -ENOTSUPP;
+	return _tegra_mce_enter_cstate(state, wake_time);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_enter_cstate);
+
+/**
+ * Specify deepest cluster/ccplex/system states allowed.
+ *
+ * @cluster:	deepest cluster-wide state
+ * @ccplex:		deepest ccplex-wide state
+ * @system:		deepest system-wide state
+ * @force:		forced system state
+ * @wake_mask:	wake mask to be updated
+ * @valid:		is wake_mask applicable?
+ *
+ * Returns 0 if success.
+ */
+int tegra_mce_update_cstate_info(u32 cluster, u32 ccplex, u32 system,
+				 u8 force, u32 wake_mask, bool valid)
+{
+	if (!_tegra_mce_update_cstate_info)
+		return -ENOTSUPP;
+	return _tegra_mce_update_cstate_info(cluster, ccplex, system,
+					     force, wake_mask, valid);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_update_cstate_info);
+
+/**
+ * Update threshold for one specific c-state crossover
+ *
+ * @type: type of state crossover.
+ * @time: idle time threshold.
+ *
+ * Returns 0 if success.
+ */
+int tegra_mce_update_crossover_time(u32 type, u32 time)
+{
+	if (!_tegra_mce_update_crossover_time)
+		return -ENOTSUPP;
+	return _tegra_mce_update_crossover_time(type, time);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_update_crossover_time);
+
+/**
+ * Query the runtime stats of a specific cstate
+ *
+ * @state: c-state of the stats.
+ * @stats: output integer to hold the stats.
+ *
+ * Returns 0 if success.
+ */
+int tegra_mce_read_cstate_stats(u32 state, u64 *stats)
+{
+	if (!_tegra_mce_read_cstate_stats)
+		return -ENOTSUPP;
+	return _tegra_mce_read_cstate_stats(state, stats);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_read_cstate_stats);
+
+/**
+ * Overwrite the runtime stats of a specific c-state
+ *
+ * @state: c-state of the stats.
+ * @stats: integer represents the new stats.
+ *
+ * Returns 0 if success.
+ */
+int tegra_mce_write_cstate_stats(u32 state, u32 stats)
+{
+	if (!_tegra_mce_write_cstate_stats)
+		return -ENOTSUPP;
+	return _tegra_mce_write_cstate_stats(state, stats);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_write_cstate_stats);
+
+/**
+ * Query MCE to determine if SC7 is allowed
+ * given a target core's C-state and wake time
+ *
+ * @state: c-state of the stats.
+ * @stats: integer represents the new stats.
+ * @allowed: pointer to result
+ *
+ * Returns 0 if success.
+ */
+int tegra_mce_is_sc7_allowed(u32 state, u32 wake, u32 *allowed)
+{
+	if (!_tegra_mce_is_sc7_allowed)
+		return -ENOTSUPP;
+	return _tegra_mce_is_sc7_allowed(state, wake, allowed);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_is_sc7_allowed);
+
+/**
+ * Bring another offlined core back online to C0 state.
+ *
+ * @cpu: logical cpuid from smp_processor_id()
+ *
+ * Returns 0 if success.
+ */
+int tegra_mce_online_core(int cpu)
+{
+	if (!_tegra_mce_online_core)
+		return -ENOTSUPP;
+	return _tegra_mce_online_core(cpu);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_online_core);
+
+/**
+ * Program Auto-CC3 feature.
+ *
+ * @ndiv:		ndiv of IDLE voltage/freq register
+ * @vindex:		vindex of IDLE voltage/freq register
+ *			(Not used on tegra19x)
+ * @enable:		enable bit for Auto-CC3
+ *
+ * Returns 0 if success.
+ */
+int tegra_mce_cc3_ctrl(u32 ndiv, u32 vindex, u8 enable)
+{
+	if (!_tegra_mce_cc3_ctrl)
+		return -ENOTSUPP;
+	return _tegra_mce_cc3_ctrl(ndiv, vindex, enable);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_cc3_ctrl);
+
+/**
+ * Send data to MCE which echoes it back.
+ *
+ * @data: data to be sent to MCE.
+ * @out: output data to hold the response.
+ * @matched: pointer to matching result
+ *
+ * Returns 0 if success.
+ */
+int tegra_mce_echo_data(u32 data, int *matched)
+{
+	if (!_tegra_mce_echo_data)
+		return -ENOTSUPP;
+	return _tegra_mce_echo_data(data, matched);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_echo_data);
+
+/**
+ * Read out MCE API major/minor versions
+ *
+ * @major: output for major number.
+ * @minor: output for minor number.
+ *
+ * Returns 0 if success.
+ */
+int tegra_mce_read_versions(u32 *major, u32 *minor)
+{
+	if (!_tegra_mce_read_versions)
+		return -ENOTSUPP;
+	return _tegra_mce_read_versions(major, minor);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_read_versions);
+
+/**
+ * Read out RT Safe Mask
+ *
+ * @rt_safe_mask: output for rt safe mask.
+ *
+ * Returns 0 if success.
+ */
+int tegra_mce_read_rt_safe_mask(u64 *rt_safe_mask)
+{
+	if (!_tegra_mce_read_rt_safe_mask)
+		return -ENOTSUPP;
+	return _tegra_mce_read_rt_safe_mask(rt_safe_mask);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_read_rt_safe_mask);
+
+/**
+ * Write RT Safe Mask
+ *
+ * @rt_safe_mask: rt safe mask value to be written
+ *
+ * Returns 0 if success.
+ */
+int tegra_mce_write_rt_safe_mask(u64 rt_safe_mask)
+{
+	if (!_tegra_mce_write_rt_safe_mask)
+		return -ENOTSUPP;
+	return _tegra_mce_write_rt_safe_mask(rt_safe_mask);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_write_rt_safe_mask);
+
+/**
+ * Read out RT Window US
+ *
+ * @rt_window_us: output for rt window us
+ *
+ * Returns 0 if success.
+ */
+int tegra_mce_read_rt_window_us(u64 *rt_window_us)
+{
+	if (!_tegra_mce_read_rt_window_us)
+		return -ENOTSUPP;
+	return _tegra_mce_read_rt_window_us(rt_window_us);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_read_rt_window_us);
+
+
+/**
+ * Write RT Window US
+ *
+ * @rt_window_us: rt window us value to be written
+ *
+ * Returns 0 if success.
+ */
+int tegra_mce_write_rt_window_us(u64 rt_window_us)
+{
+	if (!_tegra_mce_write_rt_window_us)
+		return -ENOTSUPP;
+	return _tegra_mce_write_rt_window_us(rt_window_us);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_write_rt_window_us);
+
+
+/**
+ * Read out RT Fwd Progress US
+ *
+ * @rt_fwd_progress_us: output for rt fwd progress us
+ *
+ * Returns 0 if success.
+ */
+int tegra_mce_read_rt_fwd_progress_us(u64 *rt_fwd_progress_us)
+{
+	if (!_tegra_mce_read_rt_fwd_progress_us)
+		return -ENOTSUPP;
+	return _tegra_mce_read_rt_fwd_progress_us(rt_fwd_progress_us);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_read_rt_fwd_progress_us);
+
+
+/**
+ * Write RT Fwd Progress US
+ *
+ * @rt_fwd_progress_us: rt fwd progress us value to be written
+ *
+ * Returns 0 if success.
+ */
+int tegra_mce_write_rt_fwd_progress_us(u64 rt_fwd_progress_us)
+{
+	if (!_tegra_mce_write_rt_fwd_progress_us)
+		return -ENOTSUPP;
+	return _tegra_mce_write_rt_fwd_progress_us(rt_fwd_progress_us);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_write_rt_fwd_progress_us);
+
+
+/**
+ * Enumerate MCE API features
+ *
+ * @features: output feature vector (4bits each)
+ *
+ * Returns 0 if success.
+ */
+int tegra_mce_enum_features(u64 *features)
+{
+	if (!_tegra_mce_enum_features)
+		return -ENOTSUPP;
+	return _tegra_mce_enum_features(features);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_enum_features);
+
+/**
+ * Read uncore MCA errors.
+ *
+ * @cmd: MCA command
+ * @data: output data for the command
+ * @error: error from MCA
+ *
+ * Returns 0 if success.
+ */
+int tegra_mce_read_uncore_mca(mca_cmd_t cmd, u64 *data, u32 *error)
+{
+	if (!_tegra_mce_read_uncore_mca)
+		return -ENOTSUPP;
+	return _tegra_mce_read_uncore_mca(cmd, data, error);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_read_uncore_mca);
+
+/**
+ * Write uncore MCA errors.
+ *
+ * @cmd: MCA command
+ * @data: input data for the command
+ * @error: error from MCA
+ *
+ * Returns 0 if success.
+ */
+int tegra_mce_write_uncore_mca(mca_cmd_t cmd, u64 data, u32 *error)
+{
+	if (!_tegra_mce_write_uncore_mca)
+		return -ENOTSUPP;
+	return _tegra_mce_write_uncore_mca(cmd, data, error);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_write_uncore_mca);
+
+/**
+ * Query PMU for uncore perfmon counter
+ *
+ * @req input command and counter index
+ * @data output counter value
+ *
+ * Returns status of read request.
+ */
+int tegra_mce_read_uncore_perfmon(u32 req, u32 *data)
+{
+	if (!_tegra_mce_read_uncore_perfmon)
+		return -ENOTSUPP;
+	return _tegra_mce_read_uncore_perfmon(req, data);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_read_uncore_perfmon);
+
+/**
+ * Write PMU reg for uncore perfmon counter
+ *
+ * @req input command and counter index
+ * @data data to be written
+ *
+ * Returns status of write request.
+ */
+int tegra_mce_write_uncore_perfmon(u32 req, u32 data)
+{
+	if (!_tegra_mce_write_uncore_perfmon)
+		return -ENOTSUPP;
+	return _tegra_mce_write_uncore_perfmon(req, data);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_write_uncore_perfmon);
+
+int tegra_mce_enable_latic(void)
+{
+	if (!_tegra_mce_enable_latic)
+		return -ENOTSUPP;
+	return _tegra_mce_enable_latic();
+}
+EXPORT_SYMBOL_GPL(tegra_mce_enable_latic);
+
+/**
+ * Write to NVG DDA registers
+ *
+ * @index:   NVG communication channel id
+ * @value:   Register value to be written
+ *
+ * Returns 0 on success
+ */
+int tegra_mce_write_dda_ctrl(u32 index, u64 value)
+{
+	if(!_tegra_mce_write_dda_ctrl)
+		return -ENOTSUPP;
+	return _tegra_mce_write_dda_ctrl(index, value);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_write_dda_ctrl);
+
+/**
+ * Read NVG DDA registers
+ *
+ * @index:   NVG communication channel id
+ * @value:   Associated register value read
+ *
+ * Returns 0 on success
+ */
+int tegra_mce_read_dda_ctrl(u32 index, u64 *value)
+{
+	if(!_tegra_mce_read_dda_ctrl)
+		return -ENOTSUPP;
+	return _tegra_mce_read_dda_ctrl(index, value);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_read_dda_ctrl);
+
+/**
+ * Read NVG L3 cache control register
+ *
+ * @value:   Fill L3 cache ways
+ *
+ * Returns 0 on success
+ */
+int tegra_mce_read_l3_cache_ways(u64 *value)
+{
+	if (!_tegra_mce_read_l3_cache_ways)
+		return -ENOTSUPP;
+	return _tegra_mce_read_l3_cache_ways(value);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_read_l3_cache_ways);
+
+/**
+ * Write L3 cache ways and read back the l3 cache ways written
+ *
+ * @data:   L3 cache ways to be writtein
+ * @value:  L3 cache ways returrned back
+ *
+ * Returns 0 on success
+ */
+int tegra_mce_write_l3_cache_ways(u64 data, u64 *value)
+{
+	if (!_tegra_mce_write_l3_cache_ways)
+		return -ENOTSUPP;
+	return _tegra_mce_write_l3_cache_ways(data, value);
+}
+EXPORT_SYMBOL_GPL(tegra_mce_write_l3_cache_ways);
+
+#ifdef CONFIG_DEBUG_FS
+static struct dentry *mce_debugfs;
+
+static int tegra_mce_echo_set(void *data, u64 val)
+{
+	u32 matched;
+	int ret;
+
+	ret = tegra_mce_echo_data((u32)val, &matched);
+	if (ret && ret != -ENOTSUPP)
+		return -EINVAL;
+	return 0;
+}
+
+static int tegra_mce_versions_get(void *data, u64 *val)
+{
+	u32 major, minor;
+	int ret;
+
+	ret = tegra_mce_read_versions(&major, &minor);
+	if (!ret)
+		*val = ((u64)major << 32) | minor;
+	return ret;
+}
+
+static int tegra_mce_rt_safe_mask_get(void *data, u64 *val)
+{
+	u64 rt_safe_mask;
+	int ret;
+
+	ret = tegra_mce_read_rt_safe_mask(&rt_safe_mask);
+	if (!ret)
+		*val = rt_safe_mask;
+	return ret;
+}
+
+static int tegra_mce_rt_safe_mask_set(void *data, u64 val)
+{
+	int ret;
+
+	ret = tegra_mce_write_rt_safe_mask(val);
+	return ret;
+}
+
+static int tegra_mce_rt_window_us_get(void *data, u64 *val)
+{
+	u64 rt_window_us;
+	int ret;
+
+	ret = tegra_mce_read_rt_window_us(&rt_window_us);
+	if (!ret)
+		*val = rt_window_us;
+	return ret;
+}
+
+static int tegra_mce_rt_window_us_set(void *data, u64 val)
+{
+	int ret;
+
+	ret = tegra_mce_write_rt_window_us(val);
+	return ret;
+}
+
+static int tegra_mce_rt_fwd_progress_us_get(void *data, u64 *val)
+{
+	u64 rt_fwd_progress_us;
+	int ret;
+
+	ret = tegra_mce_read_rt_fwd_progress_us(&rt_fwd_progress_us);
+	if (!ret)
+		*val = rt_fwd_progress_us;
+	return ret;
+}
+
+static int tegra_mce_rt_fwd_progress_us_set(void *data, u64 val)
+{
+	int ret;
+
+	ret = tegra_mce_write_rt_fwd_progress_us(val);
+	return ret;
+}
+
+#define TEGRA_MCE_DBGFS_FUNC(name, type1, param1, type2, param2)	\
+static int tegra_##name(type1 param1, type2 param2)			\
+{									\
+	int (*f)(type1, type2) = NULL;					\
+									\
+	switch (tegra_mce_id) {						\
+	case TEGRA_MCE_ID_186:						\
+		f = tegra18x_##name;					\
+		break;							\
+	case TEGRA_MCE_ID_194:						\
+		f = tegra19x_##name;					\
+		break;							\
+	default:							\
+		return -ENOTSUPP;					\
+	}								\
+	return f ? f(param1, param2) : -ENOTSUPP;			\
+}
+
+TEGRA_MCE_DBGFS_FUNC(mce_features_get, void *, data, u64 *, val);
+TEGRA_MCE_DBGFS_FUNC(mce_enable_latic_set, void *, data, u64, val);
+TEGRA_MCE_DBGFS_FUNC(mce_coresight_cg_set, void *, data, u64, val);
+TEGRA_MCE_DBGFS_FUNC(mce_edbgreq_set, void *, data, u64, val);
+
+static int tegra_mce_dbg_cstats_open(struct inode *inode, struct file *file)
+{
+	int (*f)(struct seq_file *, void *);
+
+	switch (tegra_mce_id) {
+	case TEGRA_MCE_ID_186:
+		f = tegra18x_mce_dbg_cstats_show;
+		break;
+	case TEGRA_MCE_ID_194:
+		f = tegra19x_mce_dbg_cstats_show;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return single_open(file, f, inode->i_private);
+}
+
+static const struct file_operations tegra_mce_cstats_fops = {
+	.open = tegra_mce_dbg_cstats_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = single_release,
+};
+
+DEFINE_SIMPLE_ATTRIBUTE(tegra_mce_echo_fops, NULL,
+			tegra_mce_echo_set, "%llu\n");
+DEFINE_SIMPLE_ATTRIBUTE(tegra_mce_versions_fops, tegra_mce_versions_get,
+			NULL, "%llu\n");
+DEFINE_SIMPLE_ATTRIBUTE(tegra_mce_features_fops, tegra_mce_features_get,
+			NULL, "%llu\n");
+DEFINE_SIMPLE_ATTRIBUTE(tegra_mce_enable_latic_fops, NULL,
+			tegra_mce_enable_latic_set, "%llu\n");
+DEFINE_SIMPLE_ATTRIBUTE(tegra_mce_coresight_cg_fops, NULL,
+			tegra_mce_coresight_cg_set, "%llu\n");
+DEFINE_SIMPLE_ATTRIBUTE(tegra_mce_edbgreq_fops, NULL,
+			tegra_mce_edbgreq_set, "%llu\n");
+DEFINE_SIMPLE_ATTRIBUTE(tegra_mce_rt_safe_mask_fops, tegra_mce_rt_safe_mask_get,
+			tegra_mce_rt_safe_mask_set, "%llu\n");
+DEFINE_SIMPLE_ATTRIBUTE(tegra_mce_rt_window_us_fops, tegra_mce_rt_window_us_get,
+			tegra_mce_rt_window_us_set, "%llu\n");
+DEFINE_SIMPLE_ATTRIBUTE(tegra_mce_rt_fwd_progress_us_fops,
+			tegra_mce_rt_fwd_progress_us_get,
+			tegra_mce_rt_fwd_progress_us_set, "%llu\n");
+
+struct debugfs_entry {
+	const char *name;
+	const struct file_operations *fops;
+	mode_t mode;
+};
+
+/* Make sure to put an NULL entry at the end of each group */
+static struct debugfs_entry tegra18x_mce_attrs[] = {
+	{ "echo", &tegra_mce_echo_fops, 0200 },
+	{ "versions", &tegra_mce_versions_fops, 0444 },
+	{ "features", &tegra_mce_features_fops, 0444 },
+	{ "cstats", &tegra_mce_cstats_fops, 0444 },
+	{ "enable-latic", &tegra_mce_enable_latic_fops, 0200 },
+	{ "coresight_cg_enable", &tegra_mce_coresight_cg_fops, 0200 },
+	{ "edbgreq", &tegra_mce_edbgreq_fops, 0200 },
+	{ NULL, NULL, 0 },
+};
+
+static struct debugfs_entry tegra19x_mce_attrs[] = {
+	{ "versions", &tegra_mce_versions_fops, 0444 },
+	{ "cstats", &tegra_mce_cstats_fops, 0444 },
+	{ "rt_safe_mask", &tegra_mce_rt_safe_mask_fops, 0644 },
+	{ "rt_window_us", &tegra_mce_rt_window_us_fops, 0644 },
+	{ "rt_fwd_progress_us", &tegra_mce_rt_fwd_progress_us_fops, 0644 },
+	{ NULL, NULL, 0 }
+};
+
+static struct debugfs_entry *tegra_mce_attrs[TEGRA_MCE_ID_MAX] = {
+	tegra18x_mce_attrs,
+	tegra19x_mce_attrs,
+};
+
+static __init int tegra_mce_init(void)
+{
+	struct debugfs_entry *fent;
+	struct dentry *dent;
+	int ret;
+
+	if (tegra_mce_id >= TEGRA_MCE_ID_MAX)
+		return -ENOTSUPP;
+
+	mce_debugfs = debugfs_create_dir("tegra_mce", NULL);
+	if (!mce_debugfs)
+		return -ENOMEM;
+
+	for (fent = tegra_mce_attrs[tegra_mce_id]; fent->name; fent++) {
+		dent = debugfs_create_file(fent->name, fent->mode,
+					   mce_debugfs, NULL, fent->fops);
+		if (IS_ERR_OR_NULL(dent)) {
+			ret = dent ? PTR_ERR(dent) : -EINVAL;
+			pr_err("%s: failed to create debugfs (%s): %d\n",
+			       __func__, fent->name, ret);
+			goto err;
+		}
+	}
+
+	pr_debug("%s: init finished\n", __func__);
+
+	return 0;
+
+err:
+	debugfs_remove_recursive(mce_debugfs);
+
+	return ret;
+}
+
+static void __exit tegra_mce_exit(void)
+{
+	if (tegra_mce_id >= TEGRA_MCE_ID_MAX)
+		return;
+
+	debugfs_remove_recursive(mce_debugfs);
+}
+module_init(tegra_mce_init);
+module_exit(tegra_mce_exit);
+#endif /* CONFIG_DEBUG_FS */
+
+/*
+ * Tegra cache functions
+ *
+ * Return 0 if success or -ENOTSUPP.
+ *
+ */
+int tegra_flush_cache_all(void)
+{
+	int ret = 0;
+
+	switch (tegra_get_chip_id()) {
+	case TEGRA186:
+		ret = tegra18x_roc_flush_cache();
+		break;
+	case TEGRA194:
+		ret = t19x_flush_cache_all();
+		/* Fallback to VA flush cache all if not support or failed */
+		if (ret)
+			flush_cache_all();
+		break;
+	default:
+		flush_cache_all();
+		break;
+	}
+
+	/* CRITICAL: failed to flush all cache */
+	WARN_ON(ret && ret != -ENOTSUPP);
+
+	return ret;
+}
+EXPORT_SYMBOL(tegra_flush_cache_all);
+
+int tegra_flush_dcache_all(void *__maybe_unused unused)
+{
+	int ret = 0;
+
+	switch (tegra_get_chip_id()) {
+	case TEGRA186:
+		ret = tegra18x_roc_flush_cache_only();
+		break;
+	case TEGRA194:
+		ret = t19x_flush_dcache_all();
+		/* Fallback to VA flush dcache if not support or failed */
+		if (ret)
+			__flush_dcache_all(unused);
+		break;
+	default:
+		__flush_dcache_all(unused);
+		break;
+	}
+
+	/* CRITICAL: failed to flush dcache */
+	WARN_ON(ret && ret != -ENOTSUPP);
+
+	return ret;
+}
+EXPORT_SYMBOL(tegra_flush_dcache_all);
+
+int tegra_clean_dcache_all(void *__maybe_unused unused)
+{
+	int ret = 0;
+
+	switch (tegra_get_chip_id()) {
+	case TEGRA186:
+		ret = tegra18x_roc_clean_cache();
+		break;
+	case TEGRA194:
+		ret = t19x_clean_dcache_all();
+		/* Fallback to VA clean if not support or failed */
+		if (ret)
+			__clean_dcache_all(unused);
+		break;
+	default:
+		__clean_dcache_all(unused);
+		break;
+	}
+
+	/* CRITICAL: failed to clean dcache */
+	WARN_ON(ret && ret != -ENOTSUPP);
+
+	return ret;
+}
+EXPORT_SYMBOL(tegra_clean_dcache_all);
+
+/* Make sure functions will be available for other drivers */
+static __init int tegra_mce_early_init(void)
+{
+	switch (tegra_get_chip_id()) {
+	case TEGRA186:
+		tegra_mce_id = TEGRA_MCE_ID_186;
+		_tegra_mce_enter_cstate = tegra18x_mce_enter_cstate;
+		_tegra_mce_update_cstate_info = tegra18x_mce_update_cstate_info;
+		_tegra_mce_update_crossover_time =
+			tegra18x_mce_update_crossover_time;
+		_tegra_mce_read_cstate_stats = tegra18x_mce_read_cstate_stats;
+		_tegra_mce_write_cstate_stats = tegra18x_mce_write_cstate_stats;
+		_tegra_mce_is_sc7_allowed = tegra18x_mce_is_sc7_allowed;
+		_tegra_mce_online_core = tegra18x_mce_online_core;
+		_tegra_mce_cc3_ctrl = tegra18x_mce_cc3_ctrl;
+		_tegra_mce_echo_data = tegra18x_mce_echo_data;
+		_tegra_mce_read_versions = tegra18x_mce_read_versions;
+		_tegra_mce_enum_features = tegra18x_mce_enum_features;
+		_tegra_mce_read_uncore_mca = tegra18x_mce_read_uncore_mca;
+		_tegra_mce_write_uncore_mca = tegra18x_mce_write_uncore_mca;
+		_tegra_mce_read_uncore_perfmon =
+			tegra18x_mce_read_uncore_perfmon;
+		_tegra_mce_write_uncore_perfmon =
+			tegra18x_mce_write_uncore_perfmon;
+		_tegra_mce_enable_latic = tegra18x_mce_enable_latic;
+		break;
+	case TEGRA194:
+		tegra_mce_id = TEGRA_MCE_ID_194;
+		_tegra_mce_enter_cstate = tegra19x_mce_enter_cstate;
+		_tegra_mce_update_cstate_info = tegra19x_mce_update_cstate_info;
+		_tegra_mce_update_crossover_time =
+			tegra19x_mce_update_crossover_time;
+		_tegra_mce_read_cstate_stats = tegra19x_mce_read_cstate_stats;
+		_tegra_mce_cc3_ctrl = tegra19x_mce_cc3_ctrl;
+		_tegra_mce_read_versions = tegra19x_mce_read_versions;
+		_tegra_mce_write_dda_ctrl = tegra19x_mce_write_dda_ctrl;
+		_tegra_mce_read_dda_ctrl = tegra19x_mce_read_dda_ctrl;
+		_tegra_mce_read_l3_cache_ways = tegra19x_mce_read_l3_cache_ways;
+		_tegra_mce_write_l3_cache_ways =
+			tegra19x_mce_write_l3_cache_ways;
+#ifdef CONFIG_ARCH_TEGRA_19x_SOC
+#ifdef CONFIG_DEBUG_FS
+		_tegra_mce_read_rt_safe_mask = tegra19x_mce_read_rt_safe_mask;
+		_tegra_mce_write_rt_safe_mask = tegra19x_mce_write_rt_safe_mask;
+		_tegra_mce_read_rt_window_us = tegra19x_mce_read_rt_window_us;
+		_tegra_mce_write_rt_window_us = tegra19x_mce_write_rt_window_us;
+		_tegra_mce_read_rt_fwd_progress_us =
+			tegra19x_mce_read_rt_fwd_progress_us;
+		_tegra_mce_write_rt_fwd_progress_us =
+			tegra19x_mce_write_rt_fwd_progress_us;
+#endif /* CONFIG_DEBUG_FS */
+#endif
+		break;
+	default:
+		/* Do not support any other platform */
+		return -ENOTSUPP;
+	}
+
+	return 0;
+}
+early_initcall(tegra_mce_early_init);
+
+MODULE_DESCRIPTION("NVIDIA Tegra MCE driver");
+MODULE_AUTHOR("NVIDIA Corporation");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/platform/tegra/tegra18x-mce.h b/drivers/platform/tegra/tegra18x-mce.h
new file mode 100644
index 000000000000..270970068043
--- /dev/null
+++ b/drivers/platform/tegra/tegra18x-mce.h
@@ -0,0 +1,155 @@
+/*
+ * Copyright (c) 2017-2018, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#ifndef _LINUX_TEGRA18X_MCE_H
+#define _LINUX_TEGRA18X_MCE_H
+
+#ifdef CONFIG_ARCH_TEGRA_18x_SOC
+int tegra18x_mce_enter_cstate(u32 state, u32 wake_time);
+int tegra18x_mce_update_cstate_info(u32 cluster, u32 ccplex, u32 system,
+				    u8 force, u32 wake_mask, bool valid);
+int tegra18x_mce_update_crossover_time(u32 type, u32 time);
+int tegra18x_mce_read_cstate_stats(u32 state, u64 *stats);
+int tegra18x_mce_write_cstate_stats(u32 state, u32 stats);
+int tegra18x_mce_is_sc7_allowed(u32 state, u32 wake, u32 *allowed);
+int tegra18x_mce_online_core(int cpu);
+int tegra18x_mce_cc3_ctrl(u32 ndiv, u32 vindex, u8 enable);
+int tegra18x_mce_echo_data(u32 data, int *matched);
+int tegra18x_mce_read_versions(u32 *major, u32 *minor);
+int tegra18x_mce_enum_features(u64 *features);
+int tegra18x_mce_read_uncore_mca(mca_cmd_t cmd, u64 *data, u32 *error);
+int tegra18x_mce_write_uncore_mca(mca_cmd_t cmd, u64 data, u32 *error);
+int tegra18x_mce_read_uncore_perfmon(u32 req, u32 *data);
+int tegra18x_mce_write_uncore_perfmon(u32 req, u32 data);
+int tegra18x_mce_enable_latic(void);
+
+#ifdef CONFIG_DEBUG_FS
+int tegra18x_mce_features_get(void *data, u64 *val);
+int tegra18x_mce_enable_latic_set(void *data, u64 val);
+int tegra18x_mce_coresight_cg_set(void *data, u64 val);
+int tegra18x_mce_edbgreq_set(void *data, u64 val);
+int tegra18x_mce_dbg_cstats_show(struct seq_file *s, void *data);
+#endif /* CONFIG_DEBUG_FS */
+
+/* Tegra18x cache functions */
+int tegra18x_roc_flush_cache(void);
+int tegra18x_roc_flush_cache_only(void);
+int tegra18x_roc_clean_cache(void);
+#else /* CONFIG_ARCH_TEGRA_18x_SOC */
+static int tegra18x_mce_enter_cstate(u32 state, u32 wake_time)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_mce_update_cstate_info(u32 cluster, u32 ccplex, u32 system,
+					   u8 force, u32 wake_mask, bool valid)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_mce_update_crossover_time(u32 type, u32 time)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_mce_read_cstate_stats(u32 state, u64 *stats)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_mce_write_cstate_stats(u32 state, u32 stats)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_mce_is_sc7_allowed(u32 state, u32 wake, u32 *allowed)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_mce_online_core(int cpu)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_mce_cc3_ctrl(u32 ndiv, u32 vindex, u8 enable)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_mce_echo_data(u32 data, int *matched)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_mce_read_versions(u32 *major, u32 *minor)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_mce_enum_features(u64 *features)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_mce_read_uncore_mca(mca_cmd_t cmd, u64 *data, u32 *error)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_mce_write_uncore_mca(mca_cmd_t cmd, u64 data, u32 *error)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_mce_read_uncore_perfmon(u32 req, u32 *data)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_mce_write_uncore_perfmon(u32 req, u32 data)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_mce_enable_latic(void)
+{
+	return -ENOTSUPP;
+}
+
+#ifdef CONFIG_DEBUG_FS
+static int tegra18x_mce_features_get(void *data, u64 *val)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_mce_enable_latic_set(void *data, u64 val)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_mce_coresight_cg_set(void *data, u64 val)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_mce_edbgreq_set(void *data, u64 val)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_mce_dbg_cstats_show(struct seq_file *s, void *data)
+{
+	return -ENOTSUPP;
+}
+#endif /* CONFIG_DEBUG_FS */
+
+/* Tegra18x cache functions */
+static int tegra18x_roc_flush_cache(void)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_roc_flush_cache_only(void)
+{
+	return -ENOTSUPP;
+}
+static int tegra18x_roc_clean_cache(void)
+{
+	return -ENOTSUPP;
+}
+#endif /* CONFIG_ARCH_TEGRA_18x_SOC */
+#endif /* _LINUX_TEGRA18X_MCE_H */
diff --git a/drivers/platform/tegra/tegra19x-mce.c b/drivers/platform/tegra/tegra19x-mce.c
new file mode 100644
index 000000000000..a2edef084821
--- /dev/null
+++ b/drivers/platform/tegra/tegra19x-mce.c
@@ -0,0 +1,438 @@
+/*
+ * Copyright (c) 2017-2019, NVIDIA CORPORATION.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ */
+
+#include <linux/debugfs.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/t194_nvg.h>
+#include <linux/tegra-mce.h>
+
+#include <asm/smp_plat.h>
+#include <soc/tegra/fuse.h>
+#include "tegra19x-mce.h"
+
+#include "dmce_perfmon.h"
+
+/* Issue a NVG request with data */
+static noinline notrace void nvg_send_req_data(uint64_t req, uint64_t data)
+{
+	asm volatile (
+		"msr s3_0_c15_c1_2, %0	\n"
+		"msr s3_0_c15_c1_3, %1	\n"
+		:: "r" (req), "r" (data));
+}
+
+/* Issue a NVG request with no data */
+static noinline notrace void nvg_send_req(uint64_t req)
+{
+	asm volatile ("msr s3_0_c15_c1_2, %0	\n" :: "r" (req));
+}
+
+/* Issue a NVG request to read the command response */
+static noinline notrace uint64_t nvg_get_response(void)
+{
+	uint64_t ret;
+
+	asm volatile ("mrs %0, s3_0_c15_c1_3" : "=r" (ret));
+
+	return ret;
+}
+
+int tegra19x_mce_enter_cstate(u32 state, u32 wake_time)
+{
+	/* use PSCI interface instead */
+	return 0;
+}
+
+int tegra19x_mce_update_cstate_info(u32 cluster, u32 ccplex, u32 system,
+				    u8 force, u32 wake_mask, bool valid)
+{
+	nvg_cstate_info_channel_t cstate_info = { 0 };
+
+	/* disable preemption */
+	preempt_disable();
+
+	/* update CLUSTER_CSTATE? */
+	if (cluster) {
+		cstate_info.bits.cluster_state = cluster;
+		cstate_info.bits.update_cluster = 1;
+	}
+
+	/* update CCPLEX_CSTATE? */
+	if (ccplex) {
+		cstate_info.bits.cg_cstate = ccplex;
+		cstate_info.bits.update_cg = 1;
+	}
+
+	/* update SYSTEM_CSTATE? */
+	if (system) {
+		cstate_info.bits.system_cstate = system;
+		cstate_info.bits.update_system = 1;
+	}
+
+	/* update wake mask value? */
+	if (valid)
+		cstate_info.bits.update_wake_mask = 1;
+
+	/* set the wake mask */
+	cstate_info.bits.wake_mask = wake_mask;
+
+	/* set the updated cstate info */
+	nvg_send_req_data(TEGRA_NVG_CHANNEL_CSTATE_INFO,
+				cstate_info.flat);
+
+	/* enable preemption */
+	preempt_enable();
+
+	return 0;
+}
+
+int tegra19x_mce_update_crossover_time(u32 type, u32 time)
+{
+	if ((type != TEGRA_NVG_CHANNEL_CROSSOVER_C6_LOWER_BOUND) &&
+	    (type != TEGRA_NVG_CHANNEL_CROSSOVER_CC6_LOWER_BOUND) &&
+	    (type != TEGRA_NVG_CHANNEL_CROSSOVER_CG7_LOWER_BOUND)) {
+		pr_err("%s: unknown crossover type (%d)\n", __func__, type);
+		return -EINVAL;
+	}
+
+	/* disable pre-emption*/
+	preempt_disable();
+
+	nvg_send_req_data(type, (uint64_t)time);
+
+	/* enable pre-emption */
+	preempt_enable();
+
+	return 0;
+}
+
+int tegra19x_mce_read_cstate_stats(u32 state, u64 *stats)
+{
+	if (!stats)
+		return -EINVAL;
+
+	/* disable preemption */
+	preempt_disable();
+
+	nvg_send_req_data(TEGRA_NVG_CHANNEL_CSTATE_STAT_QUERY_REQUEST,
+				(uint64_t)state);
+	nvg_send_req(TEGRA_NVG_CHANNEL_CSTATE_STAT_QUERY_VALUE);
+	*stats = nvg_get_response();
+
+	/* enable preemption */
+	preempt_enable();
+
+	return 0;
+}
+
+int tegra19x_mce_cc3_ctrl(u32 ndiv, u32 vindex, u8 enable)
+{
+	nvg_cc3_control_channel_t cc3_ctrl;
+
+	/* disable preemption */
+	preempt_disable();
+
+	/*
+	 * If the enable bit is cleared, Auto-CC3 will be disabled by setting
+	 * the SW visible frequency request registers for all non
+	 * floorswept cores valid independent of StandbyWFI and disabling
+	 * the IDLE frequency request register. If set, Auto-CC3
+	 * will be enabled by setting the ARM SW visible frequency
+	 * request registers for all non floorswept cores to be enabled by
+	 * StandbyWFI or the equivalent signal, and always keeping the IDLE
+	 * frequency request register enabled.
+	 */
+	cc3_ctrl.bits.freq_req = ndiv;
+	cc3_ctrl.bits.enable = !!enable;
+
+	nvg_send_req_data(TEGRA_NVG_CHANNEL_CC3_CTRL, cc3_ctrl.flat);
+
+	/* enable preemption */
+	preempt_enable();
+
+	return 0;
+}
+
+int tegra19x_mce_read_versions(u32 *major, u32 *minor)
+{
+	uint64_t version;
+
+	if (!major || !minor)
+		return -EINVAL;
+
+	/* disable preemption */
+	preempt_disable();
+
+	nvg_send_req(TEGRA_NVG_CHANNEL_VERSION);
+	version = nvg_get_response();
+	*minor = (u32)version;
+	*major = (u32)(version >> 32);
+
+	/* enable preemption */
+	preempt_enable();
+
+	return 0;
+}
+
+/* Check for valid dda channel id.*/
+static int tegra19x_check_dda_channel_id(u32 index) {
+	if ((index < TEGRA_NVG_CHANNEL_DDA_SNOC_MCF) ||
+		(index > TEGRA_NVG_CHANNEL_DDA_SNOC_CLIENT_REPLENTISH_CTRL)) {
+		pr_err("mce: invalid dda channel id: %u\n", index);
+		return -EINVAL;
+	}
+	return 0;
+}
+
+int tegra19x_mce_write_dda_ctrl(u32 index, u64 value)
+{
+	if (tegra19x_check_dda_channel_id(index))
+		return -EINVAL;
+
+	/* disable preemption */
+	preempt_disable();
+
+	nvg_send_req_data(index, value);
+
+	/* enable preemption */
+	preempt_enable();
+
+	return 0;
+}
+
+int tegra19x_mce_read_dda_ctrl(u32 index, u64* value)
+{
+	if (tegra19x_check_dda_channel_id(index))
+		return -EINVAL;
+
+	if (!value)
+		return -EINVAL;
+
+	/* disable preemption */
+	preempt_disable();
+
+	nvg_send_req(index);
+	*value = nvg_get_response();
+
+	/* enable preemption */
+	preempt_enable();
+
+	return 0;
+}
+
+int tegra19x_mce_read_l3_cache_ways(u64 *value)
+{
+	/* disable preemption */
+	preempt_disable();
+
+	nvg_send_req(TEGRA_NVG_CHANNEL_CCPLEX_CACHE_CONTROL);
+	*value = nvg_get_response();
+
+	/* enable preemption */
+	preempt_enable();
+
+	return 0;
+}
+
+int tegra19x_mce_write_l3_cache_ways(u64 data, u64 *value)
+{
+	/* disable preemption */
+	preempt_disable();
+
+	nvg_send_req_data(TEGRA_NVG_CHANNEL_CCPLEX_CACHE_CONTROL, data);
+	*value = nvg_get_response();
+
+	/* enable preemption */
+	preempt_enable();
+
+	return 0;
+}
+
+int tegra19x_mce_read_rt_safe_mask(u64 *rt_safe_mask)
+{
+	if (!rt_safe_mask)
+		return -EINVAL;
+
+	/* disable preemption */
+	preempt_disable();
+
+	nvg_send_req(TEGRA_NVG_CHANNEL_RT_SAFE_MASK);
+	*rt_safe_mask = nvg_get_response();
+
+	/* enable preemption */
+	preempt_enable();
+
+	return 0;
+}
+
+int tegra19x_mce_write_rt_safe_mask(u64 rt_safe_mask)
+{
+	/* disable preemption */
+	preempt_disable();
+
+	nvg_send_req_data(TEGRA_NVG_CHANNEL_RT_SAFE_MASK, rt_safe_mask);
+
+	/* enable preemption */
+	preempt_enable();
+
+	return 0;
+}
+
+int tegra19x_mce_read_rt_window_us(u64 *rt_window_us)
+{
+	if (!rt_window_us)
+		return -EINVAL;
+
+	/* disable preemption */
+	preempt_disable();
+
+	nvg_send_req(TEGRA_NVG_CHANNEL_RT_WINDOW_US);
+	*rt_window_us = nvg_get_response();
+
+	/* enable preemption */
+	preempt_enable();
+
+	return 0;
+}
+
+int tegra19x_mce_write_rt_window_us(u64 rt_window_us)
+{
+	/* disable preemption */
+	preempt_disable();
+
+	nvg_send_req_data(TEGRA_NVG_CHANNEL_RT_WINDOW_US, rt_window_us);
+
+	/* enable preemption */
+	preempt_enable();
+
+	return 0;
+}
+
+
+int tegra19x_mce_read_rt_fwd_progress_us(u64 *rt_fwd_progress_us)
+{
+	if (!rt_fwd_progress_us)
+		return -EINVAL;
+
+	/* disable preemption */
+	preempt_disable();
+
+	nvg_send_req(TEGRA_NVG_CHANNEL_RT_FWD_PROGRESS_US);
+	*rt_fwd_progress_us = nvg_get_response();
+
+	/* enable preemption */
+	preempt_enable();
+
+	return 0;
+}
+
+int tegra19x_mce_write_rt_fwd_progress_us(u64 rt_fwd_progress_us)
+{
+	/* disable preemption */
+	preempt_disable();
+
+	nvg_send_req_data(TEGRA_NVG_CHANNEL_RT_FWD_PROGRESS_US,
+		rt_fwd_progress_us);
+
+	/* enable preemption */
+	preempt_enable();
+
+	return 0;
+}
+
+
+#ifdef CONFIG_DEBUG_FS
+/* Dummy functions below */
+int tegra19x_mce_features_get(void *data, u64 *val) { return -ENOTSUPP; }
+int tegra19x_mce_enable_latic_set(void *data, u64 val) { return -ENOTSUPP; }
+int tegra19x_mce_coresight_cg_set(void *data, u64 val) { return -ENOTSUPP; }
+int tegra19x_mce_edbgreq_set(void *data, u64 val) { return -ENOTSUPP; }
+
+#define NVG_STAT_MAX_ENTRIES	10
+#define MCE_STAT_ID_SHIFT	16UL
+
+#define UNITGROUP_IGNORED	0
+#define UNITGROUP_CORE		1
+#define UNITGROUP_CLUSTER	2
+#define UNITGROUP_CLUSTERGROUP	3
+
+#define CSTAT_ENTRY(stat) NVG_STAT_QUERY_##stat
+
+struct cstats_info {
+	char	*name; /* name of the cstats */
+	int	id;   /* NVG id */
+	int	units;/* No of cores; No of clusters; No of cluster groups */
+	int	unit_group; /* 0:Ignored; 1:core; 2:cluster; 3:cluster group */
+};
+
+static struct cstats_info cstats_table[] = {
+	{ "SC7_ENTRIES", CSTAT_ENTRY(SC7_ENTRIES), 1, UNITGROUP_IGNORED},
+	{ "SC7_RESIDENCY_SUM",
+		CSTAT_ENTRY(SC7_RESIDENCY_SUM), 1, UNITGROUP_IGNORED},
+	{ "CG7_ENTRIES", CSTAT_ENTRY(CG7_ENTRIES), 2, UNITGROUP_CLUSTERGROUP},
+	{ "CG7_RESIDENCY_SUM",
+		CSTAT_ENTRY(CG7_RESIDENCY_SUM), 2, UNITGROUP_CLUSTERGROUP},
+	{ "CC6_ENTRIES", CSTAT_ENTRY(CC6_ENTRIES), 4, UNITGROUP_CLUSTER},
+	{ "CC6_RESIDENCY_SUM",
+		CSTAT_ENTRY(CC6_RESIDENCY_SUM), 4, UNITGROUP_CLUSTER},
+	{ "C7_ENTRIES", CSTAT_ENTRY(C7_ENTRIES), 8, UNITGROUP_CORE},
+	{ "C7_RESIDENCY_SUM", CSTAT_ENTRY(C7_RESIDENCY_SUM), 8, UNITGROUP_CORE},
+	{ "C6_ENTRIES", CSTAT_ENTRY(C6_ENTRIES), 8, UNITGROUP_CORE},
+	{ "C6_RESIDENCY_SUM", CSTAT_ENTRY(C6_RESIDENCY_SUM), 8, UNITGROUP_CORE},
+};
+
+int tegra19x_mce_dbg_cstats_show(struct seq_file *s, void *data)
+{
+	int nr_cpus = num_present_cpus();
+	int st, unit;
+	u64 val;
+	u32 mce_index;
+
+	seq_printf(s, "%-25s%-15s%-10s\n", "name", "unit-id", "count/time");
+	seq_puts(s, "---------------------------------------------------\n");
+	for (st = 0; st < NVG_STAT_MAX_ENTRIES; st++) {
+		switch (cstats_table[st].unit_group) {
+		case UNITGROUP_IGNORED:
+			cstats_table[st].units = 1;
+			break;
+		case UNITGROUP_CLUSTERGROUP:
+			cstats_table[st].units = 2;
+			break;
+		case UNITGROUP_CLUSTER:
+			/* Divide by 2 to get num of clusters
+			 * as t19x has 2 cores per cluster
+			 */
+			cstats_table[st].units = nr_cpus / 2;
+			break;
+		case UNITGROUP_CORE:
+			cstats_table[st].units = nr_cpus;
+			break;
+		default:
+			return -EINVAL;
+		}
+
+		for (unit = 0; unit < cstats_table[st].units; unit++) {
+			mce_index = ((u32)cstats_table[st].id <<
+					MCE_STAT_ID_SHIFT) + (u32)unit;
+			if (tegra19x_mce_read_cstate_stats(mce_index, &val))
+				pr_err("mce: failed to read cstat: %s, %x\n",
+					cstats_table[st].name, mce_index);
+			else
+				seq_printf(s, "%-25s%-15d%-20lld\n",
+					cstats_table[st].name, unit, val);
+		}
+	}
+	return 0;
+}
+#endif /* CONFIG_DEBUG_FS */
diff --git a/drivers/platform/tegra/tegra19x-mce.h b/drivers/platform/tegra/tegra19x-mce.h
new file mode 100644
index 000000000000..e327ea7c18bb
--- /dev/null
+++ b/drivers/platform/tegra/tegra19x-mce.h
@@ -0,0 +1,135 @@
+/*
+ * Copyright (c) 2017-2019, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#ifndef _LINUX_TEGRA19X_MCE_H
+#define _LINUX_TEGRA19X_MCE_H
+
+#ifdef CONFIG_ARCH_TEGRA_19x_SOC
+int tegra19x_mce_enter_cstate(u32 state, u32 wake_time);
+int tegra19x_mce_update_cstate_info(u32 cluster, u32 ccplex, u32 system,
+				    u8 force, u32 wake_mask, bool valid);
+int tegra19x_mce_update_crossover_time(u32 type, u32 time);
+int tegra19x_mce_read_cstate_stats(u32 state, u64 *stats);
+int tegra19x_mce_cc3_ctrl(u32 ndiv, u32 vindex, u8 enable);
+int tegra19x_mce_read_versions(u32 *major, u32 *minor);
+int tegra19x_mce_write_dda_ctrl(u32 index, u64 value);
+int tegra19x_mce_read_dda_ctrl(u32 index, u64 *value);
+
+#ifdef CONFIG_DEBUG_FS
+int tegra19x_mce_features_get(void *data, u64 *val);
+int tegra19x_mce_enable_latic_set(void *data, u64 val);
+int tegra19x_mce_coresight_cg_set(void *data, u64 val);
+int tegra19x_mce_edbgreq_set(void *data, u64 val);
+int tegra19x_mce_dbg_cstats_show(struct seq_file *s, void *data);
+int tegra19x_mce_read_rt_safe_mask(u64 *rt_safe_mask);
+int tegra19x_mce_write_rt_safe_mask(u64 rt_safe_mask);
+int tegra19x_mce_read_rt_window_us(u64 *rt_window_us);
+int tegra19x_mce_write_rt_window_us(u64 rt_window_us);
+int tegra19x_mce_read_rt_fwd_progress_us(u64 *rt_fwd_progress_us);
+int tegra19x_mce_write_rt_fwd_progress_us(u64 rt_fwd_progress_us);
+#endif
+
+/* Tegra19x cache functions */
+int t19x_flush_cache_all(void);
+int t19x_flush_dcache_all(void);
+int t19x_clean_dcache_all(void);
+
+/* Return L3 cache ways */
+int tegra19x_mce_read_l3_cache_ways(u64 *value);
+/* Write L3 cache ways and return L3 cache ways actually written */
+int tegra19x_mce_write_l3_cache_ways(u64 data, u64 *value);
+#else /* CONFIG_ARCH_TEGRA_19x_SOC */
+static int tegra19x_mce_enter_cstate(u32 state, u32 wake_time)
+{
+	return -ENOTSUPP;
+}
+static int tegra19x_mce_update_cstate_info(u32 cluster, u32 ccplex, u32 system,
+					   u8 force, u32 wake_mask, bool valid)
+{
+	return -ENOTSUPP;
+}
+static int tegra19x_mce_update_crossover_time(u32 type, u32 time)
+{
+	return -ENOTSUPP;
+}
+static int tegra19x_mce_read_cstate_stats(u32 state, u64 *stats)
+{
+	return -ENOTSUPP;
+}
+static int tegra19x_mce_cc3_ctrl(u32 ndiv, u32 vindex, u8 enable)
+{
+	return -ENOTSUPP;
+}
+static int tegra19x_mce_read_versions(u32 *major, u32 *minor)
+{
+	return -ENOTSUPP;
+}
+
+static int tegra19x_mce_write_dda_ctrl(u32 index, u64 value)
+{
+	return -ENOTSUPP;
+}
+
+static int tegra19x_mce_read_dda_ctrl(u32 index, u64 *value)
+{
+	return -ENOTSUPP;
+}
+
+#ifdef CONFIG_DEBUG_FS
+static int tegra19x_mce_features_get(void *data, u64 *val)
+{
+	return -ENOTSUPP;
+}
+static int tegra19x_mce_enable_latic_set(void *data, u64 val)
+{
+	return -ENOTSUPP;
+}
+static int tegra19x_mce_coresight_cg_set(void *data, u64 val)
+{
+	return -ENOTSUPP;
+}
+static int tegra19x_mce_edbgreq_set(void *data, u64 val)
+{
+	return -ENOTSUPP;
+}
+static int tegra19x_mce_dbg_cstats_show(struct seq_file *s, void *data)
+{
+	return -ENOTSUPP;
+}
+#endif /* CONFIG_DEBUG_FS */
+
+static int t19x_flush_cache_all(void)
+{
+	return -ENOTSUPP;
+}
+static int t19x_flush_dcache_all(void)
+{
+	return -ENOTSUPP;
+}
+static int t19x_clean_dcache_all(void)
+{
+	return -ENOTSUPP;
+}
+static int tegra19x_mce_write_l3_cache_ways(u64 data, u64 *value)
+{
+	return -ENOTSUPP;
+}
+static int tegra19x_mce_read_l3_cache_ways(u64 *value)
+{
+	return -ENOTSUPP;
+}
+#endif /* CONFIG_ARCH_TEGRA_19x_SOC */
+#endif /* _LINUX_TEGRA19X_MCE_H */
diff --git a/drivers/soc/tegra/common.c b/drivers/soc/tegra/common.c
index dff6d5ef4e46..8b171522d3f1 100644
--- a/drivers/soc/tegra/common.c
+++ b/drivers/soc/tegra/common.c
@@ -22,6 +22,14 @@ static const struct of_device_id tegra_machine_match[] = {
 	{ .compatible = "nvidia,tegra124", },
 	{ .compatible = "nvidia,tegra132", },
 	{ .compatible = "nvidia,tegra210", },
+	{ .compatible = "nvidia,tegra210b01", },
+	{ }
+};
+
+/* T186 and later architecture */
+static const struct of_device_id tegra186_ge_machine_match[] = {
+	{ .compatible = "nvidia,tegra186", },
+	{ .compatible = "nvidia,tegra194", },
 	{ }
 };
 
@@ -40,6 +48,18 @@ bool soc_is_tegra(void)
 	return match != NULL;
 }
 
+bool soc_is_tegra186_n_later(void)
+{
+	struct device_node *root;
+
+	root = of_find_node_by_path("/");
+	if (!root)
+		return false;
+
+	return of_match_node(tegra186_ge_machine_match, root) != NULL;
+}
+EXPORT_SYMBOL(soc_is_tegra186_n_later);
+
 static int tegra_core_dev_init_opp_state(struct device *dev)
 {
 	unsigned long rate;
diff --git a/drivers/soc/tegra/fuse/tegra-apbmisc.c b/drivers/soc/tegra/fuse/tegra-apbmisc.c
index 2e17b33f1535..0be70b961a86 100644
--- a/drivers/soc/tegra/fuse/tegra-apbmisc.c
+++ b/drivers/soc/tegra/fuse/tegra-apbmisc.c
@@ -173,8 +173,8 @@ bool tegra_is_silicon(void)
 
 u32 tegra_read_emu_revid(void)
 {
-	if (!apbmisc_base)
-		tegra_init_apbmisc();
+//	if (!apbmisc_base)
+//		tegra_init_apbmisc();
 
 	if (!apbmisc_base) {
 		WARN(1, "Tegra Chip ID not yet available\n");
diff --git a/drivers/video/tegra/nvmap/nvmap_init.c b/drivers/video/tegra/nvmap/nvmap_init.c
index 139bf1af9055..6b95f08bd947 100644
--- a/drivers/video/tegra/nvmap/nvmap_init.c
+++ b/drivers/video/tegra/nvmap/nvmap_init.c
@@ -22,6 +22,8 @@
 #include <linux/tegra-ivc.h>
 #include <linux/dma-contiguous.h>
 #include <linux/version.h>
+#include <asm-generic/dma-coherent.h>
+#include <soc/tegra/fuse.h>
 
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 14, 0)
 #include <linux/sched/clock.h>
diff --git a/drivers/video/tegra/nvmap/nvmap_ioctl.c b/drivers/video/tegra/nvmap/nvmap_ioctl.c
index 0e6a6959d990..f2de833f2376 100644
--- a/drivers/video/tegra/nvmap/nvmap_ioctl.c
+++ b/drivers/video/tegra/nvmap/nvmap_ioctl.c
@@ -185,7 +185,7 @@ int nvmap_ioctl_vpr_floor_size(struct file *filp, void __user *arg)
 	if (copy_from_user(&floor_size, arg, sizeof(floor_size)))
 		return -EFAULT;
 
-	err = dma_set_resizable_heap_floor_size(&tegra_vpr_dev, floor_size);
+//	err = dma_set_resizable_heap_floor_size(&tegra_vpr_dev, floor_size);
 	return err;
 }
 
@@ -522,9 +522,9 @@ static ssize_t rw_handle(struct nvmap_client *client, struct nvmap_handle *h,
 			if (h->heap_type &
 				(NVMAP_HEAP_CARVEOUT_VPR |
 					NVMAP_HEAP_CARVEOUT_IVM_VPR)) {
-				uaccess_enable();
+				uaccess_enable_privileged();
 				memcpy_toio(addr, (void *)sys_addr, elem_size);
-				uaccess_disable();
+				uaccess_disable_privileged();
 				ret = 0;
 			} else
 #endif
@@ -708,7 +708,7 @@ int nvmap_ioctl_cache_maint_list(struct file *filp, void __user *arg,
 		return -EINVAL;
 
 	bytes = op.nr * sizeof(*refs);
-	if (!access_ok(VERIFY_READ, op.handles, op.nr * sizeof(u32)))
+	if (!access_ok((void __user*)op.handles, op.nr * sizeof(u32)))
 		return -EFAULT;
 
 	elem_size  = (op.op & NVMAP_ELEM_SIZE_U64) ?
diff --git a/drivers/video/tegra/nvmap/nvmap_mm.c b/drivers/video/tegra/nvmap/nvmap_mm.c
index 529ac0c3cc57..06179f87166b 100644
--- a/drivers/video/tegra/nvmap/nvmap_mm.c
+++ b/drivers/video/tegra/nvmap/nvmap_mm.c
@@ -19,6 +19,7 @@
 #include <linux/version.h>
 
 #include <asm/pgtable.h>
+#include <asm-generic/tlb.h>
 
 #include "nvmap_priv.h"
 
@@ -78,6 +79,9 @@ static int nvmap_prot_handle(struct nvmap_handle *handle, u64 offset,
 	struct list_head *vmas;
 	struct nvmap_vma_list *vma_list;
 	struct vm_area_struct *vma;
+	struct mmu_gather tlb;
+	struct vma_iterator vmi;
+	struct vm_area_struct *prev = NULL;
 	int err = -EINVAL;
 
 	if (!handle->heap_pgalloc)
@@ -94,16 +98,17 @@ static int nvmap_prot_handle(struct nvmap_handle *handle, u64 offset,
 		size = handle->size;
 
 	size = PAGE_ALIGN((offset & ~PAGE_MASK) + size);
+	
+	tlb_gather_mmu(&tlb, current->mm);
+	vma_iter_init(&vmi, current->mm, 0);
 
 	mutex_lock(&handle->lock);
 	vmas = &handle->vmas;
 	list_for_each_entry(vma_list, vmas, list) {
 		struct nvmap_vma_priv *priv;
 		size_t vm_size = size;
-		struct vm_area_struct *prev;
 
 		vma = vma_list->vma;
-		prev = vma->vm_prev;
 		priv = vma->vm_private_data;
 		if ((offset + size) > (vma->vm_end - vma->vm_start))
 			vm_size = vma->vm_end - vma->vm_start - offset;
@@ -123,7 +128,7 @@ static int nvmap_prot_handle(struct nvmap_handle *handle, u64 offset,
 				err = 0;
 				break;
 			}
-			err = mprotect_fixup(vma, &prev, vma->vm_start,
+			err = mprotect_fixup(&vmi, &tlb, vma, &prev, vma->vm_start,
 					vma->vm_start + vm_size, VM_NONE);
 			if (err)
 				goto try_unlock;
@@ -133,7 +138,7 @@ static int nvmap_prot_handle(struct nvmap_handle *handle, u64 offset,
 		case NVMAP_HANDLE_PROT_RESTORE:
 			vm_flags_set(vma, VM_NONE);
 			(void)vma_set_page_prot(vma);
-			err = mprotect_fixup(vma, &prev, vma->vm_start,
+			err = mprotect_fixup(&vmi, &tlb, vma, &prev, vma->vm_start,
 					vma->vm_start + vm_size,
 					vma_list->save_vm_flags);
 			if (err)
diff --git a/fs/file.c b/fs/file.c
index b64a84137c00..0a50aab1b04e 100644
--- a/fs/file.c
+++ b/fs/file.c
@@ -493,12 +493,8 @@ static unsigned int find_next_fd(struct fdtable *fdt, unsigned int start)
 	return find_next_zero_bit(fdt->open_fds, maxfd, start);
 }
 
-/*
- * allocate a file descriptor, mark it busy.
- */
-static int alloc_fd(unsigned start, unsigned end, unsigned flags)
+int __alloc_fd(struct files_struct *files, unsigned start, unsigned end, unsigned flags)
 {
-	struct files_struct *files = current->files;
 	unsigned int fd;
 	int error;
 	struct fdtable *fdt;
@@ -554,6 +550,15 @@ static int alloc_fd(unsigned start, unsigned end, unsigned flags)
 	return error;
 }
 
+/*
+ * allocate a file descriptor, mark it busy.
+ */
+static int alloc_fd(unsigned start, unsigned end, unsigned flags)
+{
+	struct files_struct *files = current->files;
+	return __alloc_fd(files, start, end, flags);
+}
+
 int __get_unused_fd_flags(unsigned flags, unsigned long nofile)
 {
 	return alloc_fd(0, nofile, flags);
diff --git a/include/asm-generic/dma-coherent.h b/include/asm-generic/dma-coherent.h
index 09153288ec58..64474ef4c36b 100644
--- a/include/asm-generic/dma-coherent.h
+++ b/include/asm-generic/dma-coherent.h
@@ -1,6 +1,9 @@
 #ifndef DMA_COHERENT_H
 #define DMA_COHERENT_H
 
+#include <linux/device.h>
+#include <linux/types.h>
+
 #ifdef CONFIG_HAVE_GENERIC_DMA_COHERENT
 /*
  * These three functions are only for dma allocator.
@@ -25,9 +28,8 @@ int dma_mmap_from_coherent(struct device *dev, struct vm_area_struct *vma,
 struct dma_declare_info;
 struct dma_coherent_stats;
 
-extern int
-dma_declare_coherent_resizable_cma_memory(struct device *dev,
-				struct dma_declare_info *dma_info);
+extern int dma_set_resizable_heap_floor_size(struct device *dev, size_t floor_size);
+extern int dma_declare_coherent_resizable_cma_memory(struct device *dev, struct dma_declare_info *dma_info);
 
 extern int
 dma_set_resizable_heap_floor_size(struct device *dev, size_t floor_size);
diff --git a/include/asm-generic/dma-mapping.h b/include/asm-generic/dma-mapping.h
index 46a0016efd81..592d24e91ef5 100644
--- a/include/asm-generic/dma-mapping.h
+++ b/include/asm-generic/dma-mapping.h
@@ -2,6 +2,8 @@
 #ifndef _ASM_GENERIC_DMA_MAPPING_H
 #define _ASM_GENERIC_DMA_MAPPING_H
 
+#define DMA_ERROR_CODE	(~(dma_addr_t)0)
+
 static inline const struct dma_map_ops *get_arch_dma_ops(void)
 {
 	return NULL;
diff --git a/include/linux/cma.h b/include/linux/cma.h
index 63873b93deaa..89a8f27dc8f5 100644
--- a/include/linux/cma.h
+++ b/include/linux/cma.h
@@ -50,6 +50,8 @@ extern int cma_init_reserved_mem(phys_addr_t base, phys_addr_t size,
 					struct cma **res_cma);
 extern struct page *cma_alloc(struct cma *cma, unsigned long count, unsigned int align,
 			      bool no_warn);
+extern struct page *cma_alloc_at(struct cma *cma, size_t count,
+				unsigned int align, phys_addr_t at_addr, bool map_non_cached);
 extern bool cma_pages_valid(struct cma *cma, const struct page *pages, unsigned long count);
 extern bool cma_release(struct cma *cma, const struct page *pages, unsigned long count);
 
diff --git a/include/linux/dma-mapping.h b/include/linux/dma-mapping.h
index cbbfd364a69c..35903505d164 100644
--- a/include/linux/dma-mapping.h
+++ b/include/linux/dma-mapping.h
@@ -12,6 +12,13 @@
 #include <linux/bug.h>
 #include <linux/mem_encrypt.h>
 
+static inline bool is_device_dma_coherent(struct device *dev)
+{
+	if (!dev)
+		return false;
+	return dev->archdata.dma_coherent;
+}
+
 /* flags for the coherent memory api */
 #define	DMA_MEMORY_MAP			0x01
 #define DMA_MEMORY_IO			0x02
@@ -80,6 +87,15 @@
  */
 #define DMA_ATTR_SKIP_IOVA_GAP	(1UL << 11)
 
+/*
+ * DMA_ATTR_READ_ONLY: This tells the DMA-mapping subsystem to map as read-only
+ */
+#define DMA_ATTR_READ_ONLY	(1UL << 12)
+/*
+ * DMA_ATTR_WRITE_ONLY: This tells the DMA-mapping subsystem to map as write-only
+ */
+#define DMA_ATTR_WRITE_ONLY	(1UL << 13)
+
 /*
  * A dma_addr_t can hold any valid DMA or bus address for the platform.  It can
  * be given to a device to use as a DMA source or target.  It is specific to a
diff --git a/include/linux/fdtable.h b/include/linux/fdtable.h
index e066816f3519..e919a7f53727 100644
--- a/include/linux/fdtable.h
+++ b/include/linux/fdtable.h
@@ -123,6 +123,8 @@ int iterate_fd(struct files_struct *, unsigned,
 		int (*)(const void *, struct file *, unsigned),
 		const void *);
 
+extern int __alloc_fd(struct files_struct *files,
+		      unsigned start, unsigned end, unsigned flags);
 extern int close_fd(unsigned int fd);
 extern int __close_range(unsigned int fd, unsigned int max_fd, unsigned int flags);
 extern struct file *close_fd_get_file(unsigned int fd);
diff --git a/include/linux/platform/tegra/bwmgr_mc.h b/include/linux/platform/tegra/bwmgr_mc.h
new file mode 100644
index 000000000000..2aa7f8a720b5
--- /dev/null
+++ b/include/linux/platform/tegra/bwmgr_mc.h
@@ -0,0 +1,37 @@
+/**
+ * Copyright (c) 2015-2018, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ */
+
+#ifndef __BWMGR_MC_H
+#define __BWMGR_MC_H
+
+#include <linux/types.h>
+#include <linux/platform/tegra/iso_client.h>
+
+unsigned long bwmgr_apply_efficiency(
+		unsigned long bw, unsigned long iso_bw,
+		unsigned long emc_max, u64 usage_flags,
+		unsigned long *iso_bw_min, unsigned long iso_bw_nvdis,
+		unsigned long iso_bw_vi);
+
+void bwmgr_eff_init(void);
+
+unsigned long bwmgr_freq_to_bw(unsigned long freq);
+unsigned long bwmgr_bw_to_freq(unsigned long bw);
+unsigned long bwmgr_get_lowest_iso_emc_freq(long iso_bw,
+		long iso_bw_nvdis, long iso_bw_vi);
+u32 tegra_bwmgr_get_max_iso_bw(enum tegra_iso_client);
+
+u32 bwmgr_dvfs_latency(u32 ufreq);
+int bwmgr_iso_bw_percentage_max(void);
+int bwmgr_get_emc_to_dram_freq_factor(void);
+#endif /* __BWMGR_MC_H */
diff --git a/include/linux/platform/tegra/iso_client.h b/include/linux/platform/tegra/iso_client.h
new file mode 100644
index 000000000000..d88ee6d92380
--- /dev/null
+++ b/include/linux/platform/tegra/iso_client.h
@@ -0,0 +1,33 @@
+/*
+ *
+ * Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ */
+
+#ifndef _INCLUDE_MACH_ISO_CLIENT_H
+#define _INCLUDE_MACH_ISO_CLIENT_H
+
+enum tegra_iso_client {
+	TEGRA_ISO_CLIENT_DISP_0,
+	TEGRA_ISO_CLIENT_DISP_1,
+	TEGRA_ISO_CLIENT_DISP_2,
+	TEGRA_ISO_CLIENT_VI_0,
+	TEGRA_ISO_CLIENT_VI_1,
+	TEGRA_ISO_CLIENT_ISP_A,
+	TEGRA_ISO_CLIENT_ISP_B,
+	TEGRA_ISO_CLIENT_BBC_0,
+	TEGRA_ISO_CLIENT_TEGRA_CAMERA,
+	TEGRA_ISO_CLIENT_APE_ADMA,
+	TEGRA_ISO_CLIENT_EQOS,
+	TEGRA_ISO_CLIENT_COUNT
+};
+
+#endif /* _INCLUDE_MACH_ISO_CLIENT_H */
diff --git a/include/linux/platform/tegra/latency_allowance.h b/include/linux/platform/tegra/latency_allowance.h
new file mode 100644
index 000000000000..02929a99fd59
--- /dev/null
+++ b/include/linux/platform/tegra/latency_allowance.h
@@ -0,0 +1,341 @@
+/*
+ * arch/arm/mach-tegra/include/mach/latency_allowance.h
+ *
+ * Copyright (C) 2011-2015, NVIDIA CORPORATION. All rights reserved.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#ifndef _MACH_TEGRA_LATENCY_ALLOWANCE_H_
+#define _MACH_TEGRA_LATENCY_ALLOWANCE_H_
+
+#define FIRST_DISP_CLIENT_ID	TEGRA_LA_DISPLAY_0A
+#define DISP_CLIENT_LA_ID(id)	(id - FIRST_DISP_CLIENT_ID)
+
+
+/* Note:- When adding new display realted IDs, please add them adjacent/amongst
+	  the existing display related IDs. This is required because certain
+	  display related macros/strcuts assume that all display related
+	  tegra_la_ids are adjacent to each other.
+
+	  Please observe the same guidelines as display clients, when adding new
+	  camera clients. All camera clients need to be located adjacent to each
+	  other in tegra_la_id. This is required because certain camera related
+	  macros/structs assume that all camera related tegra_la_ids are
+	  adjacent to each other. */
+enum tegra_la_id {
+	TEGRA_LA_AFIR = 0,			/* T30 specific */
+	TEGRA_LA_AFIW,				/* T30 specific */
+	TEGRA_LA_AVPC_ARM7R,
+	TEGRA_LA_AVPC_ARM7W,
+	TEGRA_LA_DISPLAY_0A,
+	TEGRA_LA_DISPLAY_0B,
+	TEGRA_LA_DISPLAY_0C,
+	TEGRA_LA_DISPLAY_1B,			/* T30 specific */
+	TEGRA_LA_DISPLAY_HC,
+	TEGRA_LA_DISPLAY_0AB,
+	TEGRA_LA_DISPLAY_0BB,
+	TEGRA_LA_DISPLAY_0CB,
+	TEGRA_LA_DISPLAY_1BB,			/* T30 specific */
+	TEGRA_LA_DISPLAY_HCB,
+	TEGRA_LA_DISPLAY_T,			/* T14x specific */
+	TEGRA_LA_DISPLAYD,			/* T14x specific */
+	TEGRA_LA_EPPUP,
+	TEGRA_LA_EPPU,
+	TEGRA_LA_EPPV,
+	TEGRA_LA_EPPY,
+	TEGRA_LA_G2PR,
+	TEGRA_LA_G2SR,
+	TEGRA_LA_G2DR,
+	TEGRA_LA_G2DW,
+	TEGRA_LA_GPUSRD,			/* T12x specific */
+	TEGRA_LA_GPUSWR,			/* T12x specific */
+	TEGRA_LA_HOST1X_DMAR,
+	TEGRA_LA_HOST1XR,
+	TEGRA_LA_HOST1XW,
+	TEGRA_LA_HDAR,
+	TEGRA_LA_HDAW,
+	TEGRA_LA_ISPW,
+	TEGRA_LA_MPCORER,
+	TEGRA_LA_MPCOREW,
+	TEGRA_LA_MPCORE_LPR,
+	TEGRA_LA_MPCORE_LPW,
+	TEGRA_LA_MPE_UNIFBR,			/* T30 specific */
+	TEGRA_LA_MPE_IPRED,			/* T30 specific */
+	TEGRA_LA_MPE_AMEMRD,			/* T30 specific */
+	TEGRA_LA_MPE_CSRD,			/* T30 specific */
+	TEGRA_LA_MPE_UNIFBW,			/* T30 specific */
+	TEGRA_LA_MPE_CSWR,			/* T30 specific */
+	TEGRA_LA_FDCDRD,
+	TEGRA_LA_IDXSRD,
+	TEGRA_LA_TEXSRD,
+	TEGRA_LA_TEXL2SRD = TEGRA_LA_TEXSRD,	/* T11x, T14x specific */
+	TEGRA_LA_FDCDWR,
+	TEGRA_LA_FDCDRD2,
+	TEGRA_LA_IDXSRD2,			/* T30 specific */
+	TEGRA_LA_TEXSRD2,			/* T30 specific */
+	TEGRA_LA_FDCDWR2,
+	TEGRA_LA_PPCS_AHBDMAR,
+	TEGRA_LA_PPCS_AHBSLVR,
+	TEGRA_LA_PPCS_AHBDMAW,
+	TEGRA_LA_PPCS_AHBSLVW,
+	TEGRA_LA_PTCR,
+	TEGRA_LA_SATAR,				/* T30, T19x */
+	TEGRA_LA_SATAW,				/* T30, T19x */
+	TEGRA_LA_VDE_BSEVR,
+	TEGRA_LA_VDE_MBER,
+	TEGRA_LA_VDE_MCER,
+	TEGRA_LA_VDE_TPER,
+	TEGRA_LA_VDE_BSEVW,
+	TEGRA_LA_VDE_DBGW,
+	TEGRA_LA_VDE_MBEW,
+	TEGRA_LA_VDE_TPMW,
+	TEGRA_LA_VI_RUV,			/* T30 specific */
+	TEGRA_LA_VI_WSB,
+	TEGRA_LA_VI_WU,
+	TEGRA_LA_VI_WV,
+	TEGRA_LA_VI_WY,
+
+	TEGRA_LA_MSENCSRD,			/* T11x, T14x specific */
+	TEGRA_LA_MSENCSWR,			/* T11x, T14x specific */
+	TEGRA_LA_XUSB_HOSTR,			/* T11x, T19x */
+	TEGRA_LA_XUSB_HOSTW,			/* T11x, T19x */
+	TEGRA_LA_XUSB_DEVR,			/* T11x, T19x */
+	TEGRA_LA_XUSB_DEVW,			/* T11x, T19x */
+	TEGRA_LA_FDCDRD3,			/* T11x specific */
+	TEGRA_LA_FDCDRD4,			/* T11x specific */
+	TEGRA_LA_FDCDWR3,			/* T11x specific */
+	TEGRA_LA_FDCDWR4,			/* T11x specific */
+	TEGRA_LA_EMUCIFR,			/* T11x, T14x specific */
+	TEGRA_LA_EMUCIFW,			/* T11x, T14x specific */
+	TEGRA_LA_TSECSRD,			/* T11x, T14x, T19x */
+	TEGRA_LA_TSECSWR,			/* T11x, T14x, T19x */
+
+	TEGRA_LA_VI_W,				/* T14x specific */
+	TEGRA_LA_ISP_RA,			/* T14x specific */
+	TEGRA_LA_ISP_WA,			/* T14x specific */
+	TEGRA_LA_ISP_WB,			/* T14x specific */
+	TEGRA_LA_ISP_RAB,			/* T12x specific */
+	TEGRA_LA_ISP_WAB,			/* T12x specific */
+	TEGRA_LA_ISP_WBB,			/* T12x specific */
+	TEGRA_LA_BBCR,				/* T14x specific */
+	TEGRA_LA_BBCW,				/* T14x specific */
+	TEGRA_LA_BBCLLR,			/* T14x specific */
+	TEGRA_LA_SDMMCR,			/* T12x, T19x */
+	TEGRA_LA_SDMMCRA,			/* T12x, T19x */
+	TEGRA_LA_SDMMCRAA,			/* T12x specific */
+	TEGRA_LA_SDMMCRAB,			/* T12x, T19x */
+	TEGRA_LA_SDMMCW,			/* T12x, T19x */
+	TEGRA_LA_SDMMCWA,			/* T12x, T19x */
+	TEGRA_LA_SDMMCWAA,			/* T12x specific */
+	TEGRA_LA_SDMMCWAB,			/* T12x, T19x */
+	TEGRA_LA_VICSRD,			/* T12x, T19x */
+	TEGRA_LA_VICSWR,			/* T12x, T19x */
+
+	TEGRA_LA_TSECBSRD,			/* T21x specific */
+	TEGRA_LA_TSECBSWR,			/* T21x specific */
+
+	TEGRA_LA_NVDECR,			/* T21x specific */
+	TEGRA_LA_NVDECW,			/* T21x specific */
+
+	TEGRA_LA_AONR,				/* T18x, T19x */
+	TEGRA_LA_AONW,				/* T18x, T19x */
+	TEGRA_LA_AONDMAR,			/* T18x, T19x */
+	TEGRA_LA_AONDMAW,			/* T18x, T19x */
+	TEGRA_LA_APEDMAR,			/* T18x, T19x */
+	TEGRA_LA_APEDMAW,			/* T18x, T19x */
+	TEGRA_LA_APER,				/* T18x, T19x */
+	TEGRA_LA_APEW,				/* T18x, T19x */
+	TEGRA_LA_AXISR,				/* T18x, T19x */
+	TEGRA_LA_AXISW,				/* T18x, T19x */
+	TEGRA_LA_BPMPR,				/* T18x, T19x */
+	TEGRA_LA_BPMPW,				/* T18x, T19x */
+	TEGRA_LA_BPMPDMAR,			/* T18x, T19x */
+	TEGRA_LA_BPMPDMAW,			/* T18x, T19x */
+	TEGRA_LA_EQOSR,				/* T18x, T19x */
+	TEGRA_LA_EQOSW,				/* T18x, T19x */
+	TEGRA_LA_ETRR,				/* T18x, T19x */
+	TEGRA_LA_ETRW,				/* T18x, T19x */
+	TEGRA_LA_GPUSRD2,			/* T18x specific */
+	TEGRA_LA_GPUSWR2,			/* T18x specific */
+	TEGRA_LA_NVDISPLAYR,			/* T18x, T19x */
+	TEGRA_LA_NVENCSRD,			/* T18x, T19x */
+	TEGRA_LA_NVENCSWR,			/* T18x, T19x */
+	TEGRA_LA_NVJPGSRD,			/* T18x, T19x */
+	TEGRA_LA_NVJPGSWR,			/* T18x, T19x */
+	TEGRA_LA_SCER,				/* T18x, T19x */
+	TEGRA_LA_SCEW,				/* T18x, T19x */
+	TEGRA_LA_SCEDMAR,			/* T18x, T19x */
+	TEGRA_LA_SCEDMAW,			/* T18x, T19x */
+	TEGRA_LA_SESRD,				/* T18x, T19x */
+	TEGRA_LA_SESWR,				/* T18x, T19x */
+	TEGRA_LA_UFSHCR,			/* T18x, T19x */
+	TEGRA_LA_UFSHCW,			/* T18x, T19x */
+
+	TEGRA_LA_AXIAPR,			/* T19x specific */
+	TEGRA_LA_AXIAPW,			/* T19x specific */
+	TEGRA_LA_CIFLL_WR,			/* T19x specific */
+	TEGRA_LA_DLA0FALRDB,			/* T19x specific */
+	TEGRA_LA_DLA0RDA,			/* T19x specific */
+	TEGRA_LA_DLA0FALWRB,			/* T19x specific */
+	TEGRA_LA_DLA0WRA,			/* T19x specific */
+	TEGRA_LA_DLA0RDA1,			/* T19x specific */
+	TEGRA_LA_DLA1RDA1,			/* T19x specific */
+	TEGRA_LA_DLA1FALRDB,			/* T19x specific */
+	TEGRA_LA_DLA1RDA,			/* T19x specific */
+	TEGRA_LA_DLA1FALWRB,			/* T19x specific */
+	TEGRA_LA_DLA1WRA,			/* T19x specific */
+	TEGRA_LA_HOST1XDMAR,			/* T19x specific */
+	TEGRA_LA_ISPFALR,			/* T19x specific */
+	TEGRA_LA_ISPRA,				/* T19x specific */
+	TEGRA_LA_ISPWA,				/* T19x specific */
+	TEGRA_LA_ISPWB,				/* T19x specific */
+	TEGRA_LA_ISPFALW,			/* T19x specific */
+	TEGRA_LA_ISPRA1,			/* T19x specific */
+	TEGRA_LA_MIU0R,				/* T19x specific */
+	TEGRA_LA_MIU0W,				/* T19x specific */
+	TEGRA_LA_MIU1R,				/* T19x specific */
+	TEGRA_LA_MIU1W,				/* T19x specific */
+	TEGRA_LA_MIU2R,				/* T19x specific */
+	TEGRA_LA_MIU2W,				/* T19x specific */
+	TEGRA_LA_MIU3R,				/* T19x specific */
+	TEGRA_LA_MIU3W,				/* T19x specific */
+	TEGRA_LA_MIU4R,				/* T19x specific */
+	TEGRA_LA_MIU4W,				/* T19x specific */
+	TEGRA_LA_MIU5R,				/* T19x specific */
+	TEGRA_LA_MIU5W,				/* T19x specific */
+	TEGRA_LA_MIU6R,				/* T19x specific */
+	TEGRA_LA_MIU6W,				/* T19x specific */
+	TEGRA_LA_MIU7R,				/* T19x specific */
+	TEGRA_LA_MIU7W,				/* T19x specific */
+	TEGRA_LA_NVDECSRD,			/* T19x specific */
+	TEGRA_LA_NVDECSWR,			/* T19x specific */
+	TEGRA_LA_NVDEC1SRD,			/* T19x specific */
+	TEGRA_LA_NVDECSRD1,			/* T19x specific */
+	TEGRA_LA_NVDEC1SRD1,			/* T19x specific */
+	TEGRA_LA_NVDEC1SWR,			/* T19x specific */
+	TEGRA_LA_NVENC1SRD,			/* T19x specific */
+	TEGRA_LA_NVENC1SWR,			/* T19x specific */
+	TEGRA_LA_NVENC1SRD1,			/* T19x specific */
+	TEGRA_LA_NVENCSRD1,			/* T19x specific */
+	TEGRA_LA_PCIE0R,			/* T19x specific */
+	TEGRA_LA_PCIE0W,			/* T19x specific */
+	TEGRA_LA_PCIE1R,			/* T19x specific */
+	TEGRA_LA_PCIE1W,			/* T19x specific */
+	TEGRA_LA_PCIE2AR,			/* T19x specific */
+	TEGRA_LA_PCIE2AW,			/* T19x specific */
+	TEGRA_LA_PCIE3R,			/* T19x specific */
+	TEGRA_LA_PCIE3W,			/* T19x specific */
+	TEGRA_LA_PCIE4R,			/* T19x specific */
+	TEGRA_LA_PCIE4W,			/* T19x specific */
+	TEGRA_LA_PCIE5R,			/* T19x specific */
+	TEGRA_LA_PCIE5W,			/* T19x specific */
+	TEGRA_LA_PCIE0R1,			/* T19x specific */
+	TEGRA_LA_PCIE5R1,			/* T19x specific */
+	TEGRA_LA_PVA0RDA,			/* T19x specific */
+	TEGRA_LA_PVA0RDB,			/* T19x specific */
+	TEGRA_LA_PVA0RDC,			/* T19x specific */
+	TEGRA_LA_PVA0WRA,			/* T19x specific */
+	TEGRA_LA_PVA0WRB,			/* T19x specific */
+	TEGRA_LA_PVA0WRC,			/* T19x specific */
+	TEGRA_LA_PVA0RDA1,			/* T19x specific */
+	TEGRA_LA_PVA0RDB1,			/* T19x specific */
+	TEGRA_LA_PVA1RDA,			/* T19x specific */
+	TEGRA_LA_PVA1RDB,			/* T19x specific */
+	TEGRA_LA_PVA1RDC,			/* T19x specific */
+	TEGRA_LA_PVA1WRA,			/* T19x specific */
+	TEGRA_LA_PVA1WRB,			/* T19x specific */
+	TEGRA_LA_PVA1WRC,			/* T19x specific */
+	TEGRA_LA_PVA1RDA1,			/* T19x specific */
+	TEGRA_LA_PVA1RDB1,			/* T19x specific */
+	TEGRA_LA_RCEDMAR,			/* T19x specific */
+	TEGRA_LA_RCEDMAW,			/* T19x specific */
+	TEGRA_LA_RCER,				/* T19x specific */
+	TEGRA_LA_RCEW,				/* T19x specific */
+	TEGRA_LA_TSECSRDB,			/* T19x specific */
+	TEGRA_LA_TSECSWRB,			/* T19x specific */
+	TEGRA_LA_VIW,				/* T19x specific */
+	TEGRA_LA_VICSRD1,			/* T19x specific */
+	TEGRA_LA_VIFALR,			/* T19x specific */
+	TEGRA_LA_VIFALW,			/* T19x specific */
+	TEGRA_LA_WCAM,				/* T19x specific */
+	TEGRA_LA_NVLRHP,			/* T19x specific */
+	TEGRA_LA_DGPU,				/* T19x specific */
+	TEGRA_LA_IGPU,				/* T19x specific */
+
+	TEGRA_LA_MAX_ID
+};
+
+enum disp_win_type {
+	TEGRA_LA_DISP_WIN_TYPE_FULL,
+	TEGRA_LA_DISP_WIN_TYPE_FULLA,
+	TEGRA_LA_DISP_WIN_TYPE_FULLB,
+	TEGRA_LA_DISP_WIN_TYPE_SIMPLE,
+	TEGRA_LA_DISP_WIN_TYPE_CURSOR,
+	TEGRA_LA_DISP_WIN_TYPE_NUM_TYPES
+};
+
+struct disp_client {
+	enum disp_win_type win_type;
+	unsigned int mccif_size_bytes;
+	unsigned int line_buf_sz_bytes;
+};
+
+struct dc_to_la_params {
+	unsigned int thresh_lwm_bytes;
+	unsigned int spool_up_buffering_adj_bytes;
+	unsigned int drain_time_usec_fp;
+	unsigned int total_dc0_bw;
+	unsigned int total_dc1_bw;
+};
+
+struct la_to_dc_params {
+	unsigned int fp_factor;
+	unsigned int (*la_real_to_fp)(unsigned int val);
+	unsigned int (*la_fp_to_real)(unsigned int val);
+	unsigned int static_la_minus_snap_arb_to_row_srt_emcclks_fp;
+	unsigned int dram_width_bits;
+	unsigned int disp_catchup_factor_fp;
+};
+
+int tegra_set_disp_latency_allowance(enum tegra_la_id id,
+					unsigned long emc_freq_hz,
+					unsigned int bandwidth_in_mbps,
+					struct dc_to_la_params disp_params);
+
+int tegra_check_disp_latency_allowance(enum tegra_la_id id,
+				       unsigned long emc_freq_hz,
+				       unsigned int bw_mbps,
+				       struct dc_to_la_params disp_params);
+
+int tegra_set_latency_allowance(enum tegra_la_id id,
+				unsigned int bandwidth_in_mbps);
+
+int tegra_set_camera_ptsa(enum tegra_la_id id,
+			unsigned int bw_mbps,
+			int is_hiso);
+
+void tegra_latency_allowance_update_tick_length(unsigned int new_ns_per_tick);
+
+int tegra_enable_latency_scaling(enum tegra_la_id id,
+				    unsigned int threshold_low,
+				    unsigned int threshold_mid,
+				    unsigned int threshold_high);
+
+void tegra_disable_latency_scaling(enum tegra_la_id id);
+
+void mc_pcie_init(void);
+
+struct la_to_dc_params tegra_get_la_to_dc_params(void);
+
+extern const struct disp_client *tegra_la_disp_clients_info;
+
+#endif /* _MACH_TEGRA_LATENCY_ALLOWANCE_H_ */
diff --git a/include/linux/platform/tegra/mc-regs-t18x.h b/include/linux/platform/tegra/mc-regs-t18x.h
new file mode 100644
index 000000000000..96299915383d
--- /dev/null
+++ b/include/linux/platform/tegra/mc-regs-t18x.h
@@ -0,0 +1,1113 @@
+/*
+ * Copyright (c) 2015, NVIDIA Corporation. All rights reserved.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MACH_TEGRA_MC_REGS_T18X_H__
+#define __MACH_TEGRA_MC_REGS_T18X_H__
+
+/* Auto generated. Do not edit. */
+#define MC_REGIF_CONFIG                                         0xf80
+#define MC_REGIF_BROADCAST                                      0xf84
+#define MC_REGIF_UNICAST0                                       0xf90
+#define MC_REGIF_UNICAST1                                       0xf94
+#define MC_REGIF_UNICAST2                                       0xf98
+#define MC_REGIF_UNICAST3                                       0xf9c
+#define MC_INTSTATUS                                            0x0
+#define MC_INTMASK                                              0x4
+#define MC_INTPRIORITY                                          0xec4
+#define MC_HUBC_INTSTATUS                                       0xf2c
+#define MC_GLOBAL_INTSTATUS                                     0xf24
+#define MC_GLOBAL_CRITICAL_INTSTATUS                            0xf28
+#define MC_ERR_STATUS                                           0x8
+#define MC_ERR_ADR                                              0xc
+#define MC_PCFIFO_CLIENT_CONFIG0                                0xdd0
+#define MC_PCFIFO_CLIENT_CONFIG1                                0xdd4
+#define MC_PCFIFO_CLIENT_CONFIG2                                0xdd8
+#define MC_PCFIFO_CLIENT_CONFIG3                                0xddc
+#define MC_PCFIFO_CLIENT_CONFIG4                                0xde0
+#define MC_PCFIFO_CLIENT_CONFIG5                                0xbf4
+#define MC_EMEM_CFG                                             0x50
+#define MC_EMEM_ADR_CFG                                         0x54
+#define MC_EMEM_ADR_CFG_DEV0                                    0x58
+#define MC_EMEM_ADR_CFG_DEV1                                    0x5c
+#define MC_EMEM_ADR_CFG_CHANNEL_ENABLE                          0xdf8
+#define MC_EMEM_ADR_CFG_CHANNEL_MASK                            0x60
+#define MC_EMEM_ADR_CFG_CHANNEL_MASK_1                          0xdfc
+#define MC_EMEM_ADR_CFG_BANK_MASK_0                             0x64
+#define MC_EMEM_ADR_CFG_BANK_MASK_1                             0x68
+#define MC_EMEM_ADR_CFG_BANK_MASK_2                             0x6c
+#define MC_SECURITY_CFG0                                        0x70
+#define MC_SECURITY_CFG1                                        0x74
+#define MC_SECURITY_CFG3                                        0x9bc
+#define MC_SECURITY_RSV                                         0x7c
+#define MC_EMEM_ARB_CFG                                         0x90
+#define MC_EMEM_ARB_OUTSTANDING_REQ                             0x94
+#define MC_EMEM_ARB_TIMING_RCD                                  0x98
+#define MC_EMEM_ARB_TIMING_RP                                   0x9c
+#define MC_EMEM_ARB_TIMING_RC                                   0xa0
+#define MC_EMEM_ARB_TIMING_RAS                                  0xa4
+#define MC_EMEM_ARB_TIMING_FAW                                  0xa8
+#define MC_EMEM_ARB_TIMING_RRD                                  0xac
+#define MC_EMEM_ARB_TIMING_RAP2PRE                              0xb0
+#define MC_EMEM_ARB_TIMING_WAP2PRE                              0xb4
+#define MC_EMEM_ARB_TIMING_R2R                                  0xb8
+#define MC_EMEM_ARB_TIMING_W2W                                  0xbc
+#define MC_EMEM_ARB_TIMING_R2W                                  0xc0
+#define MC_EMEM_ARB_TIMING_W2R                                  0xc4
+#define MC_EMEM_ARB_TIMING_RFCPB                                0x6c0
+#define MC_EMEM_ARB_TIMING_CCDMW                                0x6c4
+#define MC_EMEM_ARB_REFPB_HP_CTRL                               0x6f0
+#define MC_EMEM_ARB_REFPB_BANK_CTRL                             0x6f4
+#define MC_EMEM_ARB_DA_TURNS                                    0xd0
+#define MC_EMEM_ARB_DA_COVERS                                   0xd4
+#define MC_EMEM_ARB_MISC0                                       0xd8
+#define MC_EMEM_ARB_MISC1                                       0xdc
+#define MC_EMEM_ARB_MISC2                                       0xc8
+#define MC_EMEM_ARB_RING1_THROTTLE                              0xe0
+#define MC_EMEM_ARB_RING3_THROTTLE                              0xe4
+#define MC_EMEM_ARB_NISO_THROTTLE                               0x6b0
+#define MC_EMEM_ARB_OVERRIDE                                    0xe8
+#define MC_EMEM_ARB_RSV                                         0xec
+#define MC_CLKEN_OVERRIDE                                       0xf4
+#define MC_TIMING_CONTROL_DBG                                   0xf8
+#define MC_TIMING_CONTROL                                       0xfc
+#define MC_STAT_CONTROL                                         0x100
+#define MC_STAT_STATUS                                          0x104
+#define MC_STAT_EMC_CLOCK_LIMIT                                 0x108
+#define MC_STAT_EMC_CLOCK_LIMIT_MSBS                            0x10c
+#define MC_STAT_EMC_CLOCKS                                      0x110
+#define MC_STAT_EMC_CLOCKS_MSBS                                 0x114
+#define MC_STAT_EMC_FILTER_SET0_ADR_LIMIT_LO                    0x118
+#define MC_STAT_EMC_FILTER_SET1_ADR_LIMIT_LO                    0x158
+#define MC_STAT_EMC_FILTER_SET0_ADR_LIMIT_HI                    0x11c
+#define MC_STAT_EMC_FILTER_SET1_ADR_LIMIT_HI                    0x15c
+#define MC_STAT_EMC_FILTER_SET0_ADR_LIMIT_UPPER                 0xa20
+#define MC_STAT_EMC_FILTER_SET1_ADR_LIMIT_UPPER                 0xa24
+#define MC_STAT_EMC_FILTER_SET0_VIRTUAL_ADR_LIMIT_LO            0x198
+#define MC_STAT_EMC_FILTER_SET1_VIRTUAL_ADR_LIMIT_LO            0x1a8
+#define MC_STAT_EMC_FILTER_SET0_VIRTUAL_ADR_LIMIT_HI            0x19c
+#define MC_STAT_EMC_FILTER_SET1_VIRTUAL_ADR_LIMIT_HI            0x1ac
+#define MC_STAT_EMC_FILTER_SET0_VIRTUAL_ADR_LIMIT_UPPER         0xa28
+#define MC_STAT_EMC_FILTER_SET1_VIRTUAL_ADR_LIMIT_UPPER         0xa2c
+#define MC_STAT_EMC_FILTER_SET0_ASID                            0x1a0
+#define MC_STAT_EMC_FILTER_SET1_ASID                            0x1b0
+#define MC_STAT_EMC_FILTER_SET0_SLACK_LIMIT                     0x120
+#define MC_STAT_EMC_FILTER_SET1_SLACK_LIMIT                     0x160
+#define MC_STAT_EMC_FILTER_SET0_CLIENT_0                        0x128
+#define MC_STAT_EMC_FILTER_SET1_CLIENT_0                        0x168
+#define MC_STAT_EMC_FILTER_SET0_CLIENT_1                        0x12c
+#define MC_STAT_EMC_FILTER_SET1_CLIENT_1                        0x16c
+#define MC_STAT_EMC_FILTER_SET0_CLIENT_2                        0x130
+#define MC_STAT_EMC_FILTER_SET1_CLIENT_2                        0x170
+#define MC_STAT_EMC_FILTER_SET0_CLIENT_3                        0x134
+#define MC_STAT_EMC_FILTER_SET0_CLIENT_4                        0xb88
+#define MC_STAT_EMC_FILTER_SET0_CLIENT_5                        0xbc4
+#define MC_STAT_EMC_FILTER_SET1_CLIENT_3                        0x174
+#define MC_STAT_EMC_FILTER_SET1_CLIENT_4                        0xb8c
+#define MC_STAT_EMC_FILTER_SET1_CLIENT_5                        0xbc8
+#define MC_STAT_EMC_SET0_COUNT                                  0x138
+#define MC_STAT_EMC_SET0_COUNT_MSBS                             0x13c
+#define MC_STAT_EMC_SET1_COUNT                                  0x178
+#define MC_STAT_EMC_SET1_COUNT_MSBS                             0x17c
+#define MC_STAT_EMC_SET0_SLACK_ACCUM                            0x140
+#define MC_STAT_EMC_SET0_SLACK_ACCUM_MSBS                       0x144
+#define MC_STAT_EMC_SET1_SLACK_ACCUM                            0x180
+#define MC_STAT_EMC_SET1_SLACK_ACCUM_MSBS                       0x184
+#define MC_STAT_EMC_SET0_HISTO_COUNT                            0x148
+#define MC_STAT_EMC_SET0_HISTO_COUNT_MSBS                       0x14c
+#define MC_STAT_EMC_SET1_HISTO_COUNT                            0x188
+#define MC_STAT_EMC_SET1_HISTO_COUNT_MSBS                       0x18c
+#define MC_STAT_EMC_SET0_MINIMUM_SLACK_OBSERVED                 0x150
+#define MC_STAT_EMC_SET1_MINIMUM_SLACK_OBSERVED                 0x190
+#define MC_STAT_EMC_SET0_IDLE_CYCLE_COUNT                       0x1b8
+#define MC_STAT_EMC_SET0_IDLE_CYCL_COUNT_MSBS                   0x1bc
+#define MC_STAT_EMC_SET1_IDLE_CYCLE_COUNT                       0x1c8
+#define MC_STAT_EMC_SET1_IDLE_CYCL_COUNT_MSBS                   0x1cc
+#define MC_STAT_EMC_SET0_IDLE_CYCLE_PARTITION_SELECT            0x1c0
+#define MC_STAT_EMC_SET1_IDLE_CYCLE_PARTITION_SELECT            0x1d0
+#define MC_CLIENT_HOTRESET_CTRL                                 0x200
+#define MC_CLIENT_HOTRESET_CTRL_1                               0x970
+#define MC_CLIENT_HOTRESET_STATUS                               0x204
+#define MC_CLIENT_HOTRESET_STATUS_1                             0x974
+#define MC_EMEM_ARB_ISOCHRONOUS_0                               0x208
+#define MC_EMEM_ARB_ISOCHRONOUS_1                               0x20c
+#define MC_EMEM_ARB_ISOCHRONOUS_2                               0x210
+#define MC_EMEM_ARB_ISOCHRONOUS_3                               0x214
+#define MC_EMEM_ARB_ISOCHRONOUS_4                               0xb94
+#define MC_EMEM_ARB_ISOCHRONOUS_5                               0xba8
+#define MC_EMEM_ARB_HYSTERESIS_0                                0x218
+#define MC_EMEM_ARB_HYSTERESIS_1                                0x21c
+#define MC_EMEM_ARB_HYSTERESIS_2                                0x220
+#define MC_EMEM_ARB_HYSTERESIS_3                                0x224
+#define MC_EMEM_ARB_HYSTERESIS_4                                0xb84
+#define MC_EMEM_ARB_HYSTERESIS_5                                0xba4
+#define MC_EMEM_ARB_DHYSTERESIS_0                               0xbb0
+#define MC_EMEM_ARB_DHYSTERESIS_1                               0xbb4
+#define MC_EMEM_ARB_DHYSTERESIS_2                               0xbb8
+#define MC_EMEM_ARB_DHYSTERESIS_3                               0xbbc
+#define MC_EMEM_ARB_DHYSTERESIS_4                               0xbc0
+#define MC_EMEM_ARB_DHYSTERESIS_5                               0xbf0
+#define MC_EMEM_ARB_DHYST_CTRL                                  0xbcc
+#define MC_EMEM_ARB_DHYST_TIMEOUT_UTIL_0                        0xbd0
+#define MC_EMEM_ARB_DHYST_TIMEOUT_UTIL_1                        0xbd4
+#define MC_EMEM_ARB_DHYST_TIMEOUT_UTIL_2                        0xbd8
+#define MC_EMEM_ARB_DHYST_TIMEOUT_UTIL_3                        0xbdc
+#define MC_EMEM_ARB_DHYST_TIMEOUT_UTIL_4                        0xbe0
+#define MC_EMEM_ARB_DHYST_TIMEOUT_UTIL_5                        0xbe4
+#define MC_EMEM_ARB_DHYST_TIMEOUT_UTIL_6                        0xbe8
+#define MC_EMEM_ARB_DHYST_TIMEOUT_UTIL_7                        0xbec
+#define MC_RESERVED_RSV                                         0x3fc
+#define MC_BPMPPC_EXTRA_SNAP_LEVELS                             0xa60
+#define MC_SCEDMAPC_EXTRA_SNAP_LEVELS                           0xa74
+#define MC_SCEPC_EXTRA_SNAP_LEVELS                              0xa70
+#define MC_FTOP_EXTRA_SNAP_LEVELS                               0x2bc
+#define MC_VICPC3_EXTRA_SNAP_LEVELS                             0xa80
+#define MC_JPG_EXTRA_SNAP_LEVELS                                0xa3c
+#define MC_HOST_EXTRA_SNAP_LEVELS                               0xa14
+#define MC_DIS_EXTRA_SNAP_LEVELS                                0x2ac
+#define MC_APEDMAPC_EXTRA_SNAP_LEVELS                           0xa78
+#define MC_VICPC_EXTRA_SNAP_LEVELS                              0xa1c
+#define MC_UFSHCPC_EXTRA_SNAP_LEVELS                            0xa58
+#define MC_AONDMAPC_EXTRA_SNAP_LEVELS                           0xa6c
+#define MC_USBX_EXTRA_SNAP_LEVELS                               0x404
+#define MC_PCX_EXTRA_SNAP_LEVELS                                0x2b8
+#define MC_MSE2_EXTRA_SNAP_LEVELS                               0xe08
+#define MC_VICPC2_EXTRA_SNAP_LEVELS                             0xa7c
+#define MC_DFD_EXTRA_SNAP_LEVELS                                0xa4c
+#define MC_NVD2_EXTRA_SNAP_LEVELS                               0xe00
+#define MC_SDM_EXTRA_SNAP_LEVELS                                0xa44
+#define MC_APB_EXTRA_SNAP_LEVELS                                0x2a4
+#define MC_ISP_EXTRA_SNAP_LEVELS                                0xa08
+#define MC_USBD_EXTRA_SNAP_LEVELS                               0xa18
+#define MC_MSE_EXTRA_SNAP_LEVELS                                0x40c
+#define MC_AUD_EXTRA_SNAP_LEVELS                                0xa10
+#define MC_NIC_EXTRA_SNAP_LEVELS                                0xa54
+#define MC_GK2_EXTRA_SNAP_LEVELS                                0xa40
+#define MC_BPMPDMAPC_EXTRA_SNAP_LEVELS                          0xa64
+#define MC_NVD3_EXTRA_SNAP_LEVELS                               0xe04
+#define MC_SAX_EXTRA_SNAP_LEVELS                                0x2c0
+#define MC_EQOSPC_EXTRA_SNAP_LEVELS                             0xa5c
+#define MC_NVD_EXTRA_SNAP_LEVELS                                0xa38
+#define MC_SDM1_EXTRA_SNAP_LEVELS                               0xa50
+#define MC_HDAPC_EXTRA_SNAP_LEVELS                              0xa48
+#define MC_AONPC_EXTRA_SNAP_LEVELS                              0xa68
+#define MC_SD_EXTRA_SNAP_LEVELS                                 0xa04
+#define MC_DIS2_EXTRA_SNAP_LEVELS                               0xa84
+#define MC_VE_EXTRA_SNAP_LEVELS                                 0x2d8
+#define MC_GK_EXTRA_SNAP_LEVELS                                 0xa00
+#define MC_VIDEO_PROTECT_BOM                                    0x648
+#define MC_VIDEO_PROTECT_SIZE_MB                                0x64c
+#define MC_VIDEO_PROTECT_BOM_ADR_HI                             0x978
+#define MC_VIDEO_PROTECT_REG_CTRL                               0x650
+#define MC_ERR_VPR_STATUS                                       0x654
+#define MC_ERR_VPR_ADR                                          0x658
+#define MC_VIDEO_PROTECT_VPR_OVERRIDE                           0x418
+#define MC_VIDEO_PROTECT_VPR_OVERRIDE1                          0x590
+#define MC_EMEM_CFG_ACCESS_CTRL                                 0x664
+#define MC_TZ_SECURITY_CTRL                                     0x668
+#define MC_EMEM_ARB_OUTSTANDING_REQ_RING3                       0x66c
+#define MC_EMEM_ARB_OUTSTANDING_REQ_NISO                        0x6b4
+#define MC_EMEM_ARB_RING0_THROTTLE_MASK                         0x6bc
+#define MC_EMEM_ARB_NISO_THROTTLE_MASK                          0x6b8
+#define MC_EMEM_ARB_NISO_THROTTLE_MASK_1                        0xb80
+#define MC_SEC_CARVEOUT_BOM                                     0x670
+#define MC_SEC_CARVEOUT_SIZE_MB                                 0x674
+#define MC_SEC_CARVEOUT_ADR_HI                                  0x9d4
+#define MC_SEC_CARVEOUT_REG_CTRL                                0x678
+#define MC_ERR_SEC_STATUS                                       0x67c
+#define MC_ERR_SEC_ADR                                          0x680
+#define MC_PC_IDLE_CLOCK_GATE_CONFIG                            0x684
+#define MC_STUTTER_CONTROL                                      0x688
+#define MC_RESERVED_RSV_1                                       0x958
+#define MC_DVFS_PIPE_SELECT                                     0x95c
+#define MC_SCEPC_PTSA_MIN                                       0x790
+#define MC_AUD_PTSA_MIN                                         0x54c
+#define MC_EQOSPC_PTSA_MAX                                      0x758
+#define MC_APEDMAPC_PTSA_RATE                                   0x7a4
+#define MC_MLL_MPCORER_PTSA_RATE                                0x44c
+#define MC_RING2_PTSA_RATE                                      0x440
+#define MC_USBD_PTSA_RATE                                       0x530
+#define MC_USBX_PTSA_MIN                                        0x528
+#define MC_JPG_PTSA_RATE                                        0x584
+#define MC_APB_PTSA_MAX                                         0x4f0
+#define MC_USBD_PTSA_MIN                                        0x534
+#define MC_DIS_PTSA_MIN                                         0x420
+#define MC_RING1_PTSA_MIN                                       0x480
+#define MC_DIS_PTSA_MAX                                         0x424
+#define MC_SD_PTSA_MAX                                          0x4d8
+#define MC_MSE_PTSA_RATE                                        0x4c4
+#define MC_PCX_PTSA_MAX                                         0x4b4
+#define MC_VICPC_PTSA_MIN                                       0x558
+#define MC_AONDMAPC_PTSA_MIN                                    0x784
+#define MC_ISP_PTSA_RATE                                        0x4a0
+#define MC_RING2_PTSA_MAX                                       0x448
+#define MC_BPMPDMAPC_PTSA_MIN                                   0x76c
+#define MC_AUD_PTSA_RATE                                        0x548
+#define MC_HOST_PTSA_MIN                                        0x51c
+#define MC_SDM1_PTSA_RATE                                       0x640
+#define MC_MLL_MPCORER_PTSA_MAX                                 0x454
+#define MC_SD_PTSA_MIN                                          0x4d4
+#define MC_NIC_PTSA_MAX                                         0x740
+#define MC_NVD_PTSA_MAX                                         0x580
+#define MC_RING1_PTSA_RATE                                      0x47c
+#define MC_JPG_PTSA_MIN                                         0x588
+#define MC_AONPC_PTSA_MAX                                       0x77c
+#define MC_MSE2_PTSA_MAX                                        0x7d0
+#define MC_HDAPC_PTSA_MIN                                       0x62c
+#define MC_JPG_PTSA_MAX                                         0x58c
+#define MC_VE_PTSA_MAX                                          0x43c
+#define MC_UFSHCPC_PTSA_MAX                                     0x74c
+#define MC_DFD_PTSA_MAX                                         0x63c
+#define MC_SCEDMAPC_PTSA_RATE                                   0x798
+#define MC_VICPC_PTSA_RATE                                      0x554
+#define MC_BPMPPC_PTSA_RATE                                     0x75c
+#define MC_GK_PTSA_MAX                                          0x544
+#define MC_SCEPC_PTSA_MAX                                       0x794
+#define MC_SCEDMAPC_PTSA_MIN                                    0x79c
+#define MC_VICPC_PTSA_MAX                                       0x55c
+#define MC_SDM_PTSA_MAX                                         0x624
+#define MC_NVD_PTSA_RATE                                        0x578
+#define MC_MSE2_PTSA_MIN                                        0x7cc
+#define MC_PCX_PTSA_MIN                                         0x4b0
+#define MC_SAX_PTSA_RATE                                        0x4b8
+#define MC_APB_PTSA_MIN                                         0x4ec
+#define MC_SCEPC_PTSA_RATE                                      0x78c
+#define MC_EQOSPC_PTSA_MIN                                      0x754
+#define MC_EQOSPC_PTSA_RATE                                     0x750
+#define MC_AONDMAPC_PTSA_MAX                                    0x788
+#define MC_AONPC_PTSA_MIN                                       0x778
+#define MC_VICPC3_PTSA_MIN                                      0x7b4
+#define MC_GK2_PTSA_MIN                                         0x614
+#define MC_PCX_PTSA_RATE                                        0x4ac
+#define MC_RING1_PTSA_MAX                                       0x484
+#define MC_HDAPC_PTSA_RATE                                      0x628
+#define MC_MLL_MPCORER_PTSA_MIN                                 0x450
+#define MC_GK2_PTSA_MAX                                         0x618
+#define MC_SDM1_PTSA_MIN                                        0x730
+#define MC_VICPC3_PTSA_RATE                                     0x7b0
+#define MC_AUD_PTSA_MAX                                         0x550
+#define MC_GK2_PTSA_RATE                                        0x610
+#define MC_NVD3_PTSA_MAX                                        0x7c4
+#define MC_ISP_PTSA_MAX                                         0x4a8
+#define MC_NVD_PTSA_MIN                                         0x57c
+#define MC_UFSHCPC_PTSA_MIN                                     0x748
+#define MC_FTOP_PTSA_RATE                                       0x50c
+#define MC_DFD_PTSA_MIN                                         0x638
+#define MC_VICPC3_PTSA_MAX                                      0x7b8
+#define MC_NVD3_PTSA_MIN                                        0x7c0
+#define MC_USBX_PTSA_MAX                                        0x52c
+#define MC_DIS_PTSA_RATE                                        0x41c
+#define MC_USBD_PTSA_MAX                                        0x538
+#define MC_APEDMAPC_PTSA_MAX                                    0x7ac
+#define MC_USBX_PTSA_RATE                                       0x524
+#define MC_BPMPDMAPC_PTSA_MAX                                   0x770
+#define MC_FTOP_PTSA_MAX                                        0x514
+#define MC_HDAPC_PTSA_MAX                                       0x630
+#define MC_SD_PTSA_RATE                                         0x4d0
+#define MC_BPMPDMAPC_PTSA_RATE                                  0x768
+#define MC_DFD_PTSA_RATE                                        0x634
+#define MC_SDM_PTSA_RATE                                        0x61c
+#define MC_FTOP_PTSA_MIN                                        0x510
+#define MC_SDM_PTSA_MIN                                         0x620
+#define MC_APB_PTSA_RATE                                        0x4e8
+#define MC_RING2_PTSA_MIN                                       0x444
+#define MC_UFSHCPC_PTSA_RATE                                    0x744
+#define MC_BPMPPC_PTSA_MAX                                      0x764
+#define MC_MSE2_PTSA_RATE                                       0x7c8
+#define MC_MSE_PTSA_MIN                                         0x4c8
+#define MC_NVD3_PTSA_RATE                                       0x7bc
+#define MC_HOST_PTSA_RATE                                       0x518
+#define MC_VE_PTSA_RATE                                         0x434
+#define MC_AONPC_PTSA_RATE                                      0x774
+#define MC_SAX_PTSA_MIN                                         0x4bc
+#define MC_NIC_PTSA_RATE                                        0x738
+#define MC_SCEDMAPC_PTSA_MAX                                    0x7a0
+#define MC_ISP_PTSA_MIN                                         0x4a4
+#define MC_AONDMAPC_PTSA_RATE                                   0x780
+#define MC_SDM1_PTSA_MAX                                        0x734
+#define MC_HOST_PTSA_MAX                                        0x520
+#define MC_BPMPPC_PTSA_MIN                                      0x760
+#define MC_SAX_PTSA_MAX                                         0x4c0
+#define MC_VE_PTSA_MIN                                          0x438
+#define MC_APEDMAPC_PTSA_MIN                                    0x7a8
+#define MC_GK_PTSA_MIN                                          0x540
+#define MC_MSE_PTSA_MAX                                         0x4cc
+#define MC_NIC_PTSA_MIN                                         0x73c
+#define MC_GK_PTSA_RATE                                         0x53c
+#define MC_SMMU_SMMU_PTSA_MIN					0x45c
+#define MC_SMMU_SMMU_PTSA_RATE					0x458
+#define MC_SMMU_SMMU_PTSA_MAX					0x460
+#define MC_PTSA_GRANT_DECREMENT                                 0x960
+#define MC_LATENCY_ALLOWANCE_AON_0                              0x714
+#define MC_LATENCY_ALLOWANCE_BPMP_0                             0x70c
+#define MC_LATENCY_ALLOWANCE_XUSB_1                             0x380
+#define MC_LATENCY_ALLOWANCE_SDMMCAA_0                          0x3bc
+#define MC_LATENCY_ALLOWANCE_SDMMCA_0                           0x3b8
+#define MC_LATENCY_ALLOWANCE_NVDISPLAY_0                        0x708
+#define MC_LATENCY_ALLOWANCE_ISP2_0                             0x370
+#define MC_LATENCY_ALLOWANCE_SE_0                               0x3e0
+#define MC_LATENCY_ALLOWANCE_ISP2_1                             0x374
+#define MC_LATENCY_ALLOWANCE_APEDMA_0                           0x724
+#define MC_LATENCY_ALLOWANCE_VIC_0                              0x394
+#define MC_LATENCY_ALLOWANCE_NVDEC_0                            0x3d8
+#define MC_LATENCY_ALLOWANCE_EQOS_0                             0x700
+#define MC_LATENCY_ALLOWANCE_TSEC_0                             0x390
+#define MC_LATENCY_ALLOWANCE_XUSB_0                             0x37c
+#define MC_LATENCY_ALLOWANCE_TSECB_0                            0x3f0
+#define MC_LATENCY_ALLOWANCE_AFI_0                              0x2e0
+#define MC_LATENCY_ALLOWANCE_SCE_0                              0x71c
+#define MC_LATENCY_ALLOWANCE_APE_0                              0x3dc
+#define MC_LATENCY_ALLOWANCE_GPU2_0                             0x3e8
+#define MC_LATENCY_ALLOWANCE_SDMMC_0                            0x3c0
+#define MC_LATENCY_ALLOWANCE_PTC_0                              0x34c
+#define MC_LATENCY_ALLOWANCE_NVJPG_0                            0x3e4
+#define MC_LATENCY_ALLOWANCE_ETR_0                              0x3ec
+#define MC_LATENCY_ALLOWANCE_MPCORE_0                           0x320
+#define MC_LATENCY_ALLOWANCE_VI2_0                              0x398
+#define MC_LATENCY_ALLOWANCE_SCEDMA_0                           0x720
+#define MC_LATENCY_ALLOWANCE_AONDMA_0                           0x718
+#define MC_LATENCY_ALLOWANCE_SATA_0                             0x350
+#define MC_LATENCY_ALLOWANCE_HC_0                               0x310
+#define MC_LATENCY_ALLOWANCE_UFSHC_0                            0x704
+#define MC_LATENCY_ALLOWANCE_AXIS_0                             0x3f8
+#define MC_LATENCY_ALLOWANCE_GPU_0                              0x3ac
+#define MC_LATENCY_ALLOWANCE_SDMMCAB_0                          0x3c4
+#define MC_LATENCY_ALLOWANCE_NVENC_0                            0x328
+#define MC_LATENCY_ALLOWANCE_HDA_0                              0x318
+#define MC_LATENCY_ALLOWANCE_BPMPDMA_0                          0x710
+#define MC_MIN_LENGTH_NVDEC_1                                   0xe28
+#define MC_MIN_LENGTH_AON_0                                     0xb68
+#define MC_MIN_LENGTH_APE_0                                     0xb34
+#define MC_MIN_LENGTH_APEDMA_0                                  0xb78
+#define MC_MIN_LENGTH_BPMP_0                                    0xb60
+#define MC_MIN_LENGTH_TSEC_0                                    0x93c
+#define MC_MIN_LENGTH_VI2_0                                     0x944
+#define MC_MIN_LENGTH_VIC_1                                     0xb7c
+#define MC_MIN_LENGTH_NVJPG_0                                   0xb3c
+#define MC_MIN_LENGTH_HDA_0                                     0x8c4
+#define MC_MIN_LENGTH_NVENC_0                                   0x8d4
+#define MC_MIN_LENGTH_AONDMA_0                                  0xb6c
+#define MC_MIN_LENGTH_SDMMC_0                                   0xb18
+#define MC_MIN_LENGTH_ISP2_0                                    0x91c
+#define MC_MIN_LENGTH_HC_0                                      0x8bc
+#define MC_MIN_LENGTH_VIC_0                                     0x940
+#define MC_MIN_LENGTH_SE_0                                      0xb38
+#define MC_MIN_LENGTH_NVDEC_0                                   0xb30
+#define MC_MIN_LENGTH_SATA_0                                    0x8fc
+#define MC_MIN_LENGTH_XUSB_1                                    0x92c
+#define MC_MIN_LENGTH_EQOS_0                                    0xb54
+#define MC_MIN_LENGTH_SDMMCAA_0                                 0xb14
+#define MC_MIN_LENGTH_NVDISPLAY_0                               0xb5c
+#define MC_MIN_LENGTH_GPU_0                                     0xb04
+#define MC_MIN_LENGTH_AFI_0                                     0x88c
+#define MC_MIN_LENGTH_ETR_0                                     0xb44
+#define MC_MIN_LENGTH_UFSHC_0                                   0xb58
+#define MC_MIN_LENGTH_ISP2_1                                    0x920
+#define MC_MIN_LENGTH_XUSB_0                                    0x928
+#define MC_MIN_LENGTH_SCE_0                                     0xb70
+#define MC_MIN_LENGTH_MPCORE_0                                  0x8cc
+#define MC_MIN_LENGTH_BPMPDMA_0                                 0xb64
+#define MC_MIN_LENGTH_TSECB_0                                   0xb48
+#define MC_MIN_LENGTH_SDMMCA_0                                  0xb10
+#define MC_MIN_LENGTH_SCEDMA_0                                  0xb74
+#define MC_MIN_LENGTH_AXIS_0                                    0xb50
+#define MC_MIN_LENGTH_PTC_0                                     0x8f8
+#define MC_MIN_LENGTH_SDMMCAB_0                                 0xb1c
+#define MC_MIN_LENGTH_GPU2_0                                    0xb40
+#define MC_EMEM_ARB_OVERRIDE_1                                  0x968
+#define MC_VIDEO_PROTECT_GPU_OVERRIDE_0                         0x984
+#define MC_VIDEO_PROTECT_GPU_OVERRIDE_1                         0x988
+#define MC_EMEM_ARB_STATS_0                                     0x990
+#define MC_EMEM_ARB_STATS_1                                     0x994
+#define MC_MTS_CARVEOUT_BOM                                     0x9a0
+#define MC_MTS_CARVEOUT_SIZE_MB                                 0x9a4
+#define MC_MTS_CARVEOUT_ADR_HI                                  0x9a8
+#define MC_MTS_CARVEOUT_REG_CTRL                                0x9ac
+#define MC_ERR_MTS_STATUS                                       0x9b0
+#define MC_ERR_MTS_ADR                                          0x9b4
+#define MC_ERR_GENERALIZED_CARVEOUT_STATUS_1                    0xbfc
+#define MC_ERR_GENERALIZED_CARVEOUT_STATUS                      0xc00
+#define MC_ERR_GENERALIZED_CARVEOUT_ADR                         0xc04
+#define MC_SECURITY_CARVEOUT5_CLIENT_FORCE_INTERNAL_ACCESS2     0xd78
+#define MC_SECURITY_CARVEOUT1_CLIENT_FORCE_INTERNAL_ACCESS5     0xc44
+#define MC_SECURITY_CARVEOUT4_CFG0                              0xcf8
+#define MC_SECURITY_CARVEOUT4_CLIENT_ACCESS2                    0xd10
+#define MC_SECURITY_CARVEOUT4_SIZE_128KB                        0xd04
+#define MC_SECURITY_CARVEOUT1_CLIENT_ACCESS4                    0xc28
+#define MC_SECURITY_CARVEOUT1_CLIENT_FORCE_INTERNAL_ACCESS1     0xc34
+#define MC_SECURITY_CARVEOUT2_CLIENT_FORCE_INTERNAL_ACCESS4     0xc90
+#define MC_SECURITY_CARVEOUT4_CLIENT_FORCE_INTERNAL_ACCESS0     0xd20
+#define MC_SECURITY_CARVEOUT5_CLIENT_FORCE_INTERNAL_ACCESS1     0xd74
+#define MC_SECURITY_CARVEOUT1_CLIENT_ACCESS5                    0xc2c
+#define MC_SECURITY_CARVEOUT1_CLIENT_FORCE_INTERNAL_ACCESS0     0xc30
+#define MC_SECURITY_CARVEOUT5_CLIENT_FORCE_INTERNAL_ACCESS4     0xd80
+#define MC_SECURITY_CARVEOUT3_CLIENT_ACCESS5                    0xccc
+#define MC_SECURITY_CARVEOUT3_SIZE_128KB                        0xcb4
+#define MC_SECURITY_CARVEOUT2_CFG0                              0xc58
+#define MC_SECURITY_CARVEOUT1_CFG0                              0xc08
+#define MC_SECURITY_CARVEOUT2_CLIENT_FORCE_INTERNAL_ACCESS2     0xc88
+#define MC_SECURITY_CARVEOUT2_CLIENT_ACCESS0                    0xc68
+#define MC_SECURITY_CARVEOUT3_BOM                               0xcac
+#define MC_SECURITY_CARVEOUT2_CLIENT_ACCESS2                    0xc70
+#define MC_SECURITY_CARVEOUT5_CLIENT_FORCE_INTERNAL_ACCESS5     0xd84
+#define MC_SECURITY_CARVEOUT5_CLIENT_FORCE_INTERNAL_ACCESS3     0xd7c
+#define MC_SECURITY_CARVEOUT2_CLIENT_FORCE_INTERNAL_ACCESS0     0xc80
+#define MC_SECURITY_CARVEOUT4_CLIENT_ACCESS4                    0xd18
+#define MC_SECURITY_CARVEOUT4_CLIENT_ACCESS5                    0xd1c
+#define MC_SECURITY_CARVEOUT3_CLIENT_ACCESS1                    0xcbc
+#define MC_SECURITY_CARVEOUT1_CLIENT_FORCE_INTERNAL_ACCESS3     0xc3c
+#define MC_SECURITY_CARVEOUT1_CLIENT_FORCE_INTERNAL_ACCESS2     0xc38
+#define MC_SECURITY_CARVEOUT3_CLIENT_ACCESS2                    0xcc0
+#define MC_SECURITY_CARVEOUT5_CLIENT_ACCESS2                    0xd60
+#define MC_SECURITY_CARVEOUT3_CFG0                              0xca8
+#define MC_SECURITY_CARVEOUT3_CLIENT_ACCESS0                    0xcb8
+#define MC_SECURITY_CARVEOUT2_CLIENT_FORCE_INTERNAL_ACCESS3     0xc8c
+#define MC_SECURITY_CARVEOUT2_SIZE_128KB                        0xc64
+#define MC_SECURITY_CARVEOUT5_BOM_HI                            0xd50
+#define MC_SECURITY_CARVEOUT1_SIZE_128KB                        0xc14
+#define MC_SECURITY_CARVEOUT4_CLIENT_ACCESS3                    0xd14
+#define MC_SECURITY_CARVEOUT1_BOM                               0xc0c
+#define MC_SECURITY_CARVEOUT4_CLIENT_FORCE_INTERNAL_ACCESS4     0xd30
+#define MC_SECURITY_CARVEOUT5_CLIENT_ACCESS4                    0xd68
+#define MC_SECURITY_CARVEOUT5_CLIENT_ACCESS0                    0xd58
+#define MC_SECURITY_CARVEOUT3_CLIENT_ACCESS4                    0xcc8
+#define MC_SECURITY_CARVEOUT3_CLIENT_FORCE_INTERNAL_ACCESS5     0xce4
+#define MC_SECURITY_CARVEOUT4_CLIENT_FORCE_INTERNAL_ACCESS2     0xd28
+#define MC_SECURITY_CARVEOUT3_CLIENT_ACCESS3                    0xcc4
+#define MC_SECURITY_CARVEOUT2_CLIENT_ACCESS4                    0xc78
+#define MC_SECURITY_CARVEOUT1_CLIENT_ACCESS1                    0xc1c
+#define MC_SECURITY_CARVEOUT1_CLIENT_ACCESS0                    0xc18
+#define MC_SECURITY_CARVEOUT5_CLIENT_ACCESS1                    0xd5c
+#define MC_SECURITY_CARVEOUT4_CLIENT_FORCE_INTERNAL_ACCESS3     0xd2c
+#define MC_SECURITY_CARVEOUT3_BOM_HI                            0xcb0
+#define MC_SECURITY_CARVEOUT3_CLIENT_FORCE_INTERNAL_ACCESS3     0xcdc
+#define MC_SECURITY_CARVEOUT2_BOM_HI                            0xc60
+#define MC_SECURITY_CARVEOUT4_BOM_HI                            0xd00
+#define MC_SECURITY_CARVEOUT5_CLIENT_ACCESS3                    0xd64
+#define MC_SECURITY_CARVEOUT3_CLIENT_FORCE_INTERNAL_ACCESS4     0xce0
+#define MC_SECURITY_CARVEOUT2_CLIENT_FORCE_INTERNAL_ACCESS1     0xc84
+#define MC_SECURITY_CARVEOUT5_SIZE_128KB                        0xd54
+#define MC_SECURITY_CARVEOUT2_CLIENT_FORCE_INTERNAL_ACCESS5     0xc94
+#define MC_SECURITY_CARVEOUT4_CLIENT_FORCE_INTERNAL_ACCESS1     0xd24
+#define MC_SECURITY_CARVEOUT3_CLIENT_FORCE_INTERNAL_ACCESS2     0xcd8
+#define MC_SECURITY_CARVEOUT4_CLIENT_ACCESS1                    0xd0c
+#define MC_SECURITY_CARVEOUT5_CLIENT_ACCESS5                    0xd6c
+#define MC_SECURITY_CARVEOUT2_CLIENT_ACCESS3                    0xc74
+#define MC_SECURITY_CARVEOUT5_CFG0                              0xd48
+#define MC_SECURITY_CARVEOUT3_CLIENT_FORCE_INTERNAL_ACCESS0     0xcd0
+#define MC_SECURITY_CARVEOUT4_BOM                               0xcfc
+#define MC_SECURITY_CARVEOUT2_BOM                               0xc5c
+#define MC_SECURITY_CARVEOUT5_BOM                               0xd4c
+#define MC_SECURITY_CARVEOUT1_CLIENT_ACCESS3                    0xc24
+#define MC_SECURITY_CARVEOUT5_CLIENT_FORCE_INTERNAL_ACCESS0     0xd70
+#define MC_SECURITY_CARVEOUT2_CLIENT_ACCESS5                    0xc7c
+#define MC_SECURITY_CARVEOUT3_CLIENT_FORCE_INTERNAL_ACCESS1     0xcd4
+#define MC_SECURITY_CARVEOUT1_BOM_HI                            0xc10
+#define MC_SECURITY_CARVEOUT4_CLIENT_FORCE_INTERNAL_ACCESS5     0xd34
+#define MC_SECURITY_CARVEOUT1_CLIENT_ACCESS2                    0xc20
+#define MC_SECURITY_CARVEOUT1_CLIENT_FORCE_INTERNAL_ACCESS4     0xc40
+#define MC_SECURITY_CARVEOUT2_CLIENT_ACCESS1                    0xc6c
+#define MC_SECURITY_CARVEOUT4_CLIENT_ACCESS0                    0xd08
+#define MC_SECURITY_CARVEOUT13_CLIENT_FORCE_INTERNAL_ACCESS1    0x225c
+#define MC_SECURITY_CARVEOUT6_CLIENT_FORCE_INTERNAL_ACCESS5     0x203c
+#define MC_SECURITY_CARVEOUT16_CLIENT_ACCESS3                   0x233c
+#define MC_SECURITY_CARVEOUT11_CLIENT_FORCE_INTERNAL_ACCESS3    0x21c4
+#define MC_SECURITY_CARVEOUT7_CFG0                              0x2050
+#define MC_SECURITY_CARVEOUT19_CLIENT_FORCE_INTERNAL_ACCESS1    0x243c
+#define MC_SECURITY_CARVEOUT22_CLIENT_FORCE_INTERNAL_ACCESS1    0x252c
+#define MC_SECURITY_CARVEOUT12_CFG0                             0x21e0
+#define MC_SECURITY_CARVEOUT29_CLIENT_FORCE_INTERNAL_ACCESS0    0x2758
+#define MC_SECURITY_CARVEOUT24_CLIENT_ACCESS5                   0x25c4
+#define MC_SECURITY_CARVEOUT10_CLIENT_ACCESS3                   0x215c
+#define MC_SECURITY_CARVEOUT15_BOM_HI                           0x22d8
+#define MC_SECURITY_CARVEOUT7_CLIENT_FORCE_INTERNAL_ACCESS5     0x208c
+#define MC_SECURITY_CARVEOUT13_CLIENT_ACCESS2                   0x2248
+#define MC_SECURITY_CARVEOUT26_CLIENT_ACCESS3                   0x265c
+#define MC_SECURITY_CARVEOUT12_CLIENT_FORCE_INTERNAL_ACCESS5    0x221c
+#define MC_SECURITY_CARVEOUT9_BOM_HI                            0x20f8
+#define MC_SECURITY_CARVEOUT15_CLIENT_ACCESS0                   0x22e0
+#define MC_SECURITY_CARVEOUT22_BOM                              0x2504
+#define MC_SECURITY_CARVEOUT10_CLIENT_FORCE_INTERNAL_ACCESS2    0x2170
+#define MC_SECURITY_CARVEOUT9_CLIENT_ACCESS3                    0x210c
+#define MC_SECURITY_CARVEOUT12_CLIENT_FORCE_INTERNAL_ACCESS0    0x2208
+#define MC_SECURITY_CARVEOUT26_CLIENT_FORCE_INTERNAL_ACCESS4    0x2678
+#define MC_SECURITY_CARVEOUT20_CLIENT_FORCE_INTERNAL_ACCESS0    0x2488
+#define MC_SECURITY_CARVEOUT21_CLIENT_FORCE_INTERNAL_ACCESS5    0x24ec
+#define MC_SECURITY_CARVEOUT9_CFG0                              0x20f0
+#define MC_SECURITY_CARVEOUT15_CFG0                             0x22d0
+#define MC_SECURITY_CARVEOUT9_CLIENT_FORCE_INTERNAL_ACCESS2     0x2120
+#define MC_SECURITY_CARVEOUT18_CLIENT_ACCESS1                   0x23d4
+#define MC_SECURITY_CARVEOUT7_SIZE_128KB                        0x205c
+#define MC_SECURITY_CARVEOUT17_CLIENT_ACCESS1                   0x2384
+#define MC_SECURITY_CARVEOUT20_CLIENT_FORCE_INTERNAL_ACCESS2    0x2490
+#define MC_SECURITY_CARVEOUT17_CLIENT_ACCESS0                   0x2380
+#define MC_SECURITY_CARVEOUT17_BOM_HI                           0x2378
+#define MC_SECURITY_CARVEOUT17_CLIENT_FORCE_INTERNAL_ACCESS5    0x23ac
+#define MC_SECURITY_CARVEOUT8_CLIENT_ACCESS4                    0x20c0
+#define MC_SECURITY_CARVEOUT16_CLIENT_FORCE_INTERNAL_ACCESS4    0x2358
+#define MC_SECURITY_CARVEOUT15_CLIENT_ACCESS2                   0x22e8
+#define MC_SECURITY_CARVEOUT16_CFG0                             0x2320
+#define MC_SECURITY_CARVEOUT9_BOM                               0x20f4
+#define MC_SECURITY_CARVEOUT14_CLIENT_FORCE_INTERNAL_ACCESS3    0x22b4
+#define MC_SECURITY_CARVEOUT21_CLIENT_ACCESS0                   0x24c0
+#define MC_SECURITY_CARVEOUT17_CLIENT_FORCE_INTERNAL_ACCESS2    0x23a0
+#define MC_SECURITY_CARVEOUT13_CLIENT_ACCESS5                   0x2254
+#define MC_SECURITY_CARVEOUT7_CLIENT_FORCE_INTERNAL_ACCESS0     0x2078
+#define MC_SECURITY_CARVEOUT24_CLIENT_FORCE_INTERNAL_ACCESS1    0x25cc
+#define MC_SECURITY_CARVEOUT17_CLIENT_FORCE_INTERNAL_ACCESS1    0x239c
+#define MC_SECURITY_CARVEOUT24_CLIENT_FORCE_INTERNAL_ACCESS3    0x25d4
+#define MC_SECURITY_CARVEOUT26_CLIENT_FORCE_INTERNAL_ACCESS5    0x267c
+#define MC_SECURITY_CARVEOUT22_BOM_HI                           0x2508
+#define MC_SECURITY_CARVEOUT7_CLIENT_ACCESS1                    0x2064
+#define MC_SECURITY_CARVEOUT16_CLIENT_FORCE_INTERNAL_ACCESS3    0x2354
+#define MC_SECURITY_CARVEOUT29_CLIENT_FORCE_INTERNAL_ACCESS5    0x276c
+#define MC_SECURITY_CARVEOUT27_CLIENT_FORCE_INTERNAL_ACCESS0    0x26b8
+#define MC_SECURITY_CARVEOUT27_SIZE_128KB                       0x269c
+#define MC_SECURITY_CARVEOUT20_CLIENT_ACCESS5                   0x2484
+#define MC_SECURITY_CARVEOUT18_CLIENT_ACCESS3                   0x23dc
+#define MC_SECURITY_CARVEOUT12_CLIENT_FORCE_INTERNAL_ACCESS2    0x2210
+#define MC_SECURITY_CARVEOUT19_CLIENT_FORCE_INTERNAL_ACCESS0    0x2438
+#define MC_SECURITY_CARVEOUT13_CLIENT_ACCESS4                   0x2250
+#define MC_SECURITY_CARVEOUT12_BOM_HI                           0x21e8
+#define MC_SECURITY_CARVEOUT28_CLIENT_FORCE_INTERNAL_ACCESS4    0x2718
+#define MC_SECURITY_CARVEOUT20_CLIENT_ACCESS0                   0x2470
+#define MC_SECURITY_CARVEOUT14_CLIENT_ACCESS0                   0x2290
+#define MC_SECURITY_CARVEOUT8_SIZE_128KB                        0x20ac
+#define MC_SECURITY_CARVEOUT25_CLIENT_FORCE_INTERNAL_ACCESS4    0x2628
+#define MC_SECURITY_CARVEOUT25_CLIENT_ACCESS3                   0x260c
+#define MC_SECURITY_CARVEOUT14_CLIENT_ACCESS4                   0x22a0
+#define MC_SECURITY_CARVEOUT24_CLIENT_ACCESS1                   0x25b4
+#define MC_SECURITY_CARVEOUT22_CLIENT_FORCE_INTERNAL_ACCESS3    0x2534
+#define MC_SECURITY_CARVEOUT19_CLIENT_FORCE_INTERNAL_ACCESS4    0x2448
+#define MC_SECURITY_CARVEOUT8_CLIENT_FORCE_INTERNAL_ACCESS1     0x20cc
+#define MC_SECURITY_CARVEOUT11_BOM                              0x2194
+#define MC_SECURITY_CARVEOUT26_CLIENT_FORCE_INTERNAL_ACCESS0    0x2668
+#define MC_SECURITY_CARVEOUT7_CLIENT_ACCESS3                    0x206c
+#define MC_SECURITY_CARVEOUT27_CLIENT_ACCESS2                   0x26a8
+#define MC_SECURITY_CARVEOUT28_CLIENT_ACCESS1                   0x26f4
+#define MC_SECURITY_CARVEOUT27_CLIENT_FORCE_INTERNAL_ACCESS3    0x26c4
+#define MC_SECURITY_CARVEOUT19_CLIENT_ACCESS4                   0x2430
+#define MC_SECURITY_CARVEOUT28_SIZE_128KB                       0x26ec
+#define MC_SECURITY_CARVEOUT22_CLIENT_ACCESS3                   0x251c
+#define MC_SECURITY_CARVEOUT23_CLIENT_ACCESS4                   0x2570
+#define MC_SECURITY_CARVEOUT12_CLIENT_ACCESS4                   0x2200
+#define MC_SECURITY_CARVEOUT22_CLIENT_FORCE_INTERNAL_ACCESS5    0x253c
+#define MC_SECURITY_CARVEOUT6_CLIENT_ACCESS4                    0x2020
+#define MC_SECURITY_CARVEOUT17_CLIENT_ACCESS5                   0x2394
+#define MC_SECURITY_CARVEOUT8_CLIENT_FORCE_INTERNAL_ACCESS5     0x20dc
+#define MC_SECURITY_CARVEOUT29_CLIENT_ACCESS1                   0x2744
+#define MC_SECURITY_CARVEOUT18_CLIENT_FORCE_INTERNAL_ACCESS5    0x23fc
+#define MC_SECURITY_CARVEOUT16_CLIENT_ACCESS0                   0x2330
+#define MC_SECURITY_CARVEOUT13_SIZE_128KB                       0x223c
+#define MC_SECURITY_CARVEOUT21_CLIENT_FORCE_INTERNAL_ACCESS2    0x24e0
+#define MC_SECURITY_CARVEOUT11_CLIENT_ACCESS3                   0x21ac
+#define MC_SECURITY_CARVEOUT19_BOM                              0x2414
+#define MC_SECURITY_CARVEOUT7_BOM                               0x2054
+#define MC_SECURITY_CARVEOUT28_CLIENT_FORCE_INTERNAL_ACCESS3    0x2714
+#define MC_SECURITY_CARVEOUT23_SIZE_128KB                       0x255c
+#define MC_SECURITY_CARVEOUT17_CLIENT_FORCE_INTERNAL_ACCESS0    0x2398
+#define MC_SECURITY_CARVEOUT7_CLIENT_ACCESS0                    0x2060
+#define MC_SECURITY_CARVEOUT8_CLIENT_ACCESS5                    0x20c4
+#define MC_SECURITY_CARVEOUT23_CFG0                             0x2550
+#define MC_SECURITY_CARVEOUT23_CLIENT_ACCESS2                   0x2568
+#define MC_SECURITY_CARVEOUT25_CLIENT_FORCE_INTERNAL_ACCESS3    0x2624
+#define MC_SECURITY_CARVEOUT19_CLIENT_FORCE_INTERNAL_ACCESS3    0x2444
+#define MC_SECURITY_CARVEOUT8_CLIENT_FORCE_INTERNAL_ACCESS0     0x20c8
+#define MC_SECURITY_CARVEOUT12_SIZE_128KB                       0x21ec
+#define MC_SECURITY_CARVEOUT13_BOM                              0x2234
+#define MC_SECURITY_CARVEOUT13_CLIENT_ACCESS1                   0x2244
+#define MC_SECURITY_CARVEOUT21_CLIENT_ACCESS3                   0x24cc
+#define MC_SECURITY_CARVEOUT15_CLIENT_FORCE_INTERNAL_ACCESS2    0x2300
+#define MC_SECURITY_CARVEOUT27_CLIENT_ACCESS5                   0x26b4
+#define MC_SECURITY_CARVEOUT17_CFG0                             0x2370
+#define MC_SECURITY_CARVEOUT14_CLIENT_ACCESS5                   0x22a4
+#define MC_SECURITY_CARVEOUT7_CLIENT_FORCE_INTERNAL_ACCESS4     0x2088
+#define MC_SECURITY_CARVEOUT29_SIZE_128KB                       0x273c
+#define MC_SECURITY_CARVEOUT29_CLIENT_ACCESS3                   0x274c
+#define MC_SECURITY_CARVEOUT15_CLIENT_FORCE_INTERNAL_ACCESS3    0x2304
+#define MC_SECURITY_CARVEOUT9_CLIENT_FORCE_INTERNAL_ACCESS1     0x211c
+#define MC_SECURITY_CARVEOUT26_CLIENT_FORCE_INTERNAL_ACCESS3    0x2674
+#define MC_SECURITY_CARVEOUT24_CLIENT_FORCE_INTERNAL_ACCESS2    0x25d0
+#define MC_SECURITY_CARVEOUT24_BOM_HI                           0x25a8
+#define MC_SECURITY_CARVEOUT27_CFG0                             0x2690
+#define MC_SECURITY_CARVEOUT15_CLIENT_ACCESS5                   0x22f4
+#define MC_SECURITY_CARVEOUT16_SIZE_128KB                       0x232c
+#define MC_SECURITY_CARVEOUT7_CLIENT_FORCE_INTERNAL_ACCESS1     0x207c
+#define MC_SECURITY_CARVEOUT9_CLIENT_ACCESS2                    0x2108
+#define MC_SECURITY_CARVEOUT15_CLIENT_ACCESS3                   0x22ec
+#define MC_SECURITY_CARVEOUT28_CLIENT_FORCE_INTERNAL_ACCESS0    0x2708
+#define MC_SECURITY_CARVEOUT25_CLIENT_FORCE_INTERNAL_ACCESS1    0x261c
+#define MC_SECURITY_CARVEOUT24_CLIENT_ACCESS0                   0x25b0
+#define MC_SECURITY_CARVEOUT18_BOM                              0x23c4
+#define MC_SECURITY_CARVEOUT23_CLIENT_FORCE_INTERNAL_ACCESS5    0x258c
+#define MC_SECURITY_CARVEOUT18_CLIENT_FORCE_INTERNAL_ACCESS2    0x23f0
+#define MC_SECURITY_CARVEOUT22_CLIENT_FORCE_INTERNAL_ACCESS0    0x2528
+#define MC_SECURITY_CARVEOUT20_CLIENT_FORCE_INTERNAL_ACCESS1    0x248c
+#define MC_SECURITY_CARVEOUT8_CLIENT_FORCE_INTERNAL_ACCESS4     0x20d8
+#define MC_SECURITY_CARVEOUT24_CLIENT_ACCESS4                   0x25c0
+#define MC_SECURITY_CARVEOUT13_CLIENT_FORCE_INTERNAL_ACCESS5    0x226c
+#define MC_SECURITY_CARVEOUT8_CLIENT_ACCESS0                    0x20b0
+#define MC_SECURITY_CARVEOUT22_CLIENT_ACCESS0                   0x2510
+#define MC_SECURITY_CARVEOUT25_CLIENT_ACCESS0                   0x2600
+#define MC_SECURITY_CARVEOUT24_CFG0                             0x25a0
+#define MC_SECURITY_CARVEOUT28_CFG0                             0x26e0
+#define MC_SECURITY_CARVEOUT24_SIZE_128KB                       0x25ac
+#define MC_SECURITY_CARVEOUT6_CFG0                              0x2000
+#define MC_SECURITY_CARVEOUT21_BOM                              0x24b4
+#define MC_SECURITY_CARVEOUT12_CLIENT_FORCE_INTERNAL_ACCESS3    0x2214
+#define MC_SECURITY_CARVEOUT20_CLIENT_FORCE_INTERNAL_ACCESS5    0x249c
+#define MC_SECURITY_CARVEOUT11_CLIENT_ACCESS2                   0x21a8
+#define MC_SECURITY_CARVEOUT25_CLIENT_ACCESS1                   0x2604
+#define MC_SECURITY_CARVEOUT16_CLIENT_ACCESS4                   0x2340
+#define MC_SECURITY_CARVEOUT29_CFG0                             0x2730
+#define MC_SECURITY_CARVEOUT14_CLIENT_FORCE_INTERNAL_ACCESS4    0x22b8
+#define MC_SECURITY_CARVEOUT14_BOM_HI                           0x2288
+#define MC_SECURITY_CARVEOUT11_CFG0                             0x2190
+#define MC_SECURITY_CARVEOUT12_CLIENT_ACCESS3                   0x21fc
+#define MC_SECURITY_CARVEOUT9_SIZE_128KB                        0x20fc
+#define MC_SECURITY_CARVEOUT29_CLIENT_FORCE_INTERNAL_ACCESS3    0x2764
+#define MC_SECURITY_CARVEOUT8_CFG0                              0x20a0
+#define MC_SECURITY_CARVEOUT23_CLIENT_FORCE_INTERNAL_ACCESS2    0x2580
+#define MC_SECURITY_CARVEOUT20_BOM                              0x2464
+#define MC_SECURITY_CARVEOUT10_CLIENT_ACCESS5                   0x2164
+#define MC_SECURITY_CARVEOUT11_CLIENT_FORCE_INTERNAL_ACCESS5    0x21cc
+#define MC_SECURITY_CARVEOUT20_CLIENT_ACCESS4                   0x2480
+#define MC_SECURITY_CARVEOUT22_CLIENT_FORCE_INTERNAL_ACCESS4    0x2538
+#define MC_SECURITY_CARVEOUT19_CLIENT_ACCESS5                   0x2434
+#define MC_SECURITY_CARVEOUT16_CLIENT_FORCE_INTERNAL_ACCESS2    0x2350
+#define MC_SECURITY_CARVEOUT29_CLIENT_ACCESS2                   0x2748
+#define MC_SECURITY_CARVEOUT21_CLIENT_FORCE_INTERNAL_ACCESS4    0x24e8
+#define MC_SECURITY_CARVEOUT14_CLIENT_ACCESS1                   0x2294
+#define MC_SECURITY_CARVEOUT11_CLIENT_ACCESS5                   0x21b4
+#define MC_SECURITY_CARVEOUT22_CLIENT_ACCESS4                   0x2520
+#define MC_SECURITY_CARVEOUT18_CLIENT_ACCESS4                   0x23e0
+#define MC_SECURITY_CARVEOUT16_CLIENT_ACCESS1                   0x2334
+#define MC_SECURITY_CARVEOUT28_BOM                              0x26e4
+#define MC_SECURITY_CARVEOUT8_CLIENT_ACCESS1                    0x20b4
+#define MC_SECURITY_CARVEOUT15_BOM                              0x22d4
+#define MC_SECURITY_CARVEOUT11_CLIENT_ACCESS1                   0x21a4
+#define MC_SECURITY_CARVEOUT10_CLIENT_FORCE_INTERNAL_ACCESS3    0x2174
+#define MC_SECURITY_CARVEOUT6_BOM                               0x2004
+#define MC_SECURITY_CARVEOUT27_CLIENT_ACCESS3                   0x26ac
+#define MC_SECURITY_CARVEOUT27_CLIENT_FORCE_INTERNAL_ACCESS2    0x26c0
+#define MC_SECURITY_CARVEOUT6_CLIENT_ACCESS3                    0x201c
+#define MC_SECURITY_CARVEOUT10_BOM                              0x2144
+#define MC_SECURITY_CARVEOUT28_CLIENT_FORCE_INTERNAL_ACCESS2    0x2710
+#define MC_SECURITY_CARVEOUT29_BOM_HI                           0x2738
+#define MC_SECURITY_CARVEOUT13_CLIENT_FORCE_INTERNAL_ACCESS0    0x2258
+#define MC_SECURITY_CARVEOUT28_CLIENT_ACCESS0                   0x26f0
+#define MC_SECURITY_CARVEOUT18_CLIENT_ACCESS0                   0x23d0
+#define MC_SECURITY_CARVEOUT10_CLIENT_ACCESS0                   0x2150
+#define MC_SECURITY_CARVEOUT29_CLIENT_FORCE_INTERNAL_ACCESS2    0x2760
+#define MC_SECURITY_CARVEOUT7_BOM_HI                            0x2058
+#define MC_SECURITY_CARVEOUT19_CLIENT_ACCESS2                   0x2428
+#define MC_SECURITY_CARVEOUT9_CLIENT_ACCESS4                    0x2110
+#define MC_SECURITY_CARVEOUT22_CLIENT_ACCESS5                   0x2524
+#define MC_SECURITY_CARVEOUT19_SIZE_128KB                       0x241c
+#define MC_SECURITY_CARVEOUT18_SIZE_128KB                       0x23cc
+#define MC_SECURITY_CARVEOUT15_CLIENT_FORCE_INTERNAL_ACCESS1    0x22fc
+#define MC_SECURITY_CARVEOUT10_CFG0                             0x2140
+#define MC_SECURITY_CARVEOUT28_CLIENT_FORCE_INTERNAL_ACCESS1    0x270c
+#define MC_SECURITY_CARVEOUT26_CFG0                             0x2640
+#define MC_SECURITY_CARVEOUT11_CLIENT_FORCE_INTERNAL_ACCESS1    0x21bc
+#define MC_SECURITY_CARVEOUT10_CLIENT_FORCE_INTERNAL_ACCESS0    0x2168
+#define MC_SECURITY_CARVEOUT15_CLIENT_FORCE_INTERNAL_ACCESS4    0x2308
+#define MC_SECURITY_CARVEOUT6_BOM_HI                            0x2008
+#define MC_SECURITY_CARVEOUT15_SIZE_128KB                       0x22dc
+#define MC_SECURITY_CARVEOUT26_CLIENT_FORCE_INTERNAL_ACCESS2    0x2670
+#define MC_SECURITY_CARVEOUT21_CLIENT_ACCESS4                   0x24d0
+#define MC_SECURITY_CARVEOUT26_CLIENT_ACCESS4                   0x2660
+#define MC_SECURITY_CARVEOUT14_SIZE_128KB                       0x228c
+#define MC_SECURITY_CARVEOUT24_CLIENT_FORCE_INTERNAL_ACCESS5    0x25dc
+#define MC_SECURITY_CARVEOUT6_SIZE_128KB                        0x200c
+#define MC_SECURITY_CARVEOUT21_CLIENT_ACCESS2                   0x24c8
+#define MC_SECURITY_CARVEOUT20_CLIENT_ACCESS2                   0x2478
+#define MC_SECURITY_CARVEOUT6_CLIENT_ACCESS1                    0x2014
+#define MC_SECURITY_CARVEOUT19_CFG0                             0x2410
+#define MC_SECURITY_CARVEOUT24_CLIENT_ACCESS3                   0x25bc
+#define MC_SECURITY_CARVEOUT12_CLIENT_ACCESS1                   0x21f4
+#define MC_SECURITY_CARVEOUT6_CLIENT_ACCESS2                    0x2018
+#define MC_SECURITY_CARVEOUT20_SIZE_128KB                       0x246c
+#define MC_SECURITY_CARVEOUT27_CLIENT_FORCE_INTERNAL_ACCESS5    0x26cc
+#define MC_SECURITY_CARVEOUT10_CLIENT_FORCE_INTERNAL_ACCESS5    0x217c
+#define MC_SECURITY_CARVEOUT28_CLIENT_ACCESS4                   0x2700
+#define MC_SECURITY_CARVEOUT26_CLIENT_ACCESS1                   0x2654
+#define MC_SECURITY_CARVEOUT23_CLIENT_ACCESS1                   0x2564
+#define MC_SECURITY_CARVEOUT20_CLIENT_FORCE_INTERNAL_ACCESS4    0x2498
+#define MC_SECURITY_CARVEOUT29_CLIENT_ACCESS0                   0x2740
+#define MC_SECURITY_CARVEOUT14_CLIENT_FORCE_INTERNAL_ACCESS1    0x22ac
+#define MC_SECURITY_CARVEOUT18_CLIENT_FORCE_INTERNAL_ACCESS3    0x23f4
+#define MC_SECURITY_CARVEOUT27_BOM                              0x2694
+#define MC_SECURITY_CARVEOUT13_CLIENT_ACCESS3                   0x224c
+#define MC_SECURITY_CARVEOUT22_CLIENT_ACCESS1                   0x2514
+#define MC_SECURITY_CARVEOUT9_CLIENT_ACCESS1                    0x2104
+#define MC_SECURITY_CARVEOUT11_CLIENT_FORCE_INTERNAL_ACCESS2    0x21c0
+#define MC_SECURITY_CARVEOUT27_CLIENT_FORCE_INTERNAL_ACCESS1    0x26bc
+#define MC_SECURITY_CARVEOUT7_CLIENT_ACCESS4                    0x2070
+#define MC_SECURITY_CARVEOUT8_CLIENT_FORCE_INTERNAL_ACCESS3     0x20d4
+#define MC_SECURITY_CARVEOUT10_CLIENT_ACCESS1                   0x2154
+#define MC_SECURITY_CARVEOUT16_CLIENT_FORCE_INTERNAL_ACCESS1    0x234c
+#define MC_SECURITY_CARVEOUT18_CLIENT_ACCESS5                   0x23e4
+#define MC_SECURITY_CARVEOUT25_CLIENT_ACCESS2                   0x2608
+#define MC_SECURITY_CARVEOUT17_CLIENT_ACCESS4                   0x2390
+#define MC_SECURITY_CARVEOUT19_BOM_HI                           0x2418
+#define MC_SECURITY_CARVEOUT27_CLIENT_ACCESS4                   0x26b0
+#define MC_SECURITY_CARVEOUT11_CLIENT_ACCESS0                   0x21a0
+#define MC_SECURITY_CARVEOUT23_CLIENT_ACCESS3                   0x256c
+#define MC_SECURITY_CARVEOUT11_BOM_HI                           0x2198
+#define MC_SECURITY_CARVEOUT24_CLIENT_FORCE_INTERNAL_ACCESS0    0x25c8
+#define MC_SECURITY_CARVEOUT23_BOM                              0x2554
+#define MC_SECURITY_CARVEOUT6_CLIENT_FORCE_INTERNAL_ACCESS0     0x2028
+#define MC_SECURITY_CARVEOUT13_CLIENT_ACCESS0                   0x2240
+#define MC_SECURITY_CARVEOUT20_CLIENT_ACCESS3                   0x247c
+#define MC_SECURITY_CARVEOUT25_CLIENT_FORCE_INTERNAL_ACCESS0    0x2618
+#define MC_SECURITY_CARVEOUT13_CLIENT_FORCE_INTERNAL_ACCESS4    0x2268
+#define MC_SECURITY_CARVEOUT15_CLIENT_ACCESS4                   0x22f0
+#define MC_SECURITY_CARVEOUT21_CLIENT_FORCE_INTERNAL_ACCESS3    0x24e4
+#define MC_SECURITY_CARVEOUT6_CLIENT_FORCE_INTERNAL_ACCESS1     0x202c
+#define MC_SECURITY_CARVEOUT24_BOM                              0x25a4
+#define MC_SECURITY_CARVEOUT9_CLIENT_FORCE_INTERNAL_ACCESS5     0x212c
+#define MC_SECURITY_CARVEOUT12_CLIENT_FORCE_INTERNAL_ACCESS4    0x2218
+#define MC_SECURITY_CARVEOUT18_CLIENT_FORCE_INTERNAL_ACCESS0    0x23e8
+#define MC_SECURITY_CARVEOUT21_BOM_HI                           0x24b8
+#define MC_SECURITY_CARVEOUT23_CLIENT_FORCE_INTERNAL_ACCESS4    0x2588
+#define MC_SECURITY_CARVEOUT25_SIZE_128KB                       0x25fc
+#define MC_SECURITY_CARVEOUT14_CLIENT_FORCE_INTERNAL_ACCESS5    0x22bc
+#define MC_SECURITY_CARVEOUT12_CLIENT_ACCESS2                   0x21f8
+#define MC_SECURITY_CARVEOUT16_CLIENT_ACCESS2                   0x2338
+#define MC_SECURITY_CARVEOUT28_CLIENT_ACCESS3                   0x26fc
+#define MC_SECURITY_CARVEOUT6_CLIENT_FORCE_INTERNAL_ACCESS2     0x2030
+#define MC_SECURITY_CARVEOUT11_CLIENT_FORCE_INTERNAL_ACCESS4    0x21c8
+#define MC_SECURITY_CARVEOUT16_BOM                              0x2324
+#define MC_SECURITY_CARVEOUT10_CLIENT_FORCE_INTERNAL_ACCESS4    0x2178
+#define MC_SECURITY_CARVEOUT9_CLIENT_FORCE_INTERNAL_ACCESS4     0x2128
+#define MC_SECURITY_CARVEOUT19_CLIENT_ACCESS0                   0x2420
+#define MC_SECURITY_CARVEOUT8_CLIENT_FORCE_INTERNAL_ACCESS2     0x20d0
+#define MC_SECURITY_CARVEOUT7_CLIENT_ACCESS5                    0x2074
+#define MC_SECURITY_CARVEOUT7_CLIENT_FORCE_INTERNAL_ACCESS3     0x2084
+#define MC_SECURITY_CARVEOUT18_BOM_HI                           0x23c8
+#define MC_SECURITY_CARVEOUT21_CLIENT_FORCE_INTERNAL_ACCESS0    0x24d8
+#define MC_SECURITY_CARVEOUT15_CLIENT_FORCE_INTERNAL_ACCESS5    0x230c
+#define MC_SECURITY_CARVEOUT16_CLIENT_ACCESS5                   0x2344
+#define MC_SECURITY_CARVEOUT26_CLIENT_ACCESS2                   0x2658
+#define MC_SECURITY_CARVEOUT15_CLIENT_ACCESS1                   0x22e4
+#define MC_SECURITY_CARVEOUT15_CLIENT_FORCE_INTERNAL_ACCESS0    0x22f8
+#define MC_SECURITY_CARVEOUT26_CLIENT_ACCESS0                   0x2650
+#define MC_SECURITY_CARVEOUT16_CLIENT_FORCE_INTERNAL_ACCESS5    0x235c
+#define MC_SECURITY_CARVEOUT19_CLIENT_ACCESS3                   0x242c
+#define MC_SECURITY_CARVEOUT29_BOM                              0x2734
+#define MC_SECURITY_CARVEOUT11_CLIENT_ACCESS4                   0x21b0
+#define MC_SECURITY_CARVEOUT13_CLIENT_FORCE_INTERNAL_ACCESS2    0x2260
+#define MC_SECURITY_CARVEOUT25_CLIENT_ACCESS5                   0x2614
+#define MC_SECURITY_CARVEOUT23_CLIENT_FORCE_INTERNAL_ACCESS1    0x257c
+#define MC_SECURITY_CARVEOUT29_CLIENT_ACCESS5                   0x2754
+#define MC_SECURITY_CARVEOUT10_CLIENT_ACCESS4                   0x2160
+#define MC_SECURITY_CARVEOUT9_CLIENT_ACCESS5                    0x2114
+#define MC_SECURITY_CARVEOUT13_BOM_HI                           0x2238
+#define MC_SECURITY_CARVEOUT26_CLIENT_FORCE_INTERNAL_ACCESS1    0x266c
+#define MC_SECURITY_CARVEOUT11_CLIENT_FORCE_INTERNAL_ACCESS0    0x21b8
+#define MC_SECURITY_CARVEOUT9_CLIENT_FORCE_INTERNAL_ACCESS0     0x2118
+#define MC_SECURITY_CARVEOUT8_CLIENT_ACCESS2                    0x20b8
+#define MC_SECURITY_CARVEOUT28_CLIENT_ACCESS2                   0x26f8
+#define MC_SECURITY_CARVEOUT28_BOM_HI                           0x26e8
+#define MC_SECURITY_CARVEOUT8_BOM_HI                            0x20a8
+#define MC_SECURITY_CARVEOUT17_CLIENT_ACCESS2                   0x2388
+#define MC_SECURITY_CARVEOUT21_CFG0                             0x24b0
+#define MC_SECURITY_CARVEOUT22_CLIENT_FORCE_INTERNAL_ACCESS2    0x2530
+#define MC_SECURITY_CARVEOUT27_CLIENT_ACCESS0                   0x26a0
+#define MC_SECURITY_CARVEOUT12_BOM                              0x21e4
+#define MC_SECURITY_CARVEOUT27_CLIENT_FORCE_INTERNAL_ACCESS4    0x26c8
+#define MC_SECURITY_CARVEOUT6_CLIENT_ACCESS5                    0x2024
+#define MC_SECURITY_CARVEOUT10_BOM_HI                           0x2148
+#define MC_SECURITY_CARVEOUT17_CLIENT_FORCE_INTERNAL_ACCESS3    0x23a4
+#define MC_SECURITY_CARVEOUT10_SIZE_128KB                       0x214c
+#define MC_SECURITY_CARVEOUT14_CLIENT_ACCESS2                   0x2298
+#define MC_SECURITY_CARVEOUT21_CLIENT_ACCESS5                   0x24d4
+#define MC_SECURITY_CARVEOUT22_CLIENT_ACCESS2                   0x2518
+#define MC_SECURITY_CARVEOUT23_BOM_HI                           0x2558
+#define MC_SECURITY_CARVEOUT24_CLIENT_ACCESS2                   0x25b8
+#define MC_SECURITY_CARVEOUT6_CLIENT_FORCE_INTERNAL_ACCESS4     0x2038
+#define MC_SECURITY_CARVEOUT26_BOM_HI                           0x2648
+#define MC_SECURITY_CARVEOUT6_CLIENT_ACCESS0                    0x2010
+#define MC_SECURITY_CARVEOUT19_CLIENT_FORCE_INTERNAL_ACCESS2    0x2440
+#define MC_SECURITY_CARVEOUT9_CLIENT_ACCESS0                    0x2100
+#define MC_SECURITY_CARVEOUT18_CFG0                             0x23c0
+#define MC_SECURITY_CARVEOUT26_CLIENT_ACCESS5                   0x2664
+#define MC_SECURITY_CARVEOUT23_CLIENT_FORCE_INTERNAL_ACCESS0    0x2578
+#define MC_SECURITY_CARVEOUT27_BOM_HI                           0x2698
+#define MC_SECURITY_CARVEOUT24_CLIENT_FORCE_INTERNAL_ACCESS4    0x25d8
+#define MC_SECURITY_CARVEOUT22_SIZE_128KB                       0x250c
+#define MC_SECURITY_CARVEOUT21_CLIENT_ACCESS1                   0x24c4
+#define MC_SECURITY_CARVEOUT27_CLIENT_ACCESS1                   0x26a4
+#define MC_SECURITY_CARVEOUT12_CLIENT_ACCESS0                   0x21f0
+#define MC_SECURITY_CARVEOUT10_CLIENT_ACCESS2                   0x2158
+#define MC_SECURITY_CARVEOUT18_CLIENT_FORCE_INTERNAL_ACCESS4    0x23f8
+#define MC_SECURITY_CARVEOUT28_CLIENT_FORCE_INTERNAL_ACCESS5    0x271c
+#define MC_SECURITY_CARVEOUT7_CLIENT_ACCESS2                    0x2068
+#define MC_SECURITY_CARVEOUT14_CLIENT_FORCE_INTERNAL_ACCESS2    0x22b0
+#define MC_SECURITY_CARVEOUT23_CLIENT_ACCESS5                   0x2574
+#define MC_SECURITY_CARVEOUT23_CLIENT_ACCESS0                   0x2560
+#define MC_SECURITY_CARVEOUT12_CLIENT_FORCE_INTERNAL_ACCESS1    0x220c
+#define MC_SECURITY_CARVEOUT28_CLIENT_ACCESS5                   0x2704
+#define MC_SECURITY_CARVEOUT11_SIZE_128KB                       0x219c
+#define MC_SECURITY_CARVEOUT7_CLIENT_FORCE_INTERNAL_ACCESS2     0x2080
+#define MC_SECURITY_CARVEOUT29_CLIENT_FORCE_INTERNAL_ACCESS4    0x2768
+#define MC_SECURITY_CARVEOUT25_BOM_HI                           0x25f8
+#define MC_SECURITY_CARVEOUT14_BOM                              0x2284
+#define MC_SECURITY_CARVEOUT16_BOM_HI                           0x2328
+#define MC_SECURITY_CARVEOUT18_CLIENT_FORCE_INTERNAL_ACCESS1    0x23ec
+#define MC_SECURITY_CARVEOUT20_CFG0                             0x2460
+#define MC_SECURITY_CARVEOUT20_CLIENT_FORCE_INTERNAL_ACCESS3    0x2494
+#define MC_SECURITY_CARVEOUT21_CLIENT_FORCE_INTERNAL_ACCESS1    0x24dc
+#define MC_SECURITY_CARVEOUT16_CLIENT_FORCE_INTERNAL_ACCESS0    0x2348
+#define MC_SECURITY_CARVEOUT14_CLIENT_FORCE_INTERNAL_ACCESS0    0x22a8
+#define MC_SECURITY_CARVEOUT17_CLIENT_FORCE_INTERNAL_ACCESS4    0x23a8
+#define MC_SECURITY_CARVEOUT25_CLIENT_FORCE_INTERNAL_ACCESS2    0x2620
+#define MC_SECURITY_CARVEOUT17_CLIENT_ACCESS3                   0x238c
+#define MC_SECURITY_CARVEOUT25_CLIENT_ACCESS4                   0x2610
+#define MC_SECURITY_CARVEOUT25_CFG0                             0x25f0
+#define MC_SECURITY_CARVEOUT19_CLIENT_ACCESS1                   0x2424
+#define MC_SECURITY_CARVEOUT8_CLIENT_ACCESS3                    0x20bc
+#define MC_SECURITY_CARVEOUT13_CLIENT_FORCE_INTERNAL_ACCESS3    0x2264
+#define MC_SECURITY_CARVEOUT10_CLIENT_FORCE_INTERNAL_ACCESS1    0x216c
+#define MC_SECURITY_CARVEOUT14_CFG0                             0x2280
+#define MC_SECURITY_CARVEOUT20_CLIENT_ACCESS1                   0x2474
+#define MC_SECURITY_CARVEOUT8_BOM                               0x20a4
+#define MC_SECURITY_CARVEOUT29_CLIENT_ACCESS4                   0x2750
+#define MC_SECURITY_CARVEOUT22_CFG0                             0x2500
+#define MC_SECURITY_CARVEOUT26_SIZE_128KB                       0x264c
+#define MC_SECURITY_CARVEOUT17_BOM                              0x2374
+#define MC_SECURITY_CARVEOUT18_CLIENT_ACCESS2                   0x23d8
+#define MC_SECURITY_CARVEOUT13_CFG0                             0x2230
+#define MC_SECURITY_CARVEOUT26_BOM                              0x2644
+#define MC_SECURITY_CARVEOUT14_CLIENT_ACCESS3                   0x229c
+#define MC_SECURITY_CARVEOUT29_CLIENT_FORCE_INTERNAL_ACCESS1    0x275c
+#define MC_SECURITY_CARVEOUT20_BOM_HI                           0x2468
+#define MC_SECURITY_CARVEOUT12_CLIENT_ACCESS5                   0x2204
+#define MC_SECURITY_CARVEOUT21_SIZE_128KB                       0x24bc
+#define MC_SECURITY_CARVEOUT17_SIZE_128KB                       0x237c
+#define MC_SECURITY_CARVEOUT19_CLIENT_FORCE_INTERNAL_ACCESS5    0x244c
+#define MC_SECURITY_CARVEOUT23_CLIENT_FORCE_INTERNAL_ACCESS3    0x2584
+#define MC_SECURITY_CARVEOUT9_CLIENT_FORCE_INTERNAL_ACCESS3     0x2124
+#define MC_SECURITY_CARVEOUT6_CLIENT_FORCE_INTERNAL_ACCESS3     0x2034
+#define MC_SECURITY_CARVEOUT25_CLIENT_FORCE_INTERNAL_ACCESS5    0x262c
+#define MC_SECURITY_CARVEOUT25_BOM                              0x25f4
+#define MC_ERR_APB_ASID_UPDATE_STATUS                           0x9d0
+#define MC_DA_CONFIG0                                           0x9dc
+#define MC_TXN_OVERRIDE_CONFIG_HDAR                             0x10a8
+#define MC_TXN_OVERRIDE_CONFIG_BPMPW                            0x14a0
+#define MC_TBU_CLIENT_STEERING_CONFIG_AONDMAR                   0x14cc
+#define MC_TXN_OVERRIDE_CONFIG_PTCR                             0x1000
+#define MC_TBU_CLIENT_STEERING_CONFIG_APEDMAW                   0x1504
+#define MC_TXN_OVERRIDE_CONFIG_NVDISPLAYR                       0x1490
+#define MC_TXN_OVERRIDE_CONFIG_EQOSW                            0x1478
+#define MC_TXN_OVERRIDE_CONFIG_NVJPGSWR                         0x13f8
+#define MC_TXN_OVERRIDE_CONFIG_ISPRA                            0x1220
+#define MC_TXN_OVERRIDE_CONFIG_SDMMCWAA                         0x1328
+#define MC_TXN_OVERRIDE_CONFIG_VICSRD                           0x1360
+#define MC_TXN_OVERRIDE_CONFIG_MPCOREW                          0x11c8
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVDECSRD1                 0x151c
+#define MC_TXN_OVERRIDE_CONFIG_GPUSRD                           0x12c0
+#define MC_TXN_OVERRIDE_CONFIG_AXISR                            0x1460
+#define MC_TBU_CLIENT_STEERING_CONFIG_VICSRD1                   0x1514
+#define MC_TBU_CLIENT_STEERING_CONFIG_BPMPDMAR                  0x14ac
+#define MC_TXN_OVERRIDE_CONFIG_SCEDMAW                          0x14f0
+#define MC_TXN_OVERRIDE_CONFIG_SDMMCW                           0x1330
+#define MC_TXN_OVERRIDE_CONFIG_EQOSR                            0x1470
+#define MC_TBU_CLIENT_STEERING_CONFIG_SESWR                     0x140c
+#define MC_TXN_OVERRIDE_CONFIG_APEDMAR                          0x14f8
+#define MC_TBU_CLIENT_STEERING_CONFIG_EQOSW                     0x147c
+#define MC_TXN_OVERRIDE_CONFIG_NVENCSRD                         0x10e0
+#define MC_TBU_CLIENT_STEERING_CONFIG_XUSB_DEVW                 0x126c
+#define MC_TBU_CLIENT_STEERING_CONFIG_AXISR                     0x1464
+#define MC_TBU_CLIENT_STEERING_CONFIG_ETRR                      0x1424
+#define MC_TXN_OVERRIDE_CONFIG_SDMMCRAB                         0x1318
+#define MC_TBU_CLIENT_STEERING_CONFIG_MPCORER                   0x113c
+#define MC_TBU_CLIENT_STEERING_CONFIG_SATAW                     0x11ec
+#define MC_TBU_CLIENT_STEERING_CONFIG_XUSB_DEVR                 0x1264
+#define MC_TXN_OVERRIDE_CONFIG_VICSRD1                          0x1510
+#define MC_TBU_CLIENT_STEERING_CONFIG_XUSB_HOSTR                0x1254
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVJPGSRD                  0x13f4
+#define MC_TXN_OVERRIDE_CONFIG_BPMPDMAR                         0x14a8
+#define MC_TXN_OVERRIDE_CONFIG_VIW                              0x1390
+#define MC_TBU_CLIENT_STEERING_CONFIG_BPMPDMAW                  0x14b4
+#define MC_TXN_OVERRIDE_CONFIG_SDMMCRAA                         0x1308
+#define MC_TXN_OVERRIDE_CONFIG_AXISW                            0x1468
+#define MC_TBU_CLIENT_STEERING_CONFIG_XUSB_HOSTW                0x125c
+#define MC_TBU_CLIENT_STEERING_CONFIG_SDMMCW                    0x1334
+#define MC_TXN_OVERRIDE_CONFIG_XUSB_DEVR                        0x1260
+#define MC_TXN_OVERRIDE_CONFIG_UFSHCR                           0x1480
+#define MC_TBU_CLIENT_STEERING_CONFIG_SDMMCRAA                  0x130c
+#define MC_TXN_OVERRIDE_CONFIG_TSECSWR                          0x12a8
+#define MC_TBU_CLIENT_STEERING_CONFIG_GPUSWR2                   0x144c
+#define MC_TXN_OVERRIDE_CONFIG_GPUSWR                           0x12c8
+#define MC_TXN_OVERRIDE_CONFIG_SATAR                            0x10f8
+#define MC_TXN_OVERRIDE_CONFIG_XUSB_HOSTW                       0x1258
+#define MC_TXN_OVERRIDE_CONFIG_TSECSWRB                         0x1438
+#define MC_TBU_CLIENT_STEERING_CONFIG_APER                      0x13d4
+#define MC_TBU_CLIENT_STEERING_CONFIG_ISPRA                     0x1224
+#define MC_TBU_CLIENT_STEERING_CONFIG_AFIR                      0x1074
+#define MC_TBU_CLIENT_STEERING_CONFIG_GPUSRD                    0x12c4
+#define MC_TBU_CLIENT_STEERING_CONFIG_VICSWR                    0x136c
+#define MC_TXN_OVERRIDE_CONFIG_GPUSRD2                          0x1440
+#define MC_TXN_OVERRIDE_CONFIG_SCEDMAR                          0x14e8
+#define MC_TBU_CLIENT_STEERING_CONFIG_AONW                      0x14c4
+#define MC_TXN_OVERRIDE_CONFIG_GPUSWR2                          0x1448
+#define MC_TBU_CLIENT_STEERING_CONFIG_SCEDMAR                   0x14ec
+#define MC_TBU_CLIENT_STEERING_CONFIG_TSECSRD                   0x12a4
+#define MC_TXN_OVERRIDE_CONFIG_AONDMAW                          0x14d0
+#define MC_TBU_CLIENT_STEERING_CONFIG_ISPWA                     0x1234
+#define MC_TXN_OVERRIDE_CONFIG_APEDMAW                          0x1500
+#define MC_TXN_OVERRIDE_CONFIG_AONW                             0x14c0
+#define MC_TXN_OVERRIDE_CONFIG_HOST1XDMAR                       0x10b0
+#define MC_TXN_OVERRIDE_CONFIG_ETRR                             0x1420
+#define MC_TXN_OVERRIDE_CONFIG_SESWR                            0x1408
+#define MC_TBU_CLIENT_STEERING_CONFIG_SDMMCRA                   0x1304
+#define MC_TBU_CLIENT_STEERING_CONFIG_VIW                       0x1394
+#define MC_TBU_CLIENT_STEERING_CONFIG_BPMPR                     0x149c
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVDECSRD                  0x13c4
+#define MC_TBU_CLIENT_STEERING_CONFIG_TSECSWR                   0x12ac
+#define MC_TBU_CLIENT_STEERING_CONFIG_EQOSR                     0x1474
+#define MC_TBU_CLIENT_STEERING_CONFIG_TSECSRDB                  0x1434
+#define MC_TXN_OVERRIDE_CONFIG_NVJPGSRD                         0x13f0
+#define MC_TBU_CLIENT_STEERING_CONFIG_APEDMAR                   0x14fc
+#define MC_TXN_OVERRIDE_CONFIG_NVDECSRD                         0x13c0
+#define MC_TBU_CLIENT_STEERING_CONFIG_SDMMCR                    0x1314
+#define MC_TXN_OVERRIDE_CONFIG_TSECSRDB                         0x1430
+#define MC_TXN_OVERRIDE_CONFIG_BPMPDMAW                         0x14b0
+#define MC_TBU_CLIENT_STEERING_CONFIG_UFSHCR                    0x1484
+#define MC_TXN_OVERRIDE_CONFIG_APER                             0x13d0
+#define MC_TBU_CLIENT_STEERING_CONFIG_UFSHCW                    0x148c
+#define MC_TBU_CLIENT_STEERING_CONFIG_AONR                      0x14bc
+#define MC_TBU_CLIENT_STEERING_CONFIG_MPCOREW                   0x11cc
+#define MC_TXN_OVERRIDE_CONFIG_NVDECSRD1                        0x1518
+#define MC_TBU_CLIENT_STEERING_CONFIG_HOST1XDMAR                0x10b4
+#define MC_TBU_CLIENT_STEERING_CONFIG_AONDMAW                   0x14d4
+#define MC_TXN_OVERRIDE_CONFIG_XUSB_HOSTR                       0x1250
+#define MC_TXN_OVERRIDE_CONFIG_ISPWA                            0x1230
+#define MC_TBU_CLIENT_STEERING_CONFIG_AFIW                      0x118c
+#define MC_TBU_CLIENT_STEERING_CONFIG_SATAR                     0x10fc
+#define MC_TXN_OVERRIDE_CONFIG_SESRD                            0x1400
+#define MC_TBU_CLIENT_STEERING_CONFIG_SESRD                     0x1404
+#define MC_TBU_CLIENT_STEERING_CONFIG_SDMMCWAB                  0x133c
+#define MC_TBU_CLIENT_STEERING_CONFIG_AXISW                     0x146c
+#define MC_TXN_OVERRIDE_CONFIG_SCER                             0x14d8
+#define MC_TBU_CLIENT_STEERING_CONFIG_ISPWB                     0x123c
+#define MC_TBU_CLIENT_STEERING_CONFIG_TSECSWRB                  0x143c
+#define MC_TXN_OVERRIDE_CONFIG_AONR                             0x14b8
+#define MC_TXN_OVERRIDE_CONFIG_MPCORER                          0x1138
+#define MC_TXN_OVERRIDE_CONFIG_SDMMCWA                          0x1320
+#define MC_TXN_OVERRIDE_CONFIG_HDAW                             0x11a8
+#define MC_TXN_OVERRIDE_CONFIG_NVDECSWR                         0x13c8
+#define MC_TBU_CLIENT_STEERING_CONFIG_GPUSRD2                   0x1444
+#define MC_TBU_CLIENT_STEERING_CONFIG_PTCR                      0x1004
+#define MC_TBU_CLIENT_STEERING_CONFIG_SDMMCWAA                  0x132c
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVDECSWR                  0x13cc
+#define MC_TXN_OVERRIDE_CONFIG_UFSHCW                           0x1488
+#define MC_TXN_OVERRIDE_CONFIG_AONDMAR                          0x14c8
+#define MC_TBU_CLIENT_STEERING_CONFIG_SDMMCRAB                  0x131c
+#define MC_TXN_OVERRIDE_CONFIG_SATAW                            0x11e8
+#define MC_TXN_OVERRIDE_CONFIG_ETRW                             0x1428
+#define MC_TXN_OVERRIDE_CONFIG_VICSWR                           0x1368
+#define MC_TBU_CLIENT_STEERING_CONFIG_GPUSWR                    0x12cc
+#define MC_TXN_OVERRIDE_CONFIG_NVENCSWR                         0x1158
+#define MC_TXN_OVERRIDE_CONFIG_AFIR                             0x1070
+#define MC_TBU_CLIENT_STEERING_CONFIG_SCEW                      0x14e4
+#define MC_TXN_OVERRIDE_CONFIG_SDMMCWAB                         0x1338
+#define MC_TBU_CLIENT_STEERING_CONFIG_SCER                      0x14dc
+#define MC_TBU_CLIENT_STEERING_CONFIG_SDMMCWA                   0x1324
+#define MC_TXN_OVERRIDE_CONFIG_SDMMCRA                          0x1300
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVDISPLAYR1               0x150c
+#define MC_TBU_CLIENT_STEERING_CONFIG_HDAR                      0x10ac
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVENCSWR                  0x115c
+#define MC_TBU_CLIENT_STEERING_CONFIG_BPMPW                     0x14a4
+#define MC_TXN_OVERRIDE_CONFIG_NVDISPLAYR1                      0x1508
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVJPGSWR                  0x13fc
+#define MC_TXN_OVERRIDE_CONFIG_ISPWB                            0x1238
+#define MC_TBU_CLIENT_STEERING_CONFIG_SCEDMAW                   0x14f4
+#define MC_TXN_OVERRIDE_CONFIG_BPMPR                            0x1498
+#define MC_TXN_OVERRIDE_CONFIG_APEW                             0x13d8
+#define MC_TBU_CLIENT_STEERING_CONFIG_ETRW                      0x142c
+#define MC_TXN_OVERRIDE_CONFIG_SDMMCR                           0x1310
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVDISPLAYR                0x1494
+#define MC_TBU_CLIENT_STEERING_CONFIG_HDAW                      0x11ac
+#define MC_TBU_CLIENT_STEERING_CONFIG_NVENCSRD                  0x10e4
+#define MC_TXN_OVERRIDE_CONFIG_XUSB_DEVW                        0x1268
+#define MC_TXN_OVERRIDE_CONFIG_TSECSRD                          0x12a0
+#define MC_TBU_CLIENT_STEERING_CONFIG_APEW                      0x13dc
+#define MC_TXN_OVERRIDE_CONFIG_AFIW                             0x1188
+#define MC_TXN_OVERRIDE_CONFIG_SCEW                             0x14e0
+#define MC_TBU_CLIENT_STEERING_CONFIG_VICSRD                    0x1364
+#define MC_TBU_ADR_MASK_0                                       0x1800
+#define MC_TBU_ADR_MASK_1                                       0x1804
+#define MC_CLIENT_TRAFFIC_TYPE_CONFIG_0                         0x1808
+#define MC_CLIENT_TRAFFIC_TYPE_CONFIG_1                         0x180c
+#define MC_CLIENT_TRAFFIC_TYPE_CONFIG_2                         0x1810
+#define MC_CLIENT_TRAFFIC_TYPE_CONFIG_3                         0x1814
+#define MC_CLIENT_TRAFFIC_TYPE_CONFIG_4                         0x1818
+#define MC_CLIENT_TRAFFIC_TYPE_CONFIG_5                         0x181c
+#define MC_CLIENT_CCI_CAPABLE_0                                 0x1824
+#define MC_CLIENT_CCI_CAPABLE_1                                 0x1828
+#define MC_CLIENT_CCI_CAPABLE_2                                 0x182c
+#define MC_CLIENT_CCI_CAPABLE_3                                 0x1830
+#define MC_CLIENT_CCI_CAPABLE_4                                 0x1834
+#define MC_CLIENT_CCI_CAPABLE_5                                 0x1838
+#define MC_CLIENT_CCI_CAPABLE_6                                 0x183c
+#define MC_MAX_OUTSTANDING_CCI                                  0x1840
+#define MC_NV_CACHE_CONFIG                                      0x1844
+#define MC_NV_CACHE_HUB_MASK                                    0x184c
+#define MC_SYSRAM_BOM                                           0x1850
+#define MC_SYSRAM_TOM                                           0x1854
+#define MC_SYSRAM_ADR_HI                                        0x1588
+#define MC_SYSRAM_REG_CTRL                                      0x185c
+#define MC_ECC_CONTROL                                          0x1880
+#define MC_ECC_CFG                                              0x1884
+#define MC_EMEM_ADR_CFG_CHANNEL_ENABLE				0xdf8
+#define MC_TR_BIT_CTL                                           0xed0
+#define MC_CH_INTSTATUS                                         0xe54
+#define MC_LATENCY_ALLOWANCE_WCAM                               0xe5c
+#define MC_CFG_WCAM                                             0xe60
+#define MC_WCAM_ENCR_KEY_STATUS                                 0xe64
+#define MC_WCAM_STATE                                           0xeb0
+#define MC_WCAM_IRQ_TEST                                        0xedc
+#define MC_WCAM_IRQ_P0_STATUS0                                  0xee0
+#define MC_WCAM_IRQ_P0_STATUS1                                  0xee4
+#define MC_WCAM_IRQ_P1_STATUS0                                  0xee8
+#define MC_WCAM_IRQ_P1_STATUS1                                  0xeec
+#define MC_ROC_DMA_R_PTSA_MIN                                   0xe68
+#define MC_ROC_DMA_R_PTSA_MAX                                   0xe6c
+#define MC_ROC_DMA_R_PTSA_RATE                                  0xe70
+#define MC_RING1_WR_B_PTSA_MIN                                  0xe74
+#define MC_RING1_WR_B_PTSA_MAX                                  0xe78
+#define MC_RING1_WR_B_PTSA_RATE                                 0xe7c
+#define MC_RING1_WR_NB_PTSA_MIN                                 0xe80
+#define MC_RING1_WR_NB_PTSA_MAX                                 0xe84
+#define MC_RING1_WR_NB_PTSA_RATE                                0xe88
+#define MC_RING1_RD_B_PTSA_MIN                                  0xe8c
+#define MC_RING1_RD_B_PTSA_MAX                                  0xe90
+#define MC_RING1_RD_B_PTSA_RATE                                 0xe94
+#define MC_RING1_RD_NB_PTSA_MIN                                 0xe98
+#define MC_RING1_RD_NB_PTSA_MAX                                 0xe9c
+#define MC_RING1_RD_NB_PTSA_RATE                                0xea0
+#define MC_FREE_BANK_QUEUES                                     0xea4
+#define MC_RING0_MT_FIFO_CREDITS                                0xea8
+#define MC_LATENCY_ALLOWANCE_ROC_DMA_R_0                        0xeac
+#define MC_MEM_SCRUBBER_ECC_ADDR                                0xf18
+#define MC_MEM_SCRUBBER_ECC_REG_CTRL                            0xf20
+#define MC_CCITRX_ENABLE_CONFIG                                 0xf3c
+#define MC_CCI_WR_LATENCY_ALLOWANCE_CONFIG			0xf40
+#define MC_EMEM_ARB_THROTTLE_CFG				0xf44
+
+/* TODO: Is this correct? */
+#define T18X_MC_LATENCY_ALLOWANCE_NUM_REGS			40
+
+#endif
diff --git a/include/linux/platform/tegra/mc-regs-t21x.h b/include/linux/platform/tegra/mc-regs-t21x.h
new file mode 100644
index 000000000000..aa7470c88464
--- /dev/null
+++ b/include/linux/platform/tegra/mc-regs-t21x.h
@@ -0,0 +1,473 @@
+/*
+ * Copyright (c) 2014, NVIDIA Corporation. All rights reserved.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __MACH_TEGRA_MC_REGS_T21X_H__
+#define __MACH_TEGRA_MC_REGS_T21X_H__
+
+/* Auto generated. Do not edit. */
+#define MC_INTSTATUS                                            0x0
+#define MC_INTMASK                                              0x4
+#define MC_ERR_STATUS                                           0x8
+#define MC_ERR_ADR                                              0xc
+#define MC_PCFIFO_CLIENT_CONFIG0                                0xdd0
+#define MC_PCFIFO_CLIENT_CONFIG1                                0xdd4
+#define MC_PCFIFO_CLIENT_CONFIG2                                0xdd8
+#define MC_PCFIFO_CLIENT_CONFIG3                                0xddc
+#define MC_PCFIFO_CLIENT_CONFIG4                                0xde0
+#define MC_EMEM_CFG                                             0x50
+#define MC_EMEM_ADR_CFG                                         0x54
+#define MC_EMEM_ADR_CFG_DEV0                                    0x58
+#define MC_EMEM_ADR_CFG_DEV1                                    0x5c
+#define MC_EMEM_ADR_CFG_CHANNEL_MASK                            0x60
+#define MC_EMEM_ADR_CFG_BANK_MASK_0                             0x64
+#define MC_EMEM_ADR_CFG_BANK_MASK_1                             0x68
+#define MC_EMEM_ADR_CFG_BANK_MASK_2                             0x6c
+#define MC_SECURITY_CFG0                                        0x70
+#define MC_SECURITY_CFG1                                        0x74
+#define MC_SECURITY_CFG3                                        0x9bc
+#define MC_SECURITY_RSV                                         0x7c
+#define MC_EMEM_ARB_CFG                                         0x90
+#define MC_EMEM_ARB_OUTSTANDING_REQ                             0x94
+#define MC_EMEM_ARB_TIMING_RCD                                  0x98
+#define MC_EMEM_ARB_TIMING_RP                                   0x9c
+#define MC_EMEM_ARB_TIMING_RC                                   0xa0
+#define MC_EMEM_ARB_TIMING_RAS                                  0xa4
+#define MC_EMEM_ARB_TIMING_FAW                                  0xa8
+#define MC_EMEM_ARB_TIMING_RRD                                  0xac
+#define MC_EMEM_ARB_TIMING_RAP2PRE                              0xb0
+#define MC_EMEM_ARB_TIMING_WAP2PRE                              0xb4
+#define MC_EMEM_ARB_TIMING_R2R                                  0xb8
+#define MC_EMEM_ARB_TIMING_W2W                                  0xbc
+#define MC_EMEM_ARB_TIMING_R2W                                  0xc0
+#define MC_EMEM_ARB_TIMING_W2R                                  0xc4
+#define MC_EMEM_ARB_TIMING_RFCPB                                0x6c0
+#define MC_EMEM_ARB_TIMING_CCDMW                                0x6c4
+#define MC_EMEM_ARB_REFPB_HP_CTRL                               0x6f0
+#define MC_EMEM_ARB_REFPB_BANK_CTRL                             0x6f4
+#define MC_EMEM_ARB_DA_TURNS                                    0xd0
+#define MC_EMEM_ARB_DA_COVERS                                   0xd4
+#define MC_EMEM_ARB_MISC0                                       0xd8
+#define MC_EMEM_ARB_MISC1                                       0xdc
+#define MC_EMEM_ARB_MISC2                                       0xc8
+#define MC_EMEM_ARB_RING1_THROTTLE                              0xe0
+#define MC_EMEM_ARB_RING3_THROTTLE                              0xe4
+#define MC_EMEM_ARB_NISO_THROTTLE                               0x6b0
+#define MC_EMEM_ARB_OVERRIDE                                    0xe8
+#define MC_EMEM_ARB_RSV                                         0xec
+#define MC_CLKEN_OVERRIDE                                       0xf4
+#define MC_TIMING_CONTROL_DBG                                   0xf8
+#define MC_TIMING_CONTROL                                       0xfc
+#define MC_STAT_CONTROL                                         0x100
+#define MC_STAT_STATUS                                          0x104
+#define MC_STAT_EMC_CLOCK_LIMIT                                 0x108
+#define MC_STAT_EMC_CLOCK_LIMIT_MSBS                            0x10c
+#define MC_STAT_EMC_CLOCKS                                      0x110
+#define MC_STAT_EMC_CLOCKS_MSBS                                 0x114
+#define MC_STAT_EMC_FILTER_SET0_ADR_LIMIT_LO                    0x118
+#define MC_STAT_EMC_FILTER_SET1_ADR_LIMIT_LO                    0x158
+#define MC_STAT_EMC_FILTER_SET0_ADR_LIMIT_HI                    0x11c
+#define MC_STAT_EMC_FILTER_SET1_ADR_LIMIT_HI                    0x15c
+#define MC_STAT_EMC_FILTER_SET0_ADR_LIMIT_UPPER                 0xa20
+#define MC_STAT_EMC_FILTER_SET1_ADR_LIMIT_UPPER                 0xa24
+#define MC_STAT_EMC_FILTER_SET0_VIRTUAL_ADR_LIMIT_LO            0x198
+#define MC_STAT_EMC_FILTER_SET1_VIRTUAL_ADR_LIMIT_LO            0x1a8
+#define MC_STAT_EMC_FILTER_SET0_VIRTUAL_ADR_LIMIT_HI            0x19c
+#define MC_STAT_EMC_FILTER_SET1_VIRTUAL_ADR_LIMIT_HI            0x1ac
+#define MC_STAT_EMC_FILTER_SET0_VIRTUAL_ADR_LIMIT_UPPER         0xa28
+#define MC_STAT_EMC_FILTER_SET1_VIRTUAL_ADR_LIMIT_UPPER         0xa2c
+#define MC_STAT_EMC_FILTER_SET0_ASID                            0x1a0
+#define MC_STAT_EMC_FILTER_SET1_ASID                            0x1b0
+#define MC_STAT_EMC_FILTER_SET0_SLACK_LIMIT                     0x120
+#define MC_STAT_EMC_FILTER_SET1_SLACK_LIMIT                     0x160
+#define MC_STAT_EMC_FILTER_SET0_CLIENT_0                        0x128
+#define MC_STAT_EMC_FILTER_SET1_CLIENT_0                        0x168
+#define MC_STAT_EMC_FILTER_SET0_CLIENT_1                        0x12c
+#define MC_STAT_EMC_FILTER_SET1_CLIENT_1                        0x16c
+#define MC_STAT_EMC_FILTER_SET0_CLIENT_2                        0x130
+#define MC_STAT_EMC_FILTER_SET1_CLIENT_2                        0x170
+#define MC_STAT_EMC_FILTER_SET0_CLIENT_3                        0x134
+#define MC_STAT_EMC_FILTER_SET0_CLIENT_4                        0xb88
+#define MC_STAT_EMC_FILTER_SET1_CLIENT_3                        0x174
+#define MC_STAT_EMC_FILTER_SET1_CLIENT_4                        0xb8c
+#define MC_STAT_EMC_SET0_COUNT                                  0x138
+#define MC_STAT_EMC_SET0_COUNT_MSBS                             0x13c
+#define MC_STAT_EMC_SET1_COUNT                                  0x178
+#define MC_STAT_EMC_SET1_COUNT_MSBS                             0x17c
+#define MC_STAT_EMC_SET0_SLACK_ACCUM                            0x140
+#define MC_STAT_EMC_SET0_SLACK_ACCUM_MSBS                       0x144
+#define MC_STAT_EMC_SET1_SLACK_ACCUM                            0x180
+#define MC_STAT_EMC_SET1_SLACK_ACCUM_MSBS                       0x184
+#define MC_STAT_EMC_SET0_HISTO_COUNT                            0x148
+#define MC_STAT_EMC_SET0_HISTO_COUNT_MSBS                       0x14c
+#define MC_STAT_EMC_SET1_HISTO_COUNT                            0x188
+#define MC_STAT_EMC_SET1_HISTO_COUNT_MSBS                       0x18c
+#define MC_STAT_EMC_SET0_MINIMUM_SLACK_OBSERVED                 0x150
+#define MC_STAT_EMC_SET1_MINIMUM_SLACK_OBSERVED                 0x190
+#define MC_STAT_EMC_SET0_IDLE_CYCLE_COUNT                       0x1b8
+#define MC_STAT_EMC_SET0_IDLE_CYCL_COUNT_MSBS                   0x1bc
+#define MC_STAT_EMC_SET1_IDLE_CYCLE_COUNT                       0x1c8
+#define MC_STAT_EMC_SET1_IDLE_CYCL_COUNT_MSBS                   0x1cc
+#define MC_STAT_EMC_SET0_IDLE_CYCLE_PARTITION_SELECT            0x1c0
+#define MC_STAT_EMC_SET1_IDLE_CYCLE_PARTITION_SELECT            0x1d0
+#define MC_CLIENT_HOTRESET_CTRL                                 0x200
+#define MC_CLIENT_HOTRESET_CTRL_1                               0x970
+#define MC_CLIENT_HOTRESET_STATUS                               0x204
+#define MC_CLIENT_HOTRESET_STATUS_1                             0x974
+#define MC_EMEM_ARB_ISOCHRONOUS_0                               0x208
+#define MC_EMEM_ARB_ISOCHRONOUS_1                               0x20c
+#define MC_EMEM_ARB_ISOCHRONOUS_2                               0x210
+#define MC_EMEM_ARB_ISOCHRONOUS_3                               0x214
+#define MC_EMEM_ARB_ISOCHRONOUS_4                               0xb94
+#define MC_EMEM_ARB_HYSTERESIS_0                                0x218
+#define MC_EMEM_ARB_HYSTERESIS_1                                0x21c
+#define MC_EMEM_ARB_HYSTERESIS_2                                0x220
+#define MC_EMEM_ARB_HYSTERESIS_3                                0x224
+#define MC_EMEM_ARB_HYSTERESIS_4                                0xb84
+#define MC_EMEM_ARB_DHYSTERESIS_0                               0xbb0
+#define MC_EMEM_ARB_DHYSTERESIS_1                               0xbb4
+#define MC_EMEM_ARB_DHYSTERESIS_2                               0xbb8
+#define MC_EMEM_ARB_DHYSTERESIS_3                               0xbbc
+#define MC_EMEM_ARB_DHYSTERESIS_4                               0xbc0
+#define MC_EMEM_ARB_DHYST_CTRL                                  0xbcc
+#define MC_EMEM_ARB_DHYST_TIMEOUT_UTIL_0                        0xbd0
+#define MC_EMEM_ARB_DHYST_TIMEOUT_UTIL_1                        0xbd4
+#define MC_EMEM_ARB_DHYST_TIMEOUT_UTIL_2                        0xbd8
+#define MC_EMEM_ARB_DHYST_TIMEOUT_UTIL_3                        0xbdc
+#define MC_EMEM_ARB_DHYST_TIMEOUT_UTIL_4                        0xbe0
+#define MC_EMEM_ARB_DHYST_TIMEOUT_UTIL_5                        0xbe4
+#define MC_EMEM_ARB_DHYST_TIMEOUT_UTIL_6                        0xbe8
+#define MC_EMEM_ARB_DHYST_TIMEOUT_UTIL_7                        0xbec
+#define MC_RESERVED_RSV                                         0x3fc
+#define MC_DISB_EXTRA_SNAP_LEVELS                               0x408
+#define MC_APB_EXTRA_SNAP_LEVELS                                0x2a4
+#define MC_AHB_EXTRA_SNAP_LEVELS                                0x2a0
+#define MC_USBD_EXTRA_SNAP_LEVELS                               0xa18
+#define MC_ISP_EXTRA_SNAP_LEVELS                                0xa08
+#define MC_AUD_EXTRA_SNAP_LEVELS                                0xa10
+#define MC_MSE_EXTRA_SNAP_LEVELS                                0x40c
+#define MC_GK2_EXTRA_SNAP_LEVELS                                0xa40
+#define MC_A9AVPPC_EXTRA_SNAP_LEVELS                            0x414
+#define MC_FTOP_EXTRA_SNAP_LEVELS                               0x2bc
+#define MC_JPG_EXTRA_SNAP_LEVELS                                0xa3c
+#define MC_HOST_EXTRA_SNAP_LEVELS                               0xa14
+#define MC_SAX_EXTRA_SNAP_LEVELS                                0x2c0
+#define MC_DIS_EXTRA_SNAP_LEVELS                                0x2ac
+#define MC_VICPC_EXTRA_SNAP_LEVELS                              0xa1c
+#define MC_HDAPC_EXTRA_SNAP_LEVELS                              0xa48
+#define MC_AVP_EXTRA_SNAP_LEVELS                                0x2a8
+#define MC_USBX_EXTRA_SNAP_LEVELS                               0x404
+#define MC_PCX_EXTRA_SNAP_LEVELS                                0x2b8
+#define MC_SD_EXTRA_SNAP_LEVELS                                 0xa04
+#define MC_DFD_EXTRA_SNAP_LEVELS                                0xa4c
+#define MC_VE_EXTRA_SNAP_LEVELS                                 0x2d8
+#define MC_GK_EXTRA_SNAP_LEVELS                                 0xa00
+#define MC_VE2_EXTRA_SNAP_LEVELS                                0x410
+#define MC_SDM_EXTRA_SNAP_LEVELS                                0xa44
+#define MC_VIDEO_PROTECT_BOM                                    0x648
+#define MC_VIDEO_PROTECT_SIZE_MB                                0x64c
+#define MC_VIDEO_PROTECT_BOM_ADR_HI                             0x978
+#define MC_VIDEO_PROTECT_REG_CTRL                               0x650
+#define MC_ERR_VPR_STATUS                                       0x654
+#define MC_ERR_VPR_ADR                                          0x658
+#define MC_VIDEO_PROTECT_VPR_OVERRIDE                           0x418
+#define MC_VIDEO_PROTECT_VPR_OVERRIDE1                          0x590
+#define MC_IRAM_BOM                                             0x65c
+#define MC_IRAM_TOM                                             0x660
+#define MC_IRAM_ADR_HI                                          0x980
+#define MC_IRAM_REG_CTRL                                        0x964
+#define MC_EMEM_CFG_ACCESS_CTRL                                 0x664
+#define MC_TZ_SECURITY_CTRL                                     0x668
+#define MC_EMEM_ARB_OUTSTANDING_REQ_RING3                       0x66c
+#define MC_EMEM_ARB_OUTSTANDING_REQ_NISO                        0x6b4
+#define MC_EMEM_ARB_RING0_THROTTLE_MASK                         0x6bc
+#define MC_EMEM_ARB_NISO_THROTTLE_MASK                          0x6b8
+#define MC_EMEM_ARB_NISO_THROTTLE_MASK_1                        0xb80
+#define MC_SEC_CARVEOUT_BOM                                     0x670
+#define MC_SEC_CARVEOUT_SIZE_MB                                 0x674
+#define MC_SEC_CARVEOUT_ADR_HI                                  0x9d4
+#define MC_SEC_CARVEOUT_REG_CTRL                                0x678
+#define MC_ERR_SEC_STATUS                                       0x67c
+#define MC_ERR_SEC_ADR                                          0x680
+#define MC_PC_IDLE_CLOCK_GATE_CONFIG                            0x684
+#define MC_STUTTER_CONTROL                                      0x688
+#define MC_RESERVED_RSV_1                                       0x958
+#define MC_DVFS_PIPE_SELECT                                     0x95c
+#define MC_AHB_PTSA_MIN                                         0x4e0
+#define MC_AUD_PTSA_MIN                                         0x54c
+#define MC_MLL_MPCORER_PTSA_RATE                                0x44c
+#define MC_RING2_PTSA_RATE                                      0x440
+#define MC_USBD_PTSA_RATE                                       0x530
+#define MC_USBX_PTSA_MIN                                        0x528
+#define MC_USBD_PTSA_MIN                                        0x534
+#define MC_APB_PTSA_MAX                                         0x4f0
+#define MC_JPG_PTSA_RATE                                        0x584
+#define MC_DIS_PTSA_MIN                                         0x420
+#define MC_AVP_PTSA_MAX                                         0x4fc
+#define MC_AVP_PTSA_RATE                                        0x4f4
+#define MC_RING1_PTSA_MIN                                       0x480
+#define MC_DIS_PTSA_MAX                                         0x424
+#define MC_SD_PTSA_MAX                                          0x4d8
+#define MC_MSE_PTSA_RATE                                        0x4c4
+#define MC_VICPC_PTSA_MIN                                       0x558
+#define MC_PCX_PTSA_MAX                                         0x4b4
+#define MC_ISP_PTSA_RATE                                        0x4a0
+#define MC_A9AVPPC_PTSA_MIN                                     0x48c
+#define MC_RING2_PTSA_MAX                                       0x448
+#define MC_AUD_PTSA_RATE                                        0x548
+#define MC_HOST_PTSA_MIN                                        0x51c
+#define MC_MLL_MPCORER_PTSA_MAX                                 0x454
+#define MC_SD_PTSA_MIN                                          0x4d4
+#define MC_RING1_PTSA_RATE                                      0x47c
+#define MC_JPG_PTSA_MIN                                         0x588
+#define MC_HDAPC_PTSA_MIN                                       0x62c
+#define MC_AVP_PTSA_MIN                                         0x4f8
+#define MC_JPG_PTSA_MAX                                         0x58c
+#define MC_VE_PTSA_MAX                                          0x43c
+#define MC_DFD_PTSA_MAX                                         0x63c
+#define MC_VICPC_PTSA_RATE                                      0x554
+#define MC_GK_PTSA_MAX                                          0x544
+#define MC_VICPC_PTSA_MAX                                       0x55c
+#define MC_SDM_PTSA_MAX                                         0x624
+#define MC_SAX_PTSA_RATE                                        0x4b8
+#define MC_PCX_PTSA_MIN                                         0x4b0
+#define MC_APB_PTSA_MIN                                         0x4ec
+#define MC_GK2_PTSA_MIN                                         0x614
+#define MC_PCX_PTSA_RATE                                        0x4ac
+#define MC_RING1_PTSA_MAX                                       0x484
+#define MC_HDAPC_PTSA_RATE                                      0x628
+#define MC_MLL_MPCORER_PTSA_MIN                                 0x450
+#define MC_GK2_PTSA_MAX                                         0x618
+#define MC_AUD_PTSA_MAX                                         0x550
+#define MC_GK2_PTSA_RATE                                        0x610
+#define MC_ISP_PTSA_MAX                                         0x4a8
+#define MC_DISB_PTSA_RATE                                       0x428
+#define MC_VE2_PTSA_MAX                                         0x49c
+#define MC_DFD_PTSA_MIN                                         0x638
+#define MC_FTOP_PTSA_RATE                                       0x50c
+#define MC_A9AVPPC_PTSA_RATE                                    0x488
+#define MC_VE2_PTSA_MIN                                         0x498
+#define MC_USBX_PTSA_MAX                                        0x52c
+#define MC_DIS_PTSA_RATE                                        0x41c
+#define MC_USBD_PTSA_MAX                                        0x538
+#define MC_A9AVPPC_PTSA_MAX                                     0x490
+#define MC_USBX_PTSA_RATE                                       0x524
+#define MC_FTOP_PTSA_MAX                                        0x514
+#define MC_HDAPC_PTSA_MAX                                       0x630
+#define MC_SD_PTSA_RATE                                         0x4d0
+#define MC_DFD_PTSA_RATE                                        0x634
+#define MC_FTOP_PTSA_MIN                                        0x510
+#define MC_SDM_PTSA_RATE                                        0x61c
+#define MC_AHB_PTSA_RATE                                        0x4dc
+#define MC_SMMU_SMMU_PTSA_MAX                                   0x460
+#define MC_RING2_PTSA_MIN                                       0x444
+#define MC_SDM_PTSA_MIN                                         0x620
+#define MC_APB_PTSA_RATE                                        0x4e8
+#define MC_MSE_PTSA_MIN                                         0x4c8
+#define MC_HOST_PTSA_RATE                                       0x518
+#define MC_VE_PTSA_RATE                                         0x434
+#define MC_AHB_PTSA_MAX                                         0x4e4
+#define MC_SAX_PTSA_MIN                                         0x4bc
+#define MC_SMMU_SMMU_PTSA_MIN                                   0x45c
+#define MC_ISP_PTSA_MIN                                         0x4a4
+#define MC_HOST_PTSA_MAX                                        0x520
+#define MC_SAX_PTSA_MAX                                         0x4c0
+#define MC_VE_PTSA_MIN                                          0x438
+#define MC_GK_PTSA_MIN                                          0x540
+#define MC_MSE_PTSA_MAX                                         0x4cc
+#define MC_DISB_PTSA_MAX                                        0x430
+#define MC_DISB_PTSA_MIN                                        0x42c
+#define MC_SMMU_SMMU_PTSA_RATE                                  0x458
+#define MC_VE2_PTSA_RATE                                        0x494
+#define MC_GK_PTSA_RATE                                         0x53c
+#define MC_PTSA_GRANT_DECREMENT                                 0x960
+#define MC_LATENCY_ALLOWANCE_AVPC_0                             0x2e4
+#define MC_LATENCY_ALLOWANCE_AXIAP_0                            0x3a0
+#define MC_LATENCY_ALLOWANCE_XUSB_1                             0x380
+#define MC_LATENCY_ALLOWANCE_ISP2B_0                            0x384
+#define MC_LATENCY_ALLOWANCE_SDMMCAA_0                          0x3bc
+#define MC_LATENCY_ALLOWANCE_SDMMCA_0                           0x3b8
+#define MC_LATENCY_ALLOWANCE_ISP2_0                             0x370
+#define MC_LATENCY_ALLOWANCE_SE_0                               0x3e0
+#define MC_LATENCY_ALLOWANCE_ISP2_1                             0x374
+#define MC_LATENCY_ALLOWANCE_DC_0                               0x2e8
+#define MC_LATENCY_ALLOWANCE_VIC_0                              0x394
+#define MC_LATENCY_ALLOWANCE_DCB_1                              0x2f8
+#define MC_LATENCY_ALLOWANCE_NVDEC_0                            0x3d8
+#define MC_LATENCY_ALLOWANCE_DCB_2                              0x2fc
+#define MC_LATENCY_ALLOWANCE_TSEC_0                             0x390
+#define MC_LATENCY_ALLOWANCE_DC_2                               0x2f0
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0AB                  0x694
+#define MC_LATENCY_ALLOWANCE_PPCS_1                             0x348
+#define MC_LATENCY_ALLOWANCE_XUSB_0                             0x37c
+#define MC_LATENCY_ALLOWANCE_PPCS_0                             0x344
+#define MC_LATENCY_ALLOWANCE_TSECB_0                            0x3f0
+#define MC_LATENCY_ALLOWANCE_AFI_0                              0x2e0
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0B                   0x698
+#define MC_LATENCY_ALLOWANCE_DC_1                               0x2ec
+#define MC_LATENCY_ALLOWANCE_APE_0                              0x3dc
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0C                   0x6a0
+#define MC_LATENCY_ALLOWANCE_A9AVP_0                            0x3a4
+#define MC_LATENCY_ALLOWANCE_GPU2_0                             0x3e8
+#define MC_LATENCY_ALLOWANCE_DCB_0                              0x2f4
+#define MC_LATENCY_ALLOWANCE_HC_1                               0x314
+#define MC_LATENCY_ALLOWANCE_SDMMC_0                            0x3c0
+#define MC_LATENCY_ALLOWANCE_NVJPG_0                            0x3e4
+#define MC_LATENCY_ALLOWANCE_PTC_0                              0x34c
+#define MC_LATENCY_ALLOWANCE_ETR_0                              0x3ec
+#define MC_LATENCY_ALLOWANCE_MPCORE_0                           0x320
+#define MC_LATENCY_ALLOWANCE_VI2_0                              0x398
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0BB                  0x69c
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0CB                  0x6a4
+#define MC_LATENCY_ALLOWANCE_SATA_0                             0x350
+#define MC_SCALED_LATENCY_ALLOWANCE_DISPLAY0A                   0x690
+#define MC_LATENCY_ALLOWANCE_HC_0                               0x310
+#define MC_LATENCY_ALLOWANCE_DC_3                               0x3c8
+#define MC_LATENCY_ALLOWANCE_GPU_0                              0x3ac
+#define MC_LATENCY_ALLOWANCE_SDMMCAB_0                          0x3c4
+#define MC_LATENCY_ALLOWANCE_ISP2B_1                            0x388
+#define MC_LATENCY_ALLOWANCE_NVENC_0                            0x328
+#define MC_LATENCY_ALLOWANCE_HDA_0                              0x318
+#define MC_MIN_LENGTH_APE_0                                     0xb34
+#define MC_MIN_LENGTH_DCB_2                                     0x8a8
+#define MC_MIN_LENGTH_A9AVP_0                                   0x950
+#define MC_MIN_LENGTH_TSEC_0                                    0x93c
+#define MC_MIN_LENGTH_DC_1                                      0x898
+#define MC_MIN_LENGTH_AXIAP_0                                   0x94c
+#define MC_MIN_LENGTH_ISP2B_0                                   0x930
+#define MC_MIN_LENGTH_VI2_0                                     0x944
+#define MC_MIN_LENGTH_DCB_0                                     0x8a0
+#define MC_MIN_LENGTH_DCB_1                                     0x8a4
+#define MC_MIN_LENGTH_PPCS_1                                    0x8f4
+#define MC_MIN_LENGTH_NVJPG_0                                   0xb3c
+#define MC_MIN_LENGTH_HDA_0                                     0x8c4
+#define MC_MIN_LENGTH_NVENC_0                                   0x8d4
+#define MC_MIN_LENGTH_SDMMC_0                                   0xb18
+#define MC_MIN_LENGTH_ISP2B_1                                   0x934
+#define MC_MIN_LENGTH_HC_1                                      0x8c0
+#define MC_MIN_LENGTH_DC_3                                      0xb20
+#define MC_MIN_LENGTH_AVPC_0                                    0x890
+#define MC_MIN_LENGTH_VIC_0                                     0x940
+#define MC_MIN_LENGTH_ISP2_0                                    0x91c
+#define MC_MIN_LENGTH_HC_0                                      0x8bc
+#define MC_MIN_LENGTH_SE_0                                      0xb38
+#define MC_MIN_LENGTH_NVDEC_0                                   0xb30
+#define MC_MIN_LENGTH_SATA_0                                    0x8fc
+#define MC_MIN_LENGTH_DC_0                                      0x894
+#define MC_MIN_LENGTH_XUSB_1                                    0x92c
+#define MC_MIN_LENGTH_DC_2                                      0x89c
+#define MC_MIN_LENGTH_SDMMCAA_0                                 0xb14
+#define MC_MIN_LENGTH_GPU_0                                     0xb04
+#define MC_MIN_LENGTH_ETR_0                                     0xb44
+#define MC_MIN_LENGTH_AFI_0                                     0x88c
+#define MC_MIN_LENGTH_PPCS_0                                    0x8f0
+#define MC_MIN_LENGTH_ISP2_1                                    0x920
+#define MC_MIN_LENGTH_XUSB_0                                    0x928
+#define MC_MIN_LENGTH_MPCORE_0                                  0x8cc
+#define MC_MIN_LENGTH_TSECB_0                                   0xb48
+#define MC_MIN_LENGTH_SDMMCA_0                                  0xb10
+#define MC_MIN_LENGTH_GPU2_0                                    0xb40
+#define MC_MIN_LENGTH_SDMMCAB_0                                 0xb1c
+#define MC_MIN_LENGTH_PTC_0                                     0x8f8
+#define MC_EMEM_ARB_OVERRIDE_1                                  0x968
+#define MC_VIDEO_PROTECT_GPU_OVERRIDE_0                         0x984
+#define MC_VIDEO_PROTECT_GPU_OVERRIDE_1                         0x988
+#define MC_EMEM_ARB_STATS_0                                     0x990
+#define MC_EMEM_ARB_STATS_1                                     0x994
+#define MC_MTS_CARVEOUT_BOM                                     0x9a0
+#define MC_MTS_CARVEOUT_SIZE_MB                                 0x9a4
+#define MC_MTS_CARVEOUT_ADR_HI                                  0x9a8
+#define MC_MTS_CARVEOUT_REG_CTRL                                0x9ac
+#define MC_ERR_MTS_STATUS                                       0x9b0
+#define MC_ERR_MTS_ADR                                          0x9b4
+#define MC_ERR_GENERALIZED_CARVEOUT_STATUS                      0xc00
+#define MC_ERR_GENERALIZED_CARVEOUT_ADR                         0xc04
+#define MC_SECURITY_CARVEOUT5_CLIENT_FORCE_INTERNAL_ACCESS2     0xd74
+#define MC_SECURITY_CARVEOUT4_CFG0                              0xcf8
+#define MC_SECURITY_CARVEOUT4_CLIENT_ACCESS2                    0xd10
+#define MC_SECURITY_CARVEOUT4_SIZE_128KB                        0xd04
+#define MC_SECURITY_CARVEOUT1_CLIENT_ACCESS4                    0xc28
+#define MC_SECURITY_CARVEOUT1_CLIENT_FORCE_INTERNAL_ACCESS1     0xc30
+#define MC_SECURITY_CARVEOUT2_CLIENT_FORCE_INTERNAL_ACCESS4     0xc8c
+#define MC_SECURITY_CARVEOUT4_CLIENT_FORCE_INTERNAL_ACCESS0     0xd1c
+#define MC_SECURITY_CARVEOUT5_CLIENT_FORCE_INTERNAL_ACCESS1     0xd70
+#define MC_SECURITY_CARVEOUT1_CLIENT_FORCE_INTERNAL_ACCESS0     0xc2c
+#define MC_SECURITY_CARVEOUT5_CLIENT_FORCE_INTERNAL_ACCESS4     0xd7c
+#define MC_SECURITY_CARVEOUT3_SIZE_128KB                        0xcb4
+#define MC_SECURITY_CARVEOUT2_CFG0                              0xc58
+#define MC_SECURITY_CARVEOUT1_CFG0                              0xc08
+#define MC_SECURITY_CARVEOUT2_CLIENT_FORCE_INTERNAL_ACCESS2     0xc84
+#define MC_SECURITY_CARVEOUT2_CLIENT_ACCESS0                    0xc68
+#define MC_SECURITY_CARVEOUT3_BOM                               0xcac
+#define MC_SECURITY_CARVEOUT2_CLIENT_ACCESS2                    0xc70
+#define MC_SECURITY_CARVEOUT5_CLIENT_FORCE_INTERNAL_ACCESS3     0xd78
+#define MC_SECURITY_CARVEOUT2_CLIENT_FORCE_INTERNAL_ACCESS0     0xc7c
+#define MC_SECURITY_CARVEOUT4_CLIENT_ACCESS4                    0xd18
+#define MC_SECURITY_CARVEOUT3_CLIENT_ACCESS1                    0xcbc
+#define MC_SECURITY_CARVEOUT1_CLIENT_FORCE_INTERNAL_ACCESS3     0xc38
+#define MC_SECURITY_CARVEOUT1_CLIENT_FORCE_INTERNAL_ACCESS2     0xc34
+#define MC_SECURITY_CARVEOUT3_CLIENT_ACCESS2                    0xcc0
+#define MC_SECURITY_CARVEOUT5_CLIENT_ACCESS2                    0xd60
+#define MC_SECURITY_CARVEOUT3_CFG0                              0xca8
+#define MC_SECURITY_CARVEOUT3_CLIENT_ACCESS0                    0xcb8
+#define MC_SECURITY_CARVEOUT2_CLIENT_FORCE_INTERNAL_ACCESS3     0xc88
+#define MC_SECURITY_CARVEOUT2_SIZE_128KB                        0xc64
+#define MC_SECURITY_CARVEOUT5_BOM_HI                            0xd50
+#define MC_SECURITY_CARVEOUT1_SIZE_128KB                        0xc14
+#define MC_SECURITY_CARVEOUT4_CLIENT_ACCESS3                    0xd14
+#define MC_SECURITY_CARVEOUT1_BOM                               0xc0c
+#define MC_SECURITY_CARVEOUT4_CLIENT_FORCE_INTERNAL_ACCESS4     0xd2c
+#define MC_SECURITY_CARVEOUT5_CLIENT_ACCESS4                    0xd68
+#define MC_SECURITY_CARVEOUT3_CLIENT_ACCESS4                    0xcc8
+#define MC_SECURITY_CARVEOUT5_CLIENT_ACCESS0                    0xd58
+#define MC_SECURITY_CARVEOUT4_CLIENT_FORCE_INTERNAL_ACCESS2     0xd24
+#define MC_SECURITY_CARVEOUT3_CLIENT_ACCESS3                    0xcc4
+#define MC_SECURITY_CARVEOUT2_CLIENT_ACCESS4                    0xc78
+#define MC_SECURITY_CARVEOUT1_CLIENT_ACCESS1                    0xc1c
+#define MC_SECURITY_CARVEOUT1_CLIENT_ACCESS0                    0xc18
+#define MC_SECURITY_CARVEOUT4_CLIENT_FORCE_INTERNAL_ACCESS3     0xd28
+#define MC_SECURITY_CARVEOUT5_CLIENT_ACCESS1                    0xd5c
+#define MC_SECURITY_CARVEOUT3_BOM_HI                            0xcb0
+#define MC_SECURITY_CARVEOUT3_CLIENT_FORCE_INTERNAL_ACCESS3     0xcd8
+#define MC_SECURITY_CARVEOUT2_BOM_HI                            0xc60
+#define MC_SECURITY_CARVEOUT4_BOM_HI                            0xd00
+#define MC_SECURITY_CARVEOUT5_CLIENT_ACCESS3                    0xd64
+#define MC_SECURITY_CARVEOUT3_CLIENT_FORCE_INTERNAL_ACCESS4     0xcdc
+#define MC_SECURITY_CARVEOUT2_CLIENT_FORCE_INTERNAL_ACCESS1     0xc80
+#define MC_SECURITY_CARVEOUT5_SIZE_128KB                        0xd54
+#define MC_SECURITY_CARVEOUT4_CLIENT_FORCE_INTERNAL_ACCESS1     0xd20
+#define MC_SECURITY_CARVEOUT3_CLIENT_FORCE_INTERNAL_ACCESS2     0xcd4
+#define MC_SECURITY_CARVEOUT4_CLIENT_ACCESS1                    0xd0c
+#define MC_SECURITY_CARVEOUT2_CLIENT_ACCESS3                    0xc74
+#define MC_SECURITY_CARVEOUT3_CLIENT_FORCE_INTERNAL_ACCESS0     0xccc
+#define MC_SECURITY_CARVEOUT4_BOM                               0xcfc
+#define MC_SECURITY_CARVEOUT5_CFG0                              0xd48
+#define MC_SECURITY_CARVEOUT2_BOM                               0xc5c
+#define MC_SECURITY_CARVEOUT5_BOM                               0xd4c
+#define MC_SECURITY_CARVEOUT1_CLIENT_ACCESS3                    0xc24
+#define MC_SECURITY_CARVEOUT5_CLIENT_FORCE_INTERNAL_ACCESS0     0xd6c
+#define MC_SECURITY_CARVEOUT3_CLIENT_FORCE_INTERNAL_ACCESS1     0xcd0
+#define MC_SECURITY_CARVEOUT1_BOM_HI                            0xc10
+#define MC_SECURITY_CARVEOUT1_CLIENT_ACCESS2                    0xc20
+#define MC_SECURITY_CARVEOUT1_CLIENT_FORCE_INTERNAL_ACCESS4     0xc3c
+#define MC_SECURITY_CARVEOUT2_CLIENT_ACCESS1                    0xc6c
+#define MC_SECURITY_CARVEOUT4_CLIENT_ACCESS0                    0xd08
+#define MC_ERR_APB_ASID_UPDATE_STATUS                           0x9d0
+#define MC_DA_CONFIG0                                           0x9dc
+
+#define T21X_MC_LATENCY_ALLOWANCE_NUM_REGS			41
+
+/* TODO: Cleanup after get_dram is implemented and LA starts working */
+static inline int tegra_emc_get_dram_type (void)
+{ return 1; };
+
+#endif
diff --git a/include/linux/platform/tegra/mc.h b/include/linux/platform/tegra/mc.h
new file mode 100644
index 000000000000..49e2a0296d5c
--- /dev/null
+++ b/include/linux/platform/tegra/mc.h
@@ -0,0 +1,256 @@
+/*
+ * Copyright (C) 2010-2012 Google, Inc.
+ * Copyright (C) 2013-2018, NVIDIA Corporation.  All rights reserved.
+ *
+ * Author:
+ *	Erik Gilling <konkers@google.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#ifndef __MACH_TEGRA_MC_H
+#define __MACH_TEGRA_MC_H
+
+#include <linux/platform/tegra/tegra_mc.h>
+
+#define MC_MAX_INTR_COUNT	32
+#define MC_MAX_CHANNELS		16
+#define MC_MAX_MSSNVLINK_HUBS	4
+
+#define MC_BROADCAST_CHANNEL	-1
+
+extern int mc_channels;
+extern int mc_err_channel;
+extern int mc_intstatus_reg;
+extern unsigned int mssnvlink_hubs;
+
+struct mc_client {
+	const char *name;
+	const char *swgroup;
+	const int swgid;
+	unsigned int intr_counts[MC_MAX_INTR_COUNT];
+};
+
+extern void __iomem *mc;
+extern void __iomem *mc_regs[MC_MAX_CHANNELS];
+extern void __iomem *mssnvlink_regs[MC_MAX_MSSNVLINK_HUBS];
+
+#include <linux/io.h>
+#include <linux/debugfs.h>
+
+#include <soc/tegra/fuse.h>
+
+/**
+ * Check if the MC has more than 1 channel.
+ */
+static inline int mc_multi_channel(void)
+{
+	return mc_channels > 1;
+}
+
+/**
+ * Read from the MC.
+ *
+ * @idx The MC channel to read from.
+ * @reg The offset of the register to read.
+ *
+ * Read from the specified MC channel: 0 -> MC0, 1 -> MC1, etc. If @idx
+ * corresponds to a non-existent channel then 0 is returned.
+ */
+static inline u32 __mc_readl(int idx, u32 reg)
+{
+	if (WARN(!mc, "Read before MC init'ed"))
+		return 0;
+
+	if ((idx != MC_BROADCAST_CHANNEL && idx < 0) || idx > mc_channels)
+		return 0;
+
+	if (idx == MC_BROADCAST_CHANNEL)
+		return readl(mc + reg);
+	else
+		return readl(mc_regs[idx] + reg);
+}
+
+/**
+ * Write to the MC.
+ *
+ * @idx The MC channel to write to.
+ * @val Value to write.
+ * @reg The offset of the register to write.
+ *
+ * Write to the specified MC channel: 0 -> MC0, 1 -> MC1, etc. For writes there
+ * is a special channel, %MC_BROADCAST_CHANNEL, which writes to all channels. If
+ * @idx corresponds to a non-existent channel then the write is dropped.
+ */
+static inline void __mc_writel(int idx, u32 val, u32 reg)
+{
+	if (WARN(!mc, "Write before MC init'ed"))
+		return;
+
+	if ((idx != MC_BROADCAST_CHANNEL && idx < 0) ||
+	    idx > mc_channels)
+		return;
+
+	if (idx == MC_BROADCAST_CHANNEL)
+		writel(val, mc + reg);
+	else
+		writel(val, mc_regs[idx] + reg);
+}
+
+static inline u32 __mc_raw_readl(int idx, u32 reg)
+{
+	if (WARN(!mc, "Read before MC init'ed"))
+		return 0;
+
+	if ((idx != MC_BROADCAST_CHANNEL && idx < 0) || idx > mc_channels)
+		return 0;
+
+	if (idx == MC_BROADCAST_CHANNEL)
+		return __raw_readl(mc + reg);
+	else
+		return __raw_readl(mc_regs[idx] + reg);
+}
+
+static inline void __mc_raw_writel(int idx, u32 val, u32 reg)
+{
+	if (WARN(!mc, "Write before MC init'ed"))
+		return;
+
+	if ((idx != MC_BROADCAST_CHANNEL && idx < 0) ||
+	    idx > mc_channels)
+		return;
+
+	if (idx == MC_BROADCAST_CHANNEL)
+		__raw_writel(val, mc + reg);
+	else
+		__raw_writel(val, mc_regs[idx] + reg);
+}
+
+#define mc_readl(reg)       __mc_readl(MC_BROADCAST_CHANNEL, reg)
+#define mc_writel(val, reg) __mc_writel(MC_BROADCAST_CHANNEL, val, reg)
+
+/**
+ * Read from the MSSNVLINK hub.
+ *
+ * @idx The mssnvlink hub ID
+ * @reg The register offset
+ *
+ * Read from the specified MSSNVLINK hub. Reads from
+ * non-existent hubs return 0.
+ */
+static inline u32 mssnvlink_readl(unsigned int idx, u32 reg)
+{
+	if (mssnvlink_hubs == UINT_MAX)
+		return 0;
+
+	if (idx >= mssnvlink_hubs) {
+		WARN(1, "mssnvlink read: invalid hub ID - %u\n", idx);
+		return 0;
+	}
+
+	if (WARN(!mssnvlink_regs[idx], "Read before MSSNVLINK is initialized."))
+		return 0;
+
+	return readl(mssnvlink_regs[idx] + reg);
+}
+
+/**
+ * Write to the MSSNVLINK hub.
+ *
+ * @idx ID of MSSNVLINK hub.
+ * @val Value to write.
+ * @reg Register offset to write.
+ *
+ * Write to the specified MSSNVLINK hub. Writes to
+ * non-existent hubs are dropped.
+ */
+
+static inline void mssnvlink_writel(unsigned int idx, u32 val, u32 reg)
+{
+	if (mssnvlink_hubs == UINT_MAX)
+		return;
+
+	if (idx >= mssnvlink_hubs) {
+		WARN(1, "mssnvlink write: invalid hub ID - %u\n", idx);
+		return;
+	}
+
+	if (WARN(!mssnvlink_regs[idx], "Write before MSSNVLINK is initialized."))
+		return;
+
+	writel(val, mssnvlink_regs[idx] + reg);
+}
+
+unsigned long tegra_emc_bw_to_freq_req(unsigned long bw);
+unsigned long tegra_emc_freq_req_to_bw(unsigned long freq);
+
+/* API to get freqency switch latency at given MC freq.
+ * freq_khz: Frequncy in KHz.
+ * retruns latency in microseconds.
+ */
+static inline unsigned tegra_emc_dvfs_latency(unsigned int freq_khz)
+{
+	/* The latency data is not available based on freq.
+	 * H/W expects it to be around 3 to 4us.
+	 */
+	return 4;
+}
+
+/*
+ * On very old chips (T30) this was not always one.
+ */
+static inline int tegra_mc_get_tiled_memory_bandwidth_multiplier(void)
+{
+	return 1;
+}
+
+
+#define TEGRA_MC_CLIENT_AFI		0
+#define TEGRA_MC_CLIENT_DC		2
+#define TEGRA_MC_CLIENT_DCB		3
+#define TEGRA_MC_CLIENT_EPP		4
+#define TEGRA_MC_CLIENT_G2		5
+#define TEGRA_MC_CLIENT_ISP		8
+#define TEGRA_MC_CLIENT_MSENC		11
+#define TEGRA_MC_CLIENT_MPE		11
+#define TEGRA_MC_CLIENT_NV		12
+#define TEGRA_MC_CLIENT_SATA		15
+#define TEGRA_MC_CLIENT_VDE		16
+#define TEGRA_MC_CLIENT_VI		17
+#define TEGRA_MC_CLIENT_VIC		18
+#define TEGRA_MC_CLIENT_XUSB_HOST	19
+#define TEGRA_MC_CLIENT_XUSB_DEV	20
+#define TEGRA_MC_CLIENT_TSEC		22
+#define TEGRA_MC_CLIENT_ISPB		33
+#define TEGRA_MC_CLIENT_GPU		34
+#define TEGRA_MC_CLIENT_NVDEC		37
+#define TEGRA_MC_CLIENT_NVJPG		40
+#define TEGRA_MC_CLIENT_TSECB		45
+
+enum {
+	DRAM_TYPE_DDR3   = 0,
+	DRAM_TYPE_LPDDR4 = 1,
+	DRAM_TYPE_LPDDR2 = 2,
+	DRAM_TYPE_DDR2   = 3,
+};
+
+int tegra_mc_flush(int id);
+int tegra_mc_flush_done(int id);
+
+/*
+ * Necessary bit fields for various MC registers. Add to these as
+ * necessary.
+ */
+#define MC_EMEM_ARB_MISC0_MC_EMC_SAME_FREQ_BIT			(1 << 27)
+
+u32 tegra_get_dvfs_clk_change_latency_nsec(unsigned long emc_freq_khz);
+
+#endif
diff --git a/include/linux/platform/tegra/mcerr.h b/include/linux/platform/tegra/mcerr.h
new file mode 100644
index 000000000000..ead72f330b10
--- /dev/null
+++ b/include/linux/platform/tegra/mcerr.h
@@ -0,0 +1,176 @@
+/*
+ * MC error interrupt handling header file. Various defines and declarations
+ * across tegra chips.
+ *
+ * Copyright (c) 2010-2021, NVIDIA Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ */
+
+#ifndef __MCERR_H
+#define __MCERR_H
+
+#include <linux/kernel.h>
+#include <linux/debugfs.h>
+#include <linux/spinlock.h>
+#include <linux/interrupt.h>
+#include <linux/of.h>
+
+#include <linux/platform/tegra/mc.h>
+
+#define MAX_PRINTS			5
+
+/* defines that are common across SOC's. */
+#define MC_INTMASK			0x4
+
+#define MC_ERR_STATUS_WRITE		(1 << 16)
+#define MC_ERR_STATUS_SECURE		(1 << 17)
+#define MC_ERR_STATUS_ADR_HI		(3 << 20)
+
+#define MC_INT_DECERR_EMEM			(1<<6)
+#define MC_INT_SECURITY_VIOLATION		(1<<8)
+#define MC_INT_ARBITRATION_EMEM			(1<<9)
+#define MC_INT_DECERR_VPR			(1<<12)
+#define MC_INT_SECERR_SEC			(1<<13)
+#define MC_INT_DECERR_GENERALIZED_CARVEOUT	(1<<17)
+
+#define MC_ERR_DECERR_EMEM		(2)
+#define MC_ERR_SECURITY_TRUSTZONE	(3)
+#define MC_ERR_SECURITY_CARVEOUT	(4)
+#define MC_ERR_INVALID_SMMU_PAGE	(6)
+
+struct platform_device;
+int tegra_mcerr_init(struct dentry *mc_paren, struct platform_device *pdev);
+void tegra_mcerr_resume(void);
+irqreturn_t tegra_mc_handle_general_fault(int src_chan, int intstatus);
+
+/*
+ * This describes errors that can be generated by the MC. One is defined for
+ * each possibility.
+ *
+ * @sig Interrupt signiture for the error.
+ * @msg Error description.
+ * @flags Relevant flags for the error.
+ * @stat_reg Register offset that holds the status of the error.
+ * @addr_reg Register offset that holds the faulting address.
+ */
+struct mc_error {
+	const char *msg;
+	u32         sig;
+	int         flags;
+	u32         stat_reg;
+	u32         addr_reg;
+	u32         addr_hi_reg;
+};
+
+#define E_SMMU       (1<<0)
+#define E_NO_STATUS  (1<<1) /* No status/addr */
+#define E_TWO_STATUS (1<<2) /* Two status registers, no addr */
+#define E_VPR        (1<<3) /* VPR violation */
+#define E_ADR_HI_REG (1<<4) /* Hi Addr bits in hi reg */
+#define E_GSC        (1<<5) /* GSC violation */
+
+extern u32 mc_int_mask;
+extern u32  mcerr_silenced;
+
+struct mcerr_ops {
+	/*
+	 * Show the statistics for each client. This is called from a debugfs
+	 * context - that means you can sleep and do general kernel stuff here.
+	 */
+	int (*mcerr_debugfs_show)(struct seq_file *s, void *v);
+
+	/* Disable MC Error interrupt.
+	 *
+	 * Called in hard irq context to disable interrupt till
+	 * soft irq handler logs the MC Error.
+	 */
+	void (*disable_interrupt)(unsigned int irq);
+
+	/* Enable MC Error interrupt.
+	 *
+	 * Called from soft irq context after MC Error is logged.
+	 */
+	void (*enable_interrupt)(unsigned int irq);
+
+	/* Clear MC Error interrupt.
+	 *
+	 * Called from soft irq context during MC Error print throttle.
+	 */
+	void (*clear_interrupt)(unsigned int irq);
+
+	/* Log MC Error fault and clear interrupt source
+	 *
+	 * Called in soft irq context.
+	 * As soon as interrupt status is cleared MC would be ready to
+	 * hold next MC Error info.
+	 */
+	void (*log_mcerr_fault)(unsigned int irq);
+
+	/* Numeric fields that must be set by the different chips. */
+	unsigned int nr_clients;
+
+	/*
+	 * This array lists a string description of each valid interrupt bit.
+	 * It must be at least 32 entries long. Entries that are not valid
+	 * interrupts should be left as NULL. Each entry should be at most 12
+	 * characters long.
+	 */
+	const char **intr_descriptions;
+	struct mc_client *mc_clients;
+};
+
+#define client(_swgroup, _name, _swgid)					\
+	{ .swgroup = _swgroup, .name = _name, .swgid = TEGRA_SWGROUP_##_swgid, }
+
+#define dummy_client   client("dummy", "dummy", INVALID)
+
+#define MC_ERR(_sig, _msg, _flags, _stat_reg, _addr_reg)		\
+	{ .sig = _sig, .msg = _msg, .flags = _flags,			\
+			.stat_reg = _stat_reg, .addr_reg = _addr_reg }
+
+#define MC_ERR_HI(_sig, _msg, _flags, _stat_reg, _addr_reg, _addr_hi_reg) \
+	{ .sig = _sig, .msg = _msg, .flags = (_flags | E_ADR_HI_REG), \
+	  .stat_reg = _stat_reg, .addr_reg = _addr_reg, \
+	  .addr_hi_reg = _addr_hi_reg}
+
+#define MC_ERR_GSC(_sig, _msg, _flags, _stat_reg, _addr_reg, _addr_hi_reg) \
+	{ .sig = _sig, .msg = _msg, .flags = (_flags | E_GSC), \
+	  .stat_reg = _stat_reg, .addr_reg = _addr_reg, \
+	  .addr_hi_reg = _addr_hi_reg}
+
+#define mcerr_pr(fmt, ...)					\
+	do {							\
+		if (!mcerr_silenced) {				\
+			pr_err(fmt, ##__VA_ARGS__);		\
+		}						\
+	} while (0)
+
+/*
+ * Error MMA tracking.
+ */
+#define MMA_HISTORY_SAMPLES 20
+struct arb_emem_intr_info {
+	int arb_intr_mma;
+	u64 time;
+	spinlock_t lock;
+};
+
+typedef struct mcerr_ops *(*of_mcerr_init_fn)(struct device_node *);
+
+#define MCERR_OF_DECLARE(name, compat, fn) \
+	_OF_DECLARE(mcerr, name, compat, fn, of_mcerr_init_fn)
+
+#endif /* __MCERR_H */
diff --git a/include/linux/platform/tegra/tegra-mc-sid.h b/include/linux/platform/tegra/tegra-mc-sid.h
new file mode 100644
index 000000000000..d0c4d5518666
--- /dev/null
+++ b/include/linux/platform/tegra/tegra-mc-sid.h
@@ -0,0 +1,72 @@
+/*
+ * Copyright (c) 2015-16, NVIDIA CORPORATION.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#ifndef __TEGRA_MC_SID_H
+#define __TEGRA_MC_SID_H
+
+#define SCEW_STREAMID_WRITE_ACCESS_DISABLED	BIT(16)
+#define SCEW_STREAMID_OVERRIDE			BIT(8)
+#define SCEW_NS					BIT(0)
+
+#define MC_SMMU_BYPASS_CONFIG_0			0x1820
+#define TBU_BYPASS_SID				2
+
+#define DEFREG(__name, __offset)		\
+	[__name] = {				\
+		.name = __stringify(__name),	\
+		.offs = __offset,		\
+	}
+
+enum mc_overrides {
+	DONTCARE,
+	OVERRIDE,
+	NO_OVERRIDE,
+
+	/* Enable override in linsim; Keep override disabled elsewhere. */
+	SIM_OVERRIDE,
+};
+
+struct sid_override_reg {
+	const char *name;
+	int offs;
+};
+
+#define MAX_OIDS_IN_SID 8
+
+struct sid_to_oids {
+	int sid;			/* StreamID */
+	int noids;			/* # of override IDs */
+	int oid[MAX_OIDS_IN_SID];	/* Override IDs */
+	enum mc_overrides ord;		/* MC or Device overrides SID? */
+	const char *name;		/* Name associated with the SID. */
+};
+
+struct tegra_mc_sid_soc_data {
+	struct sid_override_reg *sid_override_reg;
+	unsigned int nsid_override_reg;
+	struct sid_to_oids *sid_to_oids;
+	unsigned int nsid_to_oids;
+	unsigned int max_oids;
+};
+
+int tegra_mc_sid_probe(struct platform_device *pdev,
+			const struct tegra_mc_sid_soc_data *soc_data);
+int tegra_mc_sid_remove(struct platform_device *pdev);
+
+u32 tegra_mc_get_smmu_bypass_sid(void);
+const char *tegra_mc_get_sid_name(int sid);
+
+#endif
diff --git a/include/linux/platform/tegra/tegra_emc.h b/include/linux/platform/tegra/tegra_emc.h
new file mode 100644
index 000000000000..6b4ca37a4e0e
--- /dev/null
+++ b/include/linux/platform/tegra/tegra_emc.h
@@ -0,0 +1,96 @@
+/*
+ * arch/arm/mach-tegra/tegra_emc.h
+ *
+ * Copyright (c) 2013-2016, NVIDIA CORPORATION.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+ */
+
+#ifndef _MACH_TEGRA_TEGRA_EMC_H
+#define _MACH_TEGRA_TEGRA_EMC_H
+
+#define TEGRA_EMC_ISO_USE_CASES_MAX_NUM		8
+
+extern u8 tegra_emc_bw_efficiency;
+extern u8 tegra_emc_iso_share;
+
+enum {
+	DRAM_OVER_TEMP_NONE = 0,
+	DRAM_OVER_TEMP_REFRESH_X2,
+	DRAM_OVER_TEMP_REFRESH_X4,
+	DRAM_OVER_TEMP_THROTTLE, /* 4x Refresh + derating. */
+};
+
+enum emc_user_id {
+	EMC_USER_DC1 = 0,
+	EMC_USER_DC2,
+	EMC_USER_VI,
+	EMC_USER_MSENC,
+	EMC_USER_2D,
+	EMC_USER_3D,
+	EMC_USER_BB,
+	EMC_USER_VDE,
+	EMC_USER_VI2,
+	EMC_USER_ISP1,
+	EMC_USER_ISP2,
+	EMC_USER_NVDEC,
+	EMC_USER_NVJPG,
+	EMC_USER_NUM,
+};
+
+struct emc_iso_usage {
+	u32 emc_usage_flags;
+	u8 iso_usage_share;
+	u8 (*iso_share_calculator)(unsigned long iso_bw);
+};
+
+struct tegra_emc_dvfs_table_ops {
+	u32 (*get_dvfs_clk_change_latency_nsec)(unsigned long emc_freq_khz);
+};
+
+struct clk;
+struct dentry;
+
+void tegra_emc_timer_mr4_start(void);
+void tegra_emc_timer_mr4_stop(void);
+void tegra_emc_timer_training_start(void);
+void tegra_emc_timer_training_stop(void);
+
+void tegra_emc_iso_usage_table_init(struct emc_iso_usage *table, int size);
+int  tegra_emc_iso_usage_debugfs_init(struct dentry *emc_debugfs_root);
+int tegra_emc_timers_init(struct dentry *parent);
+void tegra_emc_dvfs_table_ops_init(
+		struct tegra_emc_dvfs_table_ops *dvfs_table_ops_to_copy);
+unsigned long tegra_emc_apply_efficiency(unsigned long total_bw,
+	unsigned long iso_bw, unsigned long max_rate, u32 usage_flags,
+	unsigned long *iso_bw_min);
+void tegra_emc_dram_type_init(struct clk *c);
+int tegra_emc_get_dram_type(void);
+int tegra_emc_get_dram_temperature(void);
+int tegra_emc_set_over_temp_state(unsigned long state);
+void tegra_emc_mr4_set_freq_thresh(unsigned long thresh);
+void tegra_emc_mr4_freq_check(unsigned long freq);
+
+u32 emc_do_periodic_compensation(void);
+
+long tegra_emc_round_rate(unsigned long rate);
+long tegra_emc_round_rate_updown(unsigned long rate, bool up);
+struct clk *tegra_emc_predict_parent(unsigned long rate, u32 *div_value);
+void tegra_emc_timing_invalidate(void);
+void tegra_mc_divider_update(struct clk *emc);
+
+u32 tegra_get_dvfs_clk_change_latency_nsec(unsigned long emc_freq_khz);
+
+#endif
diff --git a/include/linux/platform/tegra/tegra_emc_err.h b/include/linux/platform/tegra/tegra_emc_err.h
new file mode 100644
index 000000000000..cbb12d088928
--- /dev/null
+++ b/include/linux/platform/tegra/tegra_emc_err.h
@@ -0,0 +1,23 @@
+/*
+ * Copyright (c) 2016-2017, NVIDIA Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#ifndef __EMC_ERR_H
+#define __EMC_ERR_H
+
+#include <linux/kernel.h>
+
+void tegra_emcerr_init(struct dentry *mc_parent,
+					struct platform_device *pdev);
+#endif
diff --git a/include/linux/platform/tegra/tegra_mc.h b/include/linux/platform/tegra/tegra_mc.h
new file mode 100644
index 000000000000..9aae94d33b2a
--- /dev/null
+++ b/include/linux/platform/tegra/tegra_mc.h
@@ -0,0 +1,84 @@
+/*
+ * Copyright (C) 2017-2018, NVIDIA Corporation.  All rights reserved.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#ifndef __TEGRA_MC_H
+#define __TEGRA_MC_H
+
+/*
+ * API for reading carveout info.
+ */
+enum carveout_desc {
+	MC_SECURITY_CARVEOUT1 = 0,
+	MC_SECURITY_CARVEOUT2,
+	MC_SECURITY_CARVEOUT3,
+	MC_SECURITY_CARVEOUT4,
+	MC_NR_CARVEOUTS
+};
+
+struct mc_carveout_info {
+	enum carveout_desc desc;
+
+	u64 base;
+	u64 size;
+};
+
+#if defined(CONFIG_TEGRA_MC)
+
+/**
+ * Read from the MC.
+ *
+ * @idx The MC channel to read from.
+ * @reg The offset of the register to read.
+ *
+ * Read from the specified MC channel: 0 -> MC0, 1 -> MC1, etc. If @idx
+ * corresponds to a non-existent channel then 0 is returned.
+ */
+extern u32 tegra_mc_readl(u32 reg);
+
+/**
+ * Write to the MC.
+ *
+ * @idx The MC channel to write to.
+ * @val Value to write.
+ * @reg The offset of the register to write.
+ *
+ * Write to the specified MC channel: 0 -> MC0, 1 -> MC1, etc. For writes there
+ * is a special channel, %MC_BROADCAST_CHANNEL, which writes to all channels. If
+ * @idx corresponds to a non-existent channel then the write is dropped.
+ */
+extern void tegra_mc_writel(u32 val, u32 reg);
+
+extern int mc_get_carveout_info(struct mc_carveout_info *inf, int *nr,
+			 enum carveout_desc co);
+
+#else
+
+static inline u32 tegra_mc_readl(u32 reg)
+{
+	return 0xffffffff;
+}
+
+static inline void tegra_mc_writel(u32 val, u32 reg)
+{
+}
+
+static inline int mc_get_carveout_info(struct mc_carveout_info *inf, int *nr,
+			 enum carveout_desc co)
+{
+	return -ENODEV;
+}
+
+#endif
+
+#endif
diff --git a/include/linux/syscalls.h b/include/linux/syscalls.h
index 36c592e43d65..ac715aa5474f 100644
--- a/include/linux/syscalls.h
+++ b/include/linux/syscalls.h
@@ -98,6 +98,7 @@ struct cachestat;
  * CONFIG_ARCH_HAS_SYSCALL_WRAPPER is enabled.
  */
 #include <asm/syscall_wrapper.h>
+asmlinkage long sys_close(unsigned int fd);
 #endif /* CONFIG_ARCH_HAS_SYSCALL_WRAPPER */
 
 /*
diff --git a/include/linux/t194_nvg.h b/include/linux/t194_nvg.h
new file mode 100644
index 000000000000..3960e4df27a3
--- /dev/null
+++ b/include/linux/t194_nvg.h
@@ -0,0 +1,438 @@
+#ifndef T194_NVG_H
+#define T194_NVG_H
+
+/*
+ * Copyright (c) 2017-2019, NVIDIA CORPORATION.  All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+
+/*
+ * t194_nvg.h - Header for the NVIDIA Generic interface (NVG).
+ * Official documentation for this interface is included as part
+ * of the T194 TRM.
+ */
+
+/*
+ * Current version - Major version increments may break backwards
+ * compatibility and binary compatibility. Minor version increments
+ * occur when there is only new functionality.
+ */
+enum {
+	TEGRA_NVG_VERSION_MAJOR = 6,
+	TEGRA_NVG_VERSION_MINOR = 6,
+};
+
+typedef enum {
+	TEGRA_NVG_CHANNEL_VERSION							= 0,
+	TEGRA_NVG_CHANNEL_POWER_PERF						= 1,
+	TEGRA_NVG_CHANNEL_POWER_MODES						= 2,
+	TEGRA_NVG_CHANNEL_WAKE_TIME							= 3,
+	TEGRA_NVG_CHANNEL_CSTATE_INFO						= 4,
+	TEGRA_NVG_CHANNEL_CROSSOVER_C6_LOWER_BOUND			= 5,
+	TEGRA_NVG_CHANNEL_CROSSOVER_CC6_LOWER_BOUND			= 6,
+	TEGRA_NVG_CHANNEL_CROSSOVER_CG7_LOWER_BOUND			= 8,
+	TEGRA_NVG_CHANNEL_CSTATE_STAT_QUERY_REQUEST			= 10,
+	TEGRA_NVG_CHANNEL_CSTATE_STAT_QUERY_VALUE			= 11,
+	TEGRA_NVG_CHANNEL_NUM_CORES							= 20,
+	TEGRA_NVG_CHANNEL_UNIQUE_LOGICAL_ID					= 21,
+	TEGRA_NVG_CHANNEL_LOGICAL_TO_PHYSICAL_MAPPING		= 22,
+	TEGRA_NVG_CHANNEL_LOGICAL_TO_MPIDR					= 23,
+	TEGRA_NVG_CHANNEL_SHUTDOWN							= 42,
+	TEGRA_NVG_CHANNEL_IS_SC7_ALLOWED					= 43,
+	TEGRA_NVG_CHANNEL_ONLINE_CORE						= 44,
+	TEGRA_NVG_CHANNEL_CC3_CTRL							= 45,
+	TEGRA_NVG_CHANNEL_CCPLEX_CACHE_CONTROL				= 49,
+	TEGRA_NVG_CHANNEL_UPDATE_CCPLEX_GSC					= 50,
+	TEGRA_NVG_CHANNEL_HSM_ERROR_CTRL					= 53,
+	TEGRA_NVG_CHANNEL_SECURITY_CONFIG					= 54,
+	TEGRA_NVG_CHANNEL_DEBUG_CONFIG						= 55,
+	TEGRA_NVG_CHANNEL_DDA_SNOC_MCF						= 56,
+	TEGRA_NVG_CHANNEL_DDA_MCF_ORD1						= 57,
+	TEGRA_NVG_CHANNEL_DDA_MCF_ORD2						= 58,
+	TEGRA_NVG_CHANNEL_DDA_MCF_ORD3						= 59,
+	TEGRA_NVG_CHANNEL_DDA_MCF_ISO						= 60,
+	TEGRA_NVG_CHANNEL_DDA_MCF_SISO						= 61,
+	TEGRA_NVG_CHANNEL_DDA_MCF_NISO						= 62,
+	TEGRA_NVG_CHANNEL_DDA_MCF_NISO_REMOTE				= 63,
+	TEGRA_NVG_CHANNEL_DDA_L3CTRL_ISO					= 64,
+	TEGRA_NVG_CHANNEL_DDA_L3CTRL_SISO					= 65,
+	TEGRA_NVG_CHANNEL_DDA_L3CTRL_NISO					= 66,
+	TEGRA_NVG_CHANNEL_DDA_L3CTRL_NISO_REMOTE			= 67,
+	TEGRA_NVG_CHANNEL_DDA_L3CTRL_L3FILL					= 68,
+	TEGRA_NVG_CHANNEL_DDA_L3CTRL_L3WR					= 69,
+	TEGRA_NVG_CHANNEL_DDA_L3CTRL_RSP_L3RD_DMA			= 70,
+	TEGRA_NVG_CHANNEL_DDA_L3CTRL_RSP_MCFRD_DMA			= 71,
+	TEGRA_NVG_CHANNEL_DDA_L3CTRL_GLOBAL					= 72,
+	TEGRA_NVG_CHANNEL_DDA_L3CTRL_LL						= 73,
+	TEGRA_NVG_CHANNEL_DDA_L3CTRL_L3D					= 74,
+	TEGRA_NVG_CHANNEL_DDA_L3CTRL_FCM_RD					= 75,
+	TEGRA_NVG_CHANNEL_DDA_L3CTRL_FCM_WR					= 76,
+	TEGRA_NVG_CHANNEL_DDA_SNOC_GLOBAL_CTRL				= 77,
+	TEGRA_NVG_CHANNEL_DDA_SNOC_CLIENT_REQ_CTRL			= 78,
+	TEGRA_NVG_CHANNEL_DDA_SNOC_CLIENT_REPLENTISH_CTRL	= 79,
+
+	TEGRA_NVG_CHANNEL_RT_SAFE_MASK				= 80,
+	TEGRA_NVG_CHANNEL_RT_WINDOW_US				= 81,
+	TEGRA_NVG_CHANNEL_RT_FWD_PROGRESS_US			= 82,
+
+
+	TEGRA_NVG_CHANNEL_LAST_INDEX,
+} tegra_nvg_channel_id_t;
+
+typedef enum {
+	NVG_STAT_QUERY_SC7_ENTRIES			= 1,
+	NVG_STAT_QUERY_CC6_ENTRIES			= 6,
+	NVG_STAT_QUERY_CG7_ENTRIES			= 7,
+	NVG_STAT_QUERY_C6_ENTRIES			= 10,
+	NVG_STAT_QUERY_C7_ENTRIES			= 14,
+	NVG_STAT_QUERY_SC7_RESIDENCY_SUM	= 32,
+	NVG_STAT_QUERY_CC6_RESIDENCY_SUM	= 41,
+	NVG_STAT_QUERY_CG7_RESIDENCY_SUM	= 46,
+	NVG_STAT_QUERY_C6_RESIDENCY_SUM		= 51,
+	NVG_STAT_QUERY_C7_RESIDENCY_SUM		= 56,
+	NVG_STAT_QUERY_SC7_ENTRY_TIME_SUM	= 60,
+	NVG_STAT_QUERY_CC6_ENTRY_TIME_SUM	= 61,
+	NVG_STAT_QUERY_CG7_ENTRY_TIME_SUM	= 62,
+	NVG_STAT_QUERY_C6_ENTRY_TIME_SUM	= 63,
+	NVG_STAT_QUERY_C7_ENTRY_TIME_SUM	= 64,
+	NVG_STAT_QUERY_SC7_EXIT_TIME_SUM	= 70,
+	NVG_STAT_QUERY_CC6_EXIT_TIME_SUM	= 71,
+	NVG_STAT_QUERY_CG7_EXIT_TIME_SUM	= 72,
+	NVG_STAT_QUERY_C6_EXIT_TIME_SUM		= 73,
+	NVG_STAT_QUERY_C7_EXIT_TIME_SUM		= 74,
+	NVG_STAT_QUERY_SC7_ENTRY_LAST		= 80,
+	NVG_STAT_QUERY_CC6_ENTRY_LAST		= 81,
+	NVG_STAT_QUERY_CG7_ENTRY_LAST		= 82,
+	NVG_STAT_QUERY_C6_ENTRY_LAST		= 83,
+	NVG_STAT_QUERY_C7_ENTRY_LAST		= 84,
+	NVG_STAT_QUERY_SC7_EXIT_LAST		= 90,
+	NVG_STAT_QUERY_CC6_EXIT_LAST		= 91,
+	NVG_STAT_QUERY_CG7_EXIT_LAST		= 92,
+	NVG_STAT_QUERY_C6_EXIT_LAST			= 93,
+	NVG_STAT_QUERY_C7_EXIT_LAST			= 94,
+
+} tegra_nvg_stat_query_t;
+
+typedef enum {
+	TEGRA_NVG_CORE_C0 = 0,
+	TEGRA_NVG_CORE_C1 = 1,
+	TEGRA_NVG_CORE_C6 = 6,
+	TEGRA_NVG_CORE_C7 = 7,
+	TEGRA_NVG_CORE_WARMRSTREQ = 8,
+} tegra_nvg_core_sleep_state_t;
+
+typedef enum {
+    TEGRA_NVG_SHUTDOWN = 0U,
+    TEGRA_NVG_REBOOT = 1U,
+} tegra_nvg_shutdown_reboot_state_t;
+
+typedef enum {
+	TEGRA_NVG_CLUSTER_CC0 = 0,
+	TEGRA_NVG_CLUSTER_CC6 = 6,
+} tegra_nvg_cluster_sleep_state_t;
+
+typedef enum {
+	TEGRA_NVG_CG_CG0 = 0,
+	TEGRA_NVG_CG_CG7 = 7,
+} tegra_nvg_cluster_group_sleep_state_t;
+
+typedef enum {
+	TEGRA_NVG_SYSTEM_SC0 = 0,
+	TEGRA_NVG_SYSTEM_SC7 = 7,
+	TEGRA_NVG_SYSTEM_SC8 = 8,
+} tegra_nvg_system_sleep_state_t;
+
+// ---------------------------------------------------------------------------
+// NVG Data subformats
+// ---------------------------------------------------------------------------
+
+typedef union
+{
+	uint64_t flat;
+	struct nvg_version_channel_t {
+		uint32_t minor_version : 32;
+		uint32_t major_version : 32;
+	} bits;
+} nvg_version_data_t;
+
+typedef union
+{
+	uint64_t flat;
+	struct nvg_power_perf_channel_t {
+		uint32_t perf_per_watt	: 1;
+		uint32_t reserved_31_1	: 31;
+		uint32_t reserved_63_32	: 32;
+	} bits;
+} nvg_power_perf_channel_t;
+
+typedef union
+{
+	uint64_t flat;
+	struct nvg_power_modes_channel_t {
+		uint32_t low_battery	: 1;
+		uint32_t reserved_1_1	: 1;
+		uint32_t battery_save	: 1;
+		uint32_t reserved_31_3	: 29;
+		uint32_t reserved_63_32	: 32;
+	} bits;
+} nvg_power_modes_channel_t;
+
+typedef union nvg_channel_1_data_u
+{
+	uint64_t flat;
+	struct nvg_channel_1_data_s
+	{
+		uint32_t perf_per_watt_mode : 1;
+		uint32_t reserved_31_1		: 31;
+		uint32_t reserved_63_32		: 32;
+	} bits;
+} nvg_channel_1_data_t;
+
+typedef union
+{
+	uint64_t flat;
+	struct nvg_ccplex_cache_control_channel_t {
+		uint32_t gpu_ways		: 5;
+		uint32_t reserved_7_5	: 3;
+		uint32_t gpu_only_ways	: 5;
+		uint32_t reserved_31_13 : 19;
+		uint32_t reserved_63_32 : 32;
+	} bits;
+} nvg_ccplex_cache_control_channel_t;
+
+typedef union nvg_channel_2_data_u
+{
+	uint64_t flat;
+	struct nvg_channel_2_data_s
+	{
+		uint32_t reserved_1_0		: 2;
+		uint32_t battery_saver_mode : 1;
+		uint32_t reserved_31_3		: 29;
+		uint32_t reserved_63_32		: 32;
+	} bits;
+} nvg_channel_2_data_t;
+
+typedef union
+{
+	uint64_t flat;
+	struct nvg_wake_time_channel_t {
+		uint32_t wake_time		: 32;
+		uint32_t reserved_63_32 : 32;
+	} bits;
+} nvg_wake_time_channel_t;
+
+typedef union
+{
+	uint64_t flat;
+	struct nvg_cstate_info_channel_t {
+		uint32_t cluster_state		: 3;
+		uint32_t reserved_6_3		: 4;
+		uint32_t update_cluster		: 1;
+		uint32_t cg_cstate			: 3;
+		uint32_t reserved_14_11		: 4;
+		uint32_t update_cg			: 1;
+		uint32_t system_cstate		: 4;
+		uint32_t reserved_22_20		: 3;
+		uint32_t update_system		: 1;
+		uint32_t reserved_30_24		: 7;
+		uint32_t update_wake_mask	: 1;
+		uint32_t wake_mask			: 32;
+	} bits;
+} nvg_cstate_info_channel_t;
+
+typedef union
+{
+	uint64_t flat;
+	struct nvg_lower_bound_channel_t {
+		uint32_t crossover_value	: 32;
+		uint32_t reserved_63_32		: 32;
+	} bits;
+} nvg_lower_bound_channel_t;
+
+typedef union
+{
+	uint64_t flat;
+	struct nvg_cstate_stat_query_channel_t {
+		uint32_t unit_id		: 4;
+		uint32_t reserved_15_4	: 12;
+		uint32_t stat_id		: 16;
+		uint32_t reserved_63_32 : 32;
+	} bits;
+} nvg_cstate_stat_query_channel_t;
+
+typedef union
+{
+	uint64_t flat;
+	struct nvg_num_cores_channel_t {
+		uint32_t num_cores		: 4;
+		uint32_t reserved_31_4	: 28;
+		uint32_t reserved_63_32 : 32;
+	} bits;
+} nvg_num_cores_channel_t;
+
+typedef union
+{
+	uint64_t flat;
+	struct nvg_unique_logical_id_channel_t {
+		uint32_t unique_core_id	: 3;
+		uint32_t reserved_31_3	: 29;
+		uint32_t reserved_63_32 : 32;
+	} bits;
+} nvg_unique_logical_id_channel_t;
+
+typedef union
+{
+	uint64_t flat;
+	struct nvg_logical_to_physical_mappings_channel_t {
+		uint32_t lcore0_pcore_id	: 4;
+		uint32_t lcore1_pcore_id	: 4;
+		uint32_t lcore2_pcore_id	: 4;
+		uint32_t lcore3_pcore_id	: 4;
+		uint32_t lcore4_pcore_id	: 4;
+		uint32_t lcore5_pcore_id	: 4;
+		uint32_t lcore6_pcore_id	: 4;
+		uint32_t lcore7_pcore_id	: 4;
+		uint32_t reserved_63_32		: 32;
+	} bits;
+} nvg_logical_to_physical_mappings_channel_t;
+
+typedef union
+{
+	uint64_t flat;
+	struct nvg_logical_to_mpidr_channel_write_t {
+		uint32_t lcore_id		: 3;
+		uint32_t reserved_31_3	: 29;
+		uint32_t reserved_63_32	: 32;
+	} write;
+	struct nvg_logical_to_mpidr_channel_read_t {
+		uint32_t mpidr			: 32;
+		uint32_t reserved_63_32	: 32;
+    } read;
+} nvg_logical_to_mpidr_channel_t;
+
+typedef union
+{
+	uint64_t flat;
+	struct nvg_is_sc7_allowed_channel_t {
+		uint32_t is_sc7_allowed : 1;
+		uint32_t reserved_31_1	: 31;
+		uint32_t reserved_63_32 : 32;
+	} bits;
+} nvg_is_sc7_allowed_channel_t;
+
+typedef union
+{
+	uint64_t flat;
+	struct nvg_core_online_channel_t {
+		uint32_t core_id		: 4;
+		uint32_t reserved_31_4	: 28;
+		uint32_t reserved_63_32 : 32;
+	} bits;
+} nvg_core_online_channel_t;
+
+typedef union
+{
+	uint64_t flat;
+	struct nvg_cc3_control_channel_t {
+		uint32_t freq_req		: 9;
+		uint32_t reserved_30_9	: 22;
+		uint32_t enable			: 1;
+		uint32_t reserved_63_32 : 32;
+	} bits;
+} nvg_cc3_control_channel_t;
+
+typedef enum {
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_ALL				 =	0 ,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_NVDEC				 =	1 ,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_WPR1				 =	2 ,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_WPR2				 =	3 ,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_TSECA				 =	4 ,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_TSECB				 =	5 ,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_BPMP				 =	6 ,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_APE				 =	7 ,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_SPE				 =	8 ,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_SCE				 =	9 ,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_APR				 =	10,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_TZRAM				 =	11,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_IPC_SE_TSEC		 =	12,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_BPMP_TO_RCE		 =	13,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_BPMP_TO_MCE		 =	14,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_SE_SC7				 =	15,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_BPMP_TO_SPE		 =	16,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_RCE				 =	17,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_CPU_TZ_TO_BPMP		 =	18,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_VM_ENCR1			 =	19,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_CPU_NS_TO_BPMP		 =	20,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_OEM_SC7			 =	21,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_IPC_SE_SPE_SCE_BPMP =	22,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_SC7_RESUME_FW		 =	23,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_CAMERA_TASKLIST	 =	24,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_XUSB				 =	25,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_CV					 =	26,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_VM_ENCR2			 =	27,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_HYPERVISOR_SW		 =	28,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_SMMU_PAGETABLES	 =	29,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_30					 =	30,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_31					 =	31,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_TZ_DRAM			 =	32,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_NVLINK				 =	33,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_SBS				 =	34,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_VPR				 =	35,
+	TEGRA_NVG_CHANNEL_UPDATE_GSC_LAST_INDEX,
+} tegra_nvg_channel_update_gsc_gsc_enum_t;
+
+typedef union
+{
+	uint64_t flat;
+	struct nvg_update_ccplex_gsc_channel_t {
+		uint32_t gsc_enum		: 16;
+		uint32_t reserved_31_16 : 16;
+		uint32_t reserved_63_32 : 32;
+	} bits;
+} nvg_update_ccplex_gsc_channel_t;
+
+typedef union
+{
+	uint64_t flat;
+	struct nvg_security_config_channel_t {
+		uint32_t strict_checking_enabled 	: 1;
+		uint32_t strict_checking_locked		: 1;
+		uint32_t reserved_31_2			 	: 30;
+		uint32_t reserved_63_32			 	: 32;
+	} bits;
+} nvg_security_config_t;
+
+typedef union
+{
+	uint64_t flat;
+	struct nvg_shutdown_channel_t {
+		uint32_t reboot			: 1;
+		uint32_t reserved_31_1	: 31;
+		uint32_t reserved_63_32 : 32;
+	} bits;
+} nvg_shutdown_t;
+
+typedef union
+{
+	uint64_t flat;
+	struct nvg_debug_config_channel_t {
+		uint32_t enter_debug_state_on_mca : 1;
+		uint32_t reserved_31_1            : 31;
+		uint32_t reserved_63_32           : 32;
+	} bits;
+} nvg_debug_config_t;
+
+extern nvg_debug_config_t nvg_debug_config;
+
+#endif
diff --git a/include/soc/tegra/common.h b/include/soc/tegra/common.h
index 8ec1ac07fc85..43d30afc6a06 100644
--- a/include/soc/tegra/common.h
+++ b/include/soc/tegra/common.h
@@ -11,6 +11,7 @@
 
 struct device;
 
+
 /**
  * Tegra SoC core device OPP table configuration
  *
@@ -22,6 +23,7 @@ struct tegra_core_opp_params {
 
 #ifdef CONFIG_ARCH_TEGRA
 bool soc_is_tegra(void);
+bool soc_is_tegra186_n_later(void);
 
 int devm_tegra_core_dev_init_opp_table(struct device *dev,
 				       struct tegra_core_opp_params *params);
diff --git a/include/soc/tegra/fuse.h b/include/soc/tegra/fuse.h
index f97e18a4da41..01df707ef0cf 100644
--- a/include/soc/tegra/fuse.h
+++ b/include/soc/tegra/fuse.h
@@ -36,6 +36,8 @@
 
 #ifndef __ASSEMBLY__
 
+bool is_tegra_hypervisor_mode(void);
+
 enum tegra_revision {
 	TEGRA_REVISION_UNKNOWN = 0,
 	TEGRA_REVISION_A01,
@@ -106,6 +108,29 @@ enum tegra_ucm {
 	TEGRA_UCM2,
 };
 
+int tegra_get_platform(void);
+
+__weak bool tegra_platform_is_qt(void)
+{
+	return tegra_get_platform() == TEGRA_PLATFORM_QT;
+}
+
+__weak bool tegra_platform_is_sim(void)
+{
+	return tegra_get_platform() == TEGRA_PLATFORM_VDK;
+}
+
+__weak bool tegra_platform_is_fpga(void)
+{
+	return tegra_get_platform() == TEGRA_PLATFORM_FPGA;
+}
+
+__weak bool tegra_platform_is_silicon(void)
+{
+	return tegra_get_platform() == TEGRA_PLATFORM_SILICON;
+}
+
+
 /* wrappers for the old fuse.h names */
 #define soc_process_id core_process_id
 
diff --git a/kernel/dma/coherent.c b/kernel/dma/coherent.c
index ff5683a57f77..425b70e3c83d 100644
--- a/kernel/dma/coherent.c
+++ b/kernel/dma/coherent.c
@@ -7,19 +7,512 @@
 #include <linux/slab.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
+#include <linux/dma-attrs.h>
+#include <linux/dma-contiguous.h>
 #include <linux/dma-direct.h>
 #include <linux/dma-map-ops.h>
+#include <asm-generic/dma-coherent.h>
+
+#ifdef CONFIG_ARM_DMA_IOMMU_ALIGNMENT
+#define DMA_BUF_ALIGNMENT CONFIG_ARM_DMA_IOMMU_ALIGNMENT
+#else
+#define DMA_BUF_ALIGNMENT 8
+#endif
 
 struct dma_coherent_mem {
 	void		*virt_base;
 	dma_addr_t	device_base;
 	unsigned long	pfn_base;
 	int		size;
+	int		flags;
+	unsigned long	alloc_shift;
 	unsigned long	*bitmap;
 	spinlock_t	spinlock;
 	bool		use_dev_dma_pfn_offset;
 };
 
+static inline struct page **kvzalloc_pages(u32 count)
+{
+	if (count * sizeof(struct page *) <= PAGE_SIZE)
+		return kzalloc(count * sizeof(struct page *), GFP_KERNEL);
+	else
+		return vzalloc(count * sizeof(struct page *));
+}
+
+#define RESIZE_MAGIC 0xC11A900d
+struct heap_info {
+	int magic;
+	char *name;
+	/* number of chunks memory to manage in */
+	unsigned int num_chunks;
+	/* dev to manage cma/coherent memory allocs, if resize allowed */
+	struct device dev;
+	/* device to allocate memory from cma */
+	struct device *cma_dev;
+	/* lock to synchronise heap resizing */
+	struct mutex resize_lock;
+	/* CMA chunk size if resize supported */
+	size_t cma_chunk_size;
+	/* heap current base */
+	phys_addr_t curr_base;
+	/* heap current allocated memory in bytes */
+	size_t curr_used;
+	/* heap current length */
+	size_t curr_len;
+	/* heap lowest base */
+	phys_addr_t cma_base;
+	/* heap max length */
+	size_t cma_len;
+	size_t rem_chunk_size;
+	struct dentry *dma_debug_root;
+	int (*update_resize_cfg)(phys_addr_t , size_t);
+	/* The timer used to wakeup the shrink thread */
+	struct timer_list shrink_timer;
+	/* Pointer to the current shrink thread for this resizable heap */
+	struct task_struct *task;
+	unsigned long shrink_interval;
+	size_t floor_size;
+};
+
+/* retval: !0 on success, 0 on failure */
+static int dma_alloc_from_coherent_dev_at(struct device *dev, ssize_t size,
+				       dma_addr_t *dma_handle, void **ret,
+				       unsigned long attrs, ulong start)
+{
+	struct dma_coherent_mem *mem;
+	int order;
+	unsigned long flags;
+	int pageno, i = 0;
+	int dma_memory_map = 0;
+	unsigned int count;
+	unsigned int alloc_size;
+	unsigned long align;
+	struct page **pages = NULL;
+
+	if (!dev)
+		return 0;
+	mem = dev->dma_mem;
+	if (!mem)
+		return 0;
+
+	order = get_order(size << PAGE_SHIFT >> mem->alloc_shift);
+	if (dma_get_attr(DMA_ATTR_ALLOC_EXACT_SIZE, attrs))
+		count = ALIGN(size, 1 << mem->alloc_shift) >> mem->alloc_shift;
+	else
+		count = 1 << order;
+
+	if (!count)
+		return 0;
+
+	if ((mem->flags & DMA_MEMORY_NOMAP) &&
+	    dma_get_attr(DMA_ATTR_ALLOC_SINGLE_PAGES, attrs)) {
+		alloc_size = 1;
+		pages = kvzalloc_pages(count);
+		if (!pages)
+			return 0;
+	} else {
+		alloc_size = count;
+	}
+
+	*dma_handle = DMA_ERROR_CODE;
+	*ret = NULL;
+	spin_lock_irqsave(&mem->spinlock, flags);
+
+	if (unlikely(size > (mem->size << mem->alloc_shift)))
+		goto err;
+
+	if ((mem->flags & DMA_MEMORY_NOMAP) &&
+	    dma_get_attr(DMA_ATTR_ALLOC_SINGLE_PAGES, attrs)) {
+		align = 0;
+	} else  {
+		if (order > DMA_BUF_ALIGNMENT)
+			align = (1 << DMA_BUF_ALIGNMENT) - 1;
+		else
+			align = (1 << order) - 1;
+	}
+
+	while (count) {
+		pageno = bitmap_find_next_zero_area(mem->bitmap, mem->size,
+				start, alloc_size, align);
+
+		if (pageno >= mem->size)
+			goto err;
+
+		count -= alloc_size;
+		if (pages)
+			pages[i++] = pfn_to_page(mem->pfn_base + pageno);
+		bitmap_set(mem->bitmap, pageno, alloc_size);
+	}
+
+	/*
+	 * Memory was found in the per-device area.
+	 */
+	*dma_handle = mem->device_base + (pageno << mem->alloc_shift);
+	if (!(mem->flags & DMA_MEMORY_NOMAP)) {
+		*ret = mem->virt_base + (pageno << mem->alloc_shift);
+		dma_memory_map = (mem->flags & DMA_MEMORY_MAP);
+	} else if (dma_get_attr(DMA_ATTR_ALLOC_SINGLE_PAGES, attrs)) {
+		*ret = pages;
+	}
+	spin_unlock_irqrestore(&mem->spinlock, flags);
+	if (mem->flags & DMA_MEMORY_NOMAP)
+		/* Do nothing */;
+	else if (dma_memory_map)
+		memset(*ret, 0, size);
+	else if (*ret)
+		memset_io(*ret, 0, size);
+
+	return 1;
+
+err:
+	while (i--)
+		bitmap_clear(mem->bitmap, page_to_pfn(pages[i]) -
+					mem->pfn_base, alloc_size);
+	spin_unlock_irqrestore(&mem->spinlock, flags);
+	kvfree(pages);
+	/*
+	 * In the case where the allocation can not be satisfied from the
+	 * per-device area, try to fall back to generic memory if the
+	 * constraints allow it.
+	 */
+	return mem->flags & DMA_MEMORY_EXCLUSIVE;
+}
+
+/**
+ * dma_release_from_coherent_dev() - try to free the memory allocated from
+ * per-device coherent memory pool
+ * @dev:	device from which the memory was allocated
+ * @size:	size of the memory area to free
+ * @vaddr:	virtual address of allocated pages
+ * @attrs:	DMA Attribute
+ *
+ * This checks whether the memory was allocated from the per-device
+ * coherent memory pool and if so, releases that memory.
+ *
+ * Returns 1 if we correctly released the memory, or 0 if
+ * dma_release_coherent_attr() should proceed with releasing memory from
+ * generic pools.
+ */
+int dma_release_from_coherent_dev(struct device *dev, size_t size, void *vaddr,
+				unsigned long attrs)
+{
+	struct dma_coherent_mem *mem = dev ? dev->dma_mem : NULL;
+	void *mem_addr;
+	unsigned int count;
+	unsigned int pageno;
+	unsigned long flags;
+
+	if (!mem)
+		return 0;
+
+	if ((mem->flags & DMA_MEMORY_NOMAP) &&
+	    dma_get_attr(DMA_ATTR_ALLOC_SINGLE_PAGES, attrs)) {
+		struct page **pages = vaddr;
+		int i;
+
+		spin_lock_irqsave(&mem->spinlock, flags);
+		for (i = 0; i < (size >> PAGE_SHIFT); i++) {
+			pageno = page_to_pfn(pages[i]) - mem->pfn_base;
+			if (WARN_ONCE(pageno > mem->size,
+				"invalid pageno:%d\n", pageno))
+				continue;
+			bitmap_clear(mem->bitmap, pageno, 1);
+		}
+		spin_unlock_irqrestore(&mem->spinlock, flags);
+		kvfree(pages);
+		return 1;
+	}
+
+	if (mem->flags & DMA_MEMORY_NOMAP)
+		mem_addr =  (void *)(uintptr_t)mem->device_base;
+	else
+		mem_addr =  mem->virt_base;
+
+	if (mem && vaddr >= mem_addr &&
+	    vaddr - mem_addr < mem->size << PAGE_SHIFT) {
+
+		unsigned long flags;
+
+		pageno = (vaddr - mem_addr) >> mem->alloc_shift;
+		if (DMA_ATTR_ALLOC_EXACT_SIZE & attrs)
+			count = PAGE_ALIGN(size) >> PAGE_SHIFT;
+		else
+			count = 1 << get_order(size);
+
+		spin_lock_irqsave(&mem->spinlock, flags);
+		bitmap_clear(mem->bitmap, pageno, count);
+		spin_unlock_irqrestore(&mem->spinlock, flags);
+
+		return 1;
+	}
+	return 0;
+}
+
+static void get_first_and_last_idx(struct heap_info *h,
+				   int *first_alloc_idx, int *last_alloc_idx)
+{
+	if (!h->curr_len) {
+		*first_alloc_idx = -1;
+		*last_alloc_idx = h->num_chunks;
+	} else {
+		*first_alloc_idx = div_u64(h->curr_base - h->cma_base,
+					   h->cma_chunk_size);
+		*last_alloc_idx = div_u64(h->curr_base - h->cma_base +
+					  h->curr_len + h->cma_chunk_size -
+					  h->rem_chunk_size,
+					  h->cma_chunk_size) - 1;
+	}
+}
+
+static void shrink_resizable_heap(struct heap_info *h);
+static int heap_resize_locked(struct heap_info *h, bool skip_vpr_config);
+
+static void update_alloc_range(struct heap_info *h)
+{
+	if (!h->curr_len)
+		h->dev.dma_mem->size = 0;
+	else
+		h->dev.dma_mem->size = (h->curr_base - h->cma_base +
+					h->curr_len) >> PAGE_SHIFT;
+}
+
+static phys_addr_t alloc_from_contiguous_heap(
+				struct heap_info *h,
+				phys_addr_t base, size_t len)
+{
+	size_t count;
+	struct page *page;
+	unsigned long order;
+
+	dev_dbg(h->cma_dev, "req at base (%pa) size (0x%zx)\n",
+		&base, len);
+	order = get_order(len);
+	count = PAGE_ALIGN(len) >> PAGE_SHIFT;
+	page = dma_alloc_at_from_contiguous(h->cma_dev, count,
+		order, base, true);
+	if (!page) {
+		dev_err(h->cma_dev, "dma_alloc_at_from_contiguous failed\n");
+		goto dma_alloc_err;
+	}
+
+	base = page_to_phys(page);
+	dev_dbg(h->cma_dev, "allocated at base (%pa) size (0x%zx)\n",
+		&base, len);
+	BUG_ON(base < h->cma_base ||
+		base - h->cma_base + len > h->cma_len);
+	return base;
+
+dma_alloc_err:
+	return DMA_ERROR_CODE;
+}
+
+static void release_from_contiguous_heap(struct heap_info *h, phys_addr_t base,
+		size_t len);
+static int update_vpr_config(struct heap_info *h);
+#define RESIZE_DEFAULT_SHRINK_AGE 3
+
+static bool shrink_chunk_locked(struct heap_info *h, int idx)
+{
+	size_t chunk_size;
+	int resize_err;
+	void *ret = NULL;
+	dma_addr_t dev_base;
+	unsigned long attrs = DMA_ATTR_ALLOC_EXACT_SIZE;
+
+	/* check if entire chunk is free */
+	chunk_size = (idx == h->num_chunks - 1) ? h->rem_chunk_size :
+						  h->cma_chunk_size;
+	resize_err = dma_alloc_from_coherent_dev_at(&h->dev,
+				chunk_size, &dev_base, &ret, attrs,
+				idx * h->cma_chunk_size >> PAGE_SHIFT);
+	if (!resize_err) {
+		goto out;
+	} else if (dev_base != h->cma_base + idx * h->cma_chunk_size) {
+		resize_err = dma_release_from_coherent_dev(
+				&h->dev, chunk_size,
+				(void *)(uintptr_t)dev_base, attrs);
+		BUG_ON(!resize_err);
+		goto out;
+	} else {
+		dev_dbg(&h->dev,
+			"prep to remove chunk b=%pa, s=0x%zx\n",
+			&dev_base, chunk_size);
+		resize_err = dma_release_from_coherent_dev(
+				&h->dev, chunk_size,
+				(void *)(uintptr_t)dev_base, attrs);
+		BUG_ON(!resize_err);
+		if (!resize_err) {
+			dev_err(&h->dev, "failed to rel mem\n");
+			goto out;
+		}
+
+		/* Handle VPR configuration updates */
+		if (h->update_resize_cfg) {
+			phys_addr_t new_base = h->curr_base;
+			size_t new_len = h->curr_len - chunk_size;
+			if (h->curr_base == dev_base)
+				new_base += chunk_size;
+			dev_dbg(&h->dev, "update vpr base to %pa, size=%zx\n",
+				&new_base, new_len);
+			resize_err =
+				h->update_resize_cfg(new_base, new_len);
+			if (resize_err) {
+				dev_err(&h->dev,
+					"update resize failed\n");
+				goto out;
+			}
+		}
+
+		if (h->curr_base == dev_base)
+			h->curr_base += chunk_size;
+		h->curr_len -= chunk_size;
+		update_alloc_range(h);
+		release_from_contiguous_heap(h, dev_base, chunk_size);
+		dev_dbg(&h->dev, "removed chunk b=%pa, s=0x%zx"
+			" new heap b=%pa, s=0x%zx\n", &dev_base,
+			chunk_size, &h->curr_base, h->curr_len);
+		return true;
+	}
+out:
+	return false;
+}
+
+static void shrink_resizable_heap(struct heap_info *h)
+{
+	bool unlock = false;
+	int first_alloc_idx, last_alloc_idx;
+
+check_next_chunk:
+	if (unlock) {
+		mutex_unlock(&h->resize_lock);
+		cond_resched();
+	}
+	mutex_lock(&h->resize_lock);
+	unlock = true;
+	if (h->curr_len <= h->floor_size)
+		goto out_unlock;
+	get_first_and_last_idx(h, &first_alloc_idx, &last_alloc_idx);
+	/* All chunks are free. Exit. */
+	if (first_alloc_idx == -1)
+		goto out_unlock;
+	if (shrink_chunk_locked(h, first_alloc_idx))
+		goto check_next_chunk;
+	/* Only one chunk is in use. */
+	if (first_alloc_idx == last_alloc_idx)
+		goto out_unlock;
+	if (shrink_chunk_locked(h, last_alloc_idx))
+		goto check_next_chunk;
+
+out_unlock:
+	mutex_unlock(&h->resize_lock);
+}
+
+static int heap_resize_locked(struct heap_info *h, bool skip_vpr_config)
+{
+	phys_addr_t base = -1;
+	size_t len = h->cma_chunk_size;
+	phys_addr_t prev_base = h->curr_base;
+	size_t prev_len = h->curr_len;
+	int alloc_at_idx = 0;
+	int first_alloc_idx;
+	int last_alloc_idx;
+	phys_addr_t start_addr = h->cma_base;
+
+	get_first_and_last_idx(h, &first_alloc_idx, &last_alloc_idx);
+	pr_debug("req resize, fi=%d,li=%d\n", first_alloc_idx, last_alloc_idx);
+
+	/* All chunks are in use. Can't grow it. */
+	if (first_alloc_idx == 0 && last_alloc_idx == h->num_chunks - 1)
+		return -ENOMEM;
+
+	/* All chunks are free. Attempt to allocate the first chunk. */
+	if (first_alloc_idx == -1) {
+		base = alloc_from_contiguous_heap(h, start_addr, len);
+		if (base == start_addr)
+			goto alloc_success;
+		BUG_ON(!dma_mapping_error(h->cma_dev, base));
+	}
+
+	/* Free chunk before previously allocated chunk. Attempt
+	 * to allocate only immediate previous chunk.
+	 */
+	if (first_alloc_idx > 0) {
+		alloc_at_idx = first_alloc_idx - 1;
+		start_addr = alloc_at_idx * h->cma_chunk_size + h->cma_base;
+		base = alloc_from_contiguous_heap(h, start_addr, len);
+		if (base == start_addr)
+			goto alloc_success;
+		BUG_ON(!dma_mapping_error(h->cma_dev, base));
+	}
+
+	/* Free chunk after previously allocated chunk. */
+	if (last_alloc_idx < h->num_chunks - 1) {
+		alloc_at_idx = last_alloc_idx + 1;
+		len = (alloc_at_idx == h->num_chunks - 1) ?
+				h->rem_chunk_size : h->cma_chunk_size;
+		start_addr = alloc_at_idx * h->cma_chunk_size + h->cma_base;
+		base = alloc_from_contiguous_heap(h, start_addr, len);
+		if (base == start_addr)
+			goto alloc_success;
+		BUG_ON(!dma_mapping_error(h->cma_dev, base));
+	}
+
+	if (dma_mapping_error(h->cma_dev, base))
+		dev_err(&h->dev,
+		"Failed to allocate contiguous memory on heap grow req\n");
+
+	return -ENOMEM;
+
+alloc_success:
+	if (!h->curr_len || h->curr_base > base)
+		h->curr_base = base;
+	h->curr_len += len;
+
+	if (!skip_vpr_config && update_vpr_config(h))
+		goto fail_update;
+
+	dev_dbg(&h->dev,
+		"grow heap base from=%pa to=%pa,"
+		" len from=0x%zx to=0x%zx\n",
+		&prev_base, &h->curr_base, prev_len, h->curr_len);
+	return 0;
+
+fail_update:
+	release_from_contiguous_heap(h, base, len);
+	h->curr_base = prev_base;
+	h->curr_len = prev_len;
+	return -ENOMEM;
+}
+
+static void release_from_contiguous_heap(
+				struct heap_info *h,
+				phys_addr_t base, size_t len)
+{
+	struct page *page = phys_to_page(base);
+	size_t count = PAGE_ALIGN(len) >> PAGE_SHIFT;
+
+	dma_release_from_contiguous(h->cma_dev, page, count);
+	dev_dbg(h->cma_dev, "released at base (%pa) size (0x%zx)\n",
+		&base, len);
+}
+
+static int update_vpr_config(struct heap_info *h)
+{
+	/* Handle VPR configuration updates*/
+	if (h->update_resize_cfg) {
+		int err = h->update_resize_cfg(h->curr_base, h->curr_len);
+		if (err) {
+			dev_err(&h->dev, "Failed to update heap resize\n");
+			return err;
+		}
+		dev_dbg(&h->dev, "update vpr base to %pa, size=%zx\n",
+			&h->curr_base, h->curr_len);
+	}
+
+	update_alloc_range(h);
+	return 0;
+}
+
 static inline struct dma_coherent_mem *dev_get_coherent_memory(struct device *dev)
 {
 	if (dev && dev->dma_mem)
@@ -35,6 +528,72 @@ static inline dma_addr_t dma_get_device_base(struct device *dev,
 	return mem->device_base;
 }
 
+int dma_set_resizable_heap_floor_size(struct device *dev, size_t floor_size)
+{
+	int ret = 0;
+	struct heap_info *h = NULL;
+	phys_addr_t orig_base, prev_base, left_chunks_base, right_chunks_base;
+	size_t orig_len, prev_len, left_chunks_len, right_chunks_len;
+
+	if (!dma_is_coherent_dev(dev))
+		return -ENODEV;
+
+	h = dev_get_drvdata(dev);
+	if (!h)
+		return -ENOENT;
+
+	mutex_lock(&h->resize_lock);
+	orig_base = h->curr_base;
+	orig_len = h->curr_len;
+	right_chunks_base = h->curr_base + h->curr_len;
+	left_chunks_len = right_chunks_len = 0;
+
+	h->floor_size = floor_size > h->cma_len ? h->cma_len : floor_size;
+	while (h->curr_len < h->floor_size) {
+		prev_base = h->curr_base;
+		prev_len = h->curr_len;
+
+		ret = heap_resize_locked(h, true);
+		if (ret)
+			goto fail_set_floor;
+
+		if (h->curr_base < prev_base) {
+			left_chunks_base = h->curr_base;
+			left_chunks_len += (h->curr_len - prev_len);
+		} else {
+			right_chunks_len += (h->curr_len - prev_len);
+		}
+	}
+
+	ret = update_vpr_config(h);
+	if (!ret) {
+		dev_dbg(&h->dev,
+			"grow heap base from=%pa to=%pa,"
+			" len from=0x%zx to=0x%zx\n",
+			&orig_base, &h->curr_base, orig_len, h->curr_len);
+		goto success_set_floor;
+	}
+
+fail_set_floor:
+	if (left_chunks_len != 0)
+		release_from_contiguous_heap(h, left_chunks_base,
+				left_chunks_len);
+	if (right_chunks_len != 0)
+		release_from_contiguous_heap(h, right_chunks_base,
+				right_chunks_len);
+	h->curr_base = orig_base;
+	h->curr_len = orig_len;
+
+success_set_floor:
+	if (h->task)
+		mod_timer(&h->shrink_timer, jiffies + h->shrink_interval);
+	mutex_unlock(&h->resize_lock);
+	if (!h->task)
+		shrink_resizable_heap(h);
+	return ret;
+}
+EXPORT_SYMBOL(dma_set_resizable_heap_floor_size);
+
 static struct dma_coherent_mem *dma_init_coherent_memory(phys_addr_t phys_addr,
 		dma_addr_t device_addr, size_t size, bool use_dma_pfn_offset)
 {
@@ -97,6 +656,94 @@ static int dma_assign_coherent_memory(struct device *dev,
 	return 0;
 }
 
+#ifdef CONFIG_HAVE_GENERIC_DMA_COHERENT
+int dma_declare_coherent_resizable_cma_memory(struct device *dev,
+					struct dma_declare_info *dma_info)
+{
+#ifdef CONFIG_DMA_CMA
+	int err = 0;
+	struct heap_info *heap_info = NULL;
+	struct dma_contiguous_stats stats;
+
+	if (!dev || !dma_info || !dma_info->name || !dma_info->cma_dev)
+		return -EINVAL;
+
+	heap_info = kzalloc(sizeof(*heap_info), GFP_KERNEL);
+	if (!heap_info)
+		return -ENOMEM;
+
+	heap_info->magic = RESIZE_MAGIC;
+	heap_info->name = kmalloc(strlen(dma_info->name) + 1, GFP_KERNEL);
+	if (!heap_info->name) {
+		kfree(heap_info);
+		return -ENOMEM;
+	}
+
+	dma_get_contiguous_stats(dma_info->cma_dev, &stats);
+	pr_info("resizable heap=%s, base=%pa, size=0x%zx\n",
+		dma_info->name, &stats.base, stats.size);
+	strcpy(heap_info->name, dma_info->name);
+	dev_set_name(dev, "dma-%s", heap_info->name);
+	heap_info->cma_dev = dma_info->cma_dev;
+	heap_info->cma_chunk_size = dma_info->size ? : stats.size;
+	heap_info->cma_base = stats.base;
+	heap_info->cma_len = stats.size;
+	heap_info->curr_base = stats.base;
+	dev_set_name(heap_info->cma_dev, "cma-%s-heap", heap_info->name);
+	mutex_init(&heap_info->resize_lock);
+
+	if (heap_info->cma_len < heap_info->cma_chunk_size) {
+		dev_err(dev, "error cma_len(0x%zx) < cma_chunk_size(0x%zx)\n",
+			heap_info->cma_len, heap_info->cma_chunk_size);
+		err = -EINVAL;
+		goto fail;
+	}
+
+	heap_info->num_chunks = div64_u64_rem(heap_info->cma_len,
+		(u64)heap_info->cma_chunk_size, (u64 *)&heap_info->rem_chunk_size);
+	if (heap_info->rem_chunk_size) {
+		heap_info->num_chunks++;
+		dev_info(dev, "heap size is not multiple of cma_chunk_size "
+			"heap_info->num_chunks (%d) rem_chunk_size(0x%zx)\n",
+			heap_info->num_chunks, heap_info->rem_chunk_size);
+	} else
+		heap_info->rem_chunk_size = heap_info->cma_chunk_size;
+
+	dev_set_name(&heap_info->dev, "%s-heap", heap_info->name);
+
+	if (dma_info->notifier.ops)
+		heap_info->update_resize_cfg =
+			dma_info->notifier.ops->resize;
+
+	dev_set_drvdata(dev, heap_info);
+	dma_debugfs_init(dev, heap_info);
+
+	if (declare_coherent_heap(&heap_info->dev,
+				  heap_info->cma_base, heap_info->cma_len,
+				  (dma_info->notifier.ops &&
+					dma_info->notifier.ops->resize) ? 0 : 1))
+		goto declare_fail;
+	heap_info->dev.dma_mem->size = 0;
+	heap_info->shrink_interval = HZ * RESIZE_DEFAULT_SHRINK_AGE;
+	kthread_run(shrink_thread, heap_info, "%s-shrink_thread",
+		heap_info->name);
+
+	if (dma_info->notifier.ops && dma_info->notifier.ops->resize)
+		dma_contiguous_enable_replace_pages(dma_info->cma_dev);
+	pr_info("resizable cma heap=%s create successful", heap_info->name);
+	return 0;
+declare_fail:
+	kfree(heap_info->name);
+fail:
+	kfree(heap_info);
+	return err;
+#else
+	return -EINVAL;
+#endif
+}
+EXPORT_SYMBOL(dma_declare_coherent_resizable_cma_memory);
+#endif
+
 /*
  * Declare a region of memory to be handed out by dma_alloc_coherent() when it
  * is asked for coherent memory for this device.  This shall only be used
diff --git a/kernel/dma/contiguous.c b/kernel/dma/contiguous.c
index f005c66f378c..6e6fd24a958d 100644
--- a/kernel/dma/contiguous.c
+++ b/kernel/dma/contiguous.c
@@ -316,6 +316,17 @@ struct page *dma_alloc_from_contiguous(struct device *dev, size_t count,
 	return cma_alloc(dev_get_cma_area(dev), count, align, no_warn);
 }
 
+struct page *dma_alloc_at_from_contiguous(struct device *dev, int count,
+				       unsigned int align, phys_addr_t at_addr,
+				       bool map_non_cached)
+{
+	if (align > CONFIG_CMA_ALIGNMENT)
+		align = CONFIG_CMA_ALIGNMENT;
+
+	return cma_alloc_at(dev_get_cma_area(dev), count, align, at_addr,
+			    map_non_cached);
+}
+
 /**
  * dma_release_from_contiguous() - release allocated pages
  * @dev:   Pointer to device for which the pages were allocated.
diff --git a/mm/cma.c b/mm/cma.c
index ac363f16d392..b55d1246fd64 100644
--- a/mm/cma.c
+++ b/mm/cma.c
@@ -21,6 +21,9 @@
 #endif
 #define CREATE_TRACE_POINTS
 
+#include <linux/buffer_head.h>
+#include <linux/delay.h>
+#include <linux/dma-contiguous.h>
 #include <linux/memblock.h>
 #include <linux/err.h>
 #include <linux/mm.h>
@@ -36,6 +39,58 @@
 #include "internal.h"
 #include "cma.h"
 
+static int __dma_update_pte(pte_t *pte, unsigned long addr,
+			    void *data)
+{
+	struct page *page = virt_to_page(addr);
+	pgprot_t prot = *(pgprot_t *)data;
+
+	set_pte_at(&init_mm, addr, pte, mk_pte(page, prot));
+	return 0;
+}
+
+static void __dma_clear_buffer(struct page *page, size_t size)
+{
+	void *ptr;
+	/*
+	 * Ensure that the allocated pages are zeroed, and that any data
+	 * lurking in the kernel direct-mapped region is invalidated.
+	 * The zeroing can be skipped for VPR resize as it is not
+	 * accessible by cpu for either read or write. Since VPR's
+	 * coherent device is the only device that has heap resize notifier
+	 * and that too when resize is enabled, the API
+	 * dma_contiguous_should_replace_page() would return true
+	 * if and only if the cma is VPR and the resize is enabled.
+	 */
+	ptr = page_address(page);
+	if (ptr) {
+		if (!dma_contiguous_should_replace_page(page))
+			memset(ptr, 0, size);
+		__dma_flush_area(ptr, size);
+		/* comment out as not present for arm64 */
+		/* outer_flush_range(__pa(ptr), __pa(ptr) + size);*/
+	}
+}
+
+static void __dma_remap(struct page *page, size_t size, pgprot_t prot)
+{
+	unsigned long start = (unsigned long) page_address(page);
+	unsigned end = start + size;
+	int err;
+
+	err = apply_to_page_range(&init_mm, start,
+		size, __dma_update_pte, &prot);
+	if (err)
+		pr_err("***%s: error=%d, pfn=%lx\n", __func__,
+			err, page_to_pfn(page));
+	dsb(sy);
+	flush_tlb_kernel_range(start, end);
+}
+
+#define MAX_REPLACE_DEV 16
+static struct device *replace_dev_list[MAX_REPLACE_DEV];
+static atomic_t replace_dev_count;
+
 struct cma cma_areas[MAX_CMA_AREAS];
 unsigned cma_area_count;
 static DEFINE_MUTEX(cma_mutex);
@@ -524,6 +579,107 @@ struct page *cma_alloc(struct cma *cma, unsigned long count,
 	return page;
 }
 
+struct page *cma_alloc_at(struct cma *cma, size_t count,
+				unsigned int align, phys_addr_t at_addr, bool map_non_cached)
+{
+	unsigned long mask, offset;
+	unsigned long pfn = -1;
+	unsigned long start = 0;
+	unsigned long bitmap_maxno, bitmap_no, bitmap_count;
+	struct page *page = NULL;
+	int ret;
+	unsigned long start_pfn = __phys_to_pfn(at_addr);
+	unsigned long flags;
+
+	if (!cma || !cma->count)
+		return NULL;
+
+	pr_debug("%s(cma %p, count %zu, align %d)\n", __func__, (void *)cma,
+		 count, align);
+
+	if (!count)
+		return NULL;
+
+	mask = cma_bitmap_aligned_mask(cma, align);
+	offset = cma_bitmap_aligned_offset(cma, align);
+	bitmap_maxno = cma_bitmap_maxno(cma);
+	bitmap_count = cma_bitmap_pages_to_bits(cma, count);
+
+	if (bitmap_count > bitmap_maxno)
+		return NULL;
+
+	if (start_pfn && start_pfn < cma->base_pfn)
+		return NULL;
+	start = start_pfn ? start_pfn - cma->base_pfn : start;
+
+	for (;;) {
+		unsigned long timeout = jiffies + msecs_to_jiffies(8000);
+		int retries = 0;
+
+		spin_lock_irqsave(&cma->lock, flags);
+		bitmap_no = bitmap_find_next_zero_area_off(cma->bitmap,
+				bitmap_maxno, start, bitmap_count, mask,
+				offset);
+		if (bitmap_no >= bitmap_maxno ||
+			(start_pfn && start != bitmap_no)) {
+			spin_unlock_irqrestore(&cma->lock, flags);
+			break;
+		}
+		bitmap_set(cma->bitmap, bitmap_no, bitmap_count);
+		/*
+		 * It's safe to drop the lock here. We've marked this region for
+		 * our exclusive use. If the migration fails we will take the
+		 * lock again and unmark it.
+		 */
+		spin_unlock_irqrestore(&cma->lock, flags);
+
+		pfn = cma->base_pfn + (bitmap_no << cma->order_per_bit);
+retry:
+		mutex_lock(&cma_mutex);
+		ret = alloc_contig_range(pfn, pfn + count, MIGRATE_CMA, GFP_KERNEL);
+		mutex_unlock(&cma_mutex);
+		if (ret == 0) {
+			page = pfn_to_page(pfn);
+			break;
+		}
+
+		cma_clear_bitmap(cma, pfn, count);
+		if (start_pfn && time_before(jiffies, timeout)) {
+			/* Possible migration contention from
+			 * __get_user_pages(). Retry after a bit of sleep.
+			 */
+			if (retries >= 5) {
+				msleep(retries > 10 ? 3 : 1);
+				invalidate_bh_lrus();
+			} else {
+				cond_resched();
+			}
+			retries++;
+			goto retry;
+		} else if (ret != -EBUSY || start_pfn) {
+			break;
+		}
+
+		pr_debug("%s(): memory range at %p is busy, retrying\n",
+			 __func__, pfn_to_page(pfn));
+		/* try again with a bit different memory target */
+		start = bitmap_no + mask + 1;
+	}
+
+	//trace_cma_alloc(pfn, page, count, align);
+
+	pr_debug("%s(): returned %p\n", __func__, page);
+	if (page) {
+		__dma_remap(page, count << PAGE_SHIFT,
+			pgprot_writecombine(PAGE_KERNEL));
+		__dma_clear_buffer(page, count << PAGE_SHIFT);
+		if(map_non_cached)
+			__dma_remap(page, count << PAGE_SHIFT,
+				pgprot_noncached(PAGE_KERNEL));
+	}
+	return page;
+}
+
 bool cma_pages_valid(struct cma *cma, const struct page *pages,
 		     unsigned long count)
 {
@@ -587,3 +743,83 @@ int cma_for_each_area(int (*it)(struct cma *cma, void *data), void *data)
 
 	return 0;
 }
+
+#ifdef CONFIG_DMA_CMA
+int dma_get_contiguous_stats(struct device *dev,
+			struct dma_contiguous_stats *stats)
+{
+	struct cma *cma = NULL;
+
+	if ((!dev) || !stats)
+		return -EINVAL;
+
+	if (dev->cma_area)
+		cma = dev->cma_area;
+
+	if (!cma)
+		return -EINVAL;
+
+	stats->size = (cma->count) << PAGE_SHIFT;
+	stats->base = (cma->base_pfn) << PAGE_SHIFT;
+
+	return 0;
+}
+
+#define MAX_REPLACE_DEV 16
+static struct device *replace_dev_list[MAX_REPLACE_DEV];
+static atomic_t replace_dev_count;
+
+bool dma_contiguous_should_replace_page(struct page *page)
+{
+	int i;
+	ulong pfn;
+	struct cma *cma;
+	struct device *dev;
+	int count = atomic_read(&replace_dev_count);
+
+	if (!page)
+		return false;
+	pfn = page_to_pfn(page);
+
+	for (i = 0; i < count; i++) {
+		dev = replace_dev_list[i];
+		if (!dev)
+			continue;
+		cma = dev->cma_area;
+		if (!cma)
+			continue;
+		if (pfn >= cma->base_pfn &&
+		    pfn < cma->base_pfn + cma->count)
+			return true;
+	}
+
+	return false;
+}
+
+/* Enable replacing pages during get_user_pages.
+ * any ref count on CMA page from get_user_pages
+ * makes the page not migratable and can cause
+ * CMA allocation failure. Enabling replace
+ * would force replacing the CMA pages with non-CMA
+ * pages during get_user_pages
+ */
+int dma_contiguous_enable_replace_pages(struct device *dev)
+{
+	int idx;
+	struct cma *cma;
+
+	if (!dev)
+		return -EINVAL;
+
+	idx = atomic_inc_return(&replace_dev_count);
+	if (idx > MAX_REPLACE_DEV)
+		return -EINVAL;
+	replace_dev_list[idx - 1] = dev;
+	cma = dev->cma_area;
+	if (cma) {
+		pr_info("enabled page replacement for spfn=%lx, epfn=%lx\n",
+			cma->base_pfn, cma->base_pfn + cma->count);
+	}
+	return 0;
+}
+#endif /* CONFIG_DMA_CMA */
-- 
2.34.1

